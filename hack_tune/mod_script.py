from tvm.script import ir as I
from tvm.script import tir as T
from tvm.script import relax as R
import tvm

metadata = tvm.ir.load_json("""{
  \"root\": 1, 
  \"nodes\": [
    {
      \"type_key\": \"\"
    }, 
    {
      \"type_key\": \"Map\", 
      \"keys\": [
        \"relax.expr.Constant\"
      ], 
      \"data\": [2]
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [3, 14, 25, 34]
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"13\", 
        \"data\": \"0\", 
        \"span\": \"0\", 
        \"struct_info_\": \"4\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"5\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"12\", 
        \"span\": \"0\", 
        \"struct_info_\": \"11\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [7, 8, 9, 10]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"24\", 
        \"data\": \"1\", 
        \"span\": \"0\", 
        \"struct_info_\": \"15\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"16\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"23\", 
        \"span\": \"0\", 
        \"struct_info_\": \"22\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [18, 19, 20, 21]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"33\", 
        \"data\": \"2\", 
        \"span\": \"0\", 
        \"struct_info_\": \"26\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"27\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"32\", 
        \"span\": \"0\", 
        \"struct_info_\": \"31\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [29, 30]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"160\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"42\", 
        \"data\": \"3\", 
        \"span\": \"0\", 
        \"struct_info_\": \"35\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"36\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"41\", 
        \"span\": \"0\", 
        \"struct_info_\": \"40\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [38, 39]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"128\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }
  ], 
  \"b64ndarrays\": [
    \"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\", 
    \"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\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAKAAAAAAAAAAgAIAAAAAAAAAAIA/+a1xPwUpZD+sZVc/GFlLPxH5Pz/vOzU/lhgrP2yGIT9QfRg/mvUPPwvoBz/PTQA/4UDyPrez5D6a6Nc+tNTLPsJtwD4ZqrU+l4CrPpvooT4C2pg+HE2QPqg6iD7Mm4A+ItRyPro+ZT7Ya1g+nFBMPrviQD6HGDY+1ugrPgZLIj7sNhk+0qQQPneNCD756QA+wGfzPRTK5T1o79g9zMzMPflXwT03h7Y9VVGsPa2toj0NlJk9wPyQPXjgiD1XOIE9s/tzPcFVZj1Ec1k9SUlNPYHNQT0q9jY9FbosPZIQIz1p8Rk94VQRPaozCT3ihgE9BJD0PMLh5jxx99k8FMbNPFFDwjxjZbc8EyOtPK1zozz7Tpo8Oa2RPBKHiTyd1YE8qCR1PCBuZzzxe1o8J0NOPGO5Qjzf1Dc8U4wtPArXIzzHrBo8wwUSPKzaCTyKJAI8rbn1O8j65zvCANs7isDOO8IvwzuaRLg7zfWtO6M6pDvOCps7iF6SO3Uuijunc4I7Dk92O82HaDvdhVs7Mz5PO2mmQzuetDg7jV8uO3OeJDsNaRs7grcSO3WCCjvwwgI7weT2OigV6TpQC9w6NbzPOlkdxDrmJLk6iMmuOoUCpTqCx5s6rhCTOqjWijpuEoM633p3OtmiaToTkVw6cDpQOoqURDptlTk6yTMvOtVmJTo1Jhw6GWoTOg8rCzobYgM6QRH4Odkw6jkhF905BbnQOQsMxTk+Bro5UJ6vOWHLpTkhhZw5scOTOaR/izn1sYM5Dah4OS6/ajmPnV057TdROdODRTlTdzo5DAkwOSUwJjlC5Bw5gB0UOW3UCzkIAgQ5PT/5OOpN6zhAJN44\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAIAAAAAAAAAAAAIAAAAAAAAAAIA/+DluP9avXT+sS04/Efk/PwalMj/gPSY/K7MaP5r1Dz/u9gU/zlP5PmAE6D6a6Nc+I+vIPhv4uj7//K0+m+ihPuqqlj4DNYw+CHmCPiLUcj42+GE+7UdSPnyuQz6HGDY+CXQpPj+wHT6QvRI+d40IPt8k/j3Vf+w9ZBTcPczMzD3HlL49eFmxPVcJpT0NlJk9bOqOPUz+hD0RhXc9wVVmPeNXVj1Adkc9GJ05PRW6LD0bvCA9SJMVPcswCz3ihgE9dxHxPNFU4DyowdA8TkPCPJHGtDyJOag8loucPDmtkTwJkIc8ME18PObIajzxe1o8tVBLPA4zPTxQEDA8CtcjPAZ3GDwu4Q08dwcEPK259TtFquQ7FcrUOwoExjuaRLg7gnmrO8yRnzuvfZQ7dS6KO3yWgDsNUm87erReOzM+TzvC2kA7DXczO1MBJzsNaRs72J4QO22UBjvwePo6KBXpOnXm2DpZ18k669O7Oo3Jrjr3pqI6C1yXOtnZjDpuEoM6ovFzOuMBYzokP1M6ipREOp3uNjpEOyo6omkeOhRqEzoBLgk6rE//OeSV7TkhF905k73NOdZ0vzn7KbI5YculOaBImjl1ko85pJqFOQ2oeDmMZGc54lNXOb9gSDlTdzo5KoUtORl5ITkmQxY5bdQLOSgfAjndLPI4jlzhOA==\"
  ], 
  \"attrs\": {\"tvm_version\": \"0.14.dev0\"}
}""")
# from tvm.script import ir as I
# from tvm.script import tir as T
# from tvm.script import relax as R

@I.ir_module
class Module:
    @T.prim_func(private=True)
    def add29(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] + B[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def add48(A: T.Buffer((), "float32"), T_add: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_add"):
            vi = T.axis.spatial(1, T.int64(0))
            T.reads(A[()])
            T.writes(T_add[()])
            T_add[()] = A[()] + T.float32(1)

    @T.prim_func(private=True)
    def argmax(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), A_red: T.Buffer((T.int64(1),), "int64")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1),), "int64")
        A_red_temp_v1 = T.alloc_buffer((T.int64(1),), "int32")
        for ax0, k1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("A_red_temp"):
                v_ax0, v_k1 = T.axis.remap("SR", [ax0, k1])
                T.reads(A[v_ax0, v_k1])
                T.writes(A_red_temp_v0[v_ax0], A_red_temp_v1[v_ax0])
                with T.init():
                    A_red_temp_v0[v_ax0] = T.int64(-1)
                    A_red_temp_v1[v_ax0] = -2147483648
                v_A_red_temp_v0: T.int64 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1] or A_red_temp_v1[v_ax0] == A[v_ax0, v_k1] and A_red_temp_v0[v_ax0] < v_k1, A_red_temp_v0[v_ax0], v_k1)
                v_A_red_temp_v1: T.int32 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1], A_red_temp_v1[v_ax0], A[v_ax0, v_k1])
                A_red_temp_v0[v_ax0] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0] = v_A_red_temp_v1
        for ax0 in range(T.int64(1)):
            with T.block("A_red"):
                v_ax0 = T.axis.spatial(T.int64(1), ax0)
                T.reads(A_red_temp_v0[v_ax0])
                T.writes(A_red[v_ax0])
                A_red[v_ax0] = A_red_temp_v0[v_ax0]

    @T.prim_func(private=True)
    def cast(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), compute: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(A[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = A[v_i0, v_i1]

    @T.prim_func(private=True)
    def concatenate(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(2048)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(768) <= v_ax2, B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate10(A: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(320) <= v_ax1, B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate11(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate12(A: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(77), T.int64(2048)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate13(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])
                T.writes(T_concat[v_ax0, v_ax1])
                T_concat[v_ax0, v_ax1] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def concatenate4(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate6(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate9(A: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def divide11(A: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((), "float32"), T_divide: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                T.writes(T_divide[v_ax0, v_ax1, v_ax2, v_ax3])
                T_divide[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] / B[()]

    @T.prim_func(private=True)
    def fused_broadcast_to1_strided_slice1_reshape12_cast3_multiply1_multiply2_tir_sin_tir_cos_concatenate1_strided_slice2_reshape13_strided_slice3_reshape13_concatenate1_cast4(inp_1: T.Buffer((), "int32"), param_0: T.Buffer((T.int64(1), T.int64(160)), "float32"), var_compute_intermediate: T.Buffer((T.int64(2), T.int64(320)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_broadcast_to_intermediate = T.alloc_buffer((T.int64(2),), "int32")
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(2),), "int32")
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1)), "int32")
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_compute_intermediate_3 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_concat_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320)))
        for ax0 in range(T.int64(2)):
            with T.block("T_broadcast_to"):
                v_ax0 = T.axis.spatial(T.int64(2), ax0)
                T.reads(inp_1[()])
                T.writes(var_T_broadcast_to_intermediate[v_ax0])
                var_T_broadcast_to_intermediate[v_ax0] = inp_1[()]
        for ax0 in range(T.int64(2)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0 = T.axis.spatial(T.int64(2), ax0)
                T.reads(var_T_broadcast_to_intermediate[v_ax0])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_broadcast_to_intermediate[v_ax0]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(2)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(2)]
        for i0, i1 in T.grid(T.int64(2), T.int64(1)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1])
                T.writes(var_compute_intermediate_1[v_i0, v_i1])
                var_compute_intermediate_1[v_i0, v_i1] = T.Cast("float32", var_T_reshape_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_1[v_ax0, T.int64(0)], param_0[T.int64(0), v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate_1[v_ax0, T.int64(0)] * param_0[T.int64(0), v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("compute_1"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_2[v_i0, v_i1])
                var_compute_intermediate_2[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0, i1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("compute_2"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_3[v_i0, v_i1])
                var_compute_intermediate_3[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_strided_slice_with_axes_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)])
                T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_strided_slice_with_axes_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)])
                T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_concat_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
        for i0, i1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("compute_3"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_concat_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_concat_intermediate_1[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_cast_reshape1(lv: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(lv[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = lv[v_i0, v_i1]
        for ax0 in range(T.int64(77)):
            with T.block("T_reshape"):
                v_ax0 = T.axis.spatial(T.int64(77), ax0)
                T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_conv2d10_add20_add21(lv2553: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(3), T.int64(3)), "float32"), lv2555: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv2562: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(2560), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2555[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2555[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d11_add20(lv2551: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(1), T.int64(1)), "float32"), lv2570: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv2551[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv2551[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(2560), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2570[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2570[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d12_add20_add21(lv3963: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_conv1_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv3965: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv3972: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1920), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3965[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3965[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d13_add20(lv3961: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv3980: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3961[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv3961[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1920), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3980[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3980[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d14_add26(lv4666: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4668: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4668[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4668[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d15_add12_add14(lv4672: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv4674: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4681: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1920), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4674[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4674[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d16_add12(lv4670: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv4689: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4670[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4670[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1920), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4689[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4689[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d17_add12_add14(lv4841: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4843: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4850: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4843[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4843[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d18_add12(lv4839: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv4858: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4839[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4839[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1280), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4858[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4858[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d19_add12_add14(lv5010: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_conv1_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5012: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5019: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(960), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5012[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5012[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d1_add7_add10_divide(lv62: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_conv2_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv64: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv48: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv64[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv64[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv48[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv48[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d1_add7_add9(lv50: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv52: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv59: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv52[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv52[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d20_add12(lv5008: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5027: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5008[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5008[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(960), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5027[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5027[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d21_add27(lv5177: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5179: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5179[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5179[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d22_add7_add9(lv5183: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5185: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5192: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(960), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5185[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5185[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d23_add7(lv5181: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5200: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5181[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5181[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(960), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5200[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5200[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d24_add7_add9(lv5206: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5208: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5215: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5208[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5208[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d25_add7(lv5204: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5223: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5204[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5204[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5223[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5223[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d26_add28(lv5251: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_conv_out_weight: T.Buffer((T.int64(4), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv5253: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5253[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5253[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d27_add30(lv: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), vae_post_quant_conv_weight: T.Buffer((T.int64(4), T.int64(4), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128), T.int64(4), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d28_add31(lv3: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), vae_decoder_conv_in_weight: T.Buffer((T.int64(512), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv5: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(4), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d29_add31(lv8: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_conv1_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv10: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d29_add31_add32_divide6(lv13: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv15: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv6[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv6[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d29_add31_add32_divide6_divide6(lv61: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_1_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv63: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv54: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_divide_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv54[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv54[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d2_add11(lv86: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_downsamplers_0_conv_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv88: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv88[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv88[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d30_add34(lv104: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv106: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(258), T.int64(258)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d30_add34_add35_divide7(lv114: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv116: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(258), T.int64(258)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv107[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv107[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d31_add36(lv144: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv146: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d32_add37(lv149: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv151: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d33_add37(lv164: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv166: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d33_add37_add38_divide8(lv154: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv156: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv160: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv160[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv160[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d34_add37(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv159: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv147[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv147[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(512), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d35_add39(lv187: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_2_upsamplers_0_conv_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv189: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d36_add40(lv192: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv1_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv194: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d37_add40(lv207: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_1_conv1_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv209: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d37_add40_add41_divide9(lv197: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv2_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv199: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), lv203: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv203[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv203[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d38_add40(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv202: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv190[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv190[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(256), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d39_add42_divide10_add43_tir_clip(lv231: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_conv_out_weight: T.Buffer((T.int64(3), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv233: T.Buffer((T.int64(1), T.int64(3), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(0.5)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + T.float32(0.5)
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.max(T.min(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3], T.float32(1)), T.float32(0))

    @T.prim_func(private=True)
    def fused_conv2d3_add12_add14(lv91: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv93: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv100: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv93[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv93[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d4_add12_add14(lv259: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv261: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv268: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv261[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv261[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d4_add12_add15_divide1(lv103: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv105: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv109: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv105[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv105[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv109[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv109[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d5_add12(lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv108: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv89[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv89[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(320), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv108[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv108[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d6_add19(lv422: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_downsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv424: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv424[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv424[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d7_add20_add21(lv427: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv429: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv436: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv429[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv429[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d8_add20_add21(lv1131: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv1133: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv1140: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv1133[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv1133[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d8_add20_add22_divide4(lv439: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv441: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv445: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv441[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv441[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv445[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv445[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d9_add20(lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv444: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv425[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv425[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv444[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv444[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d_add7(inp_0: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), unet_conv_in_weight: T.Buffer((T.int64(320), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv47: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(4), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(4), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv47[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv47[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_group_norm10_silu9(lv4839: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_norm1_weight: T.Buffer((T.int64(1280),), "float32"), unet_up_blocks_1_resnets_1_norm1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv4839[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4839[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(40), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(40), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm11_silu10(lv5008: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_1_resnets_2_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5008[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5008[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm12_silu11(lv5181: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5181[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(960), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5181[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(960), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(30), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(30), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm13_silu12(lv5204: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_up_blocks_2_resnets_1_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5204[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(640), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5204[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(640), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(20), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(20), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm14_silu13(lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_mid_block_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.814697265625e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm16_silu14(lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm17_silu15(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(512), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(512), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(16), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(16), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm18_silu16(lv152: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm19_silu17(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(256), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(256), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(8), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(8), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm1_silu2(lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv89[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv89[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm20_silu18(lv195: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_weight: T.Buffer((T.int64(128),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_bias: T.Buffer((T.int64(128),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        compute = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(128), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(128), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(4)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(4)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(4), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(4), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm2_silu3(lv101: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_norm2_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_1_resnets_0_norm2_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv101[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv101[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm4_silu4(lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv425[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv425[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm5_silu5(lv437: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(1280),), "float32"), unet_down_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv437[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv437[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm7_silu6(lv2551: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(2560),), "float32"), unet_up_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(2560),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv2551[((v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(2560) + v_ax0) % T.int64(2), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv2551[((v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(2560) + v_ax0) % T.int64(2), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(80)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(80)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(2560) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(80), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(2560) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(80), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm8_silu7(lv3961: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_0_resnets_2_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv3961[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv3961[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm9_silu8(lv4670: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv4670[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4670[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(60), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(60), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm_silu1(lv48: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv48[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(320), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv48[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(320), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(10), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(10), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_matmul10_add13_strided_slice7(lv95: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv96: T.Buffer((T.int64(1280), T.int64(640)), "float32"), unet_down_blocks_1_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(640),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(2), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(640)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(640), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv95[v_i0, v_k], lv96[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv95[v_i0, v_k] * lv96[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(640)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul11_add16(lv114: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv115: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_proj_in_bias: T.Buffer((T.int64(640),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv114[v_i0, v_i1, v_k], lv115[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv114[v_i0, v_i1, v_k] * lv115[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul11_add16_divide3_add17(lv139: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv140: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(640),), "float32"), lv117: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv139[v_i0, v_i1, v_k], lv140[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv139[v_i0, v_i1, v_k] * lv140[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv117[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv117[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul12_multiply5(lv126: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), lv133: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(4096)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv126[v_i0, v_i1, v_i2, v_k], lv133[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv126[v_i0, v_i1, v_i2, v_k] * lv133[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul15_multiply6(lv153: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), lv160: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv153[v_i0, v_i1, v_i2, v_k], lv160[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv153[v_i0, v_i1, v_i2, v_k] * lv160[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul17_add18(lv172: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv173: T.Buffer((T.int64(640), T.int64(5120)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(5120),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(5120)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(5120), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv172[v_i0, v_i1, v_k], lv173[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv172[v_i0, v_i1, v_k] * lv173[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul18_add16_add17(lv180: T.Buffer((T.int64(2), T.int64(4096), T.int64(2560)), "float32"), lv181: T.Buffer((T.int64(2560), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(640),), "float32"), lv171: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(2560)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv180[v_i0, v_i1, v_k], lv181[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv180[v_i0, v_i1, v_k] * lv181[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv171[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv171[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul19_add23(lv450: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv451: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_proj_in_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv450[v_i0, v_i1, v_k], lv451[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv450[v_i0, v_i1, v_k] * lv451[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul19_add23_divide5_add24(lv475: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv476: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(1280),), "float32"), lv453: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv475[v_i0, v_i1, v_k], lv476[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv475[v_i0, v_i1, v_k] * lv476[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv453[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv453[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul20_multiply8(lv462: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), lv469: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(1024)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv462[v_i0, v_i1, v_i2, v_k], lv469[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv462[v_i0, v_i1, v_i2, v_k] * lv469[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul23_multiply9(lv489: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), lv496: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv489[v_i0, v_i1, v_i2, v_k], lv496[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv489[v_i0, v_i1, v_i2, v_k] * lv496[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul25_add25(lv508: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv509: T.Buffer((T.int64(1280), T.int64(10240)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(10240),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(10240)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(10240)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(10240), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv508[v_i0, v_i1, v_k], lv509[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv508[v_i0, v_i1, v_k] * lv509[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(10240)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul26_add23_add24(lv516: T.Buffer((T.int64(2), T.int64(1024), T.int64(5120)), "float32"), lv517: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(1280),), "float32"), lv507: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(5120)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv516[v_i0, v_i1, v_k], lv517[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv516[v_i0, v_i1, v_k] * lv517[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv507[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv507[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul27_add33(lv23: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv24: T.Buffer((T.int64(512), T.int64(512)), "float32"), vae_decoder_mid_block_attentions_0_to_q_bias: T.Buffer((T.int64(512),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(512)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(16384), T.int64(512), T.int64(512)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv23[v_i0, v_i1, v_k], lv24[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv23[v_i0, v_i1, v_k] * lv24[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul28_multiply13(lv34: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv41: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(16384)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)))
        for i0, i1, i2, i3, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384), T.int64(512)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv34[v_i0, v_i1, v_i2, v_k], lv41[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv34[v_i0, v_i1, v_i2, v_k] * lv41[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul30_add45(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv26: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul30_add45_add44(lv50: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv51: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(768),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv50[v_i0, v_i1, v_k], lv51[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv50[v_i0, v_i1, v_k] * lv51[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul30_add45_multiply15(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv22: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_matmul33_add47_multiply16_tir_sigmoid_multiply17(lv55: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv56: T.Buffer((T.int64(768), T.int64(3072)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(3072),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(3072), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv55[v_i0, v_i1, v_k], lv56[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv55[v_i0, v_i1, v_k] * lv56[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = T.float32(1.7020000219345093) * var_T_add_intermediate[v_ax0, v_ax1, v_ax2]
        for i0, i1, i2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2])
                var_compute_intermediate[v_i0, v_i1, v_i2] = T.sigmoid(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], var_compute_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * var_compute_intermediate[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul34_add45_add44(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32"), lv62: T.Buffer((T.int64(3072), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(768),), "float32"), lv54: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(3072)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv54[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv54[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul3_add4_gelu(lv57: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv58: T.Buffer((T.int64(1280), T.int64(5120)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(5120),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(5120), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv57[v_i0, v_i1, v_k], lv58[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv57[v_i0, v_i1, v_k] * lv58[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul4_add2_add(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32"), lv62: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(1280),), "float32"), lv56: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(5120)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv56[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv56[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul6_add5_silu(lv14: T.Buffer((T.int64(2), T.int64(320)), "float32"), lv15: T.Buffer((T.int64(320), T.int64(1280)), "float32"), unet_time_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(320)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv14[v_i0, v_k], lv15[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv14[v_i0, v_k] * lv15[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_1_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_1_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul7_add5(lv41: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv42: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_add_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv41[v_i0, v_k], lv42[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv41[v_i0, v_k] * lv42[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_2_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_2_bias[v_ax1]

    @T.prim_func(private=True)
    def fused_matmul7_add5_add6(lv18: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv19: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_time_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), lv44: T.Buffer((T.int64(2), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv18[v_i0, v_k], lv19[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv18[v_i0, v_k] * lv19[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_2_bias[v_ax1])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1])
                var_T_add_intermediate_1[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_2_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1], lv44[v_ax0, v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_T_add_intermediate_1[v_ax0, v_ax1] + lv44[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul7_add5_strided_slice8(lv431: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv432: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv431[v_i0, v_k], lv432[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv431[v_i0, v_k] * lv432[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul8_add5_silu(lv37: T.Buffer((T.int64(2), T.int64(2816)), "float32"), lv38: T.Buffer((T.int64(2816), T.int64(1280)), "float32"), unet_add_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(2816)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv37[v_i0, v_k], lv38[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv37[v_i0, v_k] * lv38[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_1_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_1_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul9_add8_cast4(lv54: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv55: T.Buffer((T.int64(1280), T.int64(320)), "float32"), unet_down_blocks_0_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(320),), "float32"), var_compute_intermediate: T.Buffer((T.int64(2), T.int64(320)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(320), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv54[v_i0, v_k], lv55[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv54[v_i0, v_k] * lv55[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_add_intermediate[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_matmul_add2(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv26: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul_add2_add(lv52: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv53: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(1280),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv52[v_i0, v_i1, v_k], lv53[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv52[v_i0, v_i1, v_k] * lv53[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul_add2_multiply(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv22: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_reshape14_strided_slice4_reshape15_cast5_multiply3_multiply4_tir_sin1_tir_cos1_concatenate2_strided_slice5_reshape16_strided_slice6_reshape16_concatenate2_reshape17_concatenate3(inp_4: T.Buffer((T.int64(2), T.int64(6)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(128)), "float32"), inp_3: T.Buffer((T.int64(2), T.int64(1280)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(2816)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(12),))
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(12),))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(1)))
        var_compute_intermediate = T.alloc_buffer((T.int64(12), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(256)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_reshape_intermediate_3 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_concat_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(256)))
        var_T_reshape_intermediate_4 = T.alloc_buffer((T.int64(2), T.int64(1536)))
        for ax0 in range(T.int64(12)):
            with T.block("T_reshape"):
                v_ax0 = T.axis.spatial(T.int64(12), ax0)
                T.reads(inp_4[v_ax0 % T.int64(12) // T.int64(6), v_ax0 % T.int64(6)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = inp_4[v_ax0 % T.int64(12) // T.int64(6), v_ax0 % T.int64(6)]
        for ax0 in range(T.int64(12)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0 = T.axis.spatial(T.int64(12), ax0)
                T.reads(var_T_reshape_intermediate[v_ax0])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_reshape_intermediate[v_ax0]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(1)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(12)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(12)]
        for i0, i1 in T.grid(T.int64(12), T.int64(1)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate[v_ax0, T.int64(0)], param_0[T.int64(0), v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate[v_ax0, T.int64(0)] * param_0[T.int64(0), v_ax1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0, i1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("compute_1"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_1[v_i0, v_i1])
                var_compute_intermediate_1[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0, i1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("compute_2"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_2[v_i0, v_i1])
                var_compute_intermediate_2[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(12), T.int64(256)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_strided_slice_with_axes_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)])
                T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)])
                T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_strided_slice_with_axes_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)])
                T.writes(var_T_reshape_intermediate_3[v_ax0, v_ax1])
                var_T_reshape_intermediate_3[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(256)):
            with T.block("T_concat_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_2[v_ax0, v_ax1])
                var_T_concat_intermediate_2[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1536)):
            with T.block("T_reshape_4"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_2[(v_ax0 * T.int64(6) + v_ax1 // T.int64(256)) % T.int64(12), v_ax1 % T.int64(256)])
                T.writes(var_T_reshape_intermediate_4[v_ax0, v_ax1])
                var_T_reshape_intermediate_4[v_ax0, v_ax1] = var_T_concat_intermediate_2[(v_ax0 * T.int64(6) + v_ax1 // T.int64(256)) % T.int64(12), v_ax1 % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(2816)):
            with T.block("T_concat_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(1280) <= v_ax1, var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def fused_reshape23_transpose12(lv120: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv120[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv120[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape23_transpose12_transpose13(lv122: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(4096)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv122[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv122[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(64), T.int64(4096)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape25_transpose16(lv151: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv151[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv151[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape25_transpose16_transpose17(lv149: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv149[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv149[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15(lv254: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv111: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv254[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv254[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv111[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv111[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_concatenate7(lv4835: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv4692: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), lv257: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv4835[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4835[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4692[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4692[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_concatenate8(lv5004: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv4861: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5004[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5004[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4861[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4861[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape26_transpose20_add15_resize2d1(lv5173: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv5030: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_resize_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5173[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5173[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5030[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5030[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))])
                T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape2_reshape2_add(lv3: T.Buffer((T.int64(77), T.int64(1280)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape30_transpose22(lv456: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv456[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv456[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape30_transpose22_transpose23(lv458: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv458[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv458[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(64), T.int64(1024)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape32_transpose26(lv487: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv487[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv487[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape32_transpose26_transpose27(lv485: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv485[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv485[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape33_transpose29_add22(lv1126: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv447: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv1126[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv1126[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv447[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv447[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape33_transpose29_add22_concatenate4(lv3252: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv2573: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), lv1129: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv3252[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3252[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2573[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2573[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape33_transpose29_add22_concatenate5(lv3957: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv3278: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv3957[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3957[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3278[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3278[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape33_transpose29_add22_resize2d(lv4662: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv3983: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_resize_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv4662[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4662[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3983[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3983[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))])
                T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape36_transpose30_transpose31(lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(16384)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(512)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv18[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512), v_ax2 % T.int64(16384) // T.int64(128), v_ax2 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv18[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512), v_ax2 % T.int64(16384) // T.int64(128), v_ax2 % T.int64(128)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape37_transpose33(lv26: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape37_transpose33_transpose34(lv29: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape43_reshape43_add44(lv3: T.Buffer((T.int64(77), T.int64(768)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape44_transpose38_reshape45(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape44_transpose38_reshape45_transpose39(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape46_add46_reshape47(lv42: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape48_transpose40_reshape49(lv47: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1_reshape6(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape5_transpose1_reshape6_transpose2(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape7_add3_reshape8(lv42: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape7_reshape8(lv46: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape9_transpose3_reshape10(lv49: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape_cast_reshape1(inp_0: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for ax0, ax1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(inp_0[T.int64(0), v_ax1 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = inp_0[T.int64(0), v_ax1 % T.int64(77)]
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0 in range(T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0 = T.axis.spatial(T.int64(77), ax0)
                T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_split1_gelu2_multiply10(lv511: T.Buffer((T.int64(2), T.int64(1024), T.int64(10240)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv511[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_split2_subtract_multiply11_add29(lv5254: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_subtract_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5254[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5254[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5254[v_ax0 + T.int64(1), v_ax1, v_ax2, v_ax3])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv5254[v_ax0 + T.int64(1), v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_subtract"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] - var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(5) * var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_split_gelu1_multiply7(lv175: T.Buffer((T.int64(2), T.int64(4096), T.int64(5120)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(2560)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_multiply = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        compute = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_multiply_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_add = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv175[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_strided_slice_reshape11(lv1465: T.Buffer((T.int64(1), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(lv1465[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = lv1465[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose10_reshape22(lv112: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv112[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv112[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096) // T.int64(64), (v_ax2 // T.int64(640) + v_ax1) % T.int64(64), v_ax2 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096) // T.int64(64), (v_ax2 // T.int64(640) + v_ax1) % T.int64(64), v_ax2 % T.int64(640)]

    @T.prim_func(private=True)
    def fused_transpose14_reshape24(lv137: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv137[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv137[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose21_reshape29(lv448: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv448[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv448[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(32), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(32), v_ax2 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose24_reshape31(lv473: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv473[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv473[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose31_reshape39_add32_divide6(lv50: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(16384)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv50[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = lv50[v_ax0, v_ax2, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(128) + v_ax3) // T.int64(16384) + v_ax1) % T.int64(512), (v_ax2 * T.int64(128) + v_ax3) % T.int64(16384)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(128) + v_ax3) // T.int64(16384) + v_ax1) % T.int64(512), (v_ax2 * T.int64(128) + v_ax3) % T.int64(16384)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv18[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv18[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_transpose35_reshape38(lv45: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv45[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv45[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(16384), T.int64(0), v_ax2 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(16384), T.int64(0), v_ax2 % T.int64(512)]

    @T.prim_func(private=True)
    def fused_transpose36_multiply14_tir_round(lv237: T.Buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv237[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv237[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(255)
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.round(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])

    @T.prim_func(private=True)
    def group_norm15(A: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32"), B: T.Buffer((T.int64(512),), "float32"), C: T.Buffer((T.int64(512),), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16384)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16384)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(16384) + v_ax2) % T.int64(512), v_ax3 % T.int64(16384)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(16384) + v_ax2) % T.int64(512), v_ax3 % T.int64(16384)]
        for ax0, ax1, k2, k3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3 = T.axis.remap("SSRR", [ax0, ax1, k2, k3])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.814697265625e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_group_norm[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(16), v_ax2 % T.int64(16384)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2])
                T_reshape[v_ax0, v_ax1, v_ax2] = T_group_norm[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(16), v_ax2 % T.int64(16384)]

    @T.prim_func(private=True)
    def group_norm3(A: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(A[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]

    @T.prim_func(private=True)
    def group_norm6(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(A[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]

    @T.prim_func(private=True)
    def layer_norm(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0, ax1, k2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm1(A: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_layer_norm: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(4096)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(4096)))
        for ax0, ax1, k2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0015625000000000001) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm2(A: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(1024)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(1024)))
        for ax0, ax1, k2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm3(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(768),), "float32"), C: T.Buffer((T.int64(768),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0, ax1, k2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0013020833333333333) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def matmul1(A: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(20), T.int64(77), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul11(A: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), B: T.Buffer((T.int64(640), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul13(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32"), B: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64), T.int64(4096)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul14(A: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(77), T.int64(640), T.int64(2048)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul16(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32"), B: T.Buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul19(A: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul2(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(20), T.int64(77), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul21(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32"), B: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64), T.int64(1024)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul22(A: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(77), T.int64(1280), T.int64(2048)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul24(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32"), B: T.Buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul29(A: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32"), B: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512), T.int64(16384)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul31(A: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(12), T.int64(77), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul32(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(12), T.int64(77), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul5(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, k in T.grid(T.int64(1), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_k], B[v_k, v_i1])
                T.writes(matmul[v_i0, v_i1])
                with T.init():
                    matmul[v_i0, v_i1] = T.float32(0)
                matmul[v_i0, v_i1] = matmul[v_i0, v_i1] + A[v_i0, v_k] * B[v_k, v_i1]

    @T.prim_func(private=True)
    def multiply12(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(7.6775431632995605) * A[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def multiply18(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] * B[()]

    @T.prim_func(private=True)
    def power(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_power"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads(A[()])
            T.writes(T_power[()])
            T_power[()] = T.pow(A[()], T.float32(2))

    @T.prim_func(private=True)
    def power1(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_power"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads(A[()])
            T.writes(T_power[()])
            T_power[()] = T.pow(A[()], T.float32(0.5))

    @T.prim_func(private=True)
    def reshape(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), T_reshape: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[T.int64(0), v_ax1 % T.int64(77)])
                T.writes(T_reshape[v_ax0, v_ax1])
                T_reshape[v_ax0, v_ax1] = A[T.int64(0), v_ax1 % T.int64(77)]

    @T.prim_func(private=True)
    def reshape19(A: T.Buffer((T.int64(2), T.int64(320)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)]

    @T.prim_func(private=True)
    def reshape21(A: T.Buffer((T.int64(2), T.int64(640)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)]

    @T.prim_func(private=True)
    def reshape28(A: T.Buffer((T.int64(2), T.int64(1280)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)]

    @T.prim_func(private=True)
    def resize2d2(A: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d3(A: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d4(A: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), resize: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(511)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(511)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(511)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(511)), T.int64(0))]

    @T.prim_func(private=True)
    def silu(A: T.Buffer((T.int64(2), T.int64(1280)), "float32"), T_multiply: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(A[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(A[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(T_multiply[v_ax0, v_ax1])
                T_multiply[v_ax0, v_ax1] = A[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def softmax(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(20), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(20), T.int64(77)))
        for i0, i1, k in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_i1, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0, i1, i2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0, i1, k in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0, i1, i2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                T.block_attr({"axis": 2})
                T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def softmax1(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax2(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax3(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax4(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax5(A: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax6(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(12), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(12), T.int64(77)))
        for i0, i1, k in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_i1, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0, i1, i2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0, i1, k in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0, i1, i2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                T.block_attr({"axis": 2})
                T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def squeeze(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_squeeze: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 1, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(1280)):
            with T.block("T_squeeze"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[T.int64(0), v_ax0, v_ax1])
                T.writes(T_squeeze[v_ax0, v_ax1])
                T_squeeze[v_ax0, v_ax1] = A[T.int64(0), v_ax0, v_ax1]

    @T.prim_func(private=True)
    def subtract1(A: T.Buffer((), "float32"), B: T.Buffer((), "float32"), T_subtract: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_subtract"):
            vi = T.axis.spatial(1, T.int64(0))
            T.reads(A[()], B[()])
            T.writes(T_subtract[()])
            T_subtract[()] = A[()] - B[()]

    @T.prim_func(private=True)
    def take(A: T.Buffer((T.int64(49408), T.int64(1280)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(1280)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take2(A: T.Buffer((T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1),), "int64"), T_take: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take3(A: T.Buffer((T.int64(49408), T.int64(768)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(768)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def tir_image_to_rgba(A: T.Buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)), "float32"), image_to_rgba: T.Buffer((T.int64(1024), T.int64(1024)), "uint32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for y, x in T.grid(T.int64(1024), T.int64(1024)):
            with T.block("image_to_rgba"):
                v_y, v_x = T.axis.remap("SS", [y, x])
                T.reads(A[T.int64(0), v_y, v_x, T.int64(0):T.int64(3)])
                T.writes(image_to_rgba[v_y, v_x])
                image_to_rgba[v_y, v_x] = T.bitwise_or(T.bitwise_or(T.bitwise_or(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(0)]), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(1)]), T.uint32(8))), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(2)]), T.uint32(16))), T.uint32(4278190080))

    @T.prim_func(private=True)
    def transpose30(A: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32"), T_transpose: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax2, v_ax1])
                T.writes(T_transpose[v_ax0, v_ax1, v_ax2])
                T_transpose[v_ax0, v_ax1, v_ax2] = A[v_ax0, v_ax2, v_ax1]

    @R.function
    def cat_latents(latents: R.Tensor((1, 4, 128, 128), dtype="float32")) -> R.Tensor((2, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate11, (latents, latents), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
        return gv

    @R.function
    def clip(inp_0: R.Tensor((1, 77), dtype="int32"), transformed_param_0: R.Tensor((49408, 768), dtype="float32"), transformed_param_1: R.Tensor((768,), dtype="float32"), transformed_param_2: R.Tensor((768,), dtype="float32"), transformed_param_3: R.Tensor((768,), dtype="float32"), transformed_param_4: R.Tensor((768,), dtype="float32"), transformed_param_5: R.Tensor((3072,), dtype="float32"), transformed_param_6: R.Tensor((768,), dtype="float32"), transformed_param_7: R.Tensor((768,), dtype="float32"), transformed_param_8: R.Tensor((768,), dtype="float32"), transformed_param_9: R.Tensor((768,), dtype="float32"), transformed_param_10: R.Tensor((768,), dtype="float32"), transformed_param_11: R.Tensor((768,), dtype="float32"), transformed_param_12: R.Tensor((768,), dtype="float32"), transformed_param_13: R.Tensor((768,), dtype="float32"), transformed_param_14: R.Tensor((768,), dtype="float32"), transformed_param_15: R.Tensor((3072,), dtype="float32"), transformed_param_16: R.Tensor((768,), dtype="float32"), transformed_param_17: R.Tensor((768,), dtype="float32"), transformed_param_18: R.Tensor((768,), dtype="float32"), transformed_param_19: R.Tensor((768,), dtype="float32"), transformed_param_20: R.Tensor((768,), dtype="float32"), transformed_param_21: R.Tensor((768,), dtype="float32"), transformed_param_22: R.Tensor((768,), dtype="float32"), transformed_param_23: R.Tensor((768,), dtype="float32"), transformed_param_24: R.Tensor((768,), dtype="float32"), transformed_param_25: R.Tensor((3072,), dtype="float32"), transformed_param_26: R.Tensor((768,), dtype="float32"), transformed_param_27: R.Tensor((768,), dtype="float32"), transformed_param_28: R.Tensor((768,), dtype="float32"), transformed_param_29: R.Tensor((768,), dtype="float32"), transformed_param_30: R.Tensor((768,), dtype="float32"), transformed_param_31: R.Tensor((768,), dtype="float32"), transformed_param_32: R.Tensor((768,), dtype="float32"), transformed_param_33: R.Tensor((768,), dtype="float32"), transformed_param_34: R.Tensor((768,), dtype="float32"), transformed_param_35: R.Tensor((3072,), dtype="float32"), transformed_param_36: R.Tensor((768,), dtype="float32"), transformed_param_37: R.Tensor((768,), dtype="float32"), transformed_param_38: R.Tensor((768,), dtype="float32"), transformed_param_39: R.Tensor((768,), dtype="float32"), transformed_param_40: R.Tensor((768,), dtype="float32"), transformed_param_41: R.Tensor((768,), dtype="float32"), transformed_param_42: R.Tensor((768,), dtype="float32"), transformed_param_43: R.Tensor((768,), dtype="float32"), transformed_param_44: R.Tensor((768,), dtype="float32"), transformed_param_45: R.Tensor((3072,), dtype="float32"), transformed_param_46: R.Tensor((768,), dtype="float32"), transformed_param_47: R.Tensor((768,), dtype="float32"), transformed_param_48: R.Tensor((768,), dtype="float32"), transformed_param_49: R.Tensor((768,), dtype="float32"), transformed_param_50: R.Tensor((768,), dtype="float32"), transformed_param_51: R.Tensor((768,), dtype="float32"), transformed_param_52: R.Tensor((768,), dtype="float32"), transformed_param_53: R.Tensor((768,), dtype="float32"), transformed_param_54: R.Tensor((768,), dtype="float32"), transformed_param_55: R.Tensor((3072,), dtype="float32"), transformed_param_56: R.Tensor((768,), dtype="float32"), transformed_param_57: R.Tensor((768,), dtype="float32"), transformed_param_58: R.Tensor((768,), dtype="float32"), transformed_param_59: R.Tensor((768,), dtype="float32"), transformed_param_60: R.Tensor((768,), dtype="float32"), transformed_param_61: R.Tensor((768,), dtype="float32"), transformed_param_62: R.Tensor((768,), dtype="float32"), transformed_param_63: R.Tensor((768,), dtype="float32"), transformed_param_64: R.Tensor((768,), dtype="float32"), transformed_param_65: R.Tensor((3072,), dtype="float32"), transformed_param_66: R.Tensor((768,), dtype="float32"), transformed_param_67: R.Tensor((768,), dtype="float32"), transformed_param_68: R.Tensor((768,), dtype="float32"), transformed_param_69: R.Tensor((768,), dtype="float32"), transformed_param_70: R.Tensor((768,), dtype="float32"), transformed_param_71: R.Tensor((768,), dtype="float32"), transformed_param_72: R.Tensor((768,), dtype="float32"), transformed_param_73: R.Tensor((768,), dtype="float32"), transformed_param_74: R.Tensor((768,), dtype="float32"), transformed_param_75: R.Tensor((3072,), dtype="float32"), transformed_param_76: R.Tensor((768,), dtype="float32"), transformed_param_77: R.Tensor((768,), dtype="float32"), transformed_param_78: R.Tensor((768,), dtype="float32"), transformed_param_79: R.Tensor((768,), dtype="float32"), transformed_param_80: R.Tensor((768,), dtype="float32"), transformed_param_81: R.Tensor((768,), dtype="float32"), transformed_param_82: R.Tensor((768,), dtype="float32"), transformed_param_83: R.Tensor((768,), dtype="float32"), transformed_param_84: R.Tensor((768,), dtype="float32"), transformed_param_85: R.Tensor((3072,), dtype="float32"), transformed_param_86: R.Tensor((768,), dtype="float32"), transformed_param_87: R.Tensor((768,), dtype="float32"), transformed_param_88: R.Tensor((768,), dtype="float32"), transformed_param_89: R.Tensor((768,), dtype="float32"), transformed_param_90: R.Tensor((768,), dtype="float32"), transformed_param_91: R.Tensor((768,), dtype="float32"), transformed_param_92: R.Tensor((768,), dtype="float32"), transformed_param_93: R.Tensor((768,), dtype="float32"), transformed_param_94: R.Tensor((768,), dtype="float32"), transformed_param_95: R.Tensor((3072,), dtype="float32"), transformed_param_96: R.Tensor((768,), dtype="float32"), transformed_param_97: R.Tensor((768,), dtype="float32"), transformed_param_98: R.Tensor((768,), dtype="float32"), transformed_param_99: R.Tensor((768,), dtype="float32"), transformed_param_100: R.Tensor((768,), dtype="float32"), transformed_param_101: R.Tensor((768,), dtype="float32"), transformed_param_102: R.Tensor((768,), dtype="float32"), transformed_param_103: R.Tensor((768,), dtype="float32"), transformed_param_104: R.Tensor((768,), dtype="float32"), transformed_param_105: R.Tensor((3072,), dtype="float32"), transformed_param_106: R.Tensor((768,), dtype="float32"), transformed_param_107: R.Tensor((768,), dtype="float32"), transformed_param_108: R.Tensor((768,), dtype="float32"), transformed_param_109: R.Tensor((768,), dtype="float32"), transformed_param_110: R.Tensor((768,), dtype="float32"), transformed_param_111: R.Tensor((768,), dtype="float32"), transformed_param_112: R.Tensor((768,), dtype="float32"), transformed_param_113: R.Tensor((768,), dtype="float32"), transformed_param_114: R.Tensor((768,), dtype="float32"), transformed_param_115: R.Tensor((3072,), dtype="float32"), transformed_param_116: R.Tensor((768,), dtype="float32"), transformed_param_117: R.Tensor((768,), dtype="float32"), transformed_param_118: R.Tensor((768,), dtype="float32"), transformed_param_119: R.Tensor((768,), dtype="float32"), transformed_param_120: R.Tensor((768,), dtype="float32"), transformed_param_121: R.Tensor((768,), dtype="float32"), transformed_param_122: R.Tensor((768,), dtype="float32"), transformed_param_123: R.Tensor((77, 768), dtype="float32"), transformed_param_124: R.Tensor((768, 768), dtype="float32"), transformed_param_125: R.Tensor((768, 768), dtype="float32"), transformed_param_126: R.Tensor((768, 768), dtype="float32"), transformed_param_127: R.Tensor((768, 768), dtype="float32"), transformed_param_128: R.Tensor((768, 3072), dtype="float32"), transformed_param_129: R.Tensor((3072, 768), dtype="float32"), transformed_param_130: R.Tensor((768, 768), dtype="float32"), transformed_param_131: R.Tensor((768, 768), dtype="float32"), transformed_param_132: R.Tensor((768, 768), dtype="float32"), transformed_param_133: R.Tensor((768, 768), dtype="float32"), transformed_param_134: R.Tensor((768, 3072), dtype="float32"), transformed_param_135: R.Tensor((3072, 768), dtype="float32"), transformed_param_136: R.Tensor((768, 768), dtype="float32"), transformed_param_137: R.Tensor((768, 768), dtype="float32"), transformed_param_138: R.Tensor((768, 768), dtype="float32"), transformed_param_139: R.Tensor((768, 768), dtype="float32"), transformed_param_140: R.Tensor((768, 3072), dtype="float32"), transformed_param_141: R.Tensor((3072, 768), dtype="float32"), transformed_param_142: R.Tensor((768, 768), dtype="float32"), transformed_param_143: R.Tensor((768, 768), dtype="float32"), transformed_param_144: R.Tensor((768, 768), dtype="float32"), transformed_param_145: R.Tensor((768, 768), dtype="float32"), transformed_param_146: R.Tensor((768, 3072), dtype="float32"), transformed_param_147: R.Tensor((3072, 768), dtype="float32"), transformed_param_148: R.Tensor((768, 768), dtype="float32"), transformed_param_149: R.Tensor((768, 768), dtype="float32"), transformed_param_150: R.Tensor((768, 768), dtype="float32"), transformed_param_151: R.Tensor((768, 768), dtype="float32"), transformed_param_152: R.Tensor((768, 3072), dtype="float32"), transformed_param_153: R.Tensor((3072, 768), dtype="float32"), transformed_param_154: R.Tensor((768, 768), dtype="float32"), transformed_param_155: R.Tensor((768, 768), dtype="float32"), transformed_param_156: R.Tensor((768, 768), dtype="float32"), transformed_param_157: R.Tensor((768, 768), dtype="float32"), transformed_param_158: R.Tensor((768, 3072), dtype="float32"), transformed_param_159: R.Tensor((3072, 768), dtype="float32"), transformed_param_160: R.Tensor((768, 768), dtype="float32"), transformed_param_161: R.Tensor((768, 768), dtype="float32"), transformed_param_162: R.Tensor((768, 768), dtype="float32"), transformed_param_163: R.Tensor((768, 768), dtype="float32"), transformed_param_164: R.Tensor((768, 3072), dtype="float32"), transformed_param_165: R.Tensor((3072, 768), dtype="float32"), transformed_param_166: R.Tensor((768, 768), dtype="float32"), transformed_param_167: R.Tensor((768, 768), dtype="float32"), transformed_param_168: R.Tensor((768, 768), dtype="float32"), transformed_param_169: R.Tensor((768, 768), dtype="float32"), transformed_param_170: R.Tensor((768, 3072), dtype="float32"), transformed_param_171: R.Tensor((3072, 768), dtype="float32"), transformed_param_172: R.Tensor((768, 768), dtype="float32"), transformed_param_173: R.Tensor((768, 768), dtype="float32"), transformed_param_174: R.Tensor((768, 768), dtype="float32"), transformed_param_175: R.Tensor((768, 768), dtype="float32"), transformed_param_176: R.Tensor((768, 3072), dtype="float32"), transformed_param_177: R.Tensor((3072, 768), dtype="float32"), transformed_param_178: R.Tensor((768, 768), dtype="float32"), transformed_param_179: R.Tensor((768, 768), dtype="float32"), transformed_param_180: R.Tensor((768, 768), dtype="float32"), transformed_param_181: R.Tensor((768, 768), dtype="float32"), transformed_param_182: R.Tensor((768, 3072), dtype="float32"), transformed_param_183: R.Tensor((3072, 768), dtype="float32"), transformed_param_184: R.Tensor((768, 768), dtype="float32"), transformed_param_185: R.Tensor((768, 768), dtype="float32"), transformed_param_186: R.Tensor((768, 768), dtype="float32"), transformed_param_187: R.Tensor((768, 768), dtype="float32"), transformed_param_188: R.Tensor((768, 3072), dtype="float32"), transformed_param_189: R.Tensor((3072, 768), dtype="float32"), transformed_param_190: R.Tensor((768, 768), dtype="float32"), transformed_param_191: R.Tensor((768, 768), dtype="float32"), transformed_param_192: R.Tensor((768, 768), dtype="float32"), transformed_param_193: R.Tensor((768, 768), dtype="float32"), transformed_param_194: R.Tensor((768, 3072), dtype="float32"), transformed_param_195: R.Tensor((3072, 768), dtype="float32")) -> R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv1668 = R.call_tir(cls.fused_reshape_cast_reshape1, (inp_0,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv: R.Tensor((49408, 768), dtype="float32") = transformed_param_0
            lv3 = R.call_tir(cls.take3, (lv, lv1668), out_sinfo=R.Tensor((77, 768), dtype="float32"))
            lv1: R.Tensor((77, 768), dtype="float32") = transformed_param_123
            lv1669 = R.call_tir(cls.fused_reshape43_reshape43_add44, (lv3, lv1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv2: R.Tensor((768,), dtype="float32") = transformed_param_2
            lv3_1: R.Tensor((768,), dtype="float32") = transformed_param_1
            lv21 = R.call_tir(cls.layer_norm3, (lv1669, lv2, lv3_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv4: R.Tensor((768, 768), dtype="float32") = transformed_param_124
            lv5: R.Tensor((768,), dtype="float32") = transformed_param_9
            lv1670 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv21, lv4, lv5), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv6: R.Tensor((768, 768), dtype="float32") = transformed_param_125
            lv7: R.Tensor((768,), dtype="float32") = transformed_param_7
            lv1671 = R.call_tir(cls.fused_matmul30_add45, (lv21, lv6, lv7), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1672 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1671,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv8: R.Tensor((768, 768), dtype="float32") = transformed_param_126
            lv9: R.Tensor((768,), dtype="float32") = transformed_param_10
            lv1673 = R.call_tir(cls.fused_matmul30_add45, (lv21, lv8, lv9), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1674 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1673,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1675 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1670,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul31, (lv1675, lv1672), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1676 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv42, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax6, (lv1676,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv47 = R.call_tir(cls.matmul32, (lv46, lv1674), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1677 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv47,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv10: R.Tensor((768, 768), dtype="float32") = transformed_param_127
            lv11: R.Tensor((768,), dtype="float32") = transformed_param_8
            lv1678 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1677, lv10, lv11, lv1669), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv12: R.Tensor((768,), dtype="float32") = transformed_param_4
            lv13: R.Tensor((768,), dtype="float32") = transformed_param_3
            lv55 = R.call_tir(cls.layer_norm3, (lv1678, lv12, lv13), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv14: R.Tensor((768, 3072), dtype="float32") = transformed_param_128
            lv15: R.Tensor((3072,), dtype="float32") = transformed_param_5
            lv1679 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv55, lv14, lv15), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv16: R.Tensor((3072, 768), dtype="float32") = transformed_param_129
            lv17: R.Tensor((768,), dtype="float32") = transformed_param_6
            lv1680 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1679, lv16, lv17, lv1678), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv18: R.Tensor((768,), dtype="float32") = transformed_param_32
            lv19: R.Tensor((768,), dtype="float32") = transformed_param_31
            lv66 = R.call_tir(cls.layer_norm3, (lv1680, lv18, lv19), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv20: R.Tensor((768, 768), dtype="float32") = transformed_param_130
            lv21_1: R.Tensor((768,), dtype="float32") = transformed_param_39
            lv1681 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv66, lv20, lv21_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv22: R.Tensor((768, 768), dtype="float32") = transformed_param_131
            lv23: R.Tensor((768,), dtype="float32") = transformed_param_37
            lv1682 = R.call_tir(cls.fused_matmul30_add45, (lv66, lv22, lv23), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1683 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1682,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv24: R.Tensor((768, 768), dtype="float32") = transformed_param_132
            lv25: R.Tensor((768,), dtype="float32") = transformed_param_40
            lv1684 = R.call_tir(cls.fused_matmul30_add45, (lv66, lv24, lv25), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1685 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1684,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1686 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1681,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul31, (lv1686, lv1683), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1687 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv87, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax6, (lv1687,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv92 = R.call_tir(cls.matmul32, (lv91, lv1685), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1688 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv92,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv26: R.Tensor((768, 768), dtype="float32") = transformed_param_133
            lv27: R.Tensor((768,), dtype="float32") = transformed_param_38
            lv1689 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1688, lv26, lv27, lv1680), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv28: R.Tensor((768,), dtype="float32") = transformed_param_34
            lv29: R.Tensor((768,), dtype="float32") = transformed_param_33
            lv100 = R.call_tir(cls.layer_norm3, (lv1689, lv28, lv29), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv30: R.Tensor((768, 3072), dtype="float32") = transformed_param_134
            lv31: R.Tensor((3072,), dtype="float32") = transformed_param_35
            lv1690 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv100, lv30, lv31), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv32: R.Tensor((3072, 768), dtype="float32") = transformed_param_135
            lv33: R.Tensor((768,), dtype="float32") = transformed_param_36
            lv1691 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1690, lv32, lv33, lv1689), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv34: R.Tensor((768,), dtype="float32") = transformed_param_42
            lv35: R.Tensor((768,), dtype="float32") = transformed_param_41
            lv111 = R.call_tir(cls.layer_norm3, (lv1691, lv34, lv35), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv36: R.Tensor((768, 768), dtype="float32") = transformed_param_136
            lv37: R.Tensor((768,), dtype="float32") = transformed_param_49
            lv1692 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv111, lv36, lv37), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv38: R.Tensor((768, 768), dtype="float32") = transformed_param_137
            lv39: R.Tensor((768,), dtype="float32") = transformed_param_47
            lv1693 = R.call_tir(cls.fused_matmul30_add45, (lv111, lv38, lv39), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1694 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1693,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv40: R.Tensor((768, 768), dtype="float32") = transformed_param_138
            lv41: R.Tensor((768,), dtype="float32") = transformed_param_50
            lv1695 = R.call_tir(cls.fused_matmul30_add45, (lv111, lv40, lv41), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1696 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1695,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1697 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1692,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul31, (lv1697, lv1694), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1698 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv132, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax6, (lv1698,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv137 = R.call_tir(cls.matmul32, (lv136, lv1696), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1699 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv137,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv42_1: R.Tensor((768, 768), dtype="float32") = transformed_param_139
            lv43: R.Tensor((768,), dtype="float32") = transformed_param_48
            lv1700 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1699, lv42_1, lv43, lv1691), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv44: R.Tensor((768,), dtype="float32") = transformed_param_44
            lv45: R.Tensor((768,), dtype="float32") = transformed_param_43
            lv145 = R.call_tir(cls.layer_norm3, (lv1700, lv44, lv45), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv46_1: R.Tensor((768, 3072), dtype="float32") = transformed_param_140
            lv47_1: R.Tensor((3072,), dtype="float32") = transformed_param_45
            lv1701 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv145, lv46_1, lv47_1), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv48: R.Tensor((3072, 768), dtype="float32") = transformed_param_141
            lv49: R.Tensor((768,), dtype="float32") = transformed_param_46
            lv1702 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1701, lv48, lv49, lv1700), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv50: R.Tensor((768,), dtype="float32") = transformed_param_52
            lv51: R.Tensor((768,), dtype="float32") = transformed_param_51
            lv156 = R.call_tir(cls.layer_norm3, (lv1702, lv50, lv51), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv52: R.Tensor((768, 768), dtype="float32") = transformed_param_142
            lv53: R.Tensor((768,), dtype="float32") = transformed_param_59
            lv1703 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv156, lv52, lv53), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv54: R.Tensor((768, 768), dtype="float32") = transformed_param_143
            lv55_1: R.Tensor((768,), dtype="float32") = transformed_param_57
            lv1704 = R.call_tir(cls.fused_matmul30_add45, (lv156, lv54, lv55_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1705 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1704,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv56: R.Tensor((768, 768), dtype="float32") = transformed_param_144
            lv57: R.Tensor((768,), dtype="float32") = transformed_param_60
            lv1706 = R.call_tir(cls.fused_matmul30_add45, (lv156, lv56, lv57), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1707 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1706,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1708 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1703,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv177 = R.call_tir(cls.matmul31, (lv1708, lv1705), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1709 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv177, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv181 = R.call_tir(cls.softmax6, (lv1709,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv182 = R.call_tir(cls.matmul32, (lv181, lv1707), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1710 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv182,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv58: R.Tensor((768, 768), dtype="float32") = transformed_param_145
            lv59: R.Tensor((768,), dtype="float32") = transformed_param_58
            lv1711 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1710, lv58, lv59, lv1702), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv60: R.Tensor((768,), dtype="float32") = transformed_param_54
            lv61: R.Tensor((768,), dtype="float32") = transformed_param_53
            lv190 = R.call_tir(cls.layer_norm3, (lv1711, lv60, lv61), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv62: R.Tensor((768, 3072), dtype="float32") = transformed_param_146
            lv63: R.Tensor((3072,), dtype="float32") = transformed_param_55
            lv1712 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv190, lv62, lv63), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv64: R.Tensor((3072, 768), dtype="float32") = transformed_param_147
            lv65: R.Tensor((768,), dtype="float32") = transformed_param_56
            lv1713 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1712, lv64, lv65, lv1711), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv66_1: R.Tensor((768,), dtype="float32") = transformed_param_62
            lv67: R.Tensor((768,), dtype="float32") = transformed_param_61
            lv201 = R.call_tir(cls.layer_norm3, (lv1713, lv66_1, lv67), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv68: R.Tensor((768, 768), dtype="float32") = transformed_param_148
            lv69: R.Tensor((768,), dtype="float32") = transformed_param_69
            lv1714 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv201, lv68, lv69), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv70: R.Tensor((768, 768), dtype="float32") = transformed_param_149
            lv71: R.Tensor((768,), dtype="float32") = transformed_param_67
            lv1715 = R.call_tir(cls.fused_matmul30_add45, (lv201, lv70, lv71), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1716 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1715,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv72: R.Tensor((768, 768), dtype="float32") = transformed_param_150
            lv73: R.Tensor((768,), dtype="float32") = transformed_param_70
            lv1717 = R.call_tir(cls.fused_matmul30_add45, (lv201, lv72, lv73), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1718 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1717,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1719 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1714,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.matmul31, (lv1719, lv1716), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1720 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv222, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv226 = R.call_tir(cls.softmax6, (lv1720,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv227 = R.call_tir(cls.matmul32, (lv226, lv1718), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1721 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv227,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv74: R.Tensor((768, 768), dtype="float32") = transformed_param_151
            lv75: R.Tensor((768,), dtype="float32") = transformed_param_68
            lv1722 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1721, lv74, lv75, lv1713), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv76: R.Tensor((768,), dtype="float32") = transformed_param_64
            lv77: R.Tensor((768,), dtype="float32") = transformed_param_63
            lv235 = R.call_tir(cls.layer_norm3, (lv1722, lv76, lv77), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv78: R.Tensor((768, 3072), dtype="float32") = transformed_param_152
            lv79: R.Tensor((3072,), dtype="float32") = transformed_param_65
            lv1723 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv235, lv78, lv79), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv80: R.Tensor((3072, 768), dtype="float32") = transformed_param_153
            lv81: R.Tensor((768,), dtype="float32") = transformed_param_66
            lv1724 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1723, lv80, lv81, lv1722), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv82: R.Tensor((768,), dtype="float32") = transformed_param_72
            lv83: R.Tensor((768,), dtype="float32") = transformed_param_71
            lv246 = R.call_tir(cls.layer_norm3, (lv1724, lv82, lv83), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv84: R.Tensor((768, 768), dtype="float32") = transformed_param_154
            lv85: R.Tensor((768,), dtype="float32") = transformed_param_79
            lv1725 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv246, lv84, lv85), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv86: R.Tensor((768, 768), dtype="float32") = transformed_param_155
            lv87_1: R.Tensor((768,), dtype="float32") = transformed_param_77
            lv1726 = R.call_tir(cls.fused_matmul30_add45, (lv246, lv86, lv87_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1727 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1726,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv88: R.Tensor((768, 768), dtype="float32") = transformed_param_156
            lv89: R.Tensor((768,), dtype="float32") = transformed_param_80
            lv1728 = R.call_tir(cls.fused_matmul30_add45, (lv246, lv88, lv89), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1729 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1728,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1730 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1725,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.matmul31, (lv1730, lv1727), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1731 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv267, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv271 = R.call_tir(cls.softmax6, (lv1731,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv272 = R.call_tir(cls.matmul32, (lv271, lv1729), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1732 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv272,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv90: R.Tensor((768, 768), dtype="float32") = transformed_param_157
            lv91_1: R.Tensor((768,), dtype="float32") = transformed_param_78
            lv1733 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1732, lv90, lv91_1, lv1724), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv92_1: R.Tensor((768,), dtype="float32") = transformed_param_74
            lv93: R.Tensor((768,), dtype="float32") = transformed_param_73
            lv280 = R.call_tir(cls.layer_norm3, (lv1733, lv92_1, lv93), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv94: R.Tensor((768, 3072), dtype="float32") = transformed_param_158
            lv95: R.Tensor((3072,), dtype="float32") = transformed_param_75
            lv1734 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv280, lv94, lv95), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv96: R.Tensor((3072, 768), dtype="float32") = transformed_param_159
            lv97: R.Tensor((768,), dtype="float32") = transformed_param_76
            lv1735 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1734, lv96, lv97, lv1733), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv98: R.Tensor((768,), dtype="float32") = transformed_param_82
            lv99: R.Tensor((768,), dtype="float32") = transformed_param_81
            lv291 = R.call_tir(cls.layer_norm3, (lv1735, lv98, lv99), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv100_1: R.Tensor((768, 768), dtype="float32") = transformed_param_160
            lv101: R.Tensor((768,), dtype="float32") = transformed_param_89
            lv1736 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv291, lv100_1, lv101), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv102: R.Tensor((768, 768), dtype="float32") = transformed_param_161
            lv103: R.Tensor((768,), dtype="float32") = transformed_param_87
            lv1737 = R.call_tir(cls.fused_matmul30_add45, (lv291, lv102, lv103), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1738 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1737,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv104: R.Tensor((768, 768), dtype="float32") = transformed_param_162
            lv105: R.Tensor((768,), dtype="float32") = transformed_param_90
            lv1739 = R.call_tir(cls.fused_matmul30_add45, (lv291, lv104, lv105), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1740 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1739,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1741 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1736,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul31, (lv1741, lv1738), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1742 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv312, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax6, (lv1742,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv317 = R.call_tir(cls.matmul32, (lv316, lv1740), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1743 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv317,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv106: R.Tensor((768, 768), dtype="float32") = transformed_param_163
            lv107: R.Tensor((768,), dtype="float32") = transformed_param_88
            lv1744 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1743, lv106, lv107, lv1735), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv108: R.Tensor((768,), dtype="float32") = transformed_param_84
            lv109: R.Tensor((768,), dtype="float32") = transformed_param_83
            lv325 = R.call_tir(cls.layer_norm3, (lv1744, lv108, lv109), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv110: R.Tensor((768, 3072), dtype="float32") = transformed_param_164
            lv111_1: R.Tensor((3072,), dtype="float32") = transformed_param_85
            lv1745 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv325, lv110, lv111_1), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv112: R.Tensor((3072, 768), dtype="float32") = transformed_param_165
            lv113: R.Tensor((768,), dtype="float32") = transformed_param_86
            lv1746 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1745, lv112, lv113, lv1744), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv114: R.Tensor((768,), dtype="float32") = transformed_param_92
            lv115: R.Tensor((768,), dtype="float32") = transformed_param_91
            lv336 = R.call_tir(cls.layer_norm3, (lv1746, lv114, lv115), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv116: R.Tensor((768, 768), dtype="float32") = transformed_param_166
            lv117: R.Tensor((768,), dtype="float32") = transformed_param_99
            lv1747 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv336, lv116, lv117), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv118: R.Tensor((768, 768), dtype="float32") = transformed_param_167
            lv119: R.Tensor((768,), dtype="float32") = transformed_param_97
            lv1748 = R.call_tir(cls.fused_matmul30_add45, (lv336, lv118, lv119), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1749 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1748,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv120: R.Tensor((768, 768), dtype="float32") = transformed_param_168
            lv121: R.Tensor((768,), dtype="float32") = transformed_param_100
            lv1750 = R.call_tir(cls.fused_matmul30_add45, (lv336, lv120, lv121), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1751 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1750,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1752 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1747,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul31, (lv1752, lv1749), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1753 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv357, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax6, (lv1753,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv362 = R.call_tir(cls.matmul32, (lv361, lv1751), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1754 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv362,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv122: R.Tensor((768, 768), dtype="float32") = transformed_param_169
            lv123: R.Tensor((768,), dtype="float32") = transformed_param_98
            lv1755 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1754, lv122, lv123, lv1746), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv124: R.Tensor((768,), dtype="float32") = transformed_param_94
            lv125: R.Tensor((768,), dtype="float32") = transformed_param_93
            lv370 = R.call_tir(cls.layer_norm3, (lv1755, lv124, lv125), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv126: R.Tensor((768, 3072), dtype="float32") = transformed_param_170
            lv127: R.Tensor((3072,), dtype="float32") = transformed_param_95
            lv1756 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv370, lv126, lv127), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv128: R.Tensor((3072, 768), dtype="float32") = transformed_param_171
            lv129: R.Tensor((768,), dtype="float32") = transformed_param_96
            lv1757 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1756, lv128, lv129, lv1755), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv130: R.Tensor((768,), dtype="float32") = transformed_param_102
            lv131: R.Tensor((768,), dtype="float32") = transformed_param_101
            lv381 = R.call_tir(cls.layer_norm3, (lv1757, lv130, lv131), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv132_1: R.Tensor((768, 768), dtype="float32") = transformed_param_172
            lv133: R.Tensor((768,), dtype="float32") = transformed_param_109
            lv1758 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv381, lv132_1, lv133), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv134: R.Tensor((768, 768), dtype="float32") = transformed_param_173
            lv135: R.Tensor((768,), dtype="float32") = transformed_param_107
            lv1759 = R.call_tir(cls.fused_matmul30_add45, (lv381, lv134, lv135), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1760 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1759,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv136_1: R.Tensor((768, 768), dtype="float32") = transformed_param_174
            lv137_1: R.Tensor((768,), dtype="float32") = transformed_param_110
            lv1761 = R.call_tir(cls.fused_matmul30_add45, (lv381, lv136_1, lv137_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1762 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1761,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1763 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1758,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul31, (lv1763, lv1760), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1764 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv402, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax6, (lv1764,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv407 = R.call_tir(cls.matmul32, (lv406, lv1762), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1765 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv407,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv138: R.Tensor((768, 768), dtype="float32") = transformed_param_175
            lv139: R.Tensor((768,), dtype="float32") = transformed_param_108
            lv1766 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1765, lv138, lv139, lv1757), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv140: R.Tensor((768,), dtype="float32") = transformed_param_104
            lv141: R.Tensor((768,), dtype="float32") = transformed_param_103
            lv415 = R.call_tir(cls.layer_norm3, (lv1766, lv140, lv141), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv142: R.Tensor((768, 3072), dtype="float32") = transformed_param_176
            lv143: R.Tensor((3072,), dtype="float32") = transformed_param_105
            lv1767 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv415, lv142, lv143), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv144: R.Tensor((3072, 768), dtype="float32") = transformed_param_177
            lv145_1: R.Tensor((768,), dtype="float32") = transformed_param_106
            lv1768 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1767, lv144, lv145_1, lv1766), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv146: R.Tensor((768,), dtype="float32") = transformed_param_112
            lv147: R.Tensor((768,), dtype="float32") = transformed_param_111
            lv426 = R.call_tir(cls.layer_norm3, (lv1768, lv146, lv147), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv148: R.Tensor((768, 768), dtype="float32") = transformed_param_178
            lv149: R.Tensor((768,), dtype="float32") = transformed_param_119
            lv1769 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv426, lv148, lv149), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv150: R.Tensor((768, 768), dtype="float32") = transformed_param_179
            lv151: R.Tensor((768,), dtype="float32") = transformed_param_117
            lv1770 = R.call_tir(cls.fused_matmul30_add45, (lv426, lv150, lv151), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1771 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1770,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv152: R.Tensor((768, 768), dtype="float32") = transformed_param_180
            lv153: R.Tensor((768,), dtype="float32") = transformed_param_120
            lv1772 = R.call_tir(cls.fused_matmul30_add45, (lv426, lv152, lv153), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1773 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1772,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1774 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1769,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul31, (lv1774, lv1771), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1775 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv447, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax6, (lv1775,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv452 = R.call_tir(cls.matmul32, (lv451, lv1773), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1776 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv452,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv154: R.Tensor((768, 768), dtype="float32") = transformed_param_181
            lv155: R.Tensor((768,), dtype="float32") = transformed_param_118
            lv1777 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1776, lv154, lv155, lv1768), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv156_1: R.Tensor((768,), dtype="float32") = transformed_param_114
            lv157: R.Tensor((768,), dtype="float32") = transformed_param_113
            lv460 = R.call_tir(cls.layer_norm3, (lv1777, lv156_1, lv157), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv158: R.Tensor((768, 3072), dtype="float32") = transformed_param_182
            lv159: R.Tensor((3072,), dtype="float32") = transformed_param_115
            lv1778 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv460, lv158, lv159), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv160: R.Tensor((3072, 768), dtype="float32") = transformed_param_183
            lv161: R.Tensor((768,), dtype="float32") = transformed_param_116
            lv1779 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1778, lv160, lv161, lv1777), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv162: R.Tensor((768,), dtype="float32") = transformed_param_12
            lv163: R.Tensor((768,), dtype="float32") = transformed_param_11
            lv471 = R.call_tir(cls.layer_norm3, (lv1779, lv162, lv163), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv164: R.Tensor((768, 768), dtype="float32") = transformed_param_184
            lv165: R.Tensor((768,), dtype="float32") = transformed_param_19
            lv1780 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv471, lv164, lv165), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv166: R.Tensor((768, 768), dtype="float32") = transformed_param_185
            lv167: R.Tensor((768,), dtype="float32") = transformed_param_17
            lv1781 = R.call_tir(cls.fused_matmul30_add45, (lv471, lv166, lv167), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1782 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1781,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv168: R.Tensor((768, 768), dtype="float32") = transformed_param_186
            lv169: R.Tensor((768,), dtype="float32") = transformed_param_20
            lv1783 = R.call_tir(cls.fused_matmul30_add45, (lv471, lv168, lv169), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1784 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1783,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1785 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1780,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv492 = R.call_tir(cls.matmul31, (lv1785, lv1782), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1786 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv492, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv496 = R.call_tir(cls.softmax6, (lv1786,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv497 = R.call_tir(cls.matmul32, (lv496, lv1784), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1787 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv497,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv170: R.Tensor((768, 768), dtype="float32") = transformed_param_187
            lv171: R.Tensor((768,), dtype="float32") = transformed_param_18
            lv1788 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1787, lv170, lv171, lv1779), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv172: R.Tensor((768,), dtype="float32") = transformed_param_14
            lv173: R.Tensor((768,), dtype="float32") = transformed_param_13
            lv505 = R.call_tir(cls.layer_norm3, (lv1788, lv172, lv173), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv174: R.Tensor((768, 3072), dtype="float32") = transformed_param_188
            lv175: R.Tensor((3072,), dtype="float32") = transformed_param_15
            lv1789 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv505, lv174, lv175), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv176: R.Tensor((3072, 768), dtype="float32") = transformed_param_189
            lv177_1: R.Tensor((768,), dtype="float32") = transformed_param_16
            lv1790 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1789, lv176, lv177_1, lv1788), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv178: R.Tensor((768,), dtype="float32") = transformed_param_22
            lv179: R.Tensor((768,), dtype="float32") = transformed_param_21
            lv516 = R.call_tir(cls.layer_norm3, (lv1790, lv178, lv179), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv180: R.Tensor((768, 768), dtype="float32") = transformed_param_190
            lv181_1: R.Tensor((768,), dtype="float32") = transformed_param_29
            lv1791 = R.call_tir(cls.fused_matmul30_add45_multiply15, (lv516, lv180, lv181_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv182_1: R.Tensor((768, 768), dtype="float32") = transformed_param_191
            lv183: R.Tensor((768,), dtype="float32") = transformed_param_27
            lv1792 = R.call_tir(cls.fused_matmul30_add45, (lv516, lv182_1, lv183), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1793 = R.call_tir(cls.fused_reshape44_transpose38_reshape45_transpose39, (lv1792,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv184: R.Tensor((768, 768), dtype="float32") = transformed_param_192
            lv185: R.Tensor((768,), dtype="float32") = transformed_param_30
            lv1794 = R.call_tir(cls.fused_matmul30_add45, (lv516, lv184, lv185), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv1795 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1794,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1796 = R.call_tir(cls.fused_reshape44_transpose38_reshape45, (lv1791,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv537 = R.call_tir(cls.matmul31, (lv1796, lv1793), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv1797 = R.call_tir(cls.fused_reshape46_add46_reshape47, (lv537, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv541 = R.call_tir(cls.softmax6, (lv1797,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv542 = R.call_tir(cls.matmul32, (lv541, lv1795), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv1798 = R.call_tir(cls.fused_reshape48_transpose40_reshape49, (lv542,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv186: R.Tensor((768, 768), dtype="float32") = transformed_param_193
            lv187: R.Tensor((768,), dtype="float32") = transformed_param_28
            lv1799 = R.call_tir(cls.fused_matmul30_add45_add44, (lv1798, lv186, lv187, lv1790), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv188: R.Tensor((768,), dtype="float32") = transformed_param_24
            lv189: R.Tensor((768,), dtype="float32") = transformed_param_23
            lv550 = R.call_tir(cls.layer_norm3, (lv1799, lv188, lv189), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv190_1: R.Tensor((768, 3072), dtype="float32") = transformed_param_194
            lv191: R.Tensor((3072,), dtype="float32") = transformed_param_25
            lv1800 = R.call_tir(cls.fused_matmul33_add47_multiply16_tir_sigmoid_multiply17, (lv550, lv190_1, lv191), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv192: R.Tensor((3072, 768), dtype="float32") = transformed_param_195
            lv193: R.Tensor((768,), dtype="float32") = transformed_param_26
            lv1801 = R.call_tir(cls.fused_matmul34_add45_add44, (lv1800, lv192, lv193, lv1799), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv194: R.Tensor((768,), dtype="float32") = transformed_param_122
            lv195: R.Tensor((768,), dtype="float32") = transformed_param_121
            lv561 = R.call_tir(cls.layer_norm3, (lv1801, lv194, lv195), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")) = lv1790, lv561
            R.output(gv)
        return gv

    @R.function
    def clip2(inp_0: R.Tensor((1, 77), dtype="int32"), transformed_param_0: R.Tensor((49408, 1280), dtype="float32"), transformed_param_1: R.Tensor((1280,), dtype="float32"), transformed_param_2: R.Tensor((1280,), dtype="float32"), transformed_param_3: R.Tensor((1280,), dtype="float32"), transformed_param_4: R.Tensor((1280,), dtype="float32"), transformed_param_5: R.Tensor((5120,), dtype="float32"), transformed_param_6: R.Tensor((1280,), dtype="float32"), transformed_param_7: R.Tensor((1280,), dtype="float32"), transformed_param_8: R.Tensor((1280,), dtype="float32"), transformed_param_9: R.Tensor((1280,), dtype="float32"), transformed_param_10: R.Tensor((1280,), dtype="float32"), transformed_param_11: R.Tensor((1280,), dtype="float32"), transformed_param_12: R.Tensor((1280,), dtype="float32"), transformed_param_13: R.Tensor((1280,), dtype="float32"), transformed_param_14: R.Tensor((1280,), dtype="float32"), transformed_param_15: R.Tensor((5120,), dtype="float32"), transformed_param_16: R.Tensor((1280,), dtype="float32"), transformed_param_17: R.Tensor((1280,), dtype="float32"), transformed_param_18: R.Tensor((1280,), dtype="float32"), transformed_param_19: R.Tensor((1280,), dtype="float32"), transformed_param_20: R.Tensor((1280,), dtype="float32"), transformed_param_21: R.Tensor((1280,), dtype="float32"), transformed_param_22: R.Tensor((1280,), dtype="float32"), transformed_param_23: R.Tensor((1280,), dtype="float32"), transformed_param_24: R.Tensor((1280,), dtype="float32"), transformed_param_25: R.Tensor((5120,), dtype="float32"), transformed_param_26: R.Tensor((1280,), dtype="float32"), transformed_param_27: R.Tensor((1280,), dtype="float32"), transformed_param_28: R.Tensor((1280,), dtype="float32"), transformed_param_29: R.Tensor((1280,), dtype="float32"), transformed_param_30: R.Tensor((1280,), dtype="float32"), transformed_param_31: R.Tensor((1280,), dtype="float32"), transformed_param_32: R.Tensor((1280,), dtype="float32"), transformed_param_33: R.Tensor((1280,), dtype="float32"), transformed_param_34: R.Tensor((1280,), dtype="float32"), transformed_param_35: R.Tensor((5120,), dtype="float32"), transformed_param_36: R.Tensor((1280,), dtype="float32"), transformed_param_37: R.Tensor((1280,), dtype="float32"), transformed_param_38: R.Tensor((1280,), dtype="float32"), transformed_param_39: R.Tensor((1280,), dtype="float32"), transformed_param_40: R.Tensor((1280,), dtype="float32"), transformed_param_41: R.Tensor((1280,), dtype="float32"), transformed_param_42: R.Tensor((1280,), dtype="float32"), transformed_param_43: R.Tensor((1280,), dtype="float32"), transformed_param_44: R.Tensor((1280,), dtype="float32"), transformed_param_45: R.Tensor((5120,), dtype="float32"), transformed_param_46: R.Tensor((1280,), dtype="float32"), transformed_param_47: R.Tensor((1280,), dtype="float32"), transformed_param_48: R.Tensor((1280,), dtype="float32"), transformed_param_49: R.Tensor((1280,), dtype="float32"), transformed_param_50: R.Tensor((1280,), dtype="float32"), transformed_param_51: R.Tensor((1280,), dtype="float32"), transformed_param_52: R.Tensor((1280,), dtype="float32"), transformed_param_53: R.Tensor((1280,), dtype="float32"), transformed_param_54: R.Tensor((1280,), dtype="float32"), transformed_param_55: R.Tensor((5120,), dtype="float32"), transformed_param_56: R.Tensor((1280,), dtype="float32"), transformed_param_57: R.Tensor((1280,), dtype="float32"), transformed_param_58: R.Tensor((1280,), dtype="float32"), transformed_param_59: R.Tensor((1280,), dtype="float32"), transformed_param_60: R.Tensor((1280,), dtype="float32"), transformed_param_61: R.Tensor((1280,), dtype="float32"), transformed_param_62: R.Tensor((1280,), dtype="float32"), transformed_param_63: R.Tensor((1280,), dtype="float32"), transformed_param_64: R.Tensor((1280,), dtype="float32"), transformed_param_65: R.Tensor((5120,), dtype="float32"), transformed_param_66: R.Tensor((1280,), dtype="float32"), transformed_param_67: R.Tensor((1280,), dtype="float32"), transformed_param_68: R.Tensor((1280,), dtype="float32"), transformed_param_69: R.Tensor((1280,), dtype="float32"), transformed_param_70: R.Tensor((1280,), dtype="float32"), transformed_param_71: R.Tensor((1280,), dtype="float32"), transformed_param_72: R.Tensor((1280,), dtype="float32"), transformed_param_73: R.Tensor((1280,), dtype="float32"), transformed_param_74: R.Tensor((1280,), dtype="float32"), transformed_param_75: R.Tensor((5120,), dtype="float32"), transformed_param_76: R.Tensor((1280,), dtype="float32"), transformed_param_77: R.Tensor((1280,), dtype="float32"), transformed_param_78: R.Tensor((1280,), dtype="float32"), transformed_param_79: R.Tensor((1280,), dtype="float32"), transformed_param_80: R.Tensor((1280,), dtype="float32"), transformed_param_81: R.Tensor((1280,), dtype="float32"), transformed_param_82: R.Tensor((1280,), dtype="float32"), transformed_param_83: R.Tensor((1280,), dtype="float32"), transformed_param_84: R.Tensor((1280,), dtype="float32"), transformed_param_85: R.Tensor((5120,), dtype="float32"), transformed_param_86: R.Tensor((1280,), dtype="float32"), transformed_param_87: R.Tensor((1280,), dtype="float32"), transformed_param_88: R.Tensor((1280,), dtype="float32"), transformed_param_89: R.Tensor((1280,), dtype="float32"), transformed_param_90: R.Tensor((1280,), dtype="float32"), transformed_param_91: R.Tensor((1280,), dtype="float32"), transformed_param_92: R.Tensor((1280,), dtype="float32"), transformed_param_93: R.Tensor((1280,), dtype="float32"), transformed_param_94: R.Tensor((1280,), dtype="float32"), transformed_param_95: R.Tensor((5120,), dtype="float32"), transformed_param_96: R.Tensor((1280,), dtype="float32"), transformed_param_97: R.Tensor((1280,), dtype="float32"), transformed_param_98: R.Tensor((1280,), dtype="float32"), transformed_param_99: R.Tensor((1280,), dtype="float32"), transformed_param_100: R.Tensor((1280,), dtype="float32"), transformed_param_101: R.Tensor((1280,), dtype="float32"), transformed_param_102: R.Tensor((1280,), dtype="float32"), transformed_param_103: R.Tensor((1280,), dtype="float32"), transformed_param_104: R.Tensor((1280,), dtype="float32"), transformed_param_105: R.Tensor((5120,), dtype="float32"), transformed_param_106: R.Tensor((1280,), dtype="float32"), transformed_param_107: R.Tensor((1280,), dtype="float32"), transformed_param_108: R.Tensor((1280,), dtype="float32"), transformed_param_109: R.Tensor((1280,), dtype="float32"), transformed_param_110: R.Tensor((1280,), dtype="float32"), transformed_param_111: R.Tensor((1280,), dtype="float32"), transformed_param_112: R.Tensor((1280,), dtype="float32"), transformed_param_113: R.Tensor((1280,), dtype="float32"), transformed_param_114: R.Tensor((1280,), dtype="float32"), transformed_param_115: R.Tensor((5120,), dtype="float32"), transformed_param_116: R.Tensor((1280,), dtype="float32"), transformed_param_117: R.Tensor((1280,), dtype="float32"), transformed_param_118: R.Tensor((1280,), dtype="float32"), transformed_param_119: R.Tensor((1280,), dtype="float32"), transformed_param_120: R.Tensor((1280,), dtype="float32"), transformed_param_121: R.Tensor((1280,), dtype="float32"), transformed_param_122: R.Tensor((1280,), dtype="float32"), transformed_param_123: R.Tensor((1280,), dtype="float32"), transformed_param_124: R.Tensor((1280,), dtype="float32"), transformed_param_125: R.Tensor((5120,), dtype="float32"), transformed_param_126: R.Tensor((1280,), dtype="float32"), transformed_param_127: R.Tensor((1280,), dtype="float32"), transformed_param_128: R.Tensor((1280,), dtype="float32"), transformed_param_129: R.Tensor((1280,), dtype="float32"), transformed_param_130: R.Tensor((1280,), dtype="float32"), transformed_param_131: R.Tensor((1280,), dtype="float32"), transformed_param_132: R.Tensor((1280,), dtype="float32"), transformed_param_133: R.Tensor((1280,), dtype="float32"), transformed_param_134: R.Tensor((1280,), dtype="float32"), transformed_param_135: R.Tensor((5120,), dtype="float32"), transformed_param_136: R.Tensor((1280,), dtype="float32"), transformed_param_137: R.Tensor((1280,), dtype="float32"), transformed_param_138: R.Tensor((1280,), dtype="float32"), transformed_param_139: R.Tensor((1280,), dtype="float32"), transformed_param_140: R.Tensor((1280,), dtype="float32"), transformed_param_141: R.Tensor((1280,), dtype="float32"), transformed_param_142: R.Tensor((1280,), dtype="float32"), transformed_param_143: R.Tensor((1280,), dtype="float32"), transformed_param_144: R.Tensor((1280,), dtype="float32"), transformed_param_145: R.Tensor((5120,), dtype="float32"), transformed_param_146: R.Tensor((1280,), dtype="float32"), transformed_param_147: R.Tensor((1280,), dtype="float32"), transformed_param_148: R.Tensor((1280,), dtype="float32"), transformed_param_149: R.Tensor((1280,), dtype="float32"), transformed_param_150: R.Tensor((1280,), dtype="float32"), transformed_param_151: R.Tensor((1280,), dtype="float32"), transformed_param_152: R.Tensor((1280,), dtype="float32"), transformed_param_153: R.Tensor((1280,), dtype="float32"), transformed_param_154: R.Tensor((1280,), dtype="float32"), transformed_param_155: R.Tensor((5120,), dtype="float32"), transformed_param_156: R.Tensor((1280,), dtype="float32"), transformed_param_157: R.Tensor((1280,), dtype="float32"), transformed_param_158: R.Tensor((1280,), dtype="float32"), transformed_param_159: R.Tensor((1280,), dtype="float32"), transformed_param_160: R.Tensor((1280,), dtype="float32"), transformed_param_161: R.Tensor((1280,), dtype="float32"), transformed_param_162: R.Tensor((1280,), dtype="float32"), transformed_param_163: R.Tensor((1280,), dtype="float32"), transformed_param_164: R.Tensor((1280,), dtype="float32"), transformed_param_165: R.Tensor((5120,), dtype="float32"), transformed_param_166: R.Tensor((1280,), dtype="float32"), transformed_param_167: R.Tensor((1280,), dtype="float32"), transformed_param_168: R.Tensor((1280,), dtype="float32"), transformed_param_169: R.Tensor((1280,), dtype="float32"), transformed_param_170: R.Tensor((1280,), dtype="float32"), transformed_param_171: R.Tensor((1280,), dtype="float32"), transformed_param_172: R.Tensor((1280,), dtype="float32"), transformed_param_173: R.Tensor((1280,), dtype="float32"), transformed_param_174: R.Tensor((1280,), dtype="float32"), transformed_param_175: R.Tensor((5120,), dtype="float32"), transformed_param_176: R.Tensor((1280,), dtype="float32"), transformed_param_177: R.Tensor((1280,), dtype="float32"), transformed_param_178: R.Tensor((1280,), dtype="float32"), transformed_param_179: R.Tensor((1280,), dtype="float32"), transformed_param_180: R.Tensor((1280,), dtype="float32"), transformed_param_181: R.Tensor((1280,), dtype="float32"), transformed_param_182: R.Tensor((1280,), dtype="float32"), transformed_param_183: R.Tensor((1280,), dtype="float32"), transformed_param_184: R.Tensor((1280,), dtype="float32"), transformed_param_185: R.Tensor((5120,), dtype="float32"), transformed_param_186: R.Tensor((1280,), dtype="float32"), transformed_param_187: R.Tensor((1280,), dtype="float32"), transformed_param_188: R.Tensor((1280,), dtype="float32"), transformed_param_189: R.Tensor((1280,), dtype="float32"), transformed_param_190: R.Tensor((1280,), dtype="float32"), transformed_param_191: R.Tensor((1280,), dtype="float32"), transformed_param_192: R.Tensor((1280,), dtype="float32"), transformed_param_193: R.Tensor((1280,), dtype="float32"), transformed_param_194: R.Tensor((1280,), dtype="float32"), transformed_param_195: R.Tensor((5120,), dtype="float32"), transformed_param_196: R.Tensor((1280,), dtype="float32"), transformed_param_197: R.Tensor((1280,), dtype="float32"), transformed_param_198: R.Tensor((1280,), dtype="float32"), transformed_param_199: R.Tensor((1280,), dtype="float32"), transformed_param_200: R.Tensor((1280,), dtype="float32"), transformed_param_201: R.Tensor((1280,), dtype="float32"), transformed_param_202: R.Tensor((1280,), dtype="float32"), transformed_param_203: R.Tensor((1280,), dtype="float32"), transformed_param_204: R.Tensor((1280,), dtype="float32"), transformed_param_205: R.Tensor((5120,), dtype="float32"), transformed_param_206: R.Tensor((1280,), dtype="float32"), transformed_param_207: R.Tensor((1280,), dtype="float32"), transformed_param_208: R.Tensor((1280,), dtype="float32"), transformed_param_209: R.Tensor((1280,), dtype="float32"), transformed_param_210: R.Tensor((1280,), dtype="float32"), transformed_param_211: R.Tensor((1280,), dtype="float32"), transformed_param_212: R.Tensor((1280,), dtype="float32"), transformed_param_213: R.Tensor((1280,), dtype="float32"), transformed_param_214: R.Tensor((1280,), dtype="float32"), transformed_param_215: R.Tensor((5120,), dtype="float32"), transformed_param_216: R.Tensor((1280,), dtype="float32"), transformed_param_217: R.Tensor((1280,), dtype="float32"), transformed_param_218: R.Tensor((1280,), dtype="float32"), transformed_param_219: R.Tensor((1280,), dtype="float32"), transformed_param_220: R.Tensor((1280,), dtype="float32"), transformed_param_221: R.Tensor((1280,), dtype="float32"), transformed_param_222: R.Tensor((1280,), dtype="float32"), transformed_param_223: R.Tensor((1280,), dtype="float32"), transformed_param_224: R.Tensor((1280,), dtype="float32"), transformed_param_225: R.Tensor((5120,), dtype="float32"), transformed_param_226: R.Tensor((1280,), dtype="float32"), transformed_param_227: R.Tensor((1280,), dtype="float32"), transformed_param_228: R.Tensor((1280,), dtype="float32"), transformed_param_229: R.Tensor((1280,), dtype="float32"), transformed_param_230: R.Tensor((1280,), dtype="float32"), transformed_param_231: R.Tensor((1280,), dtype="float32"), transformed_param_232: R.Tensor((1280,), dtype="float32"), transformed_param_233: R.Tensor((1280,), dtype="float32"), transformed_param_234: R.Tensor((1280,), dtype="float32"), transformed_param_235: R.Tensor((5120,), dtype="float32"), transformed_param_236: R.Tensor((1280,), dtype="float32"), transformed_param_237: R.Tensor((1280,), dtype="float32"), transformed_param_238: R.Tensor((1280,), dtype="float32"), transformed_param_239: R.Tensor((1280,), dtype="float32"), transformed_param_240: R.Tensor((1280,), dtype="float32"), transformed_param_241: R.Tensor((1280,), dtype="float32"), transformed_param_242: R.Tensor((1280,), dtype="float32"), transformed_param_243: R.Tensor((1280,), dtype="float32"), transformed_param_244: R.Tensor((1280,), dtype="float32"), transformed_param_245: R.Tensor((5120,), dtype="float32"), transformed_param_246: R.Tensor((1280,), dtype="float32"), transformed_param_247: R.Tensor((1280,), dtype="float32"), transformed_param_248: R.Tensor((1280,), dtype="float32"), transformed_param_249: R.Tensor((1280,), dtype="float32"), transformed_param_250: R.Tensor((1280,), dtype="float32"), transformed_param_251: R.Tensor((1280,), dtype="float32"), transformed_param_252: R.Tensor((1280,), dtype="float32"), transformed_param_253: R.Tensor((1280,), dtype="float32"), transformed_param_254: R.Tensor((1280,), dtype="float32"), transformed_param_255: R.Tensor((5120,), dtype="float32"), transformed_param_256: R.Tensor((1280,), dtype="float32"), transformed_param_257: R.Tensor((1280,), dtype="float32"), transformed_param_258: R.Tensor((1280,), dtype="float32"), transformed_param_259: R.Tensor((1280,), dtype="float32"), transformed_param_260: R.Tensor((1280,), dtype="float32"), transformed_param_261: R.Tensor((1280,), dtype="float32"), transformed_param_262: R.Tensor((1280,), dtype="float32"), transformed_param_263: R.Tensor((1280,), dtype="float32"), transformed_param_264: R.Tensor((1280,), dtype="float32"), transformed_param_265: R.Tensor((5120,), dtype="float32"), transformed_param_266: R.Tensor((1280,), dtype="float32"), transformed_param_267: R.Tensor((1280,), dtype="float32"), transformed_param_268: R.Tensor((1280,), dtype="float32"), transformed_param_269: R.Tensor((1280,), dtype="float32"), transformed_param_270: R.Tensor((1280,), dtype="float32"), transformed_param_271: R.Tensor((1280,), dtype="float32"), transformed_param_272: R.Tensor((1280,), dtype="float32"), transformed_param_273: R.Tensor((1280,), dtype="float32"), transformed_param_274: R.Tensor((1280,), dtype="float32"), transformed_param_275: R.Tensor((5120,), dtype="float32"), transformed_param_276: R.Tensor((1280,), dtype="float32"), transformed_param_277: R.Tensor((1280,), dtype="float32"), transformed_param_278: R.Tensor((1280,), dtype="float32"), transformed_param_279: R.Tensor((1280,), dtype="float32"), transformed_param_280: R.Tensor((1280,), dtype="float32"), transformed_param_281: R.Tensor((1280,), dtype="float32"), transformed_param_282: R.Tensor((1280,), dtype="float32"), transformed_param_283: R.Tensor((1280,), dtype="float32"), transformed_param_284: R.Tensor((1280,), dtype="float32"), transformed_param_285: R.Tensor((5120,), dtype="float32"), transformed_param_286: R.Tensor((1280,), dtype="float32"), transformed_param_287: R.Tensor((1280,), dtype="float32"), transformed_param_288: R.Tensor((1280,), dtype="float32"), transformed_param_289: R.Tensor((1280,), dtype="float32"), transformed_param_290: R.Tensor((1280,), dtype="float32"), transformed_param_291: R.Tensor((1280,), dtype="float32"), transformed_param_292: R.Tensor((1280,), dtype="float32"), transformed_param_293: R.Tensor((1280,), dtype="float32"), transformed_param_294: R.Tensor((1280,), dtype="float32"), transformed_param_295: R.Tensor((5120,), dtype="float32"), transformed_param_296: R.Tensor((1280,), dtype="float32"), transformed_param_297: R.Tensor((1280,), dtype="float32"), transformed_param_298: R.Tensor((1280,), dtype="float32"), transformed_param_299: R.Tensor((1280,), dtype="float32"), transformed_param_300: R.Tensor((1280,), dtype="float32"), transformed_param_301: R.Tensor((1280,), dtype="float32"), transformed_param_302: R.Tensor((1280,), dtype="float32"), transformed_param_303: R.Tensor((1280,), dtype="float32"), transformed_param_304: R.Tensor((1280,), dtype="float32"), transformed_param_305: R.Tensor((5120,), dtype="float32"), transformed_param_306: R.Tensor((1280,), dtype="float32"), transformed_param_307: R.Tensor((1280,), dtype="float32"), transformed_param_308: R.Tensor((1280,), dtype="float32"), transformed_param_309: R.Tensor((1280,), dtype="float32"), transformed_param_310: R.Tensor((1280,), dtype="float32"), transformed_param_311: R.Tensor((1280,), dtype="float32"), transformed_param_312: R.Tensor((1280,), dtype="float32"), transformed_param_313: R.Tensor((1280,), dtype="float32"), transformed_param_314: R.Tensor((1280,), dtype="float32"), transformed_param_315: R.Tensor((5120,), dtype="float32"), transformed_param_316: R.Tensor((1280,), dtype="float32"), transformed_param_317: R.Tensor((1280,), dtype="float32"), transformed_param_318: R.Tensor((1280,), dtype="float32"), transformed_param_319: R.Tensor((1280,), dtype="float32"), transformed_param_320: R.Tensor((1280,), dtype="float32"), transformed_param_321: R.Tensor((1280,), dtype="float32"), transformed_param_322: R.Tensor((1280,), dtype="float32"), transformed_param_323: R.Tensor((77, 1280), dtype="float32"), transformed_param_324: R.Tensor((1280, 1280), dtype="float32"), transformed_param_325: R.Tensor((1280, 1280), dtype="float32"), transformed_param_326: R.Tensor((1280, 1280), dtype="float32"), transformed_param_327: R.Tensor((1280, 1280), dtype="float32"), transformed_param_328: R.Tensor((1280, 5120), dtype="float32"), transformed_param_329: R.Tensor((5120, 1280), dtype="float32"), transformed_param_330: R.Tensor((1280, 1280), dtype="float32"), transformed_param_331: R.Tensor((1280, 1280), dtype="float32"), transformed_param_332: R.Tensor((1280, 1280), dtype="float32"), transformed_param_333: R.Tensor((1280, 1280), dtype="float32"), transformed_param_334: R.Tensor((1280, 5120), dtype="float32"), transformed_param_335: R.Tensor((5120, 1280), dtype="float32"), transformed_param_336: R.Tensor((1280, 1280), dtype="float32"), transformed_param_337: R.Tensor((1280, 1280), dtype="float32"), transformed_param_338: R.Tensor((1280, 1280), dtype="float32"), transformed_param_339: R.Tensor((1280, 1280), dtype="float32"), transformed_param_340: R.Tensor((1280, 5120), dtype="float32"), transformed_param_341: R.Tensor((5120, 1280), dtype="float32"), transformed_param_342: R.Tensor((1280, 1280), dtype="float32"), transformed_param_343: R.Tensor((1280, 1280), dtype="float32"), transformed_param_344: R.Tensor((1280, 1280), dtype="float32"), transformed_param_345: R.Tensor((1280, 1280), dtype="float32"), transformed_param_346: R.Tensor((1280, 5120), dtype="float32"), transformed_param_347: R.Tensor((5120, 1280), dtype="float32"), transformed_param_348: R.Tensor((1280, 1280), dtype="float32"), transformed_param_349: R.Tensor((1280, 1280), dtype="float32"), transformed_param_350: R.Tensor((1280, 1280), dtype="float32"), transformed_param_351: R.Tensor((1280, 1280), dtype="float32"), transformed_param_352: R.Tensor((1280, 5120), dtype="float32"), transformed_param_353: R.Tensor((5120, 1280), dtype="float32"), transformed_param_354: R.Tensor((1280, 1280), dtype="float32"), transformed_param_355: R.Tensor((1280, 1280), dtype="float32"), transformed_param_356: R.Tensor((1280, 1280), dtype="float32"), transformed_param_357: R.Tensor((1280, 1280), dtype="float32"), transformed_param_358: R.Tensor((1280, 5120), dtype="float32"), transformed_param_359: R.Tensor((5120, 1280), dtype="float32"), transformed_param_360: R.Tensor((1280, 1280), dtype="float32"), transformed_param_361: R.Tensor((1280, 1280), dtype="float32"), transformed_param_362: R.Tensor((1280, 1280), dtype="float32"), transformed_param_363: R.Tensor((1280, 1280), dtype="float32"), transformed_param_364: R.Tensor((1280, 5120), dtype="float32"), transformed_param_365: R.Tensor((5120, 1280), dtype="float32"), transformed_param_366: R.Tensor((1280, 1280), dtype="float32"), transformed_param_367: R.Tensor((1280, 1280), dtype="float32"), transformed_param_368: R.Tensor((1280, 1280), dtype="float32"), transformed_param_369: R.Tensor((1280, 1280), dtype="float32"), transformed_param_370: R.Tensor((1280, 5120), dtype="float32"), transformed_param_371: R.Tensor((5120, 1280), dtype="float32"), transformed_param_372: R.Tensor((1280, 1280), dtype="float32"), transformed_param_373: R.Tensor((1280, 1280), dtype="float32"), transformed_param_374: R.Tensor((1280, 1280), dtype="float32"), transformed_param_375: R.Tensor((1280, 1280), dtype="float32"), transformed_param_376: R.Tensor((1280, 5120), dtype="float32"), transformed_param_377: R.Tensor((5120, 1280), dtype="float32"), transformed_param_378: R.Tensor((1280, 1280), dtype="float32"), transformed_param_379: R.Tensor((1280, 1280), dtype="float32"), transformed_param_380: R.Tensor((1280, 1280), dtype="float32"), transformed_param_381: R.Tensor((1280, 1280), dtype="float32"), transformed_param_382: R.Tensor((1280, 5120), dtype="float32"), transformed_param_383: R.Tensor((5120, 1280), dtype="float32"), transformed_param_384: R.Tensor((1280, 1280), dtype="float32"), transformed_param_385: R.Tensor((1280, 1280), dtype="float32"), transformed_param_386: R.Tensor((1280, 1280), dtype="float32"), transformed_param_387: R.Tensor((1280, 1280), dtype="float32"), transformed_param_388: R.Tensor((1280, 5120), dtype="float32"), transformed_param_389: R.Tensor((5120, 1280), dtype="float32"), transformed_param_390: R.Tensor((1280, 1280), dtype="float32"), transformed_param_391: R.Tensor((1280, 1280), dtype="float32"), transformed_param_392: R.Tensor((1280, 1280), dtype="float32"), transformed_param_393: R.Tensor((1280, 1280), dtype="float32"), transformed_param_394: R.Tensor((1280, 5120), dtype="float32"), transformed_param_395: R.Tensor((5120, 1280), dtype="float32"), transformed_param_396: R.Tensor((1280, 1280), dtype="float32"), transformed_param_397: R.Tensor((1280, 1280), dtype="float32"), transformed_param_398: R.Tensor((1280, 1280), dtype="float32"), transformed_param_399: R.Tensor((1280, 1280), dtype="float32"), transformed_param_400: R.Tensor((1280, 5120), dtype="float32"), transformed_param_401: R.Tensor((5120, 1280), dtype="float32"), transformed_param_402: R.Tensor((1280, 1280), dtype="float32"), transformed_param_403: R.Tensor((1280, 1280), dtype="float32"), transformed_param_404: R.Tensor((1280, 1280), dtype="float32"), transformed_param_405: R.Tensor((1280, 1280), dtype="float32"), transformed_param_406: R.Tensor((1280, 5120), dtype="float32"), transformed_param_407: R.Tensor((5120, 1280), dtype="float32"), transformed_param_408: R.Tensor((1280, 1280), dtype="float32"), transformed_param_409: R.Tensor((1280, 1280), dtype="float32"), transformed_param_410: R.Tensor((1280, 1280), dtype="float32"), transformed_param_411: R.Tensor((1280, 1280), dtype="float32"), transformed_param_412: R.Tensor((1280, 5120), dtype="float32"), transformed_param_413: R.Tensor((5120, 1280), dtype="float32"), transformed_param_414: R.Tensor((1280, 1280), dtype="float32"), transformed_param_415: R.Tensor((1280, 1280), dtype="float32"), transformed_param_416: R.Tensor((1280, 1280), dtype="float32"), transformed_param_417: R.Tensor((1280, 1280), dtype="float32"), transformed_param_418: R.Tensor((1280, 5120), dtype="float32"), transformed_param_419: R.Tensor((5120, 1280), dtype="float32"), transformed_param_420: R.Tensor((1280, 1280), dtype="float32"), transformed_param_421: R.Tensor((1280, 1280), dtype="float32"), transformed_param_422: R.Tensor((1280, 1280), dtype="float32"), transformed_param_423: R.Tensor((1280, 1280), dtype="float32"), transformed_param_424: R.Tensor((1280, 5120), dtype="float32"), transformed_param_425: R.Tensor((5120, 1280), dtype="float32"), transformed_param_426: R.Tensor((1280, 1280), dtype="float32"), transformed_param_427: R.Tensor((1280, 1280), dtype="float32"), transformed_param_428: R.Tensor((1280, 1280), dtype="float32"), transformed_param_429: R.Tensor((1280, 1280), dtype="float32"), transformed_param_430: R.Tensor((1280, 5120), dtype="float32"), transformed_param_431: R.Tensor((5120, 1280), dtype="float32"), transformed_param_432: R.Tensor((1280, 1280), dtype="float32"), transformed_param_433: R.Tensor((1280, 1280), dtype="float32"), transformed_param_434: R.Tensor((1280, 1280), dtype="float32"), transformed_param_435: R.Tensor((1280, 1280), dtype="float32"), transformed_param_436: R.Tensor((1280, 5120), dtype="float32"), transformed_param_437: R.Tensor((5120, 1280), dtype="float32"), transformed_param_438: R.Tensor((1280, 1280), dtype="float32"), transformed_param_439: R.Tensor((1280, 1280), dtype="float32"), transformed_param_440: R.Tensor((1280, 1280), dtype="float32"), transformed_param_441: R.Tensor((1280, 1280), dtype="float32"), transformed_param_442: R.Tensor((1280, 5120), dtype="float32"), transformed_param_443: R.Tensor((5120, 1280), dtype="float32"), transformed_param_444: R.Tensor((1280, 1280), dtype="float32"), transformed_param_445: R.Tensor((1280, 1280), dtype="float32"), transformed_param_446: R.Tensor((1280, 1280), dtype="float32"), transformed_param_447: R.Tensor((1280, 1280), dtype="float32"), transformed_param_448: R.Tensor((1280, 5120), dtype="float32"), transformed_param_449: R.Tensor((5120, 1280), dtype="float32"), transformed_param_450: R.Tensor((1280, 1280), dtype="float32"), transformed_param_451: R.Tensor((1280, 1280), dtype="float32"), transformed_param_452: R.Tensor((1280, 1280), dtype="float32"), transformed_param_453: R.Tensor((1280, 1280), dtype="float32"), transformed_param_454: R.Tensor((1280, 5120), dtype="float32"), transformed_param_455: R.Tensor((5120, 1280), dtype="float32"), transformed_param_456: R.Tensor((1280, 1280), dtype="float32"), transformed_param_457: R.Tensor((1280, 1280), dtype="float32"), transformed_param_458: R.Tensor((1280, 1280), dtype="float32"), transformed_param_459: R.Tensor((1280, 1280), dtype="float32"), transformed_param_460: R.Tensor((1280, 5120), dtype="float32"), transformed_param_461: R.Tensor((5120, 1280), dtype="float32"), transformed_param_462: R.Tensor((1280, 1280), dtype="float32"), transformed_param_463: R.Tensor((1280, 1280), dtype="float32"), transformed_param_464: R.Tensor((1280, 1280), dtype="float32"), transformed_param_465: R.Tensor((1280, 1280), dtype="float32"), transformed_param_466: R.Tensor((1280, 5120), dtype="float32"), transformed_param_467: R.Tensor((5120, 1280), dtype="float32"), transformed_param_468: R.Tensor((1280, 1280), dtype="float32"), transformed_param_469: R.Tensor((1280, 1280), dtype="float32"), transformed_param_470: R.Tensor((1280, 1280), dtype="float32"), transformed_param_471: R.Tensor((1280, 1280), dtype="float32"), transformed_param_472: R.Tensor((1280, 5120), dtype="float32"), transformed_param_473: R.Tensor((5120, 1280), dtype="float32"), transformed_param_474: R.Tensor((1280, 1280), dtype="float32"), transformed_param_475: R.Tensor((1280, 1280), dtype="float32"), transformed_param_476: R.Tensor((1280, 1280), dtype="float32"), transformed_param_477: R.Tensor((1280, 1280), dtype="float32"), transformed_param_478: R.Tensor((1280, 5120), dtype="float32"), transformed_param_479: R.Tensor((5120, 1280), dtype="float32"), transformed_param_480: R.Tensor((1280, 1280), dtype="float32"), transformed_param_481: R.Tensor((1280, 1280), dtype="float32"), transformed_param_482: R.Tensor((1280, 1280), dtype="float32"), transformed_param_483: R.Tensor((1280, 1280), dtype="float32"), transformed_param_484: R.Tensor((1280, 5120), dtype="float32"), transformed_param_485: R.Tensor((5120, 1280), dtype="float32"), transformed_param_486: R.Tensor((1280, 1280), dtype="float32"), transformed_param_487: R.Tensor((1280, 1280), dtype="float32"), transformed_param_488: R.Tensor((1280, 1280), dtype="float32"), transformed_param_489: R.Tensor((1280, 1280), dtype="float32"), transformed_param_490: R.Tensor((1280, 5120), dtype="float32"), transformed_param_491: R.Tensor((5120, 1280), dtype="float32"), transformed_param_492: R.Tensor((1280, 1280), dtype="float32"), transformed_param_493: R.Tensor((1280, 1280), dtype="float32"), transformed_param_494: R.Tensor((1280, 1280), dtype="float32"), transformed_param_495: R.Tensor((1280, 1280), dtype="float32"), transformed_param_496: R.Tensor((1280, 5120), dtype="float32"), transformed_param_497: R.Tensor((5120, 1280), dtype="float32"), transformed_param_498: R.Tensor((1280, 1280), dtype="float32"), transformed_param_499: R.Tensor((1280, 1280), dtype="float32"), transformed_param_500: R.Tensor((1280, 1280), dtype="float32"), transformed_param_501: R.Tensor((1280, 1280), dtype="float32"), transformed_param_502: R.Tensor((1280, 5120), dtype="float32"), transformed_param_503: R.Tensor((5120, 1280), dtype="float32"), transformed_param_504: R.Tensor((1280, 1280), dtype="float32"), transformed_param_505: R.Tensor((1280, 1280), dtype="float32"), transformed_param_506: R.Tensor((1280, 1280), dtype="float32"), transformed_param_507: R.Tensor((1280, 1280), dtype="float32"), transformed_param_508: R.Tensor((1280, 5120), dtype="float32"), transformed_param_509: R.Tensor((5120, 1280), dtype="float32"), transformed_param_510: R.Tensor((1280, 1280), dtype="float32"), transformed_param_511: R.Tensor((1280, 1280), dtype="float32"), transformed_param_512: R.Tensor((1280, 1280), dtype="float32"), transformed_param_513: R.Tensor((1280, 1280), dtype="float32"), transformed_param_514: R.Tensor((1280, 5120), dtype="float32"), transformed_param_515: R.Tensor((5120, 1280), dtype="float32"), transformed_param_516: R.Tensor((1280, 1280), dtype="float32")) -> R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.reshape, (inp_0,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv1281 = R.call_tir(cls.fused_cast_reshape1, (lv,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv196: R.Tensor((49408, 1280), dtype="float32") = transformed_param_0
            lv3 = R.call_tir(cls.take, (lv196, lv1281), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv197: R.Tensor((77, 1280), dtype="float32") = transformed_param_323
            lv1282 = R.call_tir(cls.fused_reshape2_reshape2_add, (lv3, lv197), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv198: R.Tensor((1280,), dtype="float32") = transformed_param_2
            lv199: R.Tensor((1280,), dtype="float32") = transformed_param_1
            lv21 = R.call_tir(cls.layer_norm, (lv1282, lv198, lv199), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv200: R.Tensor((1280, 1280), dtype="float32") = transformed_param_324
            lv201: R.Tensor((1280,), dtype="float32") = transformed_param_9
            lv1283 = R.call_tir(cls.fused_matmul_add2_multiply, (lv21, lv200, lv201), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv202: R.Tensor((1280, 1280), dtype="float32") = transformed_param_325
            lv203: R.Tensor((1280,), dtype="float32") = transformed_param_7
            lv1284 = R.call_tir(cls.fused_matmul_add2, (lv21, lv202, lv203), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1285 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1284,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv204: R.Tensor((1280, 1280), dtype="float32") = transformed_param_326
            lv205: R.Tensor((1280,), dtype="float32") = transformed_param_10
            lv1286 = R.call_tir(cls.fused_matmul_add2, (lv21, lv204, lv205), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1287 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1286,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1288 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1283,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul1, (lv1288, lv1285), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1289 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv42, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax, (lv1289,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1290 = R.call_tir(cls.fused_reshape7_reshape8, (lv46,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv49 = R.call_tir(cls.matmul2, (lv1290, lv1287), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1291 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv49,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv206: R.Tensor((1280, 1280), dtype="float32") = transformed_param_327
            lv207: R.Tensor((1280,), dtype="float32") = transformed_param_8
            lv1292 = R.call_tir(cls.fused_matmul_add2_add, (lv1291, lv206, lv207, lv1282), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv208: R.Tensor((1280,), dtype="float32") = transformed_param_4
            lv209: R.Tensor((1280,), dtype="float32") = transformed_param_3
            lv57 = R.call_tir(cls.layer_norm, (lv1292, lv208, lv209), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv210: R.Tensor((1280, 5120), dtype="float32") = transformed_param_328
            lv211: R.Tensor((5120,), dtype="float32") = transformed_param_5
            lv1293 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv57, lv210, lv211), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv212: R.Tensor((5120, 1280), dtype="float32") = transformed_param_329
            lv213: R.Tensor((1280,), dtype="float32") = transformed_param_6
            lv1294 = R.call_tir(cls.fused_matmul4_add2_add, (lv1293, lv212, lv213, lv1292), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv214: R.Tensor((1280,), dtype="float32") = transformed_param_112
            lv215: R.Tensor((1280,), dtype="float32") = transformed_param_111
            lv66 = R.call_tir(cls.layer_norm, (lv1294, lv214, lv215), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv216: R.Tensor((1280, 1280), dtype="float32") = transformed_param_330
            lv217: R.Tensor((1280,), dtype="float32") = transformed_param_119
            lv1295 = R.call_tir(cls.fused_matmul_add2_multiply, (lv66, lv216, lv217), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv218: R.Tensor((1280, 1280), dtype="float32") = transformed_param_331
            lv219: R.Tensor((1280,), dtype="float32") = transformed_param_117
            lv1296 = R.call_tir(cls.fused_matmul_add2, (lv66, lv218, lv219), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1297 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1296,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv220: R.Tensor((1280, 1280), dtype="float32") = transformed_param_332
            lv221: R.Tensor((1280,), dtype="float32") = transformed_param_120
            lv1298 = R.call_tir(cls.fused_matmul_add2, (lv66, lv220, lv221), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1299 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1298,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1300 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1295,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul1, (lv1300, lv1297), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1301 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv87, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax, (lv1301,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1302 = R.call_tir(cls.fused_reshape7_reshape8, (lv91,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv94 = R.call_tir(cls.matmul2, (lv1302, lv1299), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1303 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv94,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv222: R.Tensor((1280, 1280), dtype="float32") = transformed_param_333
            lv223: R.Tensor((1280,), dtype="float32") = transformed_param_118
            lv1304 = R.call_tir(cls.fused_matmul_add2_add, (lv1303, lv222, lv223, lv1294), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv224: R.Tensor((1280,), dtype="float32") = transformed_param_114
            lv225: R.Tensor((1280,), dtype="float32") = transformed_param_113
            lv102 = R.call_tir(cls.layer_norm, (lv1304, lv224, lv225), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv226: R.Tensor((1280, 5120), dtype="float32") = transformed_param_334
            lv227: R.Tensor((5120,), dtype="float32") = transformed_param_115
            lv1305 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv102, lv226, lv227), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv228: R.Tensor((5120, 1280), dtype="float32") = transformed_param_335
            lv229: R.Tensor((1280,), dtype="float32") = transformed_param_116
            lv1306 = R.call_tir(cls.fused_matmul4_add2_add, (lv1305, lv228, lv229, lv1304), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv230: R.Tensor((1280,), dtype="float32") = transformed_param_222
            lv231: R.Tensor((1280,), dtype="float32") = transformed_param_221
            lv111 = R.call_tir(cls.layer_norm, (lv1306, lv230, lv231), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv232: R.Tensor((1280, 1280), dtype="float32") = transformed_param_336
            lv233: R.Tensor((1280,), dtype="float32") = transformed_param_229
            lv1307 = R.call_tir(cls.fused_matmul_add2_multiply, (lv111, lv232, lv233), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv234: R.Tensor((1280, 1280), dtype="float32") = transformed_param_337
            lv235: R.Tensor((1280,), dtype="float32") = transformed_param_227
            lv1308 = R.call_tir(cls.fused_matmul_add2, (lv111, lv234, lv235), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1309 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1308,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv236: R.Tensor((1280, 1280), dtype="float32") = transformed_param_338
            lv237: R.Tensor((1280,), dtype="float32") = transformed_param_230
            lv1310 = R.call_tir(cls.fused_matmul_add2, (lv111, lv236, lv237), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1311 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1310,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1312 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1307,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul1, (lv1312, lv1309), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1313 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv132, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax, (lv1313,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1314 = R.call_tir(cls.fused_reshape7_reshape8, (lv136,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv139 = R.call_tir(cls.matmul2, (lv1314, lv1311), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1315 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv139,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv238: R.Tensor((1280, 1280), dtype="float32") = transformed_param_339
            lv239: R.Tensor((1280,), dtype="float32") = transformed_param_228
            lv1316 = R.call_tir(cls.fused_matmul_add2_add, (lv1315, lv238, lv239, lv1306), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv240: R.Tensor((1280,), dtype="float32") = transformed_param_224
            lv241: R.Tensor((1280,), dtype="float32") = transformed_param_223
            lv147 = R.call_tir(cls.layer_norm, (lv1316, lv240, lv241), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv242: R.Tensor((1280, 5120), dtype="float32") = transformed_param_340
            lv243: R.Tensor((5120,), dtype="float32") = transformed_param_225
            lv1317 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv147, lv242, lv243), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv244: R.Tensor((5120, 1280), dtype="float32") = transformed_param_341
            lv245: R.Tensor((1280,), dtype="float32") = transformed_param_226
            lv1318 = R.call_tir(cls.fused_matmul4_add2_add, (lv1317, lv244, lv245, lv1316), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv246: R.Tensor((1280,), dtype="float32") = transformed_param_252
            lv247: R.Tensor((1280,), dtype="float32") = transformed_param_251
            lv156 = R.call_tir(cls.layer_norm, (lv1318, lv246, lv247), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv248: R.Tensor((1280, 1280), dtype="float32") = transformed_param_342
            lv249: R.Tensor((1280,), dtype="float32") = transformed_param_259
            lv1319 = R.call_tir(cls.fused_matmul_add2_multiply, (lv156, lv248, lv249), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv250: R.Tensor((1280, 1280), dtype="float32") = transformed_param_343
            lv251: R.Tensor((1280,), dtype="float32") = transformed_param_257
            lv1320 = R.call_tir(cls.fused_matmul_add2, (lv156, lv250, lv251), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1321 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1320,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv252: R.Tensor((1280, 1280), dtype="float32") = transformed_param_344
            lv253: R.Tensor((1280,), dtype="float32") = transformed_param_260
            lv1322 = R.call_tir(cls.fused_matmul_add2, (lv156, lv252, lv253), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1323 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1322,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1324 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1319,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv177 = R.call_tir(cls.matmul1, (lv1324, lv1321), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1325 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv177, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv181 = R.call_tir(cls.softmax, (lv1325,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1326 = R.call_tir(cls.fused_reshape7_reshape8, (lv181,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv184 = R.call_tir(cls.matmul2, (lv1326, lv1323), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1327 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv184,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv254: R.Tensor((1280, 1280), dtype="float32") = transformed_param_345
            lv255: R.Tensor((1280,), dtype="float32") = transformed_param_258
            lv1328 = R.call_tir(cls.fused_matmul_add2_add, (lv1327, lv254, lv255, lv1318), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv256: R.Tensor((1280,), dtype="float32") = transformed_param_254
            lv257: R.Tensor((1280,), dtype="float32") = transformed_param_253
            lv192 = R.call_tir(cls.layer_norm, (lv1328, lv256, lv257), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv258: R.Tensor((1280, 5120), dtype="float32") = transformed_param_346
            lv259: R.Tensor((5120,), dtype="float32") = transformed_param_255
            lv1329 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv192, lv258, lv259), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv260: R.Tensor((5120, 1280), dtype="float32") = transformed_param_347
            lv261: R.Tensor((1280,), dtype="float32") = transformed_param_256
            lv1330 = R.call_tir(cls.fused_matmul4_add2_add, (lv1329, lv260, lv261, lv1328), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv262: R.Tensor((1280,), dtype="float32") = transformed_param_262
            lv263: R.Tensor((1280,), dtype="float32") = transformed_param_261
            lv201_1 = R.call_tir(cls.layer_norm, (lv1330, lv262, lv263), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv264: R.Tensor((1280, 1280), dtype="float32") = transformed_param_348
            lv265: R.Tensor((1280,), dtype="float32") = transformed_param_269
            lv1331 = R.call_tir(cls.fused_matmul_add2_multiply, (lv201_1, lv264, lv265), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv266: R.Tensor((1280, 1280), dtype="float32") = transformed_param_349
            lv267: R.Tensor((1280,), dtype="float32") = transformed_param_267
            lv1332 = R.call_tir(cls.fused_matmul_add2, (lv201_1, lv266, lv267), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1333 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1332,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv268: R.Tensor((1280, 1280), dtype="float32") = transformed_param_350
            lv269: R.Tensor((1280,), dtype="float32") = transformed_param_270
            lv1334 = R.call_tir(cls.fused_matmul_add2, (lv201_1, lv268, lv269), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1335 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1334,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1336 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1331,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv222_1 = R.call_tir(cls.matmul1, (lv1336, lv1333), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1337 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv222_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv226_1 = R.call_tir(cls.softmax, (lv1337,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1338 = R.call_tir(cls.fused_reshape7_reshape8, (lv226_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv229_1 = R.call_tir(cls.matmul2, (lv1338, lv1335), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1339 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv229_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv270: R.Tensor((1280, 1280), dtype="float32") = transformed_param_351
            lv271: R.Tensor((1280,), dtype="float32") = transformed_param_268
            lv1340 = R.call_tir(cls.fused_matmul_add2_add, (lv1339, lv270, lv271, lv1330), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv272: R.Tensor((1280,), dtype="float32") = transformed_param_264
            lv273: R.Tensor((1280,), dtype="float32") = transformed_param_263
            lv237_1 = R.call_tir(cls.layer_norm, (lv1340, lv272, lv273), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv274: R.Tensor((1280, 5120), dtype="float32") = transformed_param_352
            lv275: R.Tensor((5120,), dtype="float32") = transformed_param_265
            lv1341 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv237_1, lv274, lv275), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv276: R.Tensor((5120, 1280), dtype="float32") = transformed_param_353
            lv277: R.Tensor((1280,), dtype="float32") = transformed_param_266
            lv1342 = R.call_tir(cls.fused_matmul4_add2_add, (lv1341, lv276, lv277, lv1340), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv278: R.Tensor((1280,), dtype="float32") = transformed_param_272
            lv279: R.Tensor((1280,), dtype="float32") = transformed_param_271
            lv246_1 = R.call_tir(cls.layer_norm, (lv1342, lv278, lv279), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv280: R.Tensor((1280, 1280), dtype="float32") = transformed_param_354
            lv281: R.Tensor((1280,), dtype="float32") = transformed_param_279
            lv1343 = R.call_tir(cls.fused_matmul_add2_multiply, (lv246_1, lv280, lv281), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv282: R.Tensor((1280, 1280), dtype="float32") = transformed_param_355
            lv283: R.Tensor((1280,), dtype="float32") = transformed_param_277
            lv1344 = R.call_tir(cls.fused_matmul_add2, (lv246_1, lv282, lv283), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1345 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1344,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv284: R.Tensor((1280, 1280), dtype="float32") = transformed_param_356
            lv285: R.Tensor((1280,), dtype="float32") = transformed_param_280
            lv1346 = R.call_tir(cls.fused_matmul_add2, (lv246_1, lv284, lv285), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1347 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1346,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1348 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1343,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv267_1 = R.call_tir(cls.matmul1, (lv1348, lv1345), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1349 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv267_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv271_1 = R.call_tir(cls.softmax, (lv1349,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1350 = R.call_tir(cls.fused_reshape7_reshape8, (lv271_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv274_1 = R.call_tir(cls.matmul2, (lv1350, lv1347), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1351 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv274_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv286: R.Tensor((1280, 1280), dtype="float32") = transformed_param_357
            lv287: R.Tensor((1280,), dtype="float32") = transformed_param_278
            lv1352 = R.call_tir(cls.fused_matmul_add2_add, (lv1351, lv286, lv287, lv1342), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv288: R.Tensor((1280,), dtype="float32") = transformed_param_274
            lv289: R.Tensor((1280,), dtype="float32") = transformed_param_273
            lv282_1 = R.call_tir(cls.layer_norm, (lv1352, lv288, lv289), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv290: R.Tensor((1280, 5120), dtype="float32") = transformed_param_358
            lv291: R.Tensor((5120,), dtype="float32") = transformed_param_275
            lv1353 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv282_1, lv290, lv291), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv292: R.Tensor((5120, 1280), dtype="float32") = transformed_param_359
            lv293: R.Tensor((1280,), dtype="float32") = transformed_param_276
            lv1354 = R.call_tir(cls.fused_matmul4_add2_add, (lv1353, lv292, lv293, lv1352), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv294: R.Tensor((1280,), dtype="float32") = transformed_param_282
            lv295: R.Tensor((1280,), dtype="float32") = transformed_param_281
            lv291_1 = R.call_tir(cls.layer_norm, (lv1354, lv294, lv295), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv296: R.Tensor((1280, 1280), dtype="float32") = transformed_param_360
            lv297: R.Tensor((1280,), dtype="float32") = transformed_param_289
            lv1355 = R.call_tir(cls.fused_matmul_add2_multiply, (lv291_1, lv296, lv297), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv298: R.Tensor((1280, 1280), dtype="float32") = transformed_param_361
            lv299: R.Tensor((1280,), dtype="float32") = transformed_param_287
            lv1356 = R.call_tir(cls.fused_matmul_add2, (lv291_1, lv298, lv299), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1357 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1356,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv300: R.Tensor((1280, 1280), dtype="float32") = transformed_param_362
            lv301: R.Tensor((1280,), dtype="float32") = transformed_param_290
            lv1358 = R.call_tir(cls.fused_matmul_add2, (lv291_1, lv300, lv301), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1359 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1358,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1360 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1355,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul1, (lv1360, lv1357), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1361 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv312, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax, (lv1361,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1362 = R.call_tir(cls.fused_reshape7_reshape8, (lv316,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv319 = R.call_tir(cls.matmul2, (lv1362, lv1359), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1363 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv319,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv302: R.Tensor((1280, 1280), dtype="float32") = transformed_param_363
            lv303: R.Tensor((1280,), dtype="float32") = transformed_param_288
            lv1364 = R.call_tir(cls.fused_matmul_add2_add, (lv1363, lv302, lv303, lv1354), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv304: R.Tensor((1280,), dtype="float32") = transformed_param_284
            lv305: R.Tensor((1280,), dtype="float32") = transformed_param_283
            lv327 = R.call_tir(cls.layer_norm, (lv1364, lv304, lv305), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv306: R.Tensor((1280, 5120), dtype="float32") = transformed_param_364
            lv307: R.Tensor((5120,), dtype="float32") = transformed_param_285
            lv1365 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv327, lv306, lv307), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv308: R.Tensor((5120, 1280), dtype="float32") = transformed_param_365
            lv309: R.Tensor((1280,), dtype="float32") = transformed_param_286
            lv1366 = R.call_tir(cls.fused_matmul4_add2_add, (lv1365, lv308, lv309, lv1364), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv310: R.Tensor((1280,), dtype="float32") = transformed_param_292
            lv311: R.Tensor((1280,), dtype="float32") = transformed_param_291
            lv336 = R.call_tir(cls.layer_norm, (lv1366, lv310, lv311), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv312_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_366
            lv313: R.Tensor((1280,), dtype="float32") = transformed_param_299
            lv1367 = R.call_tir(cls.fused_matmul_add2_multiply, (lv336, lv312_1, lv313), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv314: R.Tensor((1280, 1280), dtype="float32") = transformed_param_367
            lv315: R.Tensor((1280,), dtype="float32") = transformed_param_297
            lv1368 = R.call_tir(cls.fused_matmul_add2, (lv336, lv314, lv315), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1369 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1368,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv316_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_368
            lv317: R.Tensor((1280,), dtype="float32") = transformed_param_300
            lv1370 = R.call_tir(cls.fused_matmul_add2, (lv336, lv316_1, lv317), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1371 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1370,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1372 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1367,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul1, (lv1372, lv1369), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1373 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv357, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax, (lv1373,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1374 = R.call_tir(cls.fused_reshape7_reshape8, (lv361,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv364 = R.call_tir(cls.matmul2, (lv1374, lv1371), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1375 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv364,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv318: R.Tensor((1280, 1280), dtype="float32") = transformed_param_369
            lv319_1: R.Tensor((1280,), dtype="float32") = transformed_param_298
            lv1376 = R.call_tir(cls.fused_matmul_add2_add, (lv1375, lv318, lv319_1, lv1366), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv320: R.Tensor((1280,), dtype="float32") = transformed_param_294
            lv321: R.Tensor((1280,), dtype="float32") = transformed_param_293
            lv372 = R.call_tir(cls.layer_norm, (lv1376, lv320, lv321), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv322: R.Tensor((1280, 5120), dtype="float32") = transformed_param_370
            lv323: R.Tensor((5120,), dtype="float32") = transformed_param_295
            lv1377 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv372, lv322, lv323), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv324: R.Tensor((5120, 1280), dtype="float32") = transformed_param_371
            lv325: R.Tensor((1280,), dtype="float32") = transformed_param_296
            lv1378 = R.call_tir(cls.fused_matmul4_add2_add, (lv1377, lv324, lv325, lv1376), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv326: R.Tensor((1280,), dtype="float32") = transformed_param_302
            lv327_1: R.Tensor((1280,), dtype="float32") = transformed_param_301
            lv381 = R.call_tir(cls.layer_norm, (lv1378, lv326, lv327_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv328: R.Tensor((1280, 1280), dtype="float32") = transformed_param_372
            lv329: R.Tensor((1280,), dtype="float32") = transformed_param_309
            lv1379 = R.call_tir(cls.fused_matmul_add2_multiply, (lv381, lv328, lv329), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv330: R.Tensor((1280, 1280), dtype="float32") = transformed_param_373
            lv331: R.Tensor((1280,), dtype="float32") = transformed_param_307
            lv1380 = R.call_tir(cls.fused_matmul_add2, (lv381, lv330, lv331), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1381 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1380,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv332: R.Tensor((1280, 1280), dtype="float32") = transformed_param_374
            lv333: R.Tensor((1280,), dtype="float32") = transformed_param_310
            lv1382 = R.call_tir(cls.fused_matmul_add2, (lv381, lv332, lv333), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1383 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1382,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1384 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1379,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul1, (lv1384, lv1381), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1385 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv402, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax, (lv1385,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1386 = R.call_tir(cls.fused_reshape7_reshape8, (lv406,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv409 = R.call_tir(cls.matmul2, (lv1386, lv1383), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1387 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv409,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv334: R.Tensor((1280, 1280), dtype="float32") = transformed_param_375
            lv335: R.Tensor((1280,), dtype="float32") = transformed_param_308
            lv1388 = R.call_tir(cls.fused_matmul_add2_add, (lv1387, lv334, lv335, lv1378), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv336_1: R.Tensor((1280,), dtype="float32") = transformed_param_304
            lv337: R.Tensor((1280,), dtype="float32") = transformed_param_303
            lv417 = R.call_tir(cls.layer_norm, (lv1388, lv336_1, lv337), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv338: R.Tensor((1280, 5120), dtype="float32") = transformed_param_376
            lv339: R.Tensor((5120,), dtype="float32") = transformed_param_305
            lv1389 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv417, lv338, lv339), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv340: R.Tensor((5120, 1280), dtype="float32") = transformed_param_377
            lv341: R.Tensor((1280,), dtype="float32") = transformed_param_306
            lv1390 = R.call_tir(cls.fused_matmul4_add2_add, (lv1389, lv340, lv341, lv1388), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv342: R.Tensor((1280,), dtype="float32") = transformed_param_312
            lv343: R.Tensor((1280,), dtype="float32") = transformed_param_311
            lv426 = R.call_tir(cls.layer_norm, (lv1390, lv342, lv343), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv344: R.Tensor((1280, 1280), dtype="float32") = transformed_param_378
            lv345: R.Tensor((1280,), dtype="float32") = transformed_param_319
            lv1391 = R.call_tir(cls.fused_matmul_add2_multiply, (lv426, lv344, lv345), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv346: R.Tensor((1280, 1280), dtype="float32") = transformed_param_379
            lv347: R.Tensor((1280,), dtype="float32") = transformed_param_317
            lv1392 = R.call_tir(cls.fused_matmul_add2, (lv426, lv346, lv347), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1393 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1392,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv348: R.Tensor((1280, 1280), dtype="float32") = transformed_param_380
            lv349: R.Tensor((1280,), dtype="float32") = transformed_param_320
            lv1394 = R.call_tir(cls.fused_matmul_add2, (lv426, lv348, lv349), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1395 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1394,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1396 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1391,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul1, (lv1396, lv1393), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1397 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv447, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax, (lv1397,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1398 = R.call_tir(cls.fused_reshape7_reshape8, (lv451,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv454 = R.call_tir(cls.matmul2, (lv1398, lv1395), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1399 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv454,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv350: R.Tensor((1280, 1280), dtype="float32") = transformed_param_381
            lv351: R.Tensor((1280,), dtype="float32") = transformed_param_318
            lv1400 = R.call_tir(cls.fused_matmul_add2_add, (lv1399, lv350, lv351, lv1390), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv352: R.Tensor((1280,), dtype="float32") = transformed_param_314
            lv353: R.Tensor((1280,), dtype="float32") = transformed_param_313
            lv462 = R.call_tir(cls.layer_norm, (lv1400, lv352, lv353), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv354: R.Tensor((1280, 5120), dtype="float32") = transformed_param_382
            lv355: R.Tensor((5120,), dtype="float32") = transformed_param_315
            lv1401 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv462, lv354, lv355), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv356: R.Tensor((5120, 1280), dtype="float32") = transformed_param_383
            lv357_1: R.Tensor((1280,), dtype="float32") = transformed_param_316
            lv1402 = R.call_tir(cls.fused_matmul4_add2_add, (lv1401, lv356, lv357_1, lv1400), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv358: R.Tensor((1280,), dtype="float32") = transformed_param_12
            lv359: R.Tensor((1280,), dtype="float32") = transformed_param_11
            lv471 = R.call_tir(cls.layer_norm, (lv1402, lv358, lv359), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv360: R.Tensor((1280, 1280), dtype="float32") = transformed_param_384
            lv361_1: R.Tensor((1280,), dtype="float32") = transformed_param_19
            lv1403 = R.call_tir(cls.fused_matmul_add2_multiply, (lv471, lv360, lv361_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv362: R.Tensor((1280, 1280), dtype="float32") = transformed_param_385
            lv363: R.Tensor((1280,), dtype="float32") = transformed_param_17
            lv1404 = R.call_tir(cls.fused_matmul_add2, (lv471, lv362, lv363), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1405 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1404,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv364_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_386
            lv365: R.Tensor((1280,), dtype="float32") = transformed_param_20
            lv1406 = R.call_tir(cls.fused_matmul_add2, (lv471, lv364_1, lv365), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1407 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1406,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1408 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1403,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv492 = R.call_tir(cls.matmul1, (lv1408, lv1405), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1409 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv492, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv496 = R.call_tir(cls.softmax, (lv1409,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1410 = R.call_tir(cls.fused_reshape7_reshape8, (lv496,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv499 = R.call_tir(cls.matmul2, (lv1410, lv1407), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1411 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv499,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv366: R.Tensor((1280, 1280), dtype="float32") = transformed_param_387
            lv367: R.Tensor((1280,), dtype="float32") = transformed_param_18
            lv1412 = R.call_tir(cls.fused_matmul_add2_add, (lv1411, lv366, lv367, lv1402), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv368: R.Tensor((1280,), dtype="float32") = transformed_param_14
            lv369: R.Tensor((1280,), dtype="float32") = transformed_param_13
            lv507 = R.call_tir(cls.layer_norm, (lv1412, lv368, lv369), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv370: R.Tensor((1280, 5120), dtype="float32") = transformed_param_388
            lv371: R.Tensor((5120,), dtype="float32") = transformed_param_15
            lv1413 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv507, lv370, lv371), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv372_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_389
            lv373: R.Tensor((1280,), dtype="float32") = transformed_param_16
            lv1414 = R.call_tir(cls.fused_matmul4_add2_add, (lv1413, lv372_1, lv373, lv1412), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv374: R.Tensor((1280,), dtype="float32") = transformed_param_22
            lv375: R.Tensor((1280,), dtype="float32") = transformed_param_21
            lv516 = R.call_tir(cls.layer_norm, (lv1414, lv374, lv375), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv376: R.Tensor((1280, 1280), dtype="float32") = transformed_param_390
            lv377: R.Tensor((1280,), dtype="float32") = transformed_param_29
            lv1415 = R.call_tir(cls.fused_matmul_add2_multiply, (lv516, lv376, lv377), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv378: R.Tensor((1280, 1280), dtype="float32") = transformed_param_391
            lv379: R.Tensor((1280,), dtype="float32") = transformed_param_27
            lv1416 = R.call_tir(cls.fused_matmul_add2, (lv516, lv378, lv379), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1417 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1416,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv380: R.Tensor((1280, 1280), dtype="float32") = transformed_param_392
            lv381_1: R.Tensor((1280,), dtype="float32") = transformed_param_30
            lv1418 = R.call_tir(cls.fused_matmul_add2, (lv516, lv380, lv381_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1419 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1418,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1420 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1415,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv537 = R.call_tir(cls.matmul1, (lv1420, lv1417), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1421 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv537, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv541 = R.call_tir(cls.softmax, (lv1421,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1422 = R.call_tir(cls.fused_reshape7_reshape8, (lv541,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv544 = R.call_tir(cls.matmul2, (lv1422, lv1419), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1423 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv544,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv382: R.Tensor((1280, 1280), dtype="float32") = transformed_param_393
            lv383: R.Tensor((1280,), dtype="float32") = transformed_param_28
            lv1424 = R.call_tir(cls.fused_matmul_add2_add, (lv1423, lv382, lv383, lv1414), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv384: R.Tensor((1280,), dtype="float32") = transformed_param_24
            lv385: R.Tensor((1280,), dtype="float32") = transformed_param_23
            lv552 = R.call_tir(cls.layer_norm, (lv1424, lv384, lv385), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv386: R.Tensor((1280, 5120), dtype="float32") = transformed_param_394
            lv387: R.Tensor((5120,), dtype="float32") = transformed_param_25
            lv1425 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv552, lv386, lv387), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv388: R.Tensor((5120, 1280), dtype="float32") = transformed_param_395
            lv389: R.Tensor((1280,), dtype="float32") = transformed_param_26
            lv1426 = R.call_tir(cls.fused_matmul4_add2_add, (lv1425, lv388, lv389, lv1424), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv390: R.Tensor((1280,), dtype="float32") = transformed_param_32
            lv391: R.Tensor((1280,), dtype="float32") = transformed_param_31
            lv561 = R.call_tir(cls.layer_norm, (lv1426, lv390, lv391), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv392: R.Tensor((1280, 1280), dtype="float32") = transformed_param_396
            lv393: R.Tensor((1280,), dtype="float32") = transformed_param_39
            lv1427 = R.call_tir(cls.fused_matmul_add2_multiply, (lv561, lv392, lv393), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv394: R.Tensor((1280, 1280), dtype="float32") = transformed_param_397
            lv395: R.Tensor((1280,), dtype="float32") = transformed_param_37
            lv1428 = R.call_tir(cls.fused_matmul_add2, (lv561, lv394, lv395), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1429 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1428,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv396: R.Tensor((1280, 1280), dtype="float32") = transformed_param_398
            lv397: R.Tensor((1280,), dtype="float32") = transformed_param_40
            lv1430 = R.call_tir(cls.fused_matmul_add2, (lv561, lv396, lv397), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1431 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1430,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1432 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1427,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv582 = R.call_tir(cls.matmul1, (lv1432, lv1429), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1433 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv582, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv586 = R.call_tir(cls.softmax, (lv1433,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1434 = R.call_tir(cls.fused_reshape7_reshape8, (lv586,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv589 = R.call_tir(cls.matmul2, (lv1434, lv1431), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1435 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv589,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv398: R.Tensor((1280, 1280), dtype="float32") = transformed_param_399
            lv399: R.Tensor((1280,), dtype="float32") = transformed_param_38
            lv1436 = R.call_tir(cls.fused_matmul_add2_add, (lv1435, lv398, lv399, lv1426), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv400: R.Tensor((1280,), dtype="float32") = transformed_param_34
            lv401: R.Tensor((1280,), dtype="float32") = transformed_param_33
            lv597 = R.call_tir(cls.layer_norm, (lv1436, lv400, lv401), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv402_1: R.Tensor((1280, 5120), dtype="float32") = transformed_param_400
            lv403: R.Tensor((5120,), dtype="float32") = transformed_param_35
            lv1437 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv597, lv402_1, lv403), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv404: R.Tensor((5120, 1280), dtype="float32") = transformed_param_401
            lv405: R.Tensor((1280,), dtype="float32") = transformed_param_36
            lv1438 = R.call_tir(cls.fused_matmul4_add2_add, (lv1437, lv404, lv405, lv1436), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv406_1: R.Tensor((1280,), dtype="float32") = transformed_param_42
            lv407: R.Tensor((1280,), dtype="float32") = transformed_param_41
            lv606 = R.call_tir(cls.layer_norm, (lv1438, lv406_1, lv407), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv408: R.Tensor((1280, 1280), dtype="float32") = transformed_param_402
            lv409_1: R.Tensor((1280,), dtype="float32") = transformed_param_49
            lv1439 = R.call_tir(cls.fused_matmul_add2_multiply, (lv606, lv408, lv409_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv410: R.Tensor((1280, 1280), dtype="float32") = transformed_param_403
            lv411: R.Tensor((1280,), dtype="float32") = transformed_param_47
            lv1440 = R.call_tir(cls.fused_matmul_add2, (lv606, lv410, lv411), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1441 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1440,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv412: R.Tensor((1280, 1280), dtype="float32") = transformed_param_404
            lv413: R.Tensor((1280,), dtype="float32") = transformed_param_50
            lv1442 = R.call_tir(cls.fused_matmul_add2, (lv606, lv412, lv413), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1443 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1442,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1444 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1439,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv627 = R.call_tir(cls.matmul1, (lv1444, lv1441), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1445 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv627, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv631 = R.call_tir(cls.softmax, (lv1445,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1446 = R.call_tir(cls.fused_reshape7_reshape8, (lv631,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv634 = R.call_tir(cls.matmul2, (lv1446, lv1443), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1447 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv634,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv414: R.Tensor((1280, 1280), dtype="float32") = transformed_param_405
            lv415: R.Tensor((1280,), dtype="float32") = transformed_param_48
            lv1448 = R.call_tir(cls.fused_matmul_add2_add, (lv1447, lv414, lv415, lv1438), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv416: R.Tensor((1280,), dtype="float32") = transformed_param_44
            lv417_1: R.Tensor((1280,), dtype="float32") = transformed_param_43
            lv642 = R.call_tir(cls.layer_norm, (lv1448, lv416, lv417_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv418: R.Tensor((1280, 5120), dtype="float32") = transformed_param_406
            lv419: R.Tensor((5120,), dtype="float32") = transformed_param_45
            lv1449 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv642, lv418, lv419), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv420: R.Tensor((5120, 1280), dtype="float32") = transformed_param_407
            lv421: R.Tensor((1280,), dtype="float32") = transformed_param_46
            lv1450 = R.call_tir(cls.fused_matmul4_add2_add, (lv1449, lv420, lv421, lv1448), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv422: R.Tensor((1280,), dtype="float32") = transformed_param_52
            lv423: R.Tensor((1280,), dtype="float32") = transformed_param_51
            lv651 = R.call_tir(cls.layer_norm, (lv1450, lv422, lv423), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv424: R.Tensor((1280, 1280), dtype="float32") = transformed_param_408
            lv425: R.Tensor((1280,), dtype="float32") = transformed_param_59
            lv1451 = R.call_tir(cls.fused_matmul_add2_multiply, (lv651, lv424, lv425), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv426_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_409
            lv427: R.Tensor((1280,), dtype="float32") = transformed_param_57
            lv1452 = R.call_tir(cls.fused_matmul_add2, (lv651, lv426_1, lv427), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1453 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1452,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv428: R.Tensor((1280, 1280), dtype="float32") = transformed_param_410
            lv429: R.Tensor((1280,), dtype="float32") = transformed_param_60
            lv1454 = R.call_tir(cls.fused_matmul_add2, (lv651, lv428, lv429), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1455 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1454,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1456 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1451,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv672 = R.call_tir(cls.matmul1, (lv1456, lv1453), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1457 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv672, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv676 = R.call_tir(cls.softmax, (lv1457,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1458 = R.call_tir(cls.fused_reshape7_reshape8, (lv676,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv679 = R.call_tir(cls.matmul2, (lv1458, lv1455), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1459 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv679,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv430: R.Tensor((1280, 1280), dtype="float32") = transformed_param_411
            lv431: R.Tensor((1280,), dtype="float32") = transformed_param_58
            lv1460 = R.call_tir(cls.fused_matmul_add2_add, (lv1459, lv430, lv431, lv1450), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv432: R.Tensor((1280,), dtype="float32") = transformed_param_54
            lv433: R.Tensor((1280,), dtype="float32") = transformed_param_53
            lv687 = R.call_tir(cls.layer_norm, (lv1460, lv432, lv433), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv434: R.Tensor((1280, 5120), dtype="float32") = transformed_param_412
            lv435: R.Tensor((5120,), dtype="float32") = transformed_param_55
            lv1461 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv687, lv434, lv435), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv436: R.Tensor((5120, 1280), dtype="float32") = transformed_param_413
            lv437: R.Tensor((1280,), dtype="float32") = transformed_param_56
            lv1462 = R.call_tir(cls.fused_matmul4_add2_add, (lv1461, lv436, lv437, lv1460), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv438: R.Tensor((1280,), dtype="float32") = transformed_param_62
            lv439: R.Tensor((1280,), dtype="float32") = transformed_param_61
            lv696 = R.call_tir(cls.layer_norm, (lv1462, lv438, lv439), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv440: R.Tensor((1280, 1280), dtype="float32") = transformed_param_414
            lv441: R.Tensor((1280,), dtype="float32") = transformed_param_69
            lv1463 = R.call_tir(cls.fused_matmul_add2_multiply, (lv696, lv440, lv441), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv442: R.Tensor((1280, 1280), dtype="float32") = transformed_param_415
            lv443: R.Tensor((1280,), dtype="float32") = transformed_param_67
            lv1464 = R.call_tir(cls.fused_matmul_add2, (lv696, lv442, lv443), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1465 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1464,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv444: R.Tensor((1280, 1280), dtype="float32") = transformed_param_416
            lv445: R.Tensor((1280,), dtype="float32") = transformed_param_70
            lv1466 = R.call_tir(cls.fused_matmul_add2, (lv696, lv444, lv445), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1467 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1466,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1468 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1463,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv717 = R.call_tir(cls.matmul1, (lv1468, lv1465), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1469 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv717, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv721 = R.call_tir(cls.softmax, (lv1469,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1470 = R.call_tir(cls.fused_reshape7_reshape8, (lv721,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv724 = R.call_tir(cls.matmul2, (lv1470, lv1467), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1471 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv724,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv446: R.Tensor((1280, 1280), dtype="float32") = transformed_param_417
            lv447_1: R.Tensor((1280,), dtype="float32") = transformed_param_68
            lv1472 = R.call_tir(cls.fused_matmul_add2_add, (lv1471, lv446, lv447_1, lv1462), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv448: R.Tensor((1280,), dtype="float32") = transformed_param_64
            lv449: R.Tensor((1280,), dtype="float32") = transformed_param_63
            lv732 = R.call_tir(cls.layer_norm, (lv1472, lv448, lv449), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv450: R.Tensor((1280, 5120), dtype="float32") = transformed_param_418
            lv451_1: R.Tensor((5120,), dtype="float32") = transformed_param_65
            lv1473 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv732, lv450, lv451_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv452: R.Tensor((5120, 1280), dtype="float32") = transformed_param_419
            lv453: R.Tensor((1280,), dtype="float32") = transformed_param_66
            lv1474 = R.call_tir(cls.fused_matmul4_add2_add, (lv1473, lv452, lv453, lv1472), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv454_1: R.Tensor((1280,), dtype="float32") = transformed_param_72
            lv455: R.Tensor((1280,), dtype="float32") = transformed_param_71
            lv741 = R.call_tir(cls.layer_norm, (lv1474, lv454_1, lv455), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv456: R.Tensor((1280, 1280), dtype="float32") = transformed_param_420
            lv457: R.Tensor((1280,), dtype="float32") = transformed_param_79
            lv1475 = R.call_tir(cls.fused_matmul_add2_multiply, (lv741, lv456, lv457), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv458: R.Tensor((1280, 1280), dtype="float32") = transformed_param_421
            lv459: R.Tensor((1280,), dtype="float32") = transformed_param_77
            lv1476 = R.call_tir(cls.fused_matmul_add2, (lv741, lv458, lv459), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1477 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1476,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv460: R.Tensor((1280, 1280), dtype="float32") = transformed_param_422
            lv461: R.Tensor((1280,), dtype="float32") = transformed_param_80
            lv1478 = R.call_tir(cls.fused_matmul_add2, (lv741, lv460, lv461), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1479 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1478,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1480 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1475,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv762 = R.call_tir(cls.matmul1, (lv1480, lv1477), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1481 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv762, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv766 = R.call_tir(cls.softmax, (lv1481,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1482 = R.call_tir(cls.fused_reshape7_reshape8, (lv766,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv769 = R.call_tir(cls.matmul2, (lv1482, lv1479), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1483 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv769,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv462_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_423
            lv463: R.Tensor((1280,), dtype="float32") = transformed_param_78
            lv1484 = R.call_tir(cls.fused_matmul_add2_add, (lv1483, lv462_1, lv463, lv1474), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv464: R.Tensor((1280,), dtype="float32") = transformed_param_74
            lv465: R.Tensor((1280,), dtype="float32") = transformed_param_73
            lv777 = R.call_tir(cls.layer_norm, (lv1484, lv464, lv465), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv466: R.Tensor((1280, 5120), dtype="float32") = transformed_param_424
            lv467: R.Tensor((5120,), dtype="float32") = transformed_param_75
            lv1485 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv777, lv466, lv467), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv468: R.Tensor((5120, 1280), dtype="float32") = transformed_param_425
            lv469: R.Tensor((1280,), dtype="float32") = transformed_param_76
            lv1486 = R.call_tir(cls.fused_matmul4_add2_add, (lv1485, lv468, lv469, lv1484), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv470: R.Tensor((1280,), dtype="float32") = transformed_param_82
            lv471_1: R.Tensor((1280,), dtype="float32") = transformed_param_81
            lv786 = R.call_tir(cls.layer_norm, (lv1486, lv470, lv471_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv472: R.Tensor((1280, 1280), dtype="float32") = transformed_param_426
            lv473: R.Tensor((1280,), dtype="float32") = transformed_param_89
            lv1487 = R.call_tir(cls.fused_matmul_add2_multiply, (lv786, lv472, lv473), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv474: R.Tensor((1280, 1280), dtype="float32") = transformed_param_427
            lv475: R.Tensor((1280,), dtype="float32") = transformed_param_87
            lv1488 = R.call_tir(cls.fused_matmul_add2, (lv786, lv474, lv475), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1489 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1488,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv476: R.Tensor((1280, 1280), dtype="float32") = transformed_param_428
            lv477: R.Tensor((1280,), dtype="float32") = transformed_param_90
            lv1490 = R.call_tir(cls.fused_matmul_add2, (lv786, lv476, lv477), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1491 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1490,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1492 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1487,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv807 = R.call_tir(cls.matmul1, (lv1492, lv1489), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1493 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv807, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv811 = R.call_tir(cls.softmax, (lv1493,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1494 = R.call_tir(cls.fused_reshape7_reshape8, (lv811,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv814 = R.call_tir(cls.matmul2, (lv1494, lv1491), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1495 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv814,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv478: R.Tensor((1280, 1280), dtype="float32") = transformed_param_429
            lv479: R.Tensor((1280,), dtype="float32") = transformed_param_88
            lv1496 = R.call_tir(cls.fused_matmul_add2_add, (lv1495, lv478, lv479, lv1486), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv480: R.Tensor((1280,), dtype="float32") = transformed_param_84
            lv481: R.Tensor((1280,), dtype="float32") = transformed_param_83
            lv822 = R.call_tir(cls.layer_norm, (lv1496, lv480, lv481), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv482: R.Tensor((1280, 5120), dtype="float32") = transformed_param_430
            lv483: R.Tensor((5120,), dtype="float32") = transformed_param_85
            lv1497 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv822, lv482, lv483), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv484: R.Tensor((5120, 1280), dtype="float32") = transformed_param_431
            lv485: R.Tensor((1280,), dtype="float32") = transformed_param_86
            lv1498 = R.call_tir(cls.fused_matmul4_add2_add, (lv1497, lv484, lv485, lv1496), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv486: R.Tensor((1280,), dtype="float32") = transformed_param_92
            lv487: R.Tensor((1280,), dtype="float32") = transformed_param_91
            lv831 = R.call_tir(cls.layer_norm, (lv1498, lv486, lv487), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv488: R.Tensor((1280, 1280), dtype="float32") = transformed_param_432
            lv489: R.Tensor((1280,), dtype="float32") = transformed_param_99
            lv1499 = R.call_tir(cls.fused_matmul_add2_multiply, (lv831, lv488, lv489), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv490: R.Tensor((1280, 1280), dtype="float32") = transformed_param_433
            lv491: R.Tensor((1280,), dtype="float32") = transformed_param_97
            lv1500 = R.call_tir(cls.fused_matmul_add2, (lv831, lv490, lv491), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1501 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1500,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv492_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_434
            lv493: R.Tensor((1280,), dtype="float32") = transformed_param_100
            lv1502 = R.call_tir(cls.fused_matmul_add2, (lv831, lv492_1, lv493), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1503 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1502,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1504 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1499,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv852 = R.call_tir(cls.matmul1, (lv1504, lv1501), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1505 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv852, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv856 = R.call_tir(cls.softmax, (lv1505,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1506 = R.call_tir(cls.fused_reshape7_reshape8, (lv856,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv859 = R.call_tir(cls.matmul2, (lv1506, lv1503), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1507 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv859,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv494: R.Tensor((1280, 1280), dtype="float32") = transformed_param_435
            lv495: R.Tensor((1280,), dtype="float32") = transformed_param_98
            lv1508 = R.call_tir(cls.fused_matmul_add2_add, (lv1507, lv494, lv495, lv1498), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv496_1: R.Tensor((1280,), dtype="float32") = transformed_param_94
            lv497: R.Tensor((1280,), dtype="float32") = transformed_param_93
            lv867 = R.call_tir(cls.layer_norm, (lv1508, lv496_1, lv497), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv498: R.Tensor((1280, 5120), dtype="float32") = transformed_param_436
            lv499_1: R.Tensor((5120,), dtype="float32") = transformed_param_95
            lv1509 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv867, lv498, lv499_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv500: R.Tensor((5120, 1280), dtype="float32") = transformed_param_437
            lv501: R.Tensor((1280,), dtype="float32") = transformed_param_96
            lv1510 = R.call_tir(cls.fused_matmul4_add2_add, (lv1509, lv500, lv501, lv1508), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv502: R.Tensor((1280,), dtype="float32") = transformed_param_102
            lv503: R.Tensor((1280,), dtype="float32") = transformed_param_101
            lv876 = R.call_tir(cls.layer_norm, (lv1510, lv502, lv503), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv504: R.Tensor((1280, 1280), dtype="float32") = transformed_param_438
            lv505: R.Tensor((1280,), dtype="float32") = transformed_param_109
            lv1511 = R.call_tir(cls.fused_matmul_add2_multiply, (lv876, lv504, lv505), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv506: R.Tensor((1280, 1280), dtype="float32") = transformed_param_439
            lv507_1: R.Tensor((1280,), dtype="float32") = transformed_param_107
            lv1512 = R.call_tir(cls.fused_matmul_add2, (lv876, lv506, lv507_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1513 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1512,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv508: R.Tensor((1280, 1280), dtype="float32") = transformed_param_440
            lv509: R.Tensor((1280,), dtype="float32") = transformed_param_110
            lv1514 = R.call_tir(cls.fused_matmul_add2, (lv876, lv508, lv509), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1515 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1514,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1516 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1511,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv897 = R.call_tir(cls.matmul1, (lv1516, lv1513), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1517 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv897, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv901 = R.call_tir(cls.softmax, (lv1517,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1518 = R.call_tir(cls.fused_reshape7_reshape8, (lv901,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv904 = R.call_tir(cls.matmul2, (lv1518, lv1515), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1519 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv904,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv510: R.Tensor((1280, 1280), dtype="float32") = transformed_param_441
            lv511: R.Tensor((1280,), dtype="float32") = transformed_param_108
            lv1520 = R.call_tir(cls.fused_matmul_add2_add, (lv1519, lv510, lv511, lv1510), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv512: R.Tensor((1280,), dtype="float32") = transformed_param_104
            lv513: R.Tensor((1280,), dtype="float32") = transformed_param_103
            lv912 = R.call_tir(cls.layer_norm, (lv1520, lv512, lv513), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv514: R.Tensor((1280, 5120), dtype="float32") = transformed_param_442
            lv515: R.Tensor((5120,), dtype="float32") = transformed_param_105
            lv1521 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv912, lv514, lv515), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv516_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_443
            lv517: R.Tensor((1280,), dtype="float32") = transformed_param_106
            lv1522 = R.call_tir(cls.fused_matmul4_add2_add, (lv1521, lv516_1, lv517, lv1520), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv518: R.Tensor((1280,), dtype="float32") = transformed_param_122
            lv519: R.Tensor((1280,), dtype="float32") = transformed_param_121
            lv921 = R.call_tir(cls.layer_norm, (lv1522, lv518, lv519), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv520: R.Tensor((1280, 1280), dtype="float32") = transformed_param_444
            lv521: R.Tensor((1280,), dtype="float32") = transformed_param_129
            lv1523 = R.call_tir(cls.fused_matmul_add2_multiply, (lv921, lv520, lv521), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv522: R.Tensor((1280, 1280), dtype="float32") = transformed_param_445
            lv523: R.Tensor((1280,), dtype="float32") = transformed_param_127
            lv1524 = R.call_tir(cls.fused_matmul_add2, (lv921, lv522, lv523), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1525 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1524,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv524: R.Tensor((1280, 1280), dtype="float32") = transformed_param_446
            lv525: R.Tensor((1280,), dtype="float32") = transformed_param_130
            lv1526 = R.call_tir(cls.fused_matmul_add2, (lv921, lv524, lv525), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1527 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1526,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1528 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1523,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv942 = R.call_tir(cls.matmul1, (lv1528, lv1525), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1529 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv942, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv946 = R.call_tir(cls.softmax, (lv1529,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1530 = R.call_tir(cls.fused_reshape7_reshape8, (lv946,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv949 = R.call_tir(cls.matmul2, (lv1530, lv1527), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1531 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv949,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv526: R.Tensor((1280, 1280), dtype="float32") = transformed_param_447
            lv527: R.Tensor((1280,), dtype="float32") = transformed_param_128
            lv1532 = R.call_tir(cls.fused_matmul_add2_add, (lv1531, lv526, lv527, lv1522), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv528: R.Tensor((1280,), dtype="float32") = transformed_param_124
            lv529: R.Tensor((1280,), dtype="float32") = transformed_param_123
            lv957 = R.call_tir(cls.layer_norm, (lv1532, lv528, lv529), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv530: R.Tensor((1280, 5120), dtype="float32") = transformed_param_448
            lv531: R.Tensor((5120,), dtype="float32") = transformed_param_125
            lv1533 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv957, lv530, lv531), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv532: R.Tensor((5120, 1280), dtype="float32") = transformed_param_449
            lv533: R.Tensor((1280,), dtype="float32") = transformed_param_126
            lv1534 = R.call_tir(cls.fused_matmul4_add2_add, (lv1533, lv532, lv533, lv1532), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv534: R.Tensor((1280,), dtype="float32") = transformed_param_132
            lv535: R.Tensor((1280,), dtype="float32") = transformed_param_131
            lv966 = R.call_tir(cls.layer_norm, (lv1534, lv534, lv535), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv536: R.Tensor((1280, 1280), dtype="float32") = transformed_param_450
            lv537_1: R.Tensor((1280,), dtype="float32") = transformed_param_139
            lv1535 = R.call_tir(cls.fused_matmul_add2_multiply, (lv966, lv536, lv537_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv538: R.Tensor((1280, 1280), dtype="float32") = transformed_param_451
            lv539: R.Tensor((1280,), dtype="float32") = transformed_param_137
            lv1536 = R.call_tir(cls.fused_matmul_add2, (lv966, lv538, lv539), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1537 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1536,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv540: R.Tensor((1280, 1280), dtype="float32") = transformed_param_452
            lv541_1: R.Tensor((1280,), dtype="float32") = transformed_param_140
            lv1538 = R.call_tir(cls.fused_matmul_add2, (lv966, lv540, lv541_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1539 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1538,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1540 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1535,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv987 = R.call_tir(cls.matmul1, (lv1540, lv1537), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1541 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv987, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv991 = R.call_tir(cls.softmax, (lv1541,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1542 = R.call_tir(cls.fused_reshape7_reshape8, (lv991,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv994 = R.call_tir(cls.matmul2, (lv1542, lv1539), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1543 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv994,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv542: R.Tensor((1280, 1280), dtype="float32") = transformed_param_453
            lv543: R.Tensor((1280,), dtype="float32") = transformed_param_138
            lv1544 = R.call_tir(cls.fused_matmul_add2_add, (lv1543, lv542, lv543, lv1534), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv544_1: R.Tensor((1280,), dtype="float32") = transformed_param_134
            lv545: R.Tensor((1280,), dtype="float32") = transformed_param_133
            lv1002 = R.call_tir(cls.layer_norm, (lv1544, lv544_1, lv545), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv546: R.Tensor((1280, 5120), dtype="float32") = transformed_param_454
            lv547: R.Tensor((5120,), dtype="float32") = transformed_param_135
            lv1545 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1002, lv546, lv547), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv548: R.Tensor((5120, 1280), dtype="float32") = transformed_param_455
            lv549: R.Tensor((1280,), dtype="float32") = transformed_param_136
            lv1546 = R.call_tir(cls.fused_matmul4_add2_add, (lv1545, lv548, lv549, lv1544), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv550: R.Tensor((1280,), dtype="float32") = transformed_param_142
            lv551: R.Tensor((1280,), dtype="float32") = transformed_param_141
            lv1011 = R.call_tir(cls.layer_norm, (lv1546, lv550, lv551), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv552_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_456
            lv553: R.Tensor((1280,), dtype="float32") = transformed_param_149
            lv1547 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1011, lv552_1, lv553), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv554: R.Tensor((1280, 1280), dtype="float32") = transformed_param_457
            lv555: R.Tensor((1280,), dtype="float32") = transformed_param_147
            lv1548 = R.call_tir(cls.fused_matmul_add2, (lv1011, lv554, lv555), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1549 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1548,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv556: R.Tensor((1280, 1280), dtype="float32") = transformed_param_458
            lv557: R.Tensor((1280,), dtype="float32") = transformed_param_150
            lv1550 = R.call_tir(cls.fused_matmul_add2, (lv1011, lv556, lv557), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1551 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1550,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1552 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1547,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1032 = R.call_tir(cls.matmul1, (lv1552, lv1549), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1553 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1032, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1036 = R.call_tir(cls.softmax, (lv1553,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1554 = R.call_tir(cls.fused_reshape7_reshape8, (lv1036,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1039 = R.call_tir(cls.matmul2, (lv1554, lv1551), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1555 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1039,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv558: R.Tensor((1280, 1280), dtype="float32") = transformed_param_459
            lv559: R.Tensor((1280,), dtype="float32") = transformed_param_148
            lv1556 = R.call_tir(cls.fused_matmul_add2_add, (lv1555, lv558, lv559, lv1546), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv560: R.Tensor((1280,), dtype="float32") = transformed_param_144
            lv561_1: R.Tensor((1280,), dtype="float32") = transformed_param_143
            lv1047 = R.call_tir(cls.layer_norm, (lv1556, lv560, lv561_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv562: R.Tensor((1280, 5120), dtype="float32") = transformed_param_460
            lv563: R.Tensor((5120,), dtype="float32") = transformed_param_145
            lv1557 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1047, lv562, lv563), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv564: R.Tensor((5120, 1280), dtype="float32") = transformed_param_461
            lv565: R.Tensor((1280,), dtype="float32") = transformed_param_146
            lv1558 = R.call_tir(cls.fused_matmul4_add2_add, (lv1557, lv564, lv565, lv1556), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv566: R.Tensor((1280,), dtype="float32") = transformed_param_152
            lv567: R.Tensor((1280,), dtype="float32") = transformed_param_151
            lv1056 = R.call_tir(cls.layer_norm, (lv1558, lv566, lv567), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv568: R.Tensor((1280, 1280), dtype="float32") = transformed_param_462
            lv569: R.Tensor((1280,), dtype="float32") = transformed_param_159
            lv1559 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1056, lv568, lv569), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv570: R.Tensor((1280, 1280), dtype="float32") = transformed_param_463
            lv571: R.Tensor((1280,), dtype="float32") = transformed_param_157
            lv1560 = R.call_tir(cls.fused_matmul_add2, (lv1056, lv570, lv571), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1561 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1560,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv572: R.Tensor((1280, 1280), dtype="float32") = transformed_param_464
            lv573: R.Tensor((1280,), dtype="float32") = transformed_param_160
            lv1562 = R.call_tir(cls.fused_matmul_add2, (lv1056, lv572, lv573), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1563 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1562,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1564 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1559,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1077 = R.call_tir(cls.matmul1, (lv1564, lv1561), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1565 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1077, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1081 = R.call_tir(cls.softmax, (lv1565,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1566 = R.call_tir(cls.fused_reshape7_reshape8, (lv1081,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1084 = R.call_tir(cls.matmul2, (lv1566, lv1563), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1567 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1084,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv574: R.Tensor((1280, 1280), dtype="float32") = transformed_param_465
            lv575: R.Tensor((1280,), dtype="float32") = transformed_param_158
            lv1568 = R.call_tir(cls.fused_matmul_add2_add, (lv1567, lv574, lv575, lv1558), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv576: R.Tensor((1280,), dtype="float32") = transformed_param_154
            lv577: R.Tensor((1280,), dtype="float32") = transformed_param_153
            lv1092 = R.call_tir(cls.layer_norm, (lv1568, lv576, lv577), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv578: R.Tensor((1280, 5120), dtype="float32") = transformed_param_466
            lv579: R.Tensor((5120,), dtype="float32") = transformed_param_155
            lv1569 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1092, lv578, lv579), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv580: R.Tensor((5120, 1280), dtype="float32") = transformed_param_467
            lv581: R.Tensor((1280,), dtype="float32") = transformed_param_156
            lv1570 = R.call_tir(cls.fused_matmul4_add2_add, (lv1569, lv580, lv581, lv1568), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv582_1: R.Tensor((1280,), dtype="float32") = transformed_param_162
            lv583: R.Tensor((1280,), dtype="float32") = transformed_param_161
            lv1101 = R.call_tir(cls.layer_norm, (lv1570, lv582_1, lv583), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv584: R.Tensor((1280, 1280), dtype="float32") = transformed_param_468
            lv585: R.Tensor((1280,), dtype="float32") = transformed_param_169
            lv1571 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1101, lv584, lv585), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv586_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_469
            lv587: R.Tensor((1280,), dtype="float32") = transformed_param_167
            lv1572 = R.call_tir(cls.fused_matmul_add2, (lv1101, lv586_1, lv587), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1573 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1572,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv588: R.Tensor((1280, 1280), dtype="float32") = transformed_param_470
            lv589_1: R.Tensor((1280,), dtype="float32") = transformed_param_170
            lv1574 = R.call_tir(cls.fused_matmul_add2, (lv1101, lv588, lv589_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1575 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1574,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1576 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1571,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1122 = R.call_tir(cls.matmul1, (lv1576, lv1573), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1577 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1122, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1126 = R.call_tir(cls.softmax, (lv1577,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1578 = R.call_tir(cls.fused_reshape7_reshape8, (lv1126,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1129 = R.call_tir(cls.matmul2, (lv1578, lv1575), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1579 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1129,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv590: R.Tensor((1280, 1280), dtype="float32") = transformed_param_471
            lv591: R.Tensor((1280,), dtype="float32") = transformed_param_168
            lv1580 = R.call_tir(cls.fused_matmul_add2_add, (lv1579, lv590, lv591, lv1570), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv592: R.Tensor((1280,), dtype="float32") = transformed_param_164
            lv593: R.Tensor((1280,), dtype="float32") = transformed_param_163
            lv1137 = R.call_tir(cls.layer_norm, (lv1580, lv592, lv593), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv594: R.Tensor((1280, 5120), dtype="float32") = transformed_param_472
            lv595: R.Tensor((5120,), dtype="float32") = transformed_param_165
            lv1581 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1137, lv594, lv595), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv596: R.Tensor((5120, 1280), dtype="float32") = transformed_param_473
            lv597_1: R.Tensor((1280,), dtype="float32") = transformed_param_166
            lv1582 = R.call_tir(cls.fused_matmul4_add2_add, (lv1581, lv596, lv597_1, lv1580), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv598: R.Tensor((1280,), dtype="float32") = transformed_param_172
            lv599: R.Tensor((1280,), dtype="float32") = transformed_param_171
            lv1146 = R.call_tir(cls.layer_norm, (lv1582, lv598, lv599), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv600: R.Tensor((1280, 1280), dtype="float32") = transformed_param_474
            lv601: R.Tensor((1280,), dtype="float32") = transformed_param_179
            lv1583 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1146, lv600, lv601), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv602: R.Tensor((1280, 1280), dtype="float32") = transformed_param_475
            lv603: R.Tensor((1280,), dtype="float32") = transformed_param_177
            lv1584 = R.call_tir(cls.fused_matmul_add2, (lv1146, lv602, lv603), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1585 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1584,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv604: R.Tensor((1280, 1280), dtype="float32") = transformed_param_476
            lv605: R.Tensor((1280,), dtype="float32") = transformed_param_180
            lv1586 = R.call_tir(cls.fused_matmul_add2, (lv1146, lv604, lv605), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1587 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1586,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1588 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1583,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1167 = R.call_tir(cls.matmul1, (lv1588, lv1585), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1589 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1167, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1171 = R.call_tir(cls.softmax, (lv1589,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1590 = R.call_tir(cls.fused_reshape7_reshape8, (lv1171,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul2, (lv1590, lv1587), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1591 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1174,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv606_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_477
            lv607: R.Tensor((1280,), dtype="float32") = transformed_param_178
            lv1592 = R.call_tir(cls.fused_matmul_add2_add, (lv1591, lv606_1, lv607, lv1582), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv608: R.Tensor((1280,), dtype="float32") = transformed_param_174
            lv609: R.Tensor((1280,), dtype="float32") = transformed_param_173
            lv1182 = R.call_tir(cls.layer_norm, (lv1592, lv608, lv609), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv610: R.Tensor((1280, 5120), dtype="float32") = transformed_param_478
            lv611: R.Tensor((5120,), dtype="float32") = transformed_param_175
            lv1593 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1182, lv610, lv611), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv612: R.Tensor((5120, 1280), dtype="float32") = transformed_param_479
            lv613: R.Tensor((1280,), dtype="float32") = transformed_param_176
            lv1594 = R.call_tir(cls.fused_matmul4_add2_add, (lv1593, lv612, lv613, lv1592), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv614: R.Tensor((1280,), dtype="float32") = transformed_param_182
            lv615: R.Tensor((1280,), dtype="float32") = transformed_param_181
            lv1191 = R.call_tir(cls.layer_norm, (lv1594, lv614, lv615), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv616: R.Tensor((1280, 1280), dtype="float32") = transformed_param_480
            lv617: R.Tensor((1280,), dtype="float32") = transformed_param_189
            lv1595 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1191, lv616, lv617), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv618: R.Tensor((1280, 1280), dtype="float32") = transformed_param_481
            lv619: R.Tensor((1280,), dtype="float32") = transformed_param_187
            lv1596 = R.call_tir(cls.fused_matmul_add2, (lv1191, lv618, lv619), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1597 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1596,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv620: R.Tensor((1280, 1280), dtype="float32") = transformed_param_482
            lv621: R.Tensor((1280,), dtype="float32") = transformed_param_190
            lv1598 = R.call_tir(cls.fused_matmul_add2, (lv1191, lv620, lv621), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1599 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1598,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1600 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1595,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1212 = R.call_tir(cls.matmul1, (lv1600, lv1597), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1601 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1212, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1216 = R.call_tir(cls.softmax, (lv1601,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1602 = R.call_tir(cls.fused_reshape7_reshape8, (lv1216,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1219 = R.call_tir(cls.matmul2, (lv1602, lv1599), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1603 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1219,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv622: R.Tensor((1280, 1280), dtype="float32") = transformed_param_483
            lv623: R.Tensor((1280,), dtype="float32") = transformed_param_188
            lv1604 = R.call_tir(cls.fused_matmul_add2_add, (lv1603, lv622, lv623, lv1594), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv624: R.Tensor((1280,), dtype="float32") = transformed_param_184
            lv625: R.Tensor((1280,), dtype="float32") = transformed_param_183
            lv1227 = R.call_tir(cls.layer_norm, (lv1604, lv624, lv625), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv626: R.Tensor((1280, 5120), dtype="float32") = transformed_param_484
            lv627_1: R.Tensor((5120,), dtype="float32") = transformed_param_185
            lv1605 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1227, lv626, lv627_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv628: R.Tensor((5120, 1280), dtype="float32") = transformed_param_485
            lv629: R.Tensor((1280,), dtype="float32") = transformed_param_186
            lv1606 = R.call_tir(cls.fused_matmul4_add2_add, (lv1605, lv628, lv629, lv1604), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv630: R.Tensor((1280,), dtype="float32") = transformed_param_192
            lv631_1: R.Tensor((1280,), dtype="float32") = transformed_param_191
            lv1236 = R.call_tir(cls.layer_norm, (lv1606, lv630, lv631_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv632: R.Tensor((1280, 1280), dtype="float32") = transformed_param_486
            lv633: R.Tensor((1280,), dtype="float32") = transformed_param_199
            lv1607 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1236, lv632, lv633), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv634_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_487
            lv635: R.Tensor((1280,), dtype="float32") = transformed_param_197
            lv1608 = R.call_tir(cls.fused_matmul_add2, (lv1236, lv634_1, lv635), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1609 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1608,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv636: R.Tensor((1280, 1280), dtype="float32") = transformed_param_488
            lv637: R.Tensor((1280,), dtype="float32") = transformed_param_200
            lv1610 = R.call_tir(cls.fused_matmul_add2, (lv1236, lv636, lv637), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1611 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1610,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1612 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1607,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1257 = R.call_tir(cls.matmul1, (lv1612, lv1609), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1613 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1257, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1261 = R.call_tir(cls.softmax, (lv1613,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1614 = R.call_tir(cls.fused_reshape7_reshape8, (lv1261,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1264 = R.call_tir(cls.matmul2, (lv1614, lv1611), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1615 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1264,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv638: R.Tensor((1280, 1280), dtype="float32") = transformed_param_489
            lv639: R.Tensor((1280,), dtype="float32") = transformed_param_198
            lv1616 = R.call_tir(cls.fused_matmul_add2_add, (lv1615, lv638, lv639, lv1606), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv640: R.Tensor((1280,), dtype="float32") = transformed_param_194
            lv641: R.Tensor((1280,), dtype="float32") = transformed_param_193
            lv1272 = R.call_tir(cls.layer_norm, (lv1616, lv640, lv641), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv642_1: R.Tensor((1280, 5120), dtype="float32") = transformed_param_490
            lv643: R.Tensor((5120,), dtype="float32") = transformed_param_195
            lv1617 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1272, lv642_1, lv643), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv644: R.Tensor((5120, 1280), dtype="float32") = transformed_param_491
            lv645: R.Tensor((1280,), dtype="float32") = transformed_param_196
            lv1618 = R.call_tir(cls.fused_matmul4_add2_add, (lv1617, lv644, lv645, lv1616), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv646: R.Tensor((1280,), dtype="float32") = transformed_param_202
            lv647: R.Tensor((1280,), dtype="float32") = transformed_param_201
            lv1281_1 = R.call_tir(cls.layer_norm, (lv1618, lv646, lv647), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv648: R.Tensor((1280, 1280), dtype="float32") = transformed_param_492
            lv649: R.Tensor((1280,), dtype="float32") = transformed_param_209
            lv1619 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1281_1, lv648, lv649), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv650: R.Tensor((1280, 1280), dtype="float32") = transformed_param_493
            lv651_1: R.Tensor((1280,), dtype="float32") = transformed_param_207
            lv1620 = R.call_tir(cls.fused_matmul_add2, (lv1281_1, lv650, lv651_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1621 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1620,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv652: R.Tensor((1280, 1280), dtype="float32") = transformed_param_494
            lv653: R.Tensor((1280,), dtype="float32") = transformed_param_210
            lv1622 = R.call_tir(cls.fused_matmul_add2, (lv1281_1, lv652, lv653), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1623 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1622,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1624 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1619,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1302_1 = R.call_tir(cls.matmul1, (lv1624, lv1621), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1625 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1302_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1306_1 = R.call_tir(cls.softmax, (lv1625,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1626 = R.call_tir(cls.fused_reshape7_reshape8, (lv1306_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1309_1 = R.call_tir(cls.matmul2, (lv1626, lv1623), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1627 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1309_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv654: R.Tensor((1280, 1280), dtype="float32") = transformed_param_495
            lv655: R.Tensor((1280,), dtype="float32") = transformed_param_208
            lv1628 = R.call_tir(cls.fused_matmul_add2_add, (lv1627, lv654, lv655, lv1618), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv656: R.Tensor((1280,), dtype="float32") = transformed_param_204
            lv657: R.Tensor((1280,), dtype="float32") = transformed_param_203
            lv1317_1 = R.call_tir(cls.layer_norm, (lv1628, lv656, lv657), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv658: R.Tensor((1280, 5120), dtype="float32") = transformed_param_496
            lv659: R.Tensor((5120,), dtype="float32") = transformed_param_205
            lv1629 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1317_1, lv658, lv659), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv660: R.Tensor((5120, 1280), dtype="float32") = transformed_param_497
            lv661: R.Tensor((1280,), dtype="float32") = transformed_param_206
            lv1630 = R.call_tir(cls.fused_matmul4_add2_add, (lv1629, lv660, lv661, lv1628), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv662: R.Tensor((1280,), dtype="float32") = transformed_param_212
            lv663: R.Tensor((1280,), dtype="float32") = transformed_param_211
            lv1326_1 = R.call_tir(cls.layer_norm, (lv1630, lv662, lv663), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv664: R.Tensor((1280, 1280), dtype="float32") = transformed_param_498
            lv665: R.Tensor((1280,), dtype="float32") = transformed_param_219
            lv1631 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1326_1, lv664, lv665), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv666: R.Tensor((1280, 1280), dtype="float32") = transformed_param_499
            lv667: R.Tensor((1280,), dtype="float32") = transformed_param_217
            lv1632 = R.call_tir(cls.fused_matmul_add2, (lv1326_1, lv666, lv667), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1633 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1632,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv668: R.Tensor((1280, 1280), dtype="float32") = transformed_param_500
            lv669: R.Tensor((1280,), dtype="float32") = transformed_param_220
            lv1634 = R.call_tir(cls.fused_matmul_add2, (lv1326_1, lv668, lv669), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1635 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1634,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1636 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1631,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1347_1 = R.call_tir(cls.matmul1, (lv1636, lv1633), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1637 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1347_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1351_1 = R.call_tir(cls.softmax, (lv1637,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1638 = R.call_tir(cls.fused_reshape7_reshape8, (lv1351_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1354_1 = R.call_tir(cls.matmul2, (lv1638, lv1635), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1639 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1354_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv670: R.Tensor((1280, 1280), dtype="float32") = transformed_param_501
            lv671: R.Tensor((1280,), dtype="float32") = transformed_param_218
            lv1640 = R.call_tir(cls.fused_matmul_add2_add, (lv1639, lv670, lv671, lv1630), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv672_1: R.Tensor((1280,), dtype="float32") = transformed_param_214
            lv673: R.Tensor((1280,), dtype="float32") = transformed_param_213
            lv1362_1 = R.call_tir(cls.layer_norm, (lv1640, lv672_1, lv673), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv674: R.Tensor((1280, 5120), dtype="float32") = transformed_param_502
            lv675: R.Tensor((5120,), dtype="float32") = transformed_param_215
            lv1641 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1362_1, lv674, lv675), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv676_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_503
            lv677: R.Tensor((1280,), dtype="float32") = transformed_param_216
            lv1642 = R.call_tir(cls.fused_matmul4_add2_add, (lv1641, lv676_1, lv677, lv1640), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv678: R.Tensor((1280,), dtype="float32") = transformed_param_232
            lv679_1: R.Tensor((1280,), dtype="float32") = transformed_param_231
            lv1371_1 = R.call_tir(cls.layer_norm, (lv1642, lv678, lv679_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv680: R.Tensor((1280, 1280), dtype="float32") = transformed_param_504
            lv681: R.Tensor((1280,), dtype="float32") = transformed_param_239
            lv1643 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1371_1, lv680, lv681), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv682: R.Tensor((1280, 1280), dtype="float32") = transformed_param_505
            lv683: R.Tensor((1280,), dtype="float32") = transformed_param_237
            lv1644 = R.call_tir(cls.fused_matmul_add2, (lv1371_1, lv682, lv683), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1645 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1644,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv684: R.Tensor((1280, 1280), dtype="float32") = transformed_param_506
            lv685: R.Tensor((1280,), dtype="float32") = transformed_param_240
            lv1646 = R.call_tir(cls.fused_matmul_add2, (lv1371_1, lv684, lv685), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1647 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1646,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1648 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1643,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1392_1 = R.call_tir(cls.matmul1, (lv1648, lv1645), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1649 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1392_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1396_1 = R.call_tir(cls.softmax, (lv1649,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1650 = R.call_tir(cls.fused_reshape7_reshape8, (lv1396_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1399_1 = R.call_tir(cls.matmul2, (lv1650, lv1647), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1651 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1399_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv686: R.Tensor((1280, 1280), dtype="float32") = transformed_param_507
            lv687_1: R.Tensor((1280,), dtype="float32") = transformed_param_238
            lv1652 = R.call_tir(cls.fused_matmul_add2_add, (lv1651, lv686, lv687_1, lv1642), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv688: R.Tensor((1280,), dtype="float32") = transformed_param_234
            lv689: R.Tensor((1280,), dtype="float32") = transformed_param_233
            lv1407_1 = R.call_tir(cls.layer_norm, (lv1652, lv688, lv689), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv690: R.Tensor((1280, 5120), dtype="float32") = transformed_param_508
            lv691: R.Tensor((5120,), dtype="float32") = transformed_param_235
            lv1653 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1407_1, lv690, lv691), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv692: R.Tensor((5120, 1280), dtype="float32") = transformed_param_509
            lv693: R.Tensor((1280,), dtype="float32") = transformed_param_236
            lv1654 = R.call_tir(cls.fused_matmul4_add2_add, (lv1653, lv692, lv693, lv1652), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv694: R.Tensor((1280,), dtype="float32") = transformed_param_242
            lv695: R.Tensor((1280,), dtype="float32") = transformed_param_241
            lv1416_1 = R.call_tir(cls.layer_norm, (lv1654, lv694, lv695), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv696_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_510
            lv697: R.Tensor((1280,), dtype="float32") = transformed_param_249
            lv1655 = R.call_tir(cls.fused_matmul_add2_multiply, (lv1416_1, lv696_1, lv697), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv698: R.Tensor((1280, 1280), dtype="float32") = transformed_param_511
            lv699: R.Tensor((1280,), dtype="float32") = transformed_param_247
            lv1656 = R.call_tir(cls.fused_matmul_add2, (lv1416_1, lv698, lv699), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1657 = R.call_tir(cls.fused_reshape5_transpose1_reshape6_transpose2, (lv1656,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv700: R.Tensor((1280, 1280), dtype="float32") = transformed_param_512
            lv701: R.Tensor((1280,), dtype="float32") = transformed_param_250
            lv1658 = R.call_tir(cls.fused_matmul_add2, (lv1416_1, lv700, lv701), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1659 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1658,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1660 = R.call_tir(cls.fused_reshape5_transpose1_reshape6, (lv1655,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1437_1 = R.call_tir(cls.matmul1, (lv1660, lv1657), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1661 = R.call_tir(cls.fused_reshape7_add3_reshape8, (lv1437_1, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1441_1 = R.call_tir(cls.softmax, (lv1661,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1662 = R.call_tir(cls.fused_reshape7_reshape8, (lv1441_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1444_1 = R.call_tir(cls.matmul2, (lv1662, lv1659), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1663 = R.call_tir(cls.fused_reshape9_transpose3_reshape10, (lv1444_1,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv702: R.Tensor((1280, 1280), dtype="float32") = transformed_param_513
            lv703: R.Tensor((1280,), dtype="float32") = transformed_param_248
            lv1664 = R.call_tir(cls.fused_matmul_add2_add, (lv1663, lv702, lv703, lv1654), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv704: R.Tensor((1280,), dtype="float32") = transformed_param_244
            lv705: R.Tensor((1280,), dtype="float32") = transformed_param_243
            lv1452_1 = R.call_tir(cls.layer_norm, (lv1664, lv704, lv705), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv706: R.Tensor((1280, 5120), dtype="float32") = transformed_param_514
            lv707: R.Tensor((5120,), dtype="float32") = transformed_param_245
            lv1665 = R.call_tir(cls.fused_matmul3_add4_gelu, (lv1452_1, lv706, lv707), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv708: R.Tensor((5120, 1280), dtype="float32") = transformed_param_515
            lv709: R.Tensor((1280,), dtype="float32") = transformed_param_246
            lv1666 = R.call_tir(cls.fused_matmul4_add2_add, (lv1665, lv708, lv709, lv1664), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv710: R.Tensor((1280,), dtype="float32") = transformed_param_322
            lv711: R.Tensor((1280,), dtype="float32") = transformed_param_321
            lv1461_1 = R.call_tir(cls.layer_norm, (lv1666, lv710, lv711), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1462_1 = R.call_tir(cls.squeeze, (lv1461_1,), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv1463_1 = R.call_tir(cls.cast, (lv,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv1464_1 = R.call_tir(cls.argmax, (lv1463_1,), out_sinfo=R.Tensor((1,), dtype="int64"))
            lv1465_1 = R.call_tir(cls.take2, (lv1462_1, lv1464_1), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv1667 = R.call_tir(cls.fused_strided_slice_reshape11, (lv1465_1,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv712: R.Tensor((1280, 1280), dtype="float32") = transformed_param_516
            lv1469_1 = R.call_tir(cls.matmul5, (lv1667, lv712), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")) = lv1654, lv1469_1
            R.output(gv)
        return gv

    @R.function
    def concat_embeddings(cond_embeddings: R.Tensor((1, 77, 2048), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 2048), dtype="float32")) -> R.Tensor((2, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate12, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_enocder_outputs(cond_embeddings: R.Tensor((1, 77, 768), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 1280), dtype="float32")) -> R.Tensor((1, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((1, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_pool_embeddings(cond_embeddings: R.Tensor((1, 1280), dtype="float32"), uncond_embeddings: R.Tensor((1, 1280), dtype="float32")) -> R.Tensor((2, 1280), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate13, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
        return gv

    @R.function
    def euler_discrete_scheduler_scale(sample: R.Tensor((2, 4, 128, 128), dtype="float32"), sigma: R.Tensor((), dtype="float32")) -> R.Tensor((2, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.power, (sigma,), out_sinfo=R.Tensor((), dtype="float32"))
        gv1 = R.call_tir(cls.add48, (gv,), out_sinfo=R.Tensor((), dtype="float32"))
        gv2 = R.call_tir(cls.power1, (gv1,), out_sinfo=R.Tensor((), dtype="float32"))
        scaled_latent_model_input = R.call_tir(cls.divide11, (sample, gv2), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
        return scaled_latent_model_input

    @R.function
    def euler_discrete_scheduler_step(sample: R.Tensor((1, 4, 128, 128), dtype="float32"), model_output: R.Tensor((1, 4, 128, 128), dtype="float32"), sigma: R.Tensor((), dtype="float32"), sigma_1: R.Tensor((), dtype="float32")) -> R.Tensor((1, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.subtract1, (sigma_1, sigma), out_sinfo=R.Tensor((), dtype="float32"))
        gv1 = R.call_tir(cls.multiply18, (model_output, gv), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
        prev_sample = R.call_tir(cls.add29, (sample, gv1), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
        return prev_sample

    @R.function
    def image_to_rgba(x: R.Tensor((1, 1024, 1024, 3), dtype="float32")) -> R.Tensor((1024, 1024), dtype="uint32"):
        cls = Module
        gv = R.call_tir(cls.tir_image_to_rgba, (x,), out_sinfo=R.Tensor((1024, 1024), dtype="uint32"))
        return gv

    @R.function
    def unet(inp_0: R.Tensor((2, 4, 128, 128), dtype="float32"), inp_1: R.Tensor((), dtype="int32"), inp_2: R.Tensor((2, 77, 2048), dtype="float32"), inp_3: R.Tensor((2, 1280), dtype="float32"), inp_4: R.Tensor((2, 6), dtype="float32"), transformed_param_0: R.Tensor((1280,), dtype="float32"), transformed_param_1: R.Tensor((1280,), dtype="float32"), transformed_param_2: R.Tensor((320, 4, 3, 3), dtype="float32"), transformed_param_3: R.Tensor((320,), dtype="float32"), transformed_param_4: R.Tensor((320,), dtype="float32"), transformed_param_5: R.Tensor((4, 320, 3, 3), dtype="float32"), transformed_param_6: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_7: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_8: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_9: R.Tensor((320,), dtype="float32"), transformed_param_10: R.Tensor((320,), dtype="float32"), transformed_param_11: R.Tensor((320,), dtype="float32"), transformed_param_12: R.Tensor((320,), dtype="float32"), transformed_param_13: R.Tensor((320,), dtype="float32"), transformed_param_14: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_15: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_16: R.Tensor((320,), dtype="float32"), transformed_param_17: R.Tensor((320,), dtype="float32"), transformed_param_18: R.Tensor((320,), dtype="float32"), transformed_param_19: R.Tensor((320,), dtype="float32"), transformed_param_20: R.Tensor((320,), dtype="float32"), transformed_param_21: R.Tensor((640,), dtype="float32"), transformed_param_22: R.Tensor((640,), dtype="float32"), transformed_param_23: R.Tensor((640,), dtype="float32"), transformed_param_24: R.Tensor((640,), dtype="float32"), transformed_param_25: R.Tensor((640,), dtype="float32"), transformed_param_26: R.Tensor((640,), dtype="float32"), transformed_param_27: R.Tensor((5120,), dtype="float32"), transformed_param_28: R.Tensor((640,), dtype="float32"), transformed_param_29: R.Tensor((640,), dtype="float32"), transformed_param_30: R.Tensor((640,), dtype="float32"), transformed_param_31: R.Tensor((640,), dtype="float32"), transformed_param_32: R.Tensor((640,), dtype="float32"), transformed_param_33: R.Tensor((640,), dtype="float32"), transformed_param_34: R.Tensor((640,), dtype="float32"), transformed_param_35: R.Tensor((640,), dtype="float32"), transformed_param_36: R.Tensor((640,), dtype="float32"), transformed_param_37: R.Tensor((5120,), dtype="float32"), transformed_param_38: R.Tensor((640,), dtype="float32"), transformed_param_39: R.Tensor((640,), dtype="float32"), transformed_param_40: R.Tensor((640,), dtype="float32"), transformed_param_41: R.Tensor((640,), dtype="float32"), transformed_param_42: R.Tensor((640,), dtype="float32"), transformed_param_43: R.Tensor((640,), dtype="float32"), transformed_param_44: R.Tensor((640,), dtype="float32"), transformed_param_45: R.Tensor((640,), dtype="float32"), transformed_param_46: R.Tensor((640,), dtype="float32"), transformed_param_47: R.Tensor((640,), dtype="float32"), transformed_param_48: R.Tensor((640,), dtype="float32"), transformed_param_49: R.Tensor((640,), dtype="float32"), transformed_param_50: R.Tensor((640,), dtype="float32"), transformed_param_51: R.Tensor((5120,), dtype="float32"), transformed_param_52: R.Tensor((640,), dtype="float32"), transformed_param_53: R.Tensor((640,), dtype="float32"), transformed_param_54: R.Tensor((640,), dtype="float32"), transformed_param_55: R.Tensor((640,), dtype="float32"), transformed_param_56: R.Tensor((640,), dtype="float32"), transformed_param_57: R.Tensor((640,), dtype="float32"), transformed_param_58: R.Tensor((640,), dtype="float32"), transformed_param_59: R.Tensor((640,), dtype="float32"), transformed_param_60: R.Tensor((640,), dtype="float32"), transformed_param_61: R.Tensor((5120,), dtype="float32"), transformed_param_62: R.Tensor((640,), dtype="float32"), transformed_param_63: R.Tensor((640,), dtype="float32"), transformed_param_64: R.Tensor((640,), dtype="float32"), transformed_param_65: R.Tensor((640,), dtype="float32"), transformed_param_66: R.Tensor((640,), dtype="float32"), transformed_param_67: R.Tensor((640,), dtype="float32"), transformed_param_68: R.Tensor((640,), dtype="float32"), transformed_param_69: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_70: R.Tensor((640, 320, 3, 3), dtype="float32"), transformed_param_71: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_72: R.Tensor((640, 320, 1, 1), dtype="float32"), transformed_param_73: R.Tensor((320,), dtype="float32"), transformed_param_74: R.Tensor((320,), dtype="float32"), transformed_param_75: R.Tensor((640,), dtype="float32"), transformed_param_76: R.Tensor((640,), dtype="float32"), transformed_param_77: R.Tensor((640,), dtype="float32"), transformed_param_78: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_79: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_80: R.Tensor((640,), dtype="float32"), transformed_param_81: R.Tensor((640,), dtype="float32"), transformed_param_82: R.Tensor((640,), dtype="float32"), transformed_param_83: R.Tensor((640,), dtype="float32"), transformed_param_84: R.Tensor((640,), dtype="float32"), transformed_param_85: R.Tensor((1280,), dtype="float32"), transformed_param_86: R.Tensor((1280,), dtype="float32"), transformed_param_87: R.Tensor((1280,), dtype="float32"), transformed_param_88: R.Tensor((1280,), dtype="float32"), transformed_param_89: R.Tensor((1280,), dtype="float32"), transformed_param_90: R.Tensor((1280,), dtype="float32"), transformed_param_91: R.Tensor((10240,), dtype="float32"), transformed_param_92: R.Tensor((1280,), dtype="float32"), transformed_param_93: R.Tensor((1280,), dtype="float32"), transformed_param_94: R.Tensor((1280,), dtype="float32"), transformed_param_95: R.Tensor((1280,), dtype="float32"), transformed_param_96: R.Tensor((1280,), dtype="float32"), transformed_param_97: R.Tensor((1280,), dtype="float32"), transformed_param_98: R.Tensor((1280,), dtype="float32"), transformed_param_99: R.Tensor((1280,), dtype="float32"), transformed_param_100: R.Tensor((1280,), dtype="float32"), transformed_param_101: R.Tensor((10240,), dtype="float32"), transformed_param_102: R.Tensor((1280,), dtype="float32"), transformed_param_103: R.Tensor((1280,), dtype="float32"), transformed_param_104: R.Tensor((1280,), dtype="float32"), transformed_param_105: R.Tensor((1280,), dtype="float32"), transformed_param_106: R.Tensor((1280,), dtype="float32"), transformed_param_107: R.Tensor((1280,), dtype="float32"), transformed_param_108: R.Tensor((1280,), dtype="float32"), transformed_param_109: R.Tensor((1280,), dtype="float32"), transformed_param_110: R.Tensor((1280,), dtype="float32"), transformed_param_111: R.Tensor((10240,), dtype="float32"), transformed_param_112: R.Tensor((1280,), dtype="float32"), transformed_param_113: R.Tensor((1280,), dtype="float32"), transformed_param_114: R.Tensor((1280,), dtype="float32"), transformed_param_115: R.Tensor((1280,), dtype="float32"), transformed_param_116: R.Tensor((1280,), dtype="float32"), transformed_param_117: R.Tensor((1280,), dtype="float32"), transformed_param_118: R.Tensor((1280,), dtype="float32"), transformed_param_119: R.Tensor((1280,), dtype="float32"), transformed_param_120: R.Tensor((1280,), dtype="float32"), transformed_param_121: R.Tensor((10240,), dtype="float32"), transformed_param_122: R.Tensor((1280,), dtype="float32"), transformed_param_123: R.Tensor((1280,), dtype="float32"), transformed_param_124: R.Tensor((1280,), dtype="float32"), transformed_param_125: R.Tensor((1280,), dtype="float32"), transformed_param_126: R.Tensor((1280,), dtype="float32"), transformed_param_127: R.Tensor((1280,), dtype="float32"), transformed_param_128: R.Tensor((1280,), dtype="float32"), transformed_param_129: R.Tensor((1280,), dtype="float32"), transformed_param_130: R.Tensor((1280,), dtype="float32"), transformed_param_131: R.Tensor((10240,), dtype="float32"), transformed_param_132: R.Tensor((1280,), dtype="float32"), transformed_param_133: R.Tensor((1280,), dtype="float32"), transformed_param_134: R.Tensor((1280,), dtype="float32"), transformed_param_135: R.Tensor((1280,), dtype="float32"), transformed_param_136: R.Tensor((1280,), dtype="float32"), transformed_param_137: R.Tensor((1280,), dtype="float32"), transformed_param_138: R.Tensor((1280,), dtype="float32"), transformed_param_139: R.Tensor((1280,), dtype="float32"), transformed_param_140: R.Tensor((1280,), dtype="float32"), transformed_param_141: R.Tensor((10240,), dtype="float32"), transformed_param_142: R.Tensor((1280,), dtype="float32"), transformed_param_143: R.Tensor((1280,), dtype="float32"), transformed_param_144: R.Tensor((1280,), dtype="float32"), transformed_param_145: R.Tensor((1280,), dtype="float32"), transformed_param_146: R.Tensor((1280,), dtype="float32"), transformed_param_147: R.Tensor((1280,), dtype="float32"), transformed_param_148: R.Tensor((1280,), dtype="float32"), transformed_param_149: R.Tensor((1280,), dtype="float32"), transformed_param_150: R.Tensor((1280,), dtype="float32"), transformed_param_151: R.Tensor((10240,), dtype="float32"), transformed_param_152: R.Tensor((1280,), dtype="float32"), transformed_param_153: R.Tensor((1280,), dtype="float32"), transformed_param_154: R.Tensor((1280,), dtype="float32"), transformed_param_155: R.Tensor((1280,), dtype="float32"), transformed_param_156: R.Tensor((1280,), dtype="float32"), transformed_param_157: R.Tensor((1280,), dtype="float32"), transformed_param_158: R.Tensor((1280,), dtype="float32"), transformed_param_159: R.Tensor((1280,), dtype="float32"), transformed_param_160: R.Tensor((1280,), dtype="float32"), transformed_param_161: R.Tensor((10240,), dtype="float32"), transformed_param_162: R.Tensor((1280,), dtype="float32"), transformed_param_163: R.Tensor((1280,), dtype="float32"), transformed_param_164: R.Tensor((1280,), dtype="float32"), transformed_param_165: R.Tensor((1280,), dtype="float32"), transformed_param_166: R.Tensor((1280,), dtype="float32"), transformed_param_167: R.Tensor((1280,), dtype="float32"), transformed_param_168: R.Tensor((1280,), dtype="float32"), transformed_param_169: R.Tensor((1280,), dtype="float32"), transformed_param_170: R.Tensor((1280,), dtype="float32"), transformed_param_171: R.Tensor((10240,), dtype="float32"), transformed_param_172: R.Tensor((1280,), dtype="float32"), transformed_param_173: R.Tensor((1280,), dtype="float32"), transformed_param_174: R.Tensor((1280,), dtype="float32"), transformed_param_175: R.Tensor((1280,), dtype="float32"), transformed_param_176: R.Tensor((1280,), dtype="float32"), transformed_param_177: R.Tensor((1280,), dtype="float32"), transformed_param_178: R.Tensor((1280,), dtype="float32"), transformed_param_179: R.Tensor((1280,), dtype="float32"), transformed_param_180: R.Tensor((1280,), dtype="float32"), transformed_param_181: R.Tensor((10240,), dtype="float32"), transformed_param_182: R.Tensor((1280,), dtype="float32"), transformed_param_183: R.Tensor((1280,), dtype="float32"), transformed_param_184: R.Tensor((1280,), dtype="float32"), transformed_param_185: R.Tensor((1280,), dtype="float32"), transformed_param_186: R.Tensor((1280,), dtype="float32"), transformed_param_187: R.Tensor((1280,), dtype="float32"), transformed_param_188: R.Tensor((1280,), dtype="float32"), transformed_param_189: R.Tensor((1280,), dtype="float32"), transformed_param_190: R.Tensor((1280,), dtype="float32"), transformed_param_191: R.Tensor((1280,), dtype="float32"), transformed_param_192: R.Tensor((1280,), dtype="float32"), transformed_param_193: R.Tensor((1280,), dtype="float32"), transformed_param_194: R.Tensor((1280,), dtype="float32"), transformed_param_195: R.Tensor((10240,), dtype="float32"), transformed_param_196: R.Tensor((1280,), dtype="float32"), transformed_param_197: R.Tensor((1280,), dtype="float32"), transformed_param_198: R.Tensor((1280,), dtype="float32"), transformed_param_199: R.Tensor((1280,), dtype="float32"), transformed_param_200: R.Tensor((1280,), dtype="float32"), transformed_param_201: R.Tensor((1280,), dtype="float32"), transformed_param_202: R.Tensor((1280,), dtype="float32"), transformed_param_203: R.Tensor((1280,), dtype="float32"), transformed_param_204: R.Tensor((1280,), dtype="float32"), transformed_param_205: R.Tensor((10240,), dtype="float32"), transformed_param_206: R.Tensor((1280,), dtype="float32"), transformed_param_207: R.Tensor((1280,), dtype="float32"), transformed_param_208: R.Tensor((1280,), dtype="float32"), transformed_param_209: R.Tensor((1280,), dtype="float32"), transformed_param_210: R.Tensor((1280,), dtype="float32"), transformed_param_211: R.Tensor((1280,), dtype="float32"), transformed_param_212: R.Tensor((1280,), dtype="float32"), transformed_param_213: R.Tensor((1280,), dtype="float32"), transformed_param_214: R.Tensor((1280,), dtype="float32"), transformed_param_215: R.Tensor((10240,), dtype="float32"), transformed_param_216: R.Tensor((1280,), dtype="float32"), transformed_param_217: R.Tensor((1280,), dtype="float32"), transformed_param_218: R.Tensor((1280,), dtype="float32"), transformed_param_219: R.Tensor((1280,), dtype="float32"), transformed_param_220: R.Tensor((1280,), dtype="float32"), transformed_param_221: R.Tensor((1280,), dtype="float32"), transformed_param_222: R.Tensor((1280,), dtype="float32"), transformed_param_223: R.Tensor((1280,), dtype="float32"), transformed_param_224: R.Tensor((1280,), dtype="float32"), transformed_param_225: R.Tensor((10240,), dtype="float32"), transformed_param_226: R.Tensor((1280,), dtype="float32"), transformed_param_227: R.Tensor((1280,), dtype="float32"), transformed_param_228: R.Tensor((1280,), dtype="float32"), transformed_param_229: R.Tensor((1280,), dtype="float32"), transformed_param_230: R.Tensor((1280,), dtype="float32"), transformed_param_231: R.Tensor((1280,), dtype="float32"), transformed_param_232: R.Tensor((1280,), dtype="float32"), transformed_param_233: R.Tensor((1280,), dtype="float32"), transformed_param_234: R.Tensor((1280,), dtype="float32"), transformed_param_235: R.Tensor((10240,), dtype="float32"), transformed_param_236: R.Tensor((1280,), dtype="float32"), transformed_param_237: R.Tensor((1280,), dtype="float32"), transformed_param_238: R.Tensor((1280,), dtype="float32"), transformed_param_239: R.Tensor((1280,), dtype="float32"), transformed_param_240: R.Tensor((1280,), dtype="float32"), transformed_param_241: R.Tensor((1280,), dtype="float32"), transformed_param_242: R.Tensor((1280,), dtype="float32"), transformed_param_243: R.Tensor((1280,), dtype="float32"), transformed_param_244: R.Tensor((1280,), dtype="float32"), transformed_param_245: R.Tensor((10240,), dtype="float32"), transformed_param_246: R.Tensor((1280,), dtype="float32"), transformed_param_247: R.Tensor((1280,), dtype="float32"), transformed_param_248: R.Tensor((1280,), dtype="float32"), transformed_param_249: R.Tensor((1280,), dtype="float32"), transformed_param_250: R.Tensor((1280,), dtype="float32"), transformed_param_251: R.Tensor((1280,), dtype="float32"), transformed_param_252: R.Tensor((1280,), dtype="float32"), transformed_param_253: R.Tensor((1280,), dtype="float32"), transformed_param_254: R.Tensor((1280,), dtype="float32"), transformed_param_255: R.Tensor((10240,), dtype="float32"), transformed_param_256: R.Tensor((1280,), dtype="float32"), transformed_param_257: R.Tensor((1280,), dtype="float32"), transformed_param_258: R.Tensor((1280,), dtype="float32"), transformed_param_259: R.Tensor((1280,), dtype="float32"), transformed_param_260: R.Tensor((1280,), dtype="float32"), transformed_param_261: R.Tensor((1280,), dtype="float32"), transformed_param_262: R.Tensor((1280,), dtype="float32"), transformed_param_263: R.Tensor((1280,), dtype="float32"), transformed_param_264: R.Tensor((1280,), dtype="float32"), transformed_param_265: R.Tensor((10240,), dtype="float32"), transformed_param_266: R.Tensor((1280,), dtype="float32"), transformed_param_267: R.Tensor((1280,), dtype="float32"), transformed_param_268: R.Tensor((1280,), dtype="float32"), transformed_param_269: R.Tensor((1280,), dtype="float32"), transformed_param_270: R.Tensor((1280,), dtype="float32"), transformed_param_271: R.Tensor((1280,), dtype="float32"), transformed_param_272: R.Tensor((1280,), dtype="float32"), transformed_param_273: R.Tensor((1280,), dtype="float32"), transformed_param_274: R.Tensor((1280,), dtype="float32"), transformed_param_275: R.Tensor((10240,), dtype="float32"), transformed_param_276: R.Tensor((1280,), dtype="float32"), transformed_param_277: R.Tensor((1280,), dtype="float32"), transformed_param_278: R.Tensor((1280,), dtype="float32"), transformed_param_279: R.Tensor((1280,), dtype="float32"), transformed_param_280: R.Tensor((1280,), dtype="float32"), transformed_param_281: R.Tensor((1280,), dtype="float32"), transformed_param_282: R.Tensor((1280,), dtype="float32"), transformed_param_283: R.Tensor((1280,), dtype="float32"), transformed_param_284: R.Tensor((1280,), dtype="float32"), transformed_param_285: R.Tensor((10240,), dtype="float32"), transformed_param_286: R.Tensor((1280,), dtype="float32"), transformed_param_287: R.Tensor((1280,), dtype="float32"), transformed_param_288: R.Tensor((1280,), dtype="float32"), transformed_param_289: R.Tensor((1280,), dtype="float32"), transformed_param_290: R.Tensor((1280,), dtype="float32"), transformed_param_291: R.Tensor((1280,), dtype="float32"), transformed_param_292: R.Tensor((1280,), dtype="float32"), transformed_param_293: R.Tensor((1280, 640, 3, 3), dtype="float32"), transformed_param_294: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_295: R.Tensor((1280, 640, 1, 1), dtype="float32"), transformed_param_296: R.Tensor((640,), dtype="float32"), transformed_param_297: R.Tensor((640,), dtype="float32"), transformed_param_298: R.Tensor((1280,), dtype="float32"), transformed_param_299: R.Tensor((1280,), dtype="float32"), transformed_param_300: R.Tensor((1280,), dtype="float32"), transformed_param_301: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_302: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_303: R.Tensor((1280,), dtype="float32"), transformed_param_304: R.Tensor((1280,), dtype="float32"), transformed_param_305: R.Tensor((1280,), dtype="float32"), transformed_param_306: R.Tensor((1280,), dtype="float32"), transformed_param_307: R.Tensor((1280,), dtype="float32"), transformed_param_308: R.Tensor((1280,), dtype="float32"), transformed_param_309: R.Tensor((1280,), dtype="float32"), transformed_param_310: R.Tensor((1280,), dtype="float32"), transformed_param_311: R.Tensor((1280,), dtype="float32"), transformed_param_312: R.Tensor((1280,), dtype="float32"), transformed_param_313: R.Tensor((1280,), dtype="float32"), transformed_param_314: R.Tensor((10240,), dtype="float32"), transformed_param_315: R.Tensor((1280,), dtype="float32"), transformed_param_316: R.Tensor((1280,), dtype="float32"), transformed_param_317: R.Tensor((1280,), dtype="float32"), transformed_param_318: R.Tensor((1280,), dtype="float32"), transformed_param_319: R.Tensor((1280,), dtype="float32"), transformed_param_320: R.Tensor((1280,), dtype="float32"), transformed_param_321: R.Tensor((1280,), dtype="float32"), transformed_param_322: R.Tensor((1280,), dtype="float32"), transformed_param_323: R.Tensor((1280,), dtype="float32"), transformed_param_324: R.Tensor((10240,), dtype="float32"), transformed_param_325: R.Tensor((1280,), dtype="float32"), transformed_param_326: R.Tensor((1280,), dtype="float32"), transformed_param_327: R.Tensor((1280,), dtype="float32"), transformed_param_328: R.Tensor((1280,), dtype="float32"), transformed_param_329: R.Tensor((1280,), dtype="float32"), transformed_param_330: R.Tensor((1280,), dtype="float32"), transformed_param_331: R.Tensor((1280,), dtype="float32"), transformed_param_332: R.Tensor((1280,), dtype="float32"), transformed_param_333: R.Tensor((1280,), dtype="float32"), transformed_param_334: R.Tensor((10240,), dtype="float32"), transformed_param_335: R.Tensor((1280,), dtype="float32"), transformed_param_336: R.Tensor((1280,), dtype="float32"), transformed_param_337: R.Tensor((1280,), dtype="float32"), transformed_param_338: R.Tensor((1280,), dtype="float32"), transformed_param_339: R.Tensor((1280,), dtype="float32"), transformed_param_340: R.Tensor((1280,), dtype="float32"), transformed_param_341: R.Tensor((1280,), dtype="float32"), transformed_param_342: R.Tensor((1280,), dtype="float32"), transformed_param_343: R.Tensor((1280,), dtype="float32"), transformed_param_344: R.Tensor((10240,), dtype="float32"), transformed_param_345: R.Tensor((1280,), dtype="float32"), transformed_param_346: R.Tensor((1280,), dtype="float32"), transformed_param_347: R.Tensor((1280,), dtype="float32"), transformed_param_348: R.Tensor((1280,), dtype="float32"), transformed_param_349: R.Tensor((1280,), dtype="float32"), transformed_param_350: R.Tensor((1280,), dtype="float32"), transformed_param_351: R.Tensor((1280,), dtype="float32"), transformed_param_352: R.Tensor((1280,), dtype="float32"), transformed_param_353: R.Tensor((1280,), dtype="float32"), transformed_param_354: R.Tensor((10240,), dtype="float32"), transformed_param_355: R.Tensor((1280,), dtype="float32"), transformed_param_356: R.Tensor((1280,), dtype="float32"), transformed_param_357: R.Tensor((1280,), dtype="float32"), transformed_param_358: R.Tensor((1280,), dtype="float32"), transformed_param_359: R.Tensor((1280,), dtype="float32"), transformed_param_360: R.Tensor((1280,), dtype="float32"), transformed_param_361: R.Tensor((1280,), dtype="float32"), transformed_param_362: R.Tensor((1280,), dtype="float32"), transformed_param_363: R.Tensor((1280,), dtype="float32"), transformed_param_364: R.Tensor((10240,), dtype="float32"), transformed_param_365: R.Tensor((1280,), dtype="float32"), transformed_param_366: R.Tensor((1280,), dtype="float32"), transformed_param_367: R.Tensor((1280,), dtype="float32"), transformed_param_368: R.Tensor((1280,), dtype="float32"), transformed_param_369: R.Tensor((1280,), dtype="float32"), transformed_param_370: R.Tensor((1280,), dtype="float32"), transformed_param_371: R.Tensor((1280,), dtype="float32"), transformed_param_372: R.Tensor((1280,), dtype="float32"), transformed_param_373: R.Tensor((1280,), dtype="float32"), transformed_param_374: R.Tensor((10240,), dtype="float32"), transformed_param_375: R.Tensor((1280,), dtype="float32"), transformed_param_376: R.Tensor((1280,), dtype="float32"), transformed_param_377: R.Tensor((1280,), dtype="float32"), transformed_param_378: R.Tensor((1280,), dtype="float32"), transformed_param_379: R.Tensor((1280,), dtype="float32"), transformed_param_380: R.Tensor((1280,), dtype="float32"), transformed_param_381: R.Tensor((1280,), dtype="float32"), transformed_param_382: R.Tensor((1280,), dtype="float32"), transformed_param_383: R.Tensor((1280,), dtype="float32"), transformed_param_384: R.Tensor((10240,), dtype="float32"), transformed_param_385: R.Tensor((1280,), dtype="float32"), transformed_param_386: R.Tensor((1280,), dtype="float32"), transformed_param_387: R.Tensor((1280,), dtype="float32"), transformed_param_388: R.Tensor((1280,), dtype="float32"), transformed_param_389: R.Tensor((1280,), dtype="float32"), transformed_param_390: R.Tensor((1280,), dtype="float32"), transformed_param_391: R.Tensor((1280,), dtype="float32"), transformed_param_392: R.Tensor((1280,), dtype="float32"), transformed_param_393: R.Tensor((1280,), dtype="float32"), transformed_param_394: R.Tensor((10240,), dtype="float32"), transformed_param_395: R.Tensor((1280,), dtype="float32"), transformed_param_396: R.Tensor((1280,), dtype="float32"), transformed_param_397: R.Tensor((1280,), dtype="float32"), transformed_param_398: R.Tensor((1280,), dtype="float32"), transformed_param_399: R.Tensor((1280,), dtype="float32"), transformed_param_400: R.Tensor((1280,), dtype="float32"), transformed_param_401: R.Tensor((1280,), dtype="float32"), transformed_param_402: R.Tensor((1280,), dtype="float32"), transformed_param_403: R.Tensor((1280,), dtype="float32"), transformed_param_404: R.Tensor((10240,), dtype="float32"), transformed_param_405: R.Tensor((1280,), dtype="float32"), transformed_param_406: R.Tensor((1280,), dtype="float32"), transformed_param_407: R.Tensor((1280,), dtype="float32"), transformed_param_408: R.Tensor((1280,), dtype="float32"), transformed_param_409: R.Tensor((1280,), dtype="float32"), transformed_param_410: R.Tensor((1280,), dtype="float32"), transformed_param_411: R.Tensor((1280,), dtype="float32"), transformed_param_412: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_413: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_414: R.Tensor((1280,), dtype="float32"), transformed_param_415: R.Tensor((1280,), dtype="float32"), transformed_param_416: R.Tensor((1280,), dtype="float32"), transformed_param_417: R.Tensor((1280,), dtype="float32"), transformed_param_418: R.Tensor((1280,), dtype="float32"), transformed_param_419: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_420: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_421: R.Tensor((1280,), dtype="float32"), transformed_param_422: R.Tensor((1280,), dtype="float32"), transformed_param_423: R.Tensor((1280,), dtype="float32"), transformed_param_424: R.Tensor((1280,), dtype="float32"), transformed_param_425: R.Tensor((1280,), dtype="float32"), transformed_param_426: R.Tensor((1280,), dtype="float32"), transformed_param_427: R.Tensor((1280,), dtype="float32"), transformed_param_428: R.Tensor((1280,), dtype="float32"), transformed_param_429: R.Tensor((1280,), dtype="float32"), transformed_param_430: R.Tensor((1280,), dtype="float32"), transformed_param_431: R.Tensor((1280,), dtype="float32"), transformed_param_432: R.Tensor((1280,), dtype="float32"), transformed_param_433: R.Tensor((1280,), dtype="float32"), transformed_param_434: R.Tensor((10240,), dtype="float32"), transformed_param_435: R.Tensor((1280,), dtype="float32"), transformed_param_436: R.Tensor((1280,), dtype="float32"), transformed_param_437: R.Tensor((1280,), dtype="float32"), transformed_param_438: R.Tensor((1280,), dtype="float32"), transformed_param_439: R.Tensor((1280,), dtype="float32"), transformed_param_440: R.Tensor((1280,), dtype="float32"), transformed_param_441: R.Tensor((1280,), dtype="float32"), transformed_param_442: R.Tensor((1280,), dtype="float32"), transformed_param_443: R.Tensor((1280,), dtype="float32"), transformed_param_444: R.Tensor((10240,), dtype="float32"), transformed_param_445: R.Tensor((1280,), dtype="float32"), transformed_param_446: R.Tensor((1280,), dtype="float32"), transformed_param_447: R.Tensor((1280,), dtype="float32"), transformed_param_448: R.Tensor((1280,), dtype="float32"), transformed_param_449: R.Tensor((1280,), dtype="float32"), transformed_param_450: R.Tensor((1280,), dtype="float32"), transformed_param_451: R.Tensor((1280,), dtype="float32"), transformed_param_452: R.Tensor((1280,), dtype="float32"), transformed_param_453: R.Tensor((1280,), dtype="float32"), transformed_param_454: R.Tensor((10240,), dtype="float32"), transformed_param_455: R.Tensor((1280,), dtype="float32"), transformed_param_456: R.Tensor((1280,), dtype="float32"), transformed_param_457: R.Tensor((1280,), dtype="float32"), transformed_param_458: R.Tensor((1280,), dtype="float32"), transformed_param_459: R.Tensor((1280,), dtype="float32"), transformed_param_460: R.Tensor((1280,), dtype="float32"), transformed_param_461: R.Tensor((1280,), dtype="float32"), transformed_param_462: R.Tensor((1280,), dtype="float32"), transformed_param_463: R.Tensor((1280,), dtype="float32"), transformed_param_464: R.Tensor((10240,), dtype="float32"), transformed_param_465: R.Tensor((1280,), dtype="float32"), transformed_param_466: R.Tensor((1280,), dtype="float32"), transformed_param_467: R.Tensor((1280,), dtype="float32"), transformed_param_468: R.Tensor((1280,), dtype="float32"), transformed_param_469: R.Tensor((1280,), dtype="float32"), transformed_param_470: R.Tensor((1280,), dtype="float32"), transformed_param_471: R.Tensor((1280,), dtype="float32"), transformed_param_472: R.Tensor((1280,), dtype="float32"), transformed_param_473: R.Tensor((1280,), dtype="float32"), transformed_param_474: R.Tensor((10240,), dtype="float32"), transformed_param_475: R.Tensor((1280,), dtype="float32"), transformed_param_476: R.Tensor((1280,), dtype="float32"), transformed_param_477: R.Tensor((1280,), dtype="float32"), transformed_param_478: R.Tensor((1280,), dtype="float32"), transformed_param_479: R.Tensor((1280,), dtype="float32"), transformed_param_480: R.Tensor((1280,), dtype="float32"), transformed_param_481: R.Tensor((1280,), dtype="float32"), transformed_param_482: R.Tensor((1280,), dtype="float32"), transformed_param_483: R.Tensor((1280,), dtype="float32"), transformed_param_484: R.Tensor((10240,), dtype="float32"), transformed_param_485: R.Tensor((1280,), dtype="float32"), transformed_param_486: R.Tensor((1280,), dtype="float32"), transformed_param_487: R.Tensor((1280,), dtype="float32"), transformed_param_488: R.Tensor((1280,), dtype="float32"), transformed_param_489: R.Tensor((1280,), dtype="float32"), transformed_param_490: R.Tensor((1280,), dtype="float32"), transformed_param_491: R.Tensor((1280,), dtype="float32"), transformed_param_492: R.Tensor((1280,), dtype="float32"), transformed_param_493: R.Tensor((1280,), dtype="float32"), transformed_param_494: R.Tensor((10240,), dtype="float32"), transformed_param_495: R.Tensor((1280,), dtype="float32"), transformed_param_496: R.Tensor((1280,), dtype="float32"), transformed_param_497: R.Tensor((1280,), dtype="float32"), transformed_param_498: R.Tensor((1280,), dtype="float32"), transformed_param_499: R.Tensor((1280,), dtype="float32"), transformed_param_500: R.Tensor((1280,), dtype="float32"), transformed_param_501: R.Tensor((1280,), dtype="float32"), transformed_param_502: R.Tensor((1280,), dtype="float32"), transformed_param_503: R.Tensor((1280,), dtype="float32"), transformed_param_504: R.Tensor((10240,), dtype="float32"), transformed_param_505: R.Tensor((1280,), dtype="float32"), transformed_param_506: R.Tensor((1280,), dtype="float32"), transformed_param_507: R.Tensor((1280,), dtype="float32"), transformed_param_508: R.Tensor((1280,), dtype="float32"), transformed_param_509: R.Tensor((1280,), dtype="float32"), transformed_param_510: R.Tensor((1280,), dtype="float32"), transformed_param_511: R.Tensor((1280,), dtype="float32"), transformed_param_512: R.Tensor((1280,), dtype="float32"), transformed_param_513: R.Tensor((1280,), dtype="float32"), transformed_param_514: R.Tensor((10240,), dtype="float32"), transformed_param_515: R.Tensor((1280,), dtype="float32"), transformed_param_516: R.Tensor((1280,), dtype="float32"), transformed_param_517: R.Tensor((1280,), dtype="float32"), transformed_param_518: R.Tensor((1280,), dtype="float32"), transformed_param_519: R.Tensor((1280,), dtype="float32"), transformed_param_520: R.Tensor((1280,), dtype="float32"), transformed_param_521: R.Tensor((1280,), dtype="float32"), transformed_param_522: R.Tensor((1280,), dtype="float32"), transformed_param_523: R.Tensor((1280,), dtype="float32"), transformed_param_524: R.Tensor((10240,), dtype="float32"), transformed_param_525: R.Tensor((1280,), dtype="float32"), transformed_param_526: R.Tensor((1280,), dtype="float32"), transformed_param_527: R.Tensor((1280,), dtype="float32"), transformed_param_528: R.Tensor((1280,), dtype="float32"), transformed_param_529: R.Tensor((1280,), dtype="float32"), transformed_param_530: R.Tensor((1280,), dtype="float32"), transformed_param_531: R.Tensor((1280,), dtype="float32"), transformed_param_532: R.Tensor((1280,), dtype="float32"), transformed_param_533: R.Tensor((1280,), dtype="float32"), transformed_param_534: R.Tensor((1280,), dtype="float32"), transformed_param_535: R.Tensor((1280,), dtype="float32"), transformed_param_536: R.Tensor((1280,), dtype="float32"), transformed_param_537: R.Tensor((1280,), dtype="float32"), transformed_param_538: R.Tensor((10240,), dtype="float32"), transformed_param_539: R.Tensor((1280,), dtype="float32"), transformed_param_540: R.Tensor((1280,), dtype="float32"), transformed_param_541: R.Tensor((1280,), dtype="float32"), transformed_param_542: R.Tensor((1280,), dtype="float32"), transformed_param_543: R.Tensor((1280,), dtype="float32"), transformed_param_544: R.Tensor((1280,), dtype="float32"), transformed_param_545: R.Tensor((1280,), dtype="float32"), transformed_param_546: R.Tensor((1280,), dtype="float32"), transformed_param_547: R.Tensor((1280,), dtype="float32"), transformed_param_548: R.Tensor((10240,), dtype="float32"), transformed_param_549: R.Tensor((1280,), dtype="float32"), transformed_param_550: R.Tensor((1280,), dtype="float32"), transformed_param_551: R.Tensor((1280,), dtype="float32"), transformed_param_552: R.Tensor((1280,), dtype="float32"), transformed_param_553: R.Tensor((1280,), dtype="float32"), transformed_param_554: R.Tensor((1280,), dtype="float32"), transformed_param_555: R.Tensor((1280,), dtype="float32"), transformed_param_556: R.Tensor((1280,), dtype="float32"), transformed_param_557: R.Tensor((1280,), dtype="float32"), transformed_param_558: R.Tensor((10240,), dtype="float32"), transformed_param_559: R.Tensor((1280,), dtype="float32"), transformed_param_560: R.Tensor((1280,), dtype="float32"), transformed_param_561: R.Tensor((1280,), dtype="float32"), transformed_param_562: R.Tensor((1280,), dtype="float32"), transformed_param_563: R.Tensor((1280,), dtype="float32"), transformed_param_564: R.Tensor((1280,), dtype="float32"), transformed_param_565: R.Tensor((1280,), dtype="float32"), transformed_param_566: R.Tensor((1280,), dtype="float32"), transformed_param_567: R.Tensor((1280,), dtype="float32"), transformed_param_568: R.Tensor((10240,), dtype="float32"), transformed_param_569: R.Tensor((1280,), dtype="float32"), transformed_param_570: R.Tensor((1280,), dtype="float32"), transformed_param_571: R.Tensor((1280,), dtype="float32"), transformed_param_572: R.Tensor((1280,), dtype="float32"), transformed_param_573: R.Tensor((1280,), dtype="float32"), transformed_param_574: R.Tensor((1280,), dtype="float32"), transformed_param_575: R.Tensor((1280,), dtype="float32"), transformed_param_576: R.Tensor((1280,), dtype="float32"), transformed_param_577: R.Tensor((1280,), dtype="float32"), transformed_param_578: R.Tensor((10240,), dtype="float32"), transformed_param_579: R.Tensor((1280,), dtype="float32"), transformed_param_580: R.Tensor((1280,), dtype="float32"), transformed_param_581: R.Tensor((1280,), dtype="float32"), transformed_param_582: R.Tensor((1280,), dtype="float32"), transformed_param_583: R.Tensor((1280,), dtype="float32"), transformed_param_584: R.Tensor((1280,), dtype="float32"), transformed_param_585: R.Tensor((1280,), dtype="float32"), transformed_param_586: R.Tensor((1280,), dtype="float32"), transformed_param_587: R.Tensor((1280,), dtype="float32"), transformed_param_588: R.Tensor((10240,), dtype="float32"), transformed_param_589: R.Tensor((1280,), dtype="float32"), transformed_param_590: R.Tensor((1280,), dtype="float32"), transformed_param_591: R.Tensor((1280,), dtype="float32"), transformed_param_592: R.Tensor((1280,), dtype="float32"), transformed_param_593: R.Tensor((1280,), dtype="float32"), transformed_param_594: R.Tensor((1280,), dtype="float32"), transformed_param_595: R.Tensor((1280,), dtype="float32"), transformed_param_596: R.Tensor((1280,), dtype="float32"), transformed_param_597: R.Tensor((1280,), dtype="float32"), transformed_param_598: R.Tensor((10240,), dtype="float32"), transformed_param_599: R.Tensor((1280,), dtype="float32"), transformed_param_600: R.Tensor((1280,), dtype="float32"), transformed_param_601: R.Tensor((1280,), dtype="float32"), transformed_param_602: R.Tensor((1280,), dtype="float32"), transformed_param_603: R.Tensor((1280,), dtype="float32"), transformed_param_604: R.Tensor((1280,), dtype="float32"), transformed_param_605: R.Tensor((1280,), dtype="float32"), transformed_param_606: R.Tensor((1280,), dtype="float32"), transformed_param_607: R.Tensor((1280,), dtype="float32"), transformed_param_608: R.Tensor((10240,), dtype="float32"), transformed_param_609: R.Tensor((1280,), dtype="float32"), transformed_param_610: R.Tensor((1280,), dtype="float32"), transformed_param_611: R.Tensor((1280,), dtype="float32"), transformed_param_612: R.Tensor((1280,), dtype="float32"), transformed_param_613: R.Tensor((1280,), dtype="float32"), transformed_param_614: R.Tensor((1280,), dtype="float32"), transformed_param_615: R.Tensor((1280,), dtype="float32"), transformed_param_616: R.Tensor((1280,), dtype="float32"), transformed_param_617: R.Tensor((1280,), dtype="float32"), transformed_param_618: R.Tensor((10240,), dtype="float32"), transformed_param_619: R.Tensor((1280,), dtype="float32"), transformed_param_620: R.Tensor((1280,), dtype="float32"), transformed_param_621: R.Tensor((1280,), dtype="float32"), transformed_param_622: R.Tensor((1280,), dtype="float32"), transformed_param_623: R.Tensor((1280,), dtype="float32"), transformed_param_624: R.Tensor((1280,), dtype="float32"), transformed_param_625: R.Tensor((1280,), dtype="float32"), transformed_param_626: R.Tensor((1280,), dtype="float32"), transformed_param_627: R.Tensor((1280,), dtype="float32"), transformed_param_628: R.Tensor((10240,), dtype="float32"), transformed_param_629: R.Tensor((1280,), dtype="float32"), transformed_param_630: R.Tensor((1280,), dtype="float32"), transformed_param_631: R.Tensor((1280,), dtype="float32"), transformed_param_632: R.Tensor((1280,), dtype="float32"), transformed_param_633: R.Tensor((1280,), dtype="float32"), transformed_param_634: R.Tensor((1280,), dtype="float32"), transformed_param_635: R.Tensor((1280,), dtype="float32"), transformed_param_636: R.Tensor((1280,), dtype="float32"), transformed_param_637: R.Tensor((1280,), dtype="float32"), transformed_param_638: R.Tensor((1280,), dtype="float32"), transformed_param_639: R.Tensor((1280,), dtype="float32"), transformed_param_640: R.Tensor((1280,), dtype="float32"), transformed_param_641: R.Tensor((1280,), dtype="float32"), transformed_param_642: R.Tensor((10240,), dtype="float32"), transformed_param_643: R.Tensor((1280,), dtype="float32"), transformed_param_644: R.Tensor((1280,), dtype="float32"), transformed_param_645: R.Tensor((1280,), dtype="float32"), transformed_param_646: R.Tensor((1280,), dtype="float32"), transformed_param_647: R.Tensor((1280,), dtype="float32"), transformed_param_648: R.Tensor((1280,), dtype="float32"), transformed_param_649: R.Tensor((1280,), dtype="float32"), transformed_param_650: R.Tensor((1280,), dtype="float32"), transformed_param_651: R.Tensor((1280,), dtype="float32"), transformed_param_652: R.Tensor((10240,), dtype="float32"), transformed_param_653: R.Tensor((1280,), dtype="float32"), transformed_param_654: R.Tensor((1280,), dtype="float32"), transformed_param_655: R.Tensor((1280,), dtype="float32"), transformed_param_656: R.Tensor((1280,), dtype="float32"), transformed_param_657: R.Tensor((1280,), dtype="float32"), transformed_param_658: R.Tensor((1280,), dtype="float32"), transformed_param_659: R.Tensor((1280,), dtype="float32"), transformed_param_660: R.Tensor((1280,), dtype="float32"), transformed_param_661: R.Tensor((1280,), dtype="float32"), transformed_param_662: R.Tensor((10240,), dtype="float32"), transformed_param_663: R.Tensor((1280,), dtype="float32"), transformed_param_664: R.Tensor((1280,), dtype="float32"), transformed_param_665: R.Tensor((1280,), dtype="float32"), transformed_param_666: R.Tensor((1280,), dtype="float32"), transformed_param_667: R.Tensor((1280,), dtype="float32"), transformed_param_668: R.Tensor((1280,), dtype="float32"), transformed_param_669: R.Tensor((1280,), dtype="float32"), transformed_param_670: R.Tensor((1280,), dtype="float32"), transformed_param_671: R.Tensor((1280,), dtype="float32"), transformed_param_672: R.Tensor((10240,), dtype="float32"), transformed_param_673: R.Tensor((1280,), dtype="float32"), transformed_param_674: R.Tensor((1280,), dtype="float32"), transformed_param_675: R.Tensor((1280,), dtype="float32"), transformed_param_676: R.Tensor((1280,), dtype="float32"), transformed_param_677: R.Tensor((1280,), dtype="float32"), transformed_param_678: R.Tensor((1280,), dtype="float32"), transformed_param_679: R.Tensor((1280,), dtype="float32"), transformed_param_680: R.Tensor((1280,), dtype="float32"), transformed_param_681: R.Tensor((1280,), dtype="float32"), transformed_param_682: R.Tensor((10240,), dtype="float32"), transformed_param_683: R.Tensor((1280,), dtype="float32"), transformed_param_684: R.Tensor((1280,), dtype="float32"), transformed_param_685: R.Tensor((1280,), dtype="float32"), transformed_param_686: R.Tensor((1280,), dtype="float32"), transformed_param_687: R.Tensor((1280,), dtype="float32"), transformed_param_688: R.Tensor((1280,), dtype="float32"), transformed_param_689: R.Tensor((1280,), dtype="float32"), transformed_param_690: R.Tensor((1280,), dtype="float32"), transformed_param_691: R.Tensor((1280,), dtype="float32"), transformed_param_692: R.Tensor((10240,), dtype="float32"), transformed_param_693: R.Tensor((1280,), dtype="float32"), transformed_param_694: R.Tensor((1280,), dtype="float32"), transformed_param_695: R.Tensor((1280,), dtype="float32"), transformed_param_696: R.Tensor((1280,), dtype="float32"), transformed_param_697: R.Tensor((1280,), dtype="float32"), transformed_param_698: R.Tensor((1280,), dtype="float32"), transformed_param_699: R.Tensor((1280,), dtype="float32"), transformed_param_700: R.Tensor((1280,), dtype="float32"), transformed_param_701: R.Tensor((1280,), dtype="float32"), transformed_param_702: R.Tensor((10240,), dtype="float32"), transformed_param_703: R.Tensor((1280,), dtype="float32"), transformed_param_704: R.Tensor((1280,), dtype="float32"), transformed_param_705: R.Tensor((1280,), dtype="float32"), transformed_param_706: R.Tensor((1280,), dtype="float32"), transformed_param_707: R.Tensor((1280,), dtype="float32"), transformed_param_708: R.Tensor((1280,), dtype="float32"), transformed_param_709: R.Tensor((1280,), dtype="float32"), transformed_param_710: R.Tensor((1280,), dtype="float32"), transformed_param_711: R.Tensor((1280,), dtype="float32"), transformed_param_712: R.Tensor((10240,), dtype="float32"), transformed_param_713: R.Tensor((1280,), dtype="float32"), transformed_param_714: R.Tensor((1280,), dtype="float32"), transformed_param_715: R.Tensor((1280,), dtype="float32"), transformed_param_716: R.Tensor((1280,), dtype="float32"), transformed_param_717: R.Tensor((1280,), dtype="float32"), transformed_param_718: R.Tensor((1280,), dtype="float32"), transformed_param_719: R.Tensor((1280,), dtype="float32"), transformed_param_720: R.Tensor((1280,), dtype="float32"), transformed_param_721: R.Tensor((1280,), dtype="float32"), transformed_param_722: R.Tensor((10240,), dtype="float32"), transformed_param_723: R.Tensor((1280,), dtype="float32"), transformed_param_724: R.Tensor((1280,), dtype="float32"), transformed_param_725: R.Tensor((1280,), dtype="float32"), transformed_param_726: R.Tensor((1280,), dtype="float32"), transformed_param_727: R.Tensor((1280,), dtype="float32"), transformed_param_728: R.Tensor((1280,), dtype="float32"), transformed_param_729: R.Tensor((1280,), dtype="float32"), transformed_param_730: R.Tensor((1280,), dtype="float32"), transformed_param_731: R.Tensor((1280,), dtype="float32"), transformed_param_732: R.Tensor((10240,), dtype="float32"), transformed_param_733: R.Tensor((1280,), dtype="float32"), transformed_param_734: R.Tensor((1280,), dtype="float32"), transformed_param_735: R.Tensor((1280,), dtype="float32"), transformed_param_736: R.Tensor((1280,), dtype="float32"), transformed_param_737: R.Tensor((1280,), dtype="float32"), transformed_param_738: R.Tensor((1280,), dtype="float32"), transformed_param_739: R.Tensor((1280,), dtype="float32"), transformed_param_740: R.Tensor((1280, 2560, 3, 3), dtype="float32"), transformed_param_741: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_742: R.Tensor((1280, 2560, 1, 1), dtype="float32"), transformed_param_743: R.Tensor((2560,), dtype="float32"), transformed_param_744: R.Tensor((2560,), dtype="float32"), transformed_param_745: R.Tensor((1280,), dtype="float32"), transformed_param_746: R.Tensor((1280,), dtype="float32"), transformed_param_747: R.Tensor((1280,), dtype="float32"), transformed_param_748: R.Tensor((1280, 2560, 3, 3), dtype="float32"), transformed_param_749: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_750: R.Tensor((1280, 2560, 1, 1), dtype="float32"), transformed_param_751: R.Tensor((2560,), dtype="float32"), transformed_param_752: R.Tensor((2560,), dtype="float32"), transformed_param_753: R.Tensor((1280,), dtype="float32"), transformed_param_754: R.Tensor((1280,), dtype="float32"), transformed_param_755: R.Tensor((1280,), dtype="float32"), transformed_param_756: R.Tensor((1280, 1920, 3, 3), dtype="float32"), transformed_param_757: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_758: R.Tensor((1280, 1920, 1, 1), dtype="float32"), transformed_param_759: R.Tensor((1920,), dtype="float32"), transformed_param_760: R.Tensor((1920,), dtype="float32"), transformed_param_761: R.Tensor((1280,), dtype="float32"), transformed_param_762: R.Tensor((1280,), dtype="float32"), transformed_param_763: R.Tensor((1280,), dtype="float32"), transformed_param_764: R.Tensor((1280, 1280, 3, 3), dtype="float32"), transformed_param_765: R.Tensor((640,), dtype="float32"), transformed_param_766: R.Tensor((640,), dtype="float32"), transformed_param_767: R.Tensor((640,), dtype="float32"), transformed_param_768: R.Tensor((640,), dtype="float32"), transformed_param_769: R.Tensor((640,), dtype="float32"), transformed_param_770: R.Tensor((640,), dtype="float32"), transformed_param_771: R.Tensor((5120,), dtype="float32"), transformed_param_772: R.Tensor((640,), dtype="float32"), transformed_param_773: R.Tensor((640,), dtype="float32"), transformed_param_774: R.Tensor((640,), dtype="float32"), transformed_param_775: R.Tensor((640,), dtype="float32"), transformed_param_776: R.Tensor((640,), dtype="float32"), transformed_param_777: R.Tensor((640,), dtype="float32"), transformed_param_778: R.Tensor((640,), dtype="float32"), transformed_param_779: R.Tensor((640,), dtype="float32"), transformed_param_780: R.Tensor((640,), dtype="float32"), transformed_param_781: R.Tensor((5120,), dtype="float32"), transformed_param_782: R.Tensor((640,), dtype="float32"), transformed_param_783: R.Tensor((640,), dtype="float32"), transformed_param_784: R.Tensor((640,), dtype="float32"), transformed_param_785: R.Tensor((640,), dtype="float32"), transformed_param_786: R.Tensor((640,), dtype="float32"), transformed_param_787: R.Tensor((640,), dtype="float32"), transformed_param_788: R.Tensor((640,), dtype="float32"), transformed_param_789: R.Tensor((640,), dtype="float32"), transformed_param_790: R.Tensor((640,), dtype="float32"), transformed_param_791: R.Tensor((640,), dtype="float32"), transformed_param_792: R.Tensor((640,), dtype="float32"), transformed_param_793: R.Tensor((640,), dtype="float32"), transformed_param_794: R.Tensor((640,), dtype="float32"), transformed_param_795: R.Tensor((5120,), dtype="float32"), transformed_param_796: R.Tensor((640,), dtype="float32"), transformed_param_797: R.Tensor((640,), dtype="float32"), transformed_param_798: R.Tensor((640,), dtype="float32"), transformed_param_799: R.Tensor((640,), dtype="float32"), transformed_param_800: R.Tensor((640,), dtype="float32"), transformed_param_801: R.Tensor((640,), dtype="float32"), transformed_param_802: R.Tensor((640,), dtype="float32"), transformed_param_803: R.Tensor((640,), dtype="float32"), transformed_param_804: R.Tensor((640,), dtype="float32"), transformed_param_805: R.Tensor((5120,), dtype="float32"), transformed_param_806: R.Tensor((640,), dtype="float32"), transformed_param_807: R.Tensor((640,), dtype="float32"), transformed_param_808: R.Tensor((640,), dtype="float32"), transformed_param_809: R.Tensor((640,), dtype="float32"), transformed_param_810: R.Tensor((640,), dtype="float32"), transformed_param_811: R.Tensor((640,), dtype="float32"), transformed_param_812: R.Tensor((640,), dtype="float32"), transformed_param_813: R.Tensor((640,), dtype="float32"), transformed_param_814: R.Tensor((640,), dtype="float32"), transformed_param_815: R.Tensor((640,), dtype="float32"), transformed_param_816: R.Tensor((640,), dtype="float32"), transformed_param_817: R.Tensor((640,), dtype="float32"), transformed_param_818: R.Tensor((640,), dtype="float32"), transformed_param_819: R.Tensor((5120,), dtype="float32"), transformed_param_820: R.Tensor((640,), dtype="float32"), transformed_param_821: R.Tensor((640,), dtype="float32"), transformed_param_822: R.Tensor((640,), dtype="float32"), transformed_param_823: R.Tensor((640,), dtype="float32"), transformed_param_824: R.Tensor((640,), dtype="float32"), transformed_param_825: R.Tensor((640,), dtype="float32"), transformed_param_826: R.Tensor((640,), dtype="float32"), transformed_param_827: R.Tensor((640,), dtype="float32"), transformed_param_828: R.Tensor((640,), dtype="float32"), transformed_param_829: R.Tensor((5120,), dtype="float32"), transformed_param_830: R.Tensor((640,), dtype="float32"), transformed_param_831: R.Tensor((640,), dtype="float32"), transformed_param_832: R.Tensor((640,), dtype="float32"), transformed_param_833: R.Tensor((640,), dtype="float32"), transformed_param_834: R.Tensor((640,), dtype="float32"), transformed_param_835: R.Tensor((640,), dtype="float32"), transformed_param_836: R.Tensor((640,), dtype="float32"), transformed_param_837: R.Tensor((640, 1920, 3, 3), dtype="float32"), transformed_param_838: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_839: R.Tensor((640, 1920, 1, 1), dtype="float32"), transformed_param_840: R.Tensor((1920,), dtype="float32"), transformed_param_841: R.Tensor((1920,), dtype="float32"), transformed_param_842: R.Tensor((640,), dtype="float32"), transformed_param_843: R.Tensor((640,), dtype="float32"), transformed_param_844: R.Tensor((640,), dtype="float32"), transformed_param_845: R.Tensor((640, 1280, 3, 3), dtype="float32"), transformed_param_846: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_847: R.Tensor((640, 1280, 1, 1), dtype="float32"), transformed_param_848: R.Tensor((1280,), dtype="float32"), transformed_param_849: R.Tensor((1280,), dtype="float32"), transformed_param_850: R.Tensor((640,), dtype="float32"), transformed_param_851: R.Tensor((640,), dtype="float32"), transformed_param_852: R.Tensor((640,), dtype="float32"), transformed_param_853: R.Tensor((640, 960, 3, 3), dtype="float32"), transformed_param_854: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_855: R.Tensor((640, 960, 1, 1), dtype="float32"), transformed_param_856: R.Tensor((960,), dtype="float32"), transformed_param_857: R.Tensor((960,), dtype="float32"), transformed_param_858: R.Tensor((640,), dtype="float32"), transformed_param_859: R.Tensor((640,), dtype="float32"), transformed_param_860: R.Tensor((640,), dtype="float32"), transformed_param_861: R.Tensor((640, 640, 3, 3), dtype="float32"), transformed_param_862: R.Tensor((320, 960, 3, 3), dtype="float32"), transformed_param_863: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_864: R.Tensor((320, 960, 1, 1), dtype="float32"), transformed_param_865: R.Tensor((960,), dtype="float32"), transformed_param_866: R.Tensor((960,), dtype="float32"), transformed_param_867: R.Tensor((320,), dtype="float32"), transformed_param_868: R.Tensor((320,), dtype="float32"), transformed_param_869: R.Tensor((320,), dtype="float32"), transformed_param_870: R.Tensor((320, 640, 3, 3), dtype="float32"), transformed_param_871: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_872: R.Tensor((320, 640, 1, 1), dtype="float32"), transformed_param_873: R.Tensor((640,), dtype="float32"), transformed_param_874: R.Tensor((640,), dtype="float32"), transformed_param_875: R.Tensor((320,), dtype="float32"), transformed_param_876: R.Tensor((320,), dtype="float32"), transformed_param_877: R.Tensor((320,), dtype="float32"), transformed_param_878: R.Tensor((320, 640, 3, 3), dtype="float32"), transformed_param_879: R.Tensor((320, 320, 3, 3), dtype="float32"), transformed_param_880: R.Tensor((320, 640, 1, 1), dtype="float32"), transformed_param_881: R.Tensor((640,), dtype="float32"), transformed_param_882: R.Tensor((640,), dtype="float32"), transformed_param_883: R.Tensor((320,), dtype="float32"), transformed_param_884: R.Tensor((320,), dtype="float32"), transformed_param_885: R.Tensor((320,), dtype="float32"), transformed_param_886: R.Tensor((320, 1280), dtype="float32"), transformed_param_887: R.Tensor((1280, 1280), dtype="float32"), transformed_param_888: R.Tensor((2816, 1280), dtype="float32"), transformed_param_889: R.Tensor((1280, 1280), dtype="float32"), transformed_param_890: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_891: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_892: R.Tensor((1280, 320), dtype="float32"), transformed_param_893: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_894: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_895: R.Tensor((1280, 320), dtype="float32"), transformed_param_896: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_897: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_898: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_899: R.Tensor((1280, 640), dtype="float32"), transformed_param_900: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_901: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_902: R.Tensor((640, 640), dtype="float32"), transformed_param_903: R.Tensor((640, 640), dtype="float32"), transformed_param_904: R.Tensor((640, 640), dtype="float32"), transformed_param_905: R.Tensor((640, 640), dtype="float32"), transformed_param_906: R.Tensor((640, 640), dtype="float32"), transformed_param_907: R.Tensor((640, 640), dtype="float32"), transformed_param_908: R.Tensor((2048, 640), dtype="float32"), transformed_param_909: R.Tensor((2048, 640), dtype="float32"), transformed_param_910: R.Tensor((640, 640), dtype="float32"), transformed_param_911: R.Tensor((640, 5120), dtype="float32"), transformed_param_912: R.Tensor((2560, 640), dtype="float32"), transformed_param_913: R.Tensor((640, 640), dtype="float32"), transformed_param_914: R.Tensor((640, 640), dtype="float32"), transformed_param_915: R.Tensor((640, 640), dtype="float32"), transformed_param_916: R.Tensor((640, 640), dtype="float32"), transformed_param_917: R.Tensor((640, 640), dtype="float32"), transformed_param_918: R.Tensor((2048, 640), dtype="float32"), transformed_param_919: R.Tensor((2048, 640), dtype="float32"), transformed_param_920: R.Tensor((640, 640), dtype="float32"), transformed_param_921: R.Tensor((640, 5120), dtype="float32"), transformed_param_922: R.Tensor((2560, 640), dtype="float32"), transformed_param_923: R.Tensor((640, 640), dtype="float32"), transformed_param_924: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_925: R.Tensor((1280, 640), dtype="float32"), transformed_param_926: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_927: R.Tensor((640, 640), dtype="float32"), transformed_param_928: R.Tensor((640, 640), dtype="float32"), transformed_param_929: R.Tensor((640, 640), dtype="float32"), transformed_param_930: R.Tensor((640, 640), dtype="float32"), transformed_param_931: R.Tensor((640, 640), dtype="float32"), transformed_param_932: R.Tensor((640, 640), dtype="float32"), transformed_param_933: R.Tensor((2048, 640), dtype="float32"), transformed_param_934: R.Tensor((2048, 640), dtype="float32"), transformed_param_935: R.Tensor((640, 640), dtype="float32"), transformed_param_936: R.Tensor((640, 5120), dtype="float32"), transformed_param_937: R.Tensor((2560, 640), dtype="float32"), transformed_param_938: R.Tensor((640, 640), dtype="float32"), transformed_param_939: R.Tensor((640, 640), dtype="float32"), transformed_param_940: R.Tensor((640, 640), dtype="float32"), transformed_param_941: R.Tensor((640, 640), dtype="float32"), transformed_param_942: R.Tensor((640, 640), dtype="float32"), transformed_param_943: R.Tensor((2048, 640), dtype="float32"), transformed_param_944: R.Tensor((2048, 640), dtype="float32"), transformed_param_945: R.Tensor((640, 640), dtype="float32"), transformed_param_946: R.Tensor((640, 5120), dtype="float32"), transformed_param_947: R.Tensor((2560, 640), dtype="float32"), transformed_param_948: R.Tensor((640, 640), dtype="float32"), transformed_param_949: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_950: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_951: R.Tensor((1280, 1280), dtype="float32"), transformed_param_952: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_953: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_954: R.Tensor((1280, 1280), dtype="float32"), transformed_param_955: R.Tensor((1280, 1280), dtype="float32"), transformed_param_956: R.Tensor((1280, 1280), dtype="float32"), transformed_param_957: R.Tensor((1280, 1280), dtype="float32"), transformed_param_958: R.Tensor((1280, 1280), dtype="float32"), transformed_param_959: R.Tensor((1280, 1280), dtype="float32"), transformed_param_960: R.Tensor((2048, 1280), dtype="float32"), transformed_param_961: R.Tensor((2048, 1280), dtype="float32"), transformed_param_962: R.Tensor((1280, 1280), dtype="float32"), transformed_param_963: R.Tensor((1280, 10240), dtype="float32"), transformed_param_964: R.Tensor((5120, 1280), dtype="float32"), transformed_param_965: R.Tensor((1280, 1280), dtype="float32"), transformed_param_966: R.Tensor((1280, 1280), dtype="float32"), transformed_param_967: R.Tensor((1280, 1280), dtype="float32"), transformed_param_968: R.Tensor((1280, 1280), dtype="float32"), transformed_param_969: R.Tensor((1280, 1280), dtype="float32"), transformed_param_970: R.Tensor((2048, 1280), dtype="float32"), transformed_param_971: R.Tensor((2048, 1280), dtype="float32"), transformed_param_972: R.Tensor((1280, 1280), dtype="float32"), transformed_param_973: R.Tensor((1280, 10240), dtype="float32"), transformed_param_974: R.Tensor((5120, 1280), dtype="float32"), transformed_param_975: R.Tensor((1280, 1280), dtype="float32"), transformed_param_976: R.Tensor((1280, 1280), dtype="float32"), transformed_param_977: R.Tensor((1280, 1280), dtype="float32"), transformed_param_978: R.Tensor((1280, 1280), dtype="float32"), transformed_param_979: R.Tensor((1280, 1280), dtype="float32"), transformed_param_980: R.Tensor((2048, 1280), dtype="float32"), transformed_param_981: R.Tensor((2048, 1280), dtype="float32"), transformed_param_982: R.Tensor((1280, 1280), dtype="float32"), transformed_param_983: R.Tensor((1280, 10240), dtype="float32"), transformed_param_984: R.Tensor((5120, 1280), dtype="float32"), transformed_param_985: R.Tensor((1280, 1280), dtype="float32"), transformed_param_986: R.Tensor((1280, 1280), dtype="float32"), transformed_param_987: R.Tensor((1280, 1280), dtype="float32"), transformed_param_988: R.Tensor((1280, 1280), dtype="float32"), transformed_param_989: R.Tensor((1280, 1280), dtype="float32"), transformed_param_990: R.Tensor((2048, 1280), dtype="float32"), transformed_param_991: R.Tensor((2048, 1280), dtype="float32"), transformed_param_992: R.Tensor((1280, 1280), dtype="float32"), transformed_param_993: R.Tensor((1280, 10240), dtype="float32"), transformed_param_994: R.Tensor((5120, 1280), dtype="float32"), transformed_param_995: R.Tensor((1280, 1280), dtype="float32"), transformed_param_996: R.Tensor((1280, 1280), dtype="float32"), transformed_param_997: R.Tensor((1280, 1280), dtype="float32"), transformed_param_998: R.Tensor((1280, 1280), dtype="float32"), transformed_param_999: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1000: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1001: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1002: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1003: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1004: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1005: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1006: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1007: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1008: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1009: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1010: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1011: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1012: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1013: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1014: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1015: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1016: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1017: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1018: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1019: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1020: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1021: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1022: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1023: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1024: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1025: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1026: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1027: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1028: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1029: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1030: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1031: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1032: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1033: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1034: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1035: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1036: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1037: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1038: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1039: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1040: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1041: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1042: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1043: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1044: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1045: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1046: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1047: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1048: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1049: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1050: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1051: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1052: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1053: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1054: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1055: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1056: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1057: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1058: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1059: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1060: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1061: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1062: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1063: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1064: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1065: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1066: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1067: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1068: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1069: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1070: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1071: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1072: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1073: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1074: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1075: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1076: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1077: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1078: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1079: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1080: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1081: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1082: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1083: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1084: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1085: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1086: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1087: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1088: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1089: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1090: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1091: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1092: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1093: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1094: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1095: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1096: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1097: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1098: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1099: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1100: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1101: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1102: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1103: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1104: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1105: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1106: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1107: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1108: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1109: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1110: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1111: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1112: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1113: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1114: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1115: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1116: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1117: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1118: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1119: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1120: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1121: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1122: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1123: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1124: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1125: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1126: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1127: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1128: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1129: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1130: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1131: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1132: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1133: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1134: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1135: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1136: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1137: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1138: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1139: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1140: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1141: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1142: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1143: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1144: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1145: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1146: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1147: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1148: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1149: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1150: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1151: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1152: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1153: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1154: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1155: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1156: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1157: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1158: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1159: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1160: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1161: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1162: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1163: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1164: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1165: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1166: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1167: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1168: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1169: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1170: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1171: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1172: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1173: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1174: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1175: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1176: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1177: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1178: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1179: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1180: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1181: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1182: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1183: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1184: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1185: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1186: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1187: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1188: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1189: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1190: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1191: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1192: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1193: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1194: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1195: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1196: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1197: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1198: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1199: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1200: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1201: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1202: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1203: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1204: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1205: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1206: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1207: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1208: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1209: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1210: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1211: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1212: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1213: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1214: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1215: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1216: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1217: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1218: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1219: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1220: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1221: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1222: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1223: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1224: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1225: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1226: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1227: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1228: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1229: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1230: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1231: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1232: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1233: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1234: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1235: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1236: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1237: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1238: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1239: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1240: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1241: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1242: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1243: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1244: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1245: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1246: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1247: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1248: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1249: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1250: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1251: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1252: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1253: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1254: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1255: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1256: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1257: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1258: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1259: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1260: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1261: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1262: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1263: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1264: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1265: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1266: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1267: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1268: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1269: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1270: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1271: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1272: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1273: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1274: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1275: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1276: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1277: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1278: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1279: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1280: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1281: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1282: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1283: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1284: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1285: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1286: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1287: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1288: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1289: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1290: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1291: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1292: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1293: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1294: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1295: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1296: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1297: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1298: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1299: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1300: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1301: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1302: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1303: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1304: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1305: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1306: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1307: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1308: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1309: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1310: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1311: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1312: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1313: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1314: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1315: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1316: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1317: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1318: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1319: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1320: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1321: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1322: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1323: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1324: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1325: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1326: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1327: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1328: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1329: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1330: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1331: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1332: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1333: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1334: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1335: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1336: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1337: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1338: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1339: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1340: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1341: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1342: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1343: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1344: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1345: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1346: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1347: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1348: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1349: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1350: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1351: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1352: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1353: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1354: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1355: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1356: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1357: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1358: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1359: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1360: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1361: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1362: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1363: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1364: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1365: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1366: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1367: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1368: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1369: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1370: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1371: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1372: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1373: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1374: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1375: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1376: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1377: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1378: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1379: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1380: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1381: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1382: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1383: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1384: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1385: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1386: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1387: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1388: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1389: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1390: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1391: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1392: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1393: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1394: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1395: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1396: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1397: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1398: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1399: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1400: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1401: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1402: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1403: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1404: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1405: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1406: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1407: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1408: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1409: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1410: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1411: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1412: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1413: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1414: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1415: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1416: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1417: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1418: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1419: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1420: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1421: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1422: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1423: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1424: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1425: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1426: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1427: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1428: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1429: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1430: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1431: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1432: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1433: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1434: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1435: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1436: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1437: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1438: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1439: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1440: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1441: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1442: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1443: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1444: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1445: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1446: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1447: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1448: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1449: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1450: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1451: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1452: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1453: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1454: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1455: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1456: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1457: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1458: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1459: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1460: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1461: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1462: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1463: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1464: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1465: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1466: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1467: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1468: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1469: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1470: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1471: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1472: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1473: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1474: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1475: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1476: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1477: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1478: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1479: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1480: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1481: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1482: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1483: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1484: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1485: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1486: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1487: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1488: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1489: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1490: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1491: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1492: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1493: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1494: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1495: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1496: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1497: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1498: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1499: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1500: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1501: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1502: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1503: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1504: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1505: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1506: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1507: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1508: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1509: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1510: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1511: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1512: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1513: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1514: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1515: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1516: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1517: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1518: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1519: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1520: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1521: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1522: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1523: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1524: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1525: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1526: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1527: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1528: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1529: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1530: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1531: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1532: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1533: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1534: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1535: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1536: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1537: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1538: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1539: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1540: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1541: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1542: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1543: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1544: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1545: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1546: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1547: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1548: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1549: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1550: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1551: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1552: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1553: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1554: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1555: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1556: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1557: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1558: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1559: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1560: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1561: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1562: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1563: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1564: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1565: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1566: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1567: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1568: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1569: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1570: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1571: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1572: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1573: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1574: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1575: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1576: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1577: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1578: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1579: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1580: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1581: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1582: R.Tensor((2048, 1280), dtype="float32"), transformed_param_1583: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1584: R.Tensor((1280, 10240), dtype="float32"), transformed_param_1585: R.Tensor((5120, 1280), dtype="float32"), transformed_param_1586: R.Tensor((1280, 1280), dtype="float32"), transformed_param_1587: R.Tensor((1, 1280, 1, 1), dtype="float32"), transformed_param_1588: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1589: R.Tensor((1280, 640), dtype="float32"), transformed_param_1590: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1591: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1592: R.Tensor((640, 640), dtype="float32"), transformed_param_1593: R.Tensor((640, 640), dtype="float32"), transformed_param_1594: R.Tensor((640, 640), dtype="float32"), transformed_param_1595: R.Tensor((640, 640), dtype="float32"), transformed_param_1596: R.Tensor((640, 640), dtype="float32"), transformed_param_1597: R.Tensor((640, 640), dtype="float32"), transformed_param_1598: R.Tensor((2048, 640), dtype="float32"), transformed_param_1599: R.Tensor((2048, 640), dtype="float32"), transformed_param_1600: R.Tensor((640, 640), dtype="float32"), transformed_param_1601: R.Tensor((640, 5120), dtype="float32"), transformed_param_1602: R.Tensor((2560, 640), dtype="float32"), transformed_param_1603: R.Tensor((640, 640), dtype="float32"), transformed_param_1604: R.Tensor((640, 640), dtype="float32"), transformed_param_1605: R.Tensor((640, 640), dtype="float32"), transformed_param_1606: R.Tensor((640, 640), dtype="float32"), transformed_param_1607: R.Tensor((640, 640), dtype="float32"), transformed_param_1608: R.Tensor((2048, 640), dtype="float32"), transformed_param_1609: R.Tensor((2048, 640), dtype="float32"), transformed_param_1610: R.Tensor((640, 640), dtype="float32"), transformed_param_1611: R.Tensor((640, 5120), dtype="float32"), transformed_param_1612: R.Tensor((2560, 640), dtype="float32"), transformed_param_1613: R.Tensor((640, 640), dtype="float32"), transformed_param_1614: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1615: R.Tensor((1280, 640), dtype="float32"), transformed_param_1616: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1617: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1618: R.Tensor((640, 640), dtype="float32"), transformed_param_1619: R.Tensor((640, 640), dtype="float32"), transformed_param_1620: R.Tensor((640, 640), dtype="float32"), transformed_param_1621: R.Tensor((640, 640), dtype="float32"), transformed_param_1622: R.Tensor((640, 640), dtype="float32"), transformed_param_1623: R.Tensor((640, 640), dtype="float32"), transformed_param_1624: R.Tensor((2048, 640), dtype="float32"), transformed_param_1625: R.Tensor((2048, 640), dtype="float32"), transformed_param_1626: R.Tensor((640, 640), dtype="float32"), transformed_param_1627: R.Tensor((640, 5120), dtype="float32"), transformed_param_1628: R.Tensor((2560, 640), dtype="float32"), transformed_param_1629: R.Tensor((640, 640), dtype="float32"), transformed_param_1630: R.Tensor((640, 640), dtype="float32"), transformed_param_1631: R.Tensor((640, 640), dtype="float32"), transformed_param_1632: R.Tensor((640, 640), dtype="float32"), transformed_param_1633: R.Tensor((640, 640), dtype="float32"), transformed_param_1634: R.Tensor((2048, 640), dtype="float32"), transformed_param_1635: R.Tensor((2048, 640), dtype="float32"), transformed_param_1636: R.Tensor((640, 640), dtype="float32"), transformed_param_1637: R.Tensor((640, 5120), dtype="float32"), transformed_param_1638: R.Tensor((2560, 640), dtype="float32"), transformed_param_1639: R.Tensor((640, 640), dtype="float32"), transformed_param_1640: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1641: R.Tensor((1280, 640), dtype="float32"), transformed_param_1642: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1643: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1644: R.Tensor((640, 640), dtype="float32"), transformed_param_1645: R.Tensor((640, 640), dtype="float32"), transformed_param_1646: R.Tensor((640, 640), dtype="float32"), transformed_param_1647: R.Tensor((640, 640), dtype="float32"), transformed_param_1648: R.Tensor((640, 640), dtype="float32"), transformed_param_1649: R.Tensor((640, 640), dtype="float32"), transformed_param_1650: R.Tensor((2048, 640), dtype="float32"), transformed_param_1651: R.Tensor((2048, 640), dtype="float32"), transformed_param_1652: R.Tensor((640, 640), dtype="float32"), transformed_param_1653: R.Tensor((640, 5120), dtype="float32"), transformed_param_1654: R.Tensor((2560, 640), dtype="float32"), transformed_param_1655: R.Tensor((640, 640), dtype="float32"), transformed_param_1656: R.Tensor((640, 640), dtype="float32"), transformed_param_1657: R.Tensor((640, 640), dtype="float32"), transformed_param_1658: R.Tensor((640, 640), dtype="float32"), transformed_param_1659: R.Tensor((640, 640), dtype="float32"), transformed_param_1660: R.Tensor((2048, 640), dtype="float32"), transformed_param_1661: R.Tensor((2048, 640), dtype="float32"), transformed_param_1662: R.Tensor((640, 640), dtype="float32"), transformed_param_1663: R.Tensor((640, 5120), dtype="float32"), transformed_param_1664: R.Tensor((2560, 640), dtype="float32"), transformed_param_1665: R.Tensor((640, 640), dtype="float32"), transformed_param_1666: R.Tensor((1, 640, 1, 1), dtype="float32"), transformed_param_1667: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1668: R.Tensor((1280, 320), dtype="float32"), transformed_param_1669: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1670: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1671: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1672: R.Tensor((1280, 320), dtype="float32"), transformed_param_1673: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1674: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1675: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1676: R.Tensor((1280, 320), dtype="float32"), transformed_param_1677: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1678: R.Tensor((1, 320, 1, 1), dtype="float32"), transformed_param_1679: R.Tensor((1, 4, 1, 1), dtype="float32")) -> R.Tensor((1, 4, 128, 128), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 5})
        cls = Module
        with R.dataflow():
            lv77 = R.call_tir(cls.fused_broadcast_to1_strided_slice1_reshape12_cast3_multiply1_multiply2_tir_sin_tir_cos_concatenate1_strided_slice2_reshape13_strided_slice3_reshape13_concatenate1_cast4, (inp_1, metadata["relax.expr.Constant"][2]), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv713: R.Tensor((320, 1280), dtype="float32") = transformed_param_886
            lv714: R.Tensor((1280,), dtype="float32") = transformed_param_426
            lv78 = R.call_tir(cls.fused_matmul6_add5_silu, (lv77, lv713, lv714), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv79 = R.call_tir(cls.fused_reshape14_strided_slice4_reshape15_cast5_multiply3_multiply4_tir_sin1_tir_cos1_concatenate2_strided_slice5_reshape16_strided_slice6_reshape16_concatenate2_reshape17_concatenate3, (inp_4, metadata["relax.expr.Constant"][3], inp_3), out_sinfo=R.Tensor((2, 2816), dtype="float32"))
            lv715: R.Tensor((2816, 1280), dtype="float32") = transformed_param_888
            lv716: R.Tensor((1280,), dtype="float32") = transformed_param_0
            lv80 = R.call_tir(cls.fused_matmul8_add5_silu, (lv79, lv715, lv716), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv717: R.Tensor((1280, 1280), dtype="float32") = transformed_param_889
            lv718: R.Tensor((1280,), dtype="float32") = transformed_param_1
            lv81 = R.call_tir(cls.fused_matmul7_add5, (lv80, lv717, lv718), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv719: R.Tensor((1280, 1280), dtype="float32") = transformed_param_887
            lv720: R.Tensor((1280,), dtype="float32") = transformed_param_427
            lv82 = R.call_tir(cls.fused_matmul7_add5_add6, (lv78, lv719, lv720, lv81), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv721: R.Tensor((320, 4, 3, 3), dtype="float32") = transformed_param_2
            lv722: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_890
            lv83 = R.call_tir(cls.fused_conv2d_add7, (inp_0, lv721, lv722), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv723: R.Tensor((320,), dtype="float32") = transformed_param_10
            lv724: R.Tensor((320,), dtype="float32") = transformed_param_9
            lv84 = R.call_tir(cls.fused_group_norm_silu1, (lv83, lv723, lv724), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv54 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv725: R.Tensor((1280, 320), dtype="float32") = transformed_param_892
            lv726: R.Tensor((320,), dtype="float32") = transformed_param_13
            lv85 = R.call_tir(cls.fused_matmul9_add8_cast4, (lv54, lv725, lv726), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv59 = R.call_tir(cls.reshape19, (lv85,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv727: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_7
            lv728: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_891
            lv86 = R.call_tir(cls.fused_conv2d1_add7_add9, (lv84, lv727, lv728, lv59), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv729: R.Tensor((320,), dtype="float32") = transformed_param_12
            lv730: R.Tensor((320,), dtype="float32") = transformed_param_11
            lv87 = R.call_tir(cls.fused_group_norm_silu1, (lv86, lv729, lv730), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv731: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_8
            lv732: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_893
            lv88 = R.call_tir(cls.fused_conv2d1_add7_add10_divide, (lv87, lv731, lv732, lv83), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv733: R.Tensor((320,), dtype="float32") = transformed_param_17
            lv734: R.Tensor((320,), dtype="float32") = transformed_param_16
            lv89 = R.call_tir(cls.fused_group_norm_silu1, (lv88, lv733, lv734), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv73 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv735: R.Tensor((1280, 320), dtype="float32") = transformed_param_895
            lv736: R.Tensor((320,), dtype="float32") = transformed_param_20
            lv90 = R.call_tir(cls.fused_matmul9_add8_cast4, (lv73, lv735, lv736), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv78_1 = R.call_tir(cls.reshape19, (lv90,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv737: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_14
            lv738: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_894
            lv91 = R.call_tir(cls.fused_conv2d1_add7_add9, (lv89, lv737, lv738, lv78_1), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv739: R.Tensor((320,), dtype="float32") = transformed_param_19
            lv740: R.Tensor((320,), dtype="float32") = transformed_param_18
            lv92 = R.call_tir(cls.fused_group_norm_silu1, (lv91, lv739, lv740), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv741: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_15
            lv742: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_896
            lv93 = R.call_tir(cls.fused_conv2d1_add7_add10_divide, (lv92, lv741, lv742, lv88), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv743: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_6
            lv744: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_897
            lv94 = R.call_tir(cls.fused_conv2d2_add11, (lv93, lv743, lv744), out_sinfo=R.Tensor((2, 320, 64, 64), dtype="float32"))
            lv745: R.Tensor((320,), dtype="float32") = transformed_param_74
            lv746: R.Tensor((320,), dtype="float32") = transformed_param_73
            lv95 = R.call_tir(cls.fused_group_norm1_silu2, (lv94, lv745, lv746), out_sinfo=R.Tensor((2, 320, 64, 64), dtype="float32"))
            lv95_1 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv747: R.Tensor((1280, 640), dtype="float32") = transformed_param_899
            lv748: R.Tensor((640,), dtype="float32") = transformed_param_77
            lv96 = R.call_tir(cls.fused_matmul10_add13_strided_slice7, (lv95_1, lv747, lv748), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv100 = R.call_tir(cls.reshape21, (lv96,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv749: R.Tensor((640, 320, 3, 3), dtype="float32") = transformed_param_70
            lv750: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_898
            lv97 = R.call_tir(cls.fused_conv2d3_add12_add14, (lv95, lv749, lv750, lv100), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv751: R.Tensor((640,), dtype="float32") = transformed_param_76
            lv752: R.Tensor((640,), dtype="float32") = transformed_param_75
            lv98 = R.call_tir(cls.fused_group_norm2_silu3, (lv97, lv751, lv752), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv753: R.Tensor((640, 320, 1, 1), dtype="float32") = transformed_param_72
            lv754: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_901
            lv99 = R.call_tir(cls.fused_conv2d5_add12, (lv94, lv753, lv754), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv755: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_71
            lv756: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_900
            lv100_1 = R.call_tir(cls.fused_conv2d4_add12_add15_divide1, (lv98, lv755, lv756, lv99), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv757: R.Tensor((640,), dtype="float32") = transformed_param_22
            lv758: R.Tensor((640,), dtype="float32") = transformed_param_21
            lv112 = R.call_tir(cls.group_norm3, (lv100_1, lv757, lv758), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv101 = R.call_tir(cls.fused_transpose10_reshape22, (lv112,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv759: R.Tensor((640, 640), dtype="float32") = transformed_param_902
            lv760: R.Tensor((640,), dtype="float32") = transformed_param_23
            lv102 = R.call_tir(cls.fused_matmul11_add16, (lv101, lv759, lv760), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv761: R.Tensor((640,), dtype="float32") = transformed_param_30
            lv762: R.Tensor((640,), dtype="float32") = transformed_param_29
            lv118 = R.call_tir(cls.layer_norm1, (lv102, lv761, lv762), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv763: R.Tensor((640, 640), dtype="float32") = transformed_param_903
            lv120 = R.call_tir(cls.matmul11, (lv118, lv763), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv764: R.Tensor((640, 640), dtype="float32") = transformed_param_904
            lv122 = R.call_tir(cls.matmul11, (lv118, lv764), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv765: R.Tensor((640, 640), dtype="float32") = transformed_param_905
            lv124 = R.call_tir(cls.matmul11, (lv118, lv765), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv103 = R.call_tir(cls.fused_reshape23_transpose12, (lv120,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv104 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv122,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv105 = R.call_tir(cls.fused_reshape23_transpose12, (lv124,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv106 = R.call_tir(cls.fused_matmul12_multiply5, (lv103, lv104, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv136 = R.call_tir(cls.softmax1, (lv106,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv137 = R.call_tir(cls.matmul13, (lv136, lv105), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv107 = R.call_tir(cls.fused_transpose14_reshape24, (lv137,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv766: R.Tensor((640, 640), dtype="float32") = transformed_param_906
            lv767: R.Tensor((640,), dtype="float32") = transformed_param_25
            lv108 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv107, lv766, lv767, lv102), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv768: R.Tensor((640,), dtype="float32") = transformed_param_32
            lv769: R.Tensor((640,), dtype="float32") = transformed_param_31
            lv145 = R.call_tir(cls.layer_norm1, (lv108, lv768, lv769), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv770: R.Tensor((640, 640), dtype="float32") = transformed_param_907
            lv147 = R.call_tir(cls.matmul11, (lv145, lv770), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv771: R.Tensor((2048, 640), dtype="float32") = transformed_param_908
            lv149 = R.call_tir(cls.matmul14, (inp_2, lv771), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv772: R.Tensor((2048, 640), dtype="float32") = transformed_param_909
            lv151 = R.call_tir(cls.matmul14, (inp_2, lv772), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv109 = R.call_tir(cls.fused_reshape23_transpose12, (lv147,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv110 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv149,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv111 = R.call_tir(cls.fused_reshape25_transpose16, (lv151,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv112_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv109, lv110, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv163 = R.call_tir(cls.softmax2, (lv112_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv164 = R.call_tir(cls.matmul16, (lv163, lv111), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv113 = R.call_tir(cls.fused_transpose14_reshape24, (lv164,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv773: R.Tensor((640, 640), dtype="float32") = transformed_param_910
            lv774: R.Tensor((640,), dtype="float32") = transformed_param_26
            lv114 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv113, lv773, lv774, lv108), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv775: R.Tensor((640,), dtype="float32") = transformed_param_34
            lv776: R.Tensor((640,), dtype="float32") = transformed_param_33
            lv172 = R.call_tir(cls.layer_norm1, (lv114, lv775, lv776), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv777: R.Tensor((640, 5120), dtype="float32") = transformed_param_911
            lv778: R.Tensor((5120,), dtype="float32") = transformed_param_27
            lv115 = R.call_tir(cls.fused_matmul17_add18, (lv172, lv777, lv778), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv116 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv115,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv779: R.Tensor((2560, 640), dtype="float32") = transformed_param_912
            lv780: R.Tensor((640,), dtype="float32") = transformed_param_28
            lv117 = R.call_tir(cls.fused_matmul18_add16_add17, (lv116, lv779, lv780, lv114), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv781: R.Tensor((640,), dtype="float32") = transformed_param_40
            lv782: R.Tensor((640,), dtype="float32") = transformed_param_39
            lv185 = R.call_tir(cls.layer_norm1, (lv117, lv781, lv782), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv783: R.Tensor((640, 640), dtype="float32") = transformed_param_913
            lv187 = R.call_tir(cls.matmul11, (lv185, lv783), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv784: R.Tensor((640, 640), dtype="float32") = transformed_param_914
            lv189 = R.call_tir(cls.matmul11, (lv185, lv784), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv785: R.Tensor((640, 640), dtype="float32") = transformed_param_915
            lv191 = R.call_tir(cls.matmul11, (lv185, lv785), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv118_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv187,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv119 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv189,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv120_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv191,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv121 = R.call_tir(cls.fused_matmul12_multiply5, (lv118_1, lv119, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv203 = R.call_tir(cls.softmax1, (lv121,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv204 = R.call_tir(cls.matmul13, (lv203, lv120_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv122_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv204,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv786: R.Tensor((640, 640), dtype="float32") = transformed_param_916
            lv787: R.Tensor((640,), dtype="float32") = transformed_param_35
            lv123 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv122_1, lv786, lv787, lv117), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv788: R.Tensor((640,), dtype="float32") = transformed_param_42
            lv789: R.Tensor((640,), dtype="float32") = transformed_param_41
            lv212 = R.call_tir(cls.layer_norm1, (lv123, lv788, lv789), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv790: R.Tensor((640, 640), dtype="float32") = transformed_param_917
            lv214 = R.call_tir(cls.matmul11, (lv212, lv790), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv791: R.Tensor((2048, 640), dtype="float32") = transformed_param_918
            lv216 = R.call_tir(cls.matmul14, (inp_2, lv791), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv792: R.Tensor((2048, 640), dtype="float32") = transformed_param_919
            lv218 = R.call_tir(cls.matmul14, (inp_2, lv792), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv124_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv214,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv125 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv216,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv126 = R.call_tir(cls.fused_reshape25_transpose16, (lv218,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv127 = R.call_tir(cls.fused_matmul15_multiply6, (lv124_1, lv125, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv230 = R.call_tir(cls.softmax2, (lv127,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv231 = R.call_tir(cls.matmul16, (lv230, lv126), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv128 = R.call_tir(cls.fused_transpose14_reshape24, (lv231,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv793: R.Tensor((640, 640), dtype="float32") = transformed_param_920
            lv794: R.Tensor((640,), dtype="float32") = transformed_param_36
            lv129 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv128, lv793, lv794, lv123), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv795: R.Tensor((640,), dtype="float32") = transformed_param_44
            lv796: R.Tensor((640,), dtype="float32") = transformed_param_43
            lv239 = R.call_tir(cls.layer_norm1, (lv129, lv795, lv796), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv797: R.Tensor((640, 5120), dtype="float32") = transformed_param_921
            lv798: R.Tensor((5120,), dtype="float32") = transformed_param_37
            lv130 = R.call_tir(cls.fused_matmul17_add18, (lv239, lv797, lv798), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv131 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv130,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv799: R.Tensor((2560, 640), dtype="float32") = transformed_param_922
            lv800: R.Tensor((640,), dtype="float32") = transformed_param_38
            lv132 = R.call_tir(cls.fused_matmul18_add16_add17, (lv131, lv799, lv800, lv129), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv801: R.Tensor((640, 640), dtype="float32") = transformed_param_923
            lv802: R.Tensor((640,), dtype="float32") = transformed_param_24
            lv133 = R.call_tir(cls.fused_matmul11_add16, (lv132, lv801, lv802), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv134 = R.call_tir(cls.fused_reshape26_transpose20_add15, (lv133, lv100_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv803: R.Tensor((640,), dtype="float32") = transformed_param_81
            lv804: R.Tensor((640,), dtype="float32") = transformed_param_80
            lv135 = R.call_tir(cls.fused_group_norm2_silu3, (lv134, lv803, lv804), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv263 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv805: R.Tensor((1280, 640), dtype="float32") = transformed_param_925
            lv806: R.Tensor((640,), dtype="float32") = transformed_param_84
            lv136_1 = R.call_tir(cls.fused_matmul10_add13_strided_slice7, (lv263, lv805, lv806), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv268 = R.call_tir(cls.reshape21, (lv136_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv807: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_78
            lv808: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_924
            lv137_1 = R.call_tir(cls.fused_conv2d4_add12_add14, (lv135, lv807, lv808, lv268), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv809: R.Tensor((640,), dtype="float32") = transformed_param_83
            lv810: R.Tensor((640,), dtype="float32") = transformed_param_82
            lv138 = R.call_tir(cls.fused_group_norm2_silu3, (lv137_1, lv809, lv810), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv811: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_79
            lv812: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_926
            lv139 = R.call_tir(cls.fused_conv2d4_add12_add15_divide1, (lv138, lv811, lv812, lv134), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv813: R.Tensor((640,), dtype="float32") = transformed_param_46
            lv814: R.Tensor((640,), dtype="float32") = transformed_param_45
            lv277 = R.call_tir(cls.group_norm3, (lv139, lv813, lv814), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv140 = R.call_tir(cls.fused_transpose10_reshape22, (lv277,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv815: R.Tensor((640, 640), dtype="float32") = transformed_param_927
            lv816: R.Tensor((640,), dtype="float32") = transformed_param_47
            lv141 = R.call_tir(cls.fused_matmul11_add16, (lv140, lv815, lv816), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv817: R.Tensor((640,), dtype="float32") = transformed_param_54
            lv818: R.Tensor((640,), dtype="float32") = transformed_param_53
            lv283 = R.call_tir(cls.layer_norm1, (lv141, lv817, lv818), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv819: R.Tensor((640, 640), dtype="float32") = transformed_param_928
            lv285 = R.call_tir(cls.matmul11, (lv283, lv819), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv820: R.Tensor((640, 640), dtype="float32") = transformed_param_929
            lv287 = R.call_tir(cls.matmul11, (lv283, lv820), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv821: R.Tensor((640, 640), dtype="float32") = transformed_param_930
            lv289 = R.call_tir(cls.matmul11, (lv283, lv821), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv142 = R.call_tir(cls.fused_reshape23_transpose12, (lv285,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv143 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv287,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv144 = R.call_tir(cls.fused_reshape23_transpose12, (lv289,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv145_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv142, lv143, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv301 = R.call_tir(cls.softmax1, (lv145_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv302 = R.call_tir(cls.matmul13, (lv301, lv144), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv146 = R.call_tir(cls.fused_transpose14_reshape24, (lv302,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv822: R.Tensor((640, 640), dtype="float32") = transformed_param_931
            lv823: R.Tensor((640,), dtype="float32") = transformed_param_49
            lv147_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv146, lv822, lv823, lv141), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv824: R.Tensor((640,), dtype="float32") = transformed_param_56
            lv825: R.Tensor((640,), dtype="float32") = transformed_param_55
            lv310 = R.call_tir(cls.layer_norm1, (lv147_1, lv824, lv825), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv826: R.Tensor((640, 640), dtype="float32") = transformed_param_932
            lv312 = R.call_tir(cls.matmul11, (lv310, lv826), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv827: R.Tensor((2048, 640), dtype="float32") = transformed_param_933
            lv314 = R.call_tir(cls.matmul14, (inp_2, lv827), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv828: R.Tensor((2048, 640), dtype="float32") = transformed_param_934
            lv316 = R.call_tir(cls.matmul14, (inp_2, lv828), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv148 = R.call_tir(cls.fused_reshape23_transpose12, (lv312,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv149_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv314,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv150 = R.call_tir(cls.fused_reshape25_transpose16, (lv316,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv151_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv148, lv149_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv328 = R.call_tir(cls.softmax2, (lv151_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv329 = R.call_tir(cls.matmul16, (lv328, lv150), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv152 = R.call_tir(cls.fused_transpose14_reshape24, (lv329,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv829: R.Tensor((640, 640), dtype="float32") = transformed_param_935
            lv830: R.Tensor((640,), dtype="float32") = transformed_param_50
            lv153 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv152, lv829, lv830, lv147_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv831: R.Tensor((640,), dtype="float32") = transformed_param_58
            lv832: R.Tensor((640,), dtype="float32") = transformed_param_57
            lv337 = R.call_tir(cls.layer_norm1, (lv153, lv831, lv832), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv833: R.Tensor((640, 5120), dtype="float32") = transformed_param_936
            lv834: R.Tensor((5120,), dtype="float32") = transformed_param_51
            lv154 = R.call_tir(cls.fused_matmul17_add18, (lv337, lv833, lv834), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv155 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv154,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv835: R.Tensor((2560, 640), dtype="float32") = transformed_param_937
            lv836: R.Tensor((640,), dtype="float32") = transformed_param_52
            lv156 = R.call_tir(cls.fused_matmul18_add16_add17, (lv155, lv835, lv836, lv153), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv837: R.Tensor((640,), dtype="float32") = transformed_param_64
            lv838: R.Tensor((640,), dtype="float32") = transformed_param_63
            lv350 = R.call_tir(cls.layer_norm1, (lv156, lv837, lv838), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv839: R.Tensor((640, 640), dtype="float32") = transformed_param_938
            lv352 = R.call_tir(cls.matmul11, (lv350, lv839), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv840: R.Tensor((640, 640), dtype="float32") = transformed_param_939
            lv354 = R.call_tir(cls.matmul11, (lv350, lv840), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv841: R.Tensor((640, 640), dtype="float32") = transformed_param_940
            lv356 = R.call_tir(cls.matmul11, (lv350, lv841), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv157 = R.call_tir(cls.fused_reshape23_transpose12, (lv352,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv158 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv354,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv159 = R.call_tir(cls.fused_reshape23_transpose12, (lv356,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv160 = R.call_tir(cls.fused_matmul12_multiply5, (lv157, lv158, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv368 = R.call_tir(cls.softmax1, (lv160,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv369 = R.call_tir(cls.matmul13, (lv368, lv159), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv161 = R.call_tir(cls.fused_transpose14_reshape24, (lv369,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv842: R.Tensor((640, 640), dtype="float32") = transformed_param_941
            lv843: R.Tensor((640,), dtype="float32") = transformed_param_59
            lv162 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv161, lv842, lv843, lv156), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv844: R.Tensor((640,), dtype="float32") = transformed_param_66
            lv845: R.Tensor((640,), dtype="float32") = transformed_param_65
            lv377 = R.call_tir(cls.layer_norm1, (lv162, lv844, lv845), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv846: R.Tensor((640, 640), dtype="float32") = transformed_param_942
            lv379 = R.call_tir(cls.matmul11, (lv377, lv846), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv847: R.Tensor((2048, 640), dtype="float32") = transformed_param_943
            lv381 = R.call_tir(cls.matmul14, (inp_2, lv847), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv848: R.Tensor((2048, 640), dtype="float32") = transformed_param_944
            lv383 = R.call_tir(cls.matmul14, (inp_2, lv848), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv163_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv379,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv164_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv381,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv165 = R.call_tir(cls.fused_reshape25_transpose16, (lv383,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv166 = R.call_tir(cls.fused_matmul15_multiply6, (lv163_1, lv164_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv395 = R.call_tir(cls.softmax2, (lv166,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv396 = R.call_tir(cls.matmul16, (lv395, lv165), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv167 = R.call_tir(cls.fused_transpose14_reshape24, (lv396,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv849: R.Tensor((640, 640), dtype="float32") = transformed_param_945
            lv850: R.Tensor((640,), dtype="float32") = transformed_param_60
            lv168 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv167, lv849, lv850, lv162), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv851: R.Tensor((640,), dtype="float32") = transformed_param_68
            lv852: R.Tensor((640,), dtype="float32") = transformed_param_67
            lv404 = R.call_tir(cls.layer_norm1, (lv168, lv851, lv852), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv853: R.Tensor((640, 5120), dtype="float32") = transformed_param_946
            lv854: R.Tensor((5120,), dtype="float32") = transformed_param_61
            lv169 = R.call_tir(cls.fused_matmul17_add18, (lv404, lv853, lv854), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv170 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv169,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv855: R.Tensor((2560, 640), dtype="float32") = transformed_param_947
            lv856: R.Tensor((640,), dtype="float32") = transformed_param_62
            lv171 = R.call_tir(cls.fused_matmul18_add16_add17, (lv170, lv855, lv856, lv168), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv857: R.Tensor((640, 640), dtype="float32") = transformed_param_948
            lv858: R.Tensor((640,), dtype="float32") = transformed_param_48
            lv172_1 = R.call_tir(cls.fused_matmul11_add16, (lv171, lv857, lv858), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv173 = R.call_tir(cls.fused_reshape26_transpose20_add15, (lv172_1, lv139), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv859: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_69
            lv860: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_949
            lv174 = R.call_tir(cls.fused_conv2d6_add19, (lv173, lv859, lv860), out_sinfo=R.Tensor((2, 640, 32, 32), dtype="float32"))
            lv861: R.Tensor((640,), dtype="float32") = transformed_param_297
            lv862: R.Tensor((640,), dtype="float32") = transformed_param_296
            lv175 = R.call_tir(cls.fused_group_norm4_silu4, (lv174, lv861, lv862), out_sinfo=R.Tensor((2, 640, 32, 32), dtype="float32"))
            lv431 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv863: R.Tensor((1280, 1280), dtype="float32") = transformed_param_951
            lv864: R.Tensor((1280,), dtype="float32") = transformed_param_300
            lv176 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv431, lv863, lv864), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv436 = R.call_tir(cls.reshape28, (lv176,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv865: R.Tensor((1280, 640, 3, 3), dtype="float32") = transformed_param_293
            lv866: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_950
            lv177 = R.call_tir(cls.fused_conv2d7_add20_add21, (lv175, lv865, lv866, lv436), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv867: R.Tensor((1280,), dtype="float32") = transformed_param_299
            lv868: R.Tensor((1280,), dtype="float32") = transformed_param_298
            lv178 = R.call_tir(cls.fused_group_norm5_silu5, (lv177, lv867, lv868), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv869: R.Tensor((1280, 640, 1, 1), dtype="float32") = transformed_param_295
            lv870: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_953
            lv179 = R.call_tir(cls.fused_conv2d9_add20, (lv174, lv869, lv870), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv871: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_294
            lv872: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_952
            lv180 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv178, lv871, lv872, lv179), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv873: R.Tensor((1280,), dtype="float32") = transformed_param_86
            lv874: R.Tensor((1280,), dtype="float32") = transformed_param_85
            lv448 = R.call_tir(cls.group_norm6, (lv180, lv873, lv874), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv181 = R.call_tir(cls.fused_transpose21_reshape29, (lv448,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv875: R.Tensor((1280, 1280), dtype="float32") = transformed_param_954
            lv876: R.Tensor((1280,), dtype="float32") = transformed_param_87
            lv182 = R.call_tir(cls.fused_matmul19_add23, (lv181, lv875, lv876), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv877: R.Tensor((1280,), dtype="float32") = transformed_param_94
            lv878: R.Tensor((1280,), dtype="float32") = transformed_param_93
            lv454 = R.call_tir(cls.layer_norm2, (lv182, lv877, lv878), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv879: R.Tensor((1280, 1280), dtype="float32") = transformed_param_955
            lv456 = R.call_tir(cls.matmul19, (lv454, lv879), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv880: R.Tensor((1280, 1280), dtype="float32") = transformed_param_956
            lv458 = R.call_tir(cls.matmul19, (lv454, lv880), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv881: R.Tensor((1280, 1280), dtype="float32") = transformed_param_957
            lv460 = R.call_tir(cls.matmul19, (lv454, lv881), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv183 = R.call_tir(cls.fused_reshape30_transpose22, (lv456,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv184 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv458,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv185_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv460,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv186 = R.call_tir(cls.fused_matmul20_multiply8, (lv183, lv184, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv472 = R.call_tir(cls.softmax3, (lv186,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv473 = R.call_tir(cls.matmul21, (lv472, lv185_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv187_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv473,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv882: R.Tensor((1280, 1280), dtype="float32") = transformed_param_958
            lv883: R.Tensor((1280,), dtype="float32") = transformed_param_89
            lv188 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv187_1, lv882, lv883, lv182), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv884: R.Tensor((1280,), dtype="float32") = transformed_param_96
            lv885: R.Tensor((1280,), dtype="float32") = transformed_param_95
            lv481 = R.call_tir(cls.layer_norm2, (lv188, lv884, lv885), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv886: R.Tensor((1280, 1280), dtype="float32") = transformed_param_959
            lv483 = R.call_tir(cls.matmul19, (lv481, lv886), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv887: R.Tensor((2048, 1280), dtype="float32") = transformed_param_960
            lv485 = R.call_tir(cls.matmul22, (inp_2, lv887), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv888: R.Tensor((2048, 1280), dtype="float32") = transformed_param_961
            lv487 = R.call_tir(cls.matmul22, (inp_2, lv888), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv189_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv483,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv190 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv485,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv191_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv487,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv192 = R.call_tir(cls.fused_matmul23_multiply9, (lv189_1, lv190, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv499 = R.call_tir(cls.softmax4, (lv192,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv500 = R.call_tir(cls.matmul24, (lv499, lv191_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv193 = R.call_tir(cls.fused_transpose24_reshape31, (lv500,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv889: R.Tensor((1280, 1280), dtype="float32") = transformed_param_962
            lv890: R.Tensor((1280,), dtype="float32") = transformed_param_90
            lv194 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv193, lv889, lv890, lv188), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv891: R.Tensor((1280,), dtype="float32") = transformed_param_98
            lv892: R.Tensor((1280,), dtype="float32") = transformed_param_97
            lv508 = R.call_tir(cls.layer_norm2, (lv194, lv891, lv892), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv893: R.Tensor((1280, 10240), dtype="float32") = transformed_param_963
            lv894: R.Tensor((10240,), dtype="float32") = transformed_param_91
            lv195 = R.call_tir(cls.fused_matmul25_add25, (lv508, lv893, lv894), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv196 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv195,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv895: R.Tensor((5120, 1280), dtype="float32") = transformed_param_964
            lv896: R.Tensor((1280,), dtype="float32") = transformed_param_92
            lv197 = R.call_tir(cls.fused_matmul26_add23_add24, (lv196, lv895, lv896, lv194), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv897: R.Tensor((1280,), dtype="float32") = transformed_param_104
            lv898: R.Tensor((1280,), dtype="float32") = transformed_param_103
            lv521 = R.call_tir(cls.layer_norm2, (lv197, lv897, lv898), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv899: R.Tensor((1280, 1280), dtype="float32") = transformed_param_965
            lv523 = R.call_tir(cls.matmul19, (lv521, lv899), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv900: R.Tensor((1280, 1280), dtype="float32") = transformed_param_966
            lv525 = R.call_tir(cls.matmul19, (lv521, lv900), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv901: R.Tensor((1280, 1280), dtype="float32") = transformed_param_967
            lv527 = R.call_tir(cls.matmul19, (lv521, lv901), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv198 = R.call_tir(cls.fused_reshape30_transpose22, (lv523,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv199 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv525,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv200 = R.call_tir(cls.fused_reshape30_transpose22, (lv527,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv201 = R.call_tir(cls.fused_matmul20_multiply8, (lv198, lv199, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv539 = R.call_tir(cls.softmax3, (lv201,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv540 = R.call_tir(cls.matmul21, (lv539, lv200), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv202 = R.call_tir(cls.fused_transpose24_reshape31, (lv540,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv902: R.Tensor((1280, 1280), dtype="float32") = transformed_param_968
            lv903: R.Tensor((1280,), dtype="float32") = transformed_param_99
            lv203_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv202, lv902, lv903, lv197), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv904: R.Tensor((1280,), dtype="float32") = transformed_param_106
            lv905: R.Tensor((1280,), dtype="float32") = transformed_param_105
            lv548 = R.call_tir(cls.layer_norm2, (lv203_1, lv904, lv905), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv906: R.Tensor((1280, 1280), dtype="float32") = transformed_param_969
            lv550 = R.call_tir(cls.matmul19, (lv548, lv906), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv907: R.Tensor((2048, 1280), dtype="float32") = transformed_param_970
            lv552 = R.call_tir(cls.matmul22, (inp_2, lv907), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv908: R.Tensor((2048, 1280), dtype="float32") = transformed_param_971
            lv554 = R.call_tir(cls.matmul22, (inp_2, lv908), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv204_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv550,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv205 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv552,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv206 = R.call_tir(cls.fused_reshape32_transpose26, (lv554,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv207 = R.call_tir(cls.fused_matmul23_multiply9, (lv204_1, lv205, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv566 = R.call_tir(cls.softmax4, (lv207,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv567 = R.call_tir(cls.matmul24, (lv566, lv206), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv208 = R.call_tir(cls.fused_transpose24_reshape31, (lv567,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv909: R.Tensor((1280, 1280), dtype="float32") = transformed_param_972
            lv910: R.Tensor((1280,), dtype="float32") = transformed_param_100
            lv209 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv208, lv909, lv910, lv203_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv911: R.Tensor((1280,), dtype="float32") = transformed_param_108
            lv912: R.Tensor((1280,), dtype="float32") = transformed_param_107
            lv575 = R.call_tir(cls.layer_norm2, (lv209, lv911, lv912), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv913: R.Tensor((1280, 10240), dtype="float32") = transformed_param_973
            lv914: R.Tensor((10240,), dtype="float32") = transformed_param_101
            lv210 = R.call_tir(cls.fused_matmul25_add25, (lv575, lv913, lv914), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv211 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv210,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv915: R.Tensor((5120, 1280), dtype="float32") = transformed_param_974
            lv916: R.Tensor((1280,), dtype="float32") = transformed_param_102
            lv212_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv211, lv915, lv916, lv209), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv917: R.Tensor((1280,), dtype="float32") = transformed_param_114
            lv918: R.Tensor((1280,), dtype="float32") = transformed_param_113
            lv588 = R.call_tir(cls.layer_norm2, (lv212_1, lv917, lv918), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv919: R.Tensor((1280, 1280), dtype="float32") = transformed_param_975
            lv590 = R.call_tir(cls.matmul19, (lv588, lv919), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv920: R.Tensor((1280, 1280), dtype="float32") = transformed_param_976
            lv592 = R.call_tir(cls.matmul19, (lv588, lv920), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv921: R.Tensor((1280, 1280), dtype="float32") = transformed_param_977
            lv594 = R.call_tir(cls.matmul19, (lv588, lv921), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv213 = R.call_tir(cls.fused_reshape30_transpose22, (lv590,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv214_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv592,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv215 = R.call_tir(cls.fused_reshape30_transpose22, (lv594,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv216_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv213, lv214_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv606 = R.call_tir(cls.softmax3, (lv216_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv607 = R.call_tir(cls.matmul21, (lv606, lv215), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv217 = R.call_tir(cls.fused_transpose24_reshape31, (lv607,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv922: R.Tensor((1280, 1280), dtype="float32") = transformed_param_978
            lv923: R.Tensor((1280,), dtype="float32") = transformed_param_109
            lv218_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv217, lv922, lv923, lv212_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv924: R.Tensor((1280,), dtype="float32") = transformed_param_116
            lv925: R.Tensor((1280,), dtype="float32") = transformed_param_115
            lv615 = R.call_tir(cls.layer_norm2, (lv218_1, lv924, lv925), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv926: R.Tensor((1280, 1280), dtype="float32") = transformed_param_979
            lv617 = R.call_tir(cls.matmul19, (lv615, lv926), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv927: R.Tensor((2048, 1280), dtype="float32") = transformed_param_980
            lv619 = R.call_tir(cls.matmul22, (inp_2, lv927), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv928: R.Tensor((2048, 1280), dtype="float32") = transformed_param_981
            lv621 = R.call_tir(cls.matmul22, (inp_2, lv928), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv219 = R.call_tir(cls.fused_reshape30_transpose22, (lv617,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv220 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv619,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv221 = R.call_tir(cls.fused_reshape32_transpose26, (lv621,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.fused_matmul23_multiply9, (lv219, lv220, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv633 = R.call_tir(cls.softmax4, (lv222,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv634 = R.call_tir(cls.matmul24, (lv633, lv221), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv223 = R.call_tir(cls.fused_transpose24_reshape31, (lv634,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv929: R.Tensor((1280, 1280), dtype="float32") = transformed_param_982
            lv930: R.Tensor((1280,), dtype="float32") = transformed_param_110
            lv224 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv223, lv929, lv930, lv218_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv931: R.Tensor((1280,), dtype="float32") = transformed_param_118
            lv932: R.Tensor((1280,), dtype="float32") = transformed_param_117
            lv642 = R.call_tir(cls.layer_norm2, (lv224, lv931, lv932), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv933: R.Tensor((1280, 10240), dtype="float32") = transformed_param_983
            lv934: R.Tensor((10240,), dtype="float32") = transformed_param_111
            lv225 = R.call_tir(cls.fused_matmul25_add25, (lv642, lv933, lv934), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv226 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv225,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv935: R.Tensor((5120, 1280), dtype="float32") = transformed_param_984
            lv936: R.Tensor((1280,), dtype="float32") = transformed_param_112
            lv227 = R.call_tir(cls.fused_matmul26_add23_add24, (lv226, lv935, lv936, lv224), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv937: R.Tensor((1280,), dtype="float32") = transformed_param_124
            lv938: R.Tensor((1280,), dtype="float32") = transformed_param_123
            lv655 = R.call_tir(cls.layer_norm2, (lv227, lv937, lv938), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv939: R.Tensor((1280, 1280), dtype="float32") = transformed_param_985
            lv657 = R.call_tir(cls.matmul19, (lv655, lv939), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv940: R.Tensor((1280, 1280), dtype="float32") = transformed_param_986
            lv659 = R.call_tir(cls.matmul19, (lv655, lv940), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv941: R.Tensor((1280, 1280), dtype="float32") = transformed_param_987
            lv661 = R.call_tir(cls.matmul19, (lv655, lv941), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv228 = R.call_tir(cls.fused_reshape30_transpose22, (lv657,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv229 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv659,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv230_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv661,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv231_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv228, lv229, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv673 = R.call_tir(cls.softmax3, (lv231_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv674 = R.call_tir(cls.matmul21, (lv673, lv230_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv232 = R.call_tir(cls.fused_transpose24_reshape31, (lv674,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv942: R.Tensor((1280, 1280), dtype="float32") = transformed_param_988
            lv943: R.Tensor((1280,), dtype="float32") = transformed_param_119
            lv233 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv232, lv942, lv943, lv227), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv944: R.Tensor((1280,), dtype="float32") = transformed_param_126
            lv945: R.Tensor((1280,), dtype="float32") = transformed_param_125
            lv682 = R.call_tir(cls.layer_norm2, (lv233, lv944, lv945), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv946: R.Tensor((1280, 1280), dtype="float32") = transformed_param_989
            lv684 = R.call_tir(cls.matmul19, (lv682, lv946), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv947: R.Tensor((2048, 1280), dtype="float32") = transformed_param_990
            lv686 = R.call_tir(cls.matmul22, (inp_2, lv947), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv948: R.Tensor((2048, 1280), dtype="float32") = transformed_param_991
            lv688 = R.call_tir(cls.matmul22, (inp_2, lv948), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv234 = R.call_tir(cls.fused_reshape30_transpose22, (lv684,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv235 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv686,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv236 = R.call_tir(cls.fused_reshape32_transpose26, (lv688,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv237 = R.call_tir(cls.fused_matmul23_multiply9, (lv234, lv235, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv700 = R.call_tir(cls.softmax4, (lv237,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv701 = R.call_tir(cls.matmul24, (lv700, lv236), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv238 = R.call_tir(cls.fused_transpose24_reshape31, (lv701,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv949: R.Tensor((1280, 1280), dtype="float32") = transformed_param_992
            lv950: R.Tensor((1280,), dtype="float32") = transformed_param_120
            lv239_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv238, lv949, lv950, lv233), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv951: R.Tensor((1280,), dtype="float32") = transformed_param_128
            lv952: R.Tensor((1280,), dtype="float32") = transformed_param_127
            lv709 = R.call_tir(cls.layer_norm2, (lv239_1, lv951, lv952), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv953: R.Tensor((1280, 10240), dtype="float32") = transformed_param_993
            lv954: R.Tensor((10240,), dtype="float32") = transformed_param_121
            lv240 = R.call_tir(cls.fused_matmul25_add25, (lv709, lv953, lv954), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv241 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv240,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv955: R.Tensor((5120, 1280), dtype="float32") = transformed_param_994
            lv956: R.Tensor((1280,), dtype="float32") = transformed_param_122
            lv242 = R.call_tir(cls.fused_matmul26_add23_add24, (lv241, lv955, lv956, lv239_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv957: R.Tensor((1280,), dtype="float32") = transformed_param_134
            lv958: R.Tensor((1280,), dtype="float32") = transformed_param_133
            lv722_1 = R.call_tir(cls.layer_norm2, (lv242, lv957, lv958), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv959: R.Tensor((1280, 1280), dtype="float32") = transformed_param_995
            lv724_1 = R.call_tir(cls.matmul19, (lv722_1, lv959), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv960: R.Tensor((1280, 1280), dtype="float32") = transformed_param_996
            lv726_1 = R.call_tir(cls.matmul19, (lv722_1, lv960), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv961: R.Tensor((1280, 1280), dtype="float32") = transformed_param_997
            lv728_1 = R.call_tir(cls.matmul19, (lv722_1, lv961), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv243 = R.call_tir(cls.fused_reshape30_transpose22, (lv724_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv244 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv726_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv245 = R.call_tir(cls.fused_reshape30_transpose22, (lv728_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv246 = R.call_tir(cls.fused_matmul20_multiply8, (lv243, lv244, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv740_1 = R.call_tir(cls.softmax3, (lv246,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv741_1 = R.call_tir(cls.matmul21, (lv740_1, lv245), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv247 = R.call_tir(cls.fused_transpose24_reshape31, (lv741_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv962: R.Tensor((1280, 1280), dtype="float32") = transformed_param_998
            lv963: R.Tensor((1280,), dtype="float32") = transformed_param_129
            lv248 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv247, lv962, lv963, lv242), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv964: R.Tensor((1280,), dtype="float32") = transformed_param_136
            lv965: R.Tensor((1280,), dtype="float32") = transformed_param_135
            lv749_1 = R.call_tir(cls.layer_norm2, (lv248, lv964, lv965), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv966: R.Tensor((1280, 1280), dtype="float32") = transformed_param_999
            lv751_1 = R.call_tir(cls.matmul19, (lv749_1, lv966), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv967: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1000
            lv753_1 = R.call_tir(cls.matmul22, (inp_2, lv967), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv968: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1001
            lv755_1 = R.call_tir(cls.matmul22, (inp_2, lv968), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv249 = R.call_tir(cls.fused_reshape30_transpose22, (lv751_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv250 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv753_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv251 = R.call_tir(cls.fused_reshape32_transpose26, (lv755_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv252 = R.call_tir(cls.fused_matmul23_multiply9, (lv249, lv250, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv767_1 = R.call_tir(cls.softmax4, (lv252,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv768_1 = R.call_tir(cls.matmul24, (lv767_1, lv251), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv253 = R.call_tir(cls.fused_transpose24_reshape31, (lv768_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv969: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1002
            lv970: R.Tensor((1280,), dtype="float32") = transformed_param_130
            lv254 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv253, lv969, lv970, lv248), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv971: R.Tensor((1280,), dtype="float32") = transformed_param_138
            lv972: R.Tensor((1280,), dtype="float32") = transformed_param_137
            lv776_1 = R.call_tir(cls.layer_norm2, (lv254, lv971, lv972), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv973: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1003
            lv974: R.Tensor((10240,), dtype="float32") = transformed_param_131
            lv255 = R.call_tir(cls.fused_matmul25_add25, (lv776_1, lv973, lv974), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv256 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv255,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv975: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1004
            lv976: R.Tensor((1280,), dtype="float32") = transformed_param_132
            lv257 = R.call_tir(cls.fused_matmul26_add23_add24, (lv256, lv975, lv976, lv254), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv977: R.Tensor((1280,), dtype="float32") = transformed_param_144
            lv978: R.Tensor((1280,), dtype="float32") = transformed_param_143
            lv789_1 = R.call_tir(cls.layer_norm2, (lv257, lv977, lv978), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv979: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1005
            lv791_1 = R.call_tir(cls.matmul19, (lv789_1, lv979), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv980: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1006
            lv793_1 = R.call_tir(cls.matmul19, (lv789_1, lv980), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv981: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1007
            lv795_1 = R.call_tir(cls.matmul19, (lv789_1, lv981), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv258 = R.call_tir(cls.fused_reshape30_transpose22, (lv791_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv259 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv793_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv260 = R.call_tir(cls.fused_reshape30_transpose22, (lv795_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv261 = R.call_tir(cls.fused_matmul20_multiply8, (lv258, lv259, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv807_1 = R.call_tir(cls.softmax3, (lv261,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv808_1 = R.call_tir(cls.matmul21, (lv807_1, lv260), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv262 = R.call_tir(cls.fused_transpose24_reshape31, (lv808_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv982: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1008
            lv983: R.Tensor((1280,), dtype="float32") = transformed_param_139
            lv263_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv262, lv982, lv983, lv257), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv984: R.Tensor((1280,), dtype="float32") = transformed_param_146
            lv985: R.Tensor((1280,), dtype="float32") = transformed_param_145
            lv816_1 = R.call_tir(cls.layer_norm2, (lv263_1, lv984, lv985), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv986: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1009
            lv818_1 = R.call_tir(cls.matmul19, (lv816_1, lv986), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv987: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1010
            lv820_1 = R.call_tir(cls.matmul22, (inp_2, lv987), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv988: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1011
            lv822_1 = R.call_tir(cls.matmul22, (inp_2, lv988), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv264 = R.call_tir(cls.fused_reshape30_transpose22, (lv818_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv265 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv820_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv266 = R.call_tir(cls.fused_reshape32_transpose26, (lv822_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.fused_matmul23_multiply9, (lv264, lv265, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv834_1 = R.call_tir(cls.softmax4, (lv267,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv835_1 = R.call_tir(cls.matmul24, (lv834_1, lv266), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv268_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv835_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv989: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1012
            lv990: R.Tensor((1280,), dtype="float32") = transformed_param_140
            lv269 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv268_1, lv989, lv990, lv263_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv991: R.Tensor((1280,), dtype="float32") = transformed_param_148
            lv992: R.Tensor((1280,), dtype="float32") = transformed_param_147
            lv843_1 = R.call_tir(cls.layer_norm2, (lv269, lv991, lv992), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv993: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1013
            lv994: R.Tensor((10240,), dtype="float32") = transformed_param_141
            lv270 = R.call_tir(cls.fused_matmul25_add25, (lv843_1, lv993, lv994), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv271 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv270,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv995: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1014
            lv996: R.Tensor((1280,), dtype="float32") = transformed_param_142
            lv272 = R.call_tir(cls.fused_matmul26_add23_add24, (lv271, lv995, lv996, lv269), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv997: R.Tensor((1280,), dtype="float32") = transformed_param_154
            lv998: R.Tensor((1280,), dtype="float32") = transformed_param_153
            lv856_1 = R.call_tir(cls.layer_norm2, (lv272, lv997, lv998), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv999: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1015
            lv858_1 = R.call_tir(cls.matmul19, (lv856_1, lv999), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1000: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1016
            lv860_1 = R.call_tir(cls.matmul19, (lv856_1, lv1000), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1001: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1017
            lv862_1 = R.call_tir(cls.matmul19, (lv856_1, lv1001), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv273 = R.call_tir(cls.fused_reshape30_transpose22, (lv858_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv274 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv860_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv275 = R.call_tir(cls.fused_reshape30_transpose22, (lv862_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv276 = R.call_tir(cls.fused_matmul20_multiply8, (lv273, lv274, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv874_1 = R.call_tir(cls.softmax3, (lv276,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv875_1 = R.call_tir(cls.matmul21, (lv874_1, lv275), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv277_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv875_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1002: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1018
            lv1003: R.Tensor((1280,), dtype="float32") = transformed_param_149
            lv278 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv277_1, lv1002, lv1003, lv272), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1004: R.Tensor((1280,), dtype="float32") = transformed_param_156
            lv1005: R.Tensor((1280,), dtype="float32") = transformed_param_155
            lv883_1 = R.call_tir(cls.layer_norm2, (lv278, lv1004, lv1005), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1006: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1019
            lv885_1 = R.call_tir(cls.matmul19, (lv883_1, lv1006), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1007: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1020
            lv887_1 = R.call_tir(cls.matmul22, (inp_2, lv1007), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1008: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1021
            lv889_1 = R.call_tir(cls.matmul22, (inp_2, lv1008), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv279 = R.call_tir(cls.fused_reshape30_transpose22, (lv885_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv280 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv887_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv281 = R.call_tir(cls.fused_reshape32_transpose26, (lv889_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv282 = R.call_tir(cls.fused_matmul23_multiply9, (lv279, lv280, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv901_1 = R.call_tir(cls.softmax4, (lv282,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv902_1 = R.call_tir(cls.matmul24, (lv901_1, lv281), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv283_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv902_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1009: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1022
            lv1010: R.Tensor((1280,), dtype="float32") = transformed_param_150
            lv284 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv283_1, lv1009, lv1010, lv278), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1011: R.Tensor((1280,), dtype="float32") = transformed_param_158
            lv1012: R.Tensor((1280,), dtype="float32") = transformed_param_157
            lv910_1 = R.call_tir(cls.layer_norm2, (lv284, lv1011, lv1012), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1013: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1023
            lv1014: R.Tensor((10240,), dtype="float32") = transformed_param_151
            lv285_1 = R.call_tir(cls.fused_matmul25_add25, (lv910_1, lv1013, lv1014), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv286 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv285_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1015: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1024
            lv1016: R.Tensor((1280,), dtype="float32") = transformed_param_152
            lv287_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv286, lv1015, lv1016, lv284), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1017: R.Tensor((1280,), dtype="float32") = transformed_param_164
            lv1018: R.Tensor((1280,), dtype="float32") = transformed_param_163
            lv923_1 = R.call_tir(cls.layer_norm2, (lv287_1, lv1017, lv1018), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1019: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1025
            lv925_1 = R.call_tir(cls.matmul19, (lv923_1, lv1019), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1020: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1026
            lv927_1 = R.call_tir(cls.matmul19, (lv923_1, lv1020), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1021: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1027
            lv929_1 = R.call_tir(cls.matmul19, (lv923_1, lv1021), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv288 = R.call_tir(cls.fused_reshape30_transpose22, (lv925_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv289_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv927_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv290 = R.call_tir(cls.fused_reshape30_transpose22, (lv929_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv291 = R.call_tir(cls.fused_matmul20_multiply8, (lv288, lv289_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv941_1 = R.call_tir(cls.softmax3, (lv291,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv942_1 = R.call_tir(cls.matmul21, (lv941_1, lv290), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv292 = R.call_tir(cls.fused_transpose24_reshape31, (lv942_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1022: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1028
            lv1023: R.Tensor((1280,), dtype="float32") = transformed_param_159
            lv293 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv292, lv1022, lv1023, lv287_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1024: R.Tensor((1280,), dtype="float32") = transformed_param_166
            lv1025: R.Tensor((1280,), dtype="float32") = transformed_param_165
            lv950_1 = R.call_tir(cls.layer_norm2, (lv293, lv1024, lv1025), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1026: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1029
            lv952_1 = R.call_tir(cls.matmul19, (lv950_1, lv1026), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1027: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1030
            lv954_1 = R.call_tir(cls.matmul22, (inp_2, lv1027), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1028: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1031
            lv956_1 = R.call_tir(cls.matmul22, (inp_2, lv1028), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv294 = R.call_tir(cls.fused_reshape30_transpose22, (lv952_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv295 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv954_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv296 = R.call_tir(cls.fused_reshape32_transpose26, (lv956_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv297 = R.call_tir(cls.fused_matmul23_multiply9, (lv294, lv295, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv968_1 = R.call_tir(cls.softmax4, (lv297,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv969_1 = R.call_tir(cls.matmul24, (lv968_1, lv296), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv298 = R.call_tir(cls.fused_transpose24_reshape31, (lv969_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1029: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1032
            lv1030: R.Tensor((1280,), dtype="float32") = transformed_param_160
            lv299 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv298, lv1029, lv1030, lv293), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1031: R.Tensor((1280,), dtype="float32") = transformed_param_168
            lv1032: R.Tensor((1280,), dtype="float32") = transformed_param_167
            lv977_1 = R.call_tir(cls.layer_norm2, (lv299, lv1031, lv1032), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1033: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1033
            lv1034: R.Tensor((10240,), dtype="float32") = transformed_param_161
            lv300 = R.call_tir(cls.fused_matmul25_add25, (lv977_1, lv1033, lv1034), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv301_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv300,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1035: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1034
            lv1036: R.Tensor((1280,), dtype="float32") = transformed_param_162
            lv302_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv301_1, lv1035, lv1036, lv299), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1037: R.Tensor((1280,), dtype="float32") = transformed_param_174
            lv1038: R.Tensor((1280,), dtype="float32") = transformed_param_173
            lv990_1 = R.call_tir(cls.layer_norm2, (lv302_1, lv1037, lv1038), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1039: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1035
            lv992_1 = R.call_tir(cls.matmul19, (lv990_1, lv1039), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1040: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1036
            lv994_1 = R.call_tir(cls.matmul19, (lv990_1, lv1040), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1041: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1037
            lv996_1 = R.call_tir(cls.matmul19, (lv990_1, lv1041), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv303 = R.call_tir(cls.fused_reshape30_transpose22, (lv992_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv304 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv994_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv305 = R.call_tir(cls.fused_reshape30_transpose22, (lv996_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv306 = R.call_tir(cls.fused_matmul20_multiply8, (lv303, lv304, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1008_1 = R.call_tir(cls.softmax3, (lv306,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1009_1 = R.call_tir(cls.matmul21, (lv1008_1, lv305), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv307 = R.call_tir(cls.fused_transpose24_reshape31, (lv1009_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1042: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1038
            lv1043: R.Tensor((1280,), dtype="float32") = transformed_param_169
            lv308 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv307, lv1042, lv1043, lv302_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1044: R.Tensor((1280,), dtype="float32") = transformed_param_176
            lv1045: R.Tensor((1280,), dtype="float32") = transformed_param_175
            lv1017_1 = R.call_tir(cls.layer_norm2, (lv308, lv1044, lv1045), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1046: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1039
            lv1019_1 = R.call_tir(cls.matmul19, (lv1017_1, lv1046), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1047: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1040
            lv1021_1 = R.call_tir(cls.matmul22, (inp_2, lv1047), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1048: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1041
            lv1023_1 = R.call_tir(cls.matmul22, (inp_2, lv1048), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv309 = R.call_tir(cls.fused_reshape30_transpose22, (lv1019_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv310_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1021_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv311 = R.call_tir(cls.fused_reshape32_transpose26, (lv1023_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv312_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv309, lv310_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1035_1 = R.call_tir(cls.softmax4, (lv312_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1036_1 = R.call_tir(cls.matmul24, (lv1035_1, lv311), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv313 = R.call_tir(cls.fused_transpose24_reshape31, (lv1036_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1049: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1042
            lv1050: R.Tensor((1280,), dtype="float32") = transformed_param_170
            lv314_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv313, lv1049, lv1050, lv308), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1051: R.Tensor((1280,), dtype="float32") = transformed_param_178
            lv1052: R.Tensor((1280,), dtype="float32") = transformed_param_177
            lv1044_1 = R.call_tir(cls.layer_norm2, (lv314_1, lv1051, lv1052), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1053: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1043
            lv1054: R.Tensor((10240,), dtype="float32") = transformed_param_171
            lv315 = R.call_tir(cls.fused_matmul25_add25, (lv1044_1, lv1053, lv1054), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv316_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv315,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1055: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1044
            lv1056: R.Tensor((1280,), dtype="float32") = transformed_param_172
            lv317 = R.call_tir(cls.fused_matmul26_add23_add24, (lv316_1, lv1055, lv1056, lv314_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1057: R.Tensor((1280,), dtype="float32") = transformed_param_184
            lv1058: R.Tensor((1280,), dtype="float32") = transformed_param_183
            lv1057_1 = R.call_tir(cls.layer_norm2, (lv317, lv1057, lv1058), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1059: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1045
            lv1059_1 = R.call_tir(cls.matmul19, (lv1057_1, lv1059), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1060: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1046
            lv1061 = R.call_tir(cls.matmul19, (lv1057_1, lv1060), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1061_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1047
            lv1063 = R.call_tir(cls.matmul19, (lv1057_1, lv1061_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv318 = R.call_tir(cls.fused_reshape30_transpose22, (lv1059_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv319 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv320 = R.call_tir(cls.fused_reshape30_transpose22, (lv1063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv321 = R.call_tir(cls.fused_matmul20_multiply8, (lv318, lv319, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1075 = R.call_tir(cls.softmax3, (lv321,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1076 = R.call_tir(cls.matmul21, (lv1075, lv320), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv322 = R.call_tir(cls.fused_transpose24_reshape31, (lv1076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1062: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1048
            lv1063_1: R.Tensor((1280,), dtype="float32") = transformed_param_179
            lv323 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv322, lv1062, lv1063_1, lv317), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1064: R.Tensor((1280,), dtype="float32") = transformed_param_186
            lv1065: R.Tensor((1280,), dtype="float32") = transformed_param_185
            lv1084 = R.call_tir(cls.layer_norm2, (lv323, lv1064, lv1065), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1066: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1049
            lv1086 = R.call_tir(cls.matmul19, (lv1084, lv1066), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1067: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1050
            lv1088 = R.call_tir(cls.matmul22, (inp_2, lv1067), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1068: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1051
            lv1090 = R.call_tir(cls.matmul22, (inp_2, lv1068), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv324 = R.call_tir(cls.fused_reshape30_transpose22, (lv1086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv325 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv326 = R.call_tir(cls.fused_reshape32_transpose26, (lv1090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv327 = R.call_tir(cls.fused_matmul23_multiply9, (lv324, lv325, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1102 = R.call_tir(cls.softmax4, (lv327,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1103 = R.call_tir(cls.matmul24, (lv1102, lv326), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv328_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1069: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1052
            lv1070: R.Tensor((1280,), dtype="float32") = transformed_param_180
            lv329_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv328_1, lv1069, lv1070, lv323), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1071: R.Tensor((1280,), dtype="float32") = transformed_param_188
            lv1072: R.Tensor((1280,), dtype="float32") = transformed_param_187
            lv1111 = R.call_tir(cls.layer_norm2, (lv329_1, lv1071, lv1072), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1073: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1053
            lv1074: R.Tensor((10240,), dtype="float32") = transformed_param_181
            lv330 = R.call_tir(cls.fused_matmul25_add25, (lv1111, lv1073, lv1074), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv331 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv330,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1075_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1054
            lv1076_1: R.Tensor((1280,), dtype="float32") = transformed_param_182
            lv332 = R.call_tir(cls.fused_matmul26_add23_add24, (lv331, lv1075_1, lv1076_1, lv329_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1077: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1055
            lv1078: R.Tensor((1280,), dtype="float32") = transformed_param_88
            lv333 = R.call_tir(cls.fused_matmul19_add23, (lv332, lv1077, lv1078), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv334 = R.call_tir(cls.fused_reshape33_transpose29_add22, (lv333, lv180), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1079: R.Tensor((1280,), dtype="float32") = transformed_param_304
            lv1080: R.Tensor((1280,), dtype="float32") = transformed_param_303
            lv335 = R.call_tir(cls.fused_group_norm5_silu5, (lv334, lv1079, lv1080), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1135 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1081: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1057
            lv1082: R.Tensor((1280,), dtype="float32") = transformed_param_307
            lv336 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv1135, lv1081, lv1082), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1140 = R.call_tir(cls.reshape28, (lv336,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1083: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_301
            lv1084_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1056
            lv337_1 = R.call_tir(cls.fused_conv2d8_add20_add21, (lv335, lv1083, lv1084_1, lv1140), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1085: R.Tensor((1280,), dtype="float32") = transformed_param_306
            lv1086_1: R.Tensor((1280,), dtype="float32") = transformed_param_305
            lv338 = R.call_tir(cls.fused_group_norm5_silu5, (lv337_1, lv1085, lv1086_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1087: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_302
            lv1088_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1058
            lv339 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv338, lv1087, lv1088_1, lv334), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1089: R.Tensor((1280,), dtype="float32") = transformed_param_190
            lv1090_1: R.Tensor((1280,), dtype="float32") = transformed_param_189
            lv1149 = R.call_tir(cls.group_norm6, (lv339, lv1089, lv1090_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv340 = R.call_tir(cls.fused_transpose21_reshape29, (lv1149,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1091: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1059
            lv1092: R.Tensor((1280,), dtype="float32") = transformed_param_191
            lv341 = R.call_tir(cls.fused_matmul19_add23, (lv340, lv1091, lv1092), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1093: R.Tensor((1280,), dtype="float32") = transformed_param_198
            lv1094: R.Tensor((1280,), dtype="float32") = transformed_param_197
            lv1155 = R.call_tir(cls.layer_norm2, (lv341, lv1093, lv1094), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1095: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1060
            lv1157 = R.call_tir(cls.matmul19, (lv1155, lv1095), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1096: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1061
            lv1159 = R.call_tir(cls.matmul19, (lv1155, lv1096), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1097: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1062
            lv1161 = R.call_tir(cls.matmul19, (lv1155, lv1097), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv342 = R.call_tir(cls.fused_reshape30_transpose22, (lv1157,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv343 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1159,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv344 = R.call_tir(cls.fused_reshape30_transpose22, (lv1161,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv345 = R.call_tir(cls.fused_matmul20_multiply8, (lv342, lv343, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1173 = R.call_tir(cls.softmax3, (lv345,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul21, (lv1173, lv344), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv346 = R.call_tir(cls.fused_transpose24_reshape31, (lv1174,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1098: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1063
            lv1099: R.Tensor((1280,), dtype="float32") = transformed_param_193
            lv347 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv346, lv1098, lv1099, lv341), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1100: R.Tensor((1280,), dtype="float32") = transformed_param_200
            lv1101: R.Tensor((1280,), dtype="float32") = transformed_param_199
            lv1182 = R.call_tir(cls.layer_norm2, (lv347, lv1100, lv1101), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1102_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1064
            lv1184 = R.call_tir(cls.matmul19, (lv1182, lv1102_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1103_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1065
            lv1186 = R.call_tir(cls.matmul22, (inp_2, lv1103_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1104: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1066
            lv1188 = R.call_tir(cls.matmul22, (inp_2, lv1104), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv348 = R.call_tir(cls.fused_reshape30_transpose22, (lv1184,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv349 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1186,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv350_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv1188,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv351 = R.call_tir(cls.fused_matmul23_multiply9, (lv348, lv349, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1200 = R.call_tir(cls.softmax4, (lv351,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1201 = R.call_tir(cls.matmul24, (lv1200, lv350_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv352_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1201,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1105: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1067
            lv1106: R.Tensor((1280,), dtype="float32") = transformed_param_194
            lv353 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv352_1, lv1105, lv1106, lv347), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1107: R.Tensor((1280,), dtype="float32") = transformed_param_202
            lv1108: R.Tensor((1280,), dtype="float32") = transformed_param_201
            lv1209 = R.call_tir(cls.layer_norm2, (lv353, lv1107, lv1108), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1109: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1068
            lv1110: R.Tensor((10240,), dtype="float32") = transformed_param_195
            lv354_1 = R.call_tir(cls.fused_matmul25_add25, (lv1209, lv1109, lv1110), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv355 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv354_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1111_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1069
            lv1112: R.Tensor((1280,), dtype="float32") = transformed_param_196
            lv356_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv355, lv1111_1, lv1112, lv353), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1113: R.Tensor((1280,), dtype="float32") = transformed_param_208
            lv1114: R.Tensor((1280,), dtype="float32") = transformed_param_207
            lv1222 = R.call_tir(cls.layer_norm2, (lv356_1, lv1113, lv1114), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1115: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1070
            lv1224 = R.call_tir(cls.matmul19, (lv1222, lv1115), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1116: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1071
            lv1226 = R.call_tir(cls.matmul19, (lv1222, lv1116), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1117: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1072
            lv1228 = R.call_tir(cls.matmul19, (lv1222, lv1117), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv357 = R.call_tir(cls.fused_reshape30_transpose22, (lv1224,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv358 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1226,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv359 = R.call_tir(cls.fused_reshape30_transpose22, (lv1228,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv360 = R.call_tir(cls.fused_matmul20_multiply8, (lv357, lv358, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1240 = R.call_tir(cls.softmax3, (lv360,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1241 = R.call_tir(cls.matmul21, (lv1240, lv359), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv361 = R.call_tir(cls.fused_transpose24_reshape31, (lv1241,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1118: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1073
            lv1119: R.Tensor((1280,), dtype="float32") = transformed_param_203
            lv362 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv361, lv1118, lv1119, lv356_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1120: R.Tensor((1280,), dtype="float32") = transformed_param_210
            lv1121: R.Tensor((1280,), dtype="float32") = transformed_param_209
            lv1249 = R.call_tir(cls.layer_norm2, (lv362, lv1120, lv1121), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1122: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1074
            lv1251 = R.call_tir(cls.matmul19, (lv1249, lv1122), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1123: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1075
            lv1253 = R.call_tir(cls.matmul22, (inp_2, lv1123), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1124: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1076
            lv1255 = R.call_tir(cls.matmul22, (inp_2, lv1124), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv363 = R.call_tir(cls.fused_reshape30_transpose22, (lv1251,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv364 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1253,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv365 = R.call_tir(cls.fused_reshape32_transpose26, (lv1255,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv366 = R.call_tir(cls.fused_matmul23_multiply9, (lv363, lv364, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1267 = R.call_tir(cls.softmax4, (lv366,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1268 = R.call_tir(cls.matmul24, (lv1267, lv365), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv367 = R.call_tir(cls.fused_transpose24_reshape31, (lv1268,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1125: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1077
            lv1126: R.Tensor((1280,), dtype="float32") = transformed_param_204
            lv368_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv367, lv1125, lv1126, lv362), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1127: R.Tensor((1280,), dtype="float32") = transformed_param_212
            lv1128: R.Tensor((1280,), dtype="float32") = transformed_param_211
            lv1276 = R.call_tir(cls.layer_norm2, (lv368_1, lv1127, lv1128), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1129: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1078
            lv1130: R.Tensor((10240,), dtype="float32") = transformed_param_205
            lv369_1 = R.call_tir(cls.fused_matmul25_add25, (lv1276, lv1129, lv1130), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv370 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv369_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1131: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1079
            lv1132: R.Tensor((1280,), dtype="float32") = transformed_param_206
            lv371 = R.call_tir(cls.fused_matmul26_add23_add24, (lv370, lv1131, lv1132, lv368_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1133: R.Tensor((1280,), dtype="float32") = transformed_param_218
            lv1134: R.Tensor((1280,), dtype="float32") = transformed_param_217
            lv1289 = R.call_tir(cls.layer_norm2, (lv371, lv1133, lv1134), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1135_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1080
            lv1291 = R.call_tir(cls.matmul19, (lv1289, lv1135_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1136: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1081
            lv1293 = R.call_tir(cls.matmul19, (lv1289, lv1136), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1137: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1082
            lv1295 = R.call_tir(cls.matmul19, (lv1289, lv1137), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv372 = R.call_tir(cls.fused_reshape30_transpose22, (lv1291,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv373 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1293,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv374 = R.call_tir(cls.fused_reshape30_transpose22, (lv1295,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv375 = R.call_tir(cls.fused_matmul20_multiply8, (lv372, lv373, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1307 = R.call_tir(cls.softmax3, (lv375,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1308 = R.call_tir(cls.matmul21, (lv1307, lv374), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv376 = R.call_tir(cls.fused_transpose24_reshape31, (lv1308,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1138: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1083
            lv1139: R.Tensor((1280,), dtype="float32") = transformed_param_213
            lv377_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv376, lv1138, lv1139, lv371), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1140_1: R.Tensor((1280,), dtype="float32") = transformed_param_220
            lv1141: R.Tensor((1280,), dtype="float32") = transformed_param_219
            lv1316 = R.call_tir(cls.layer_norm2, (lv377_1, lv1140_1, lv1141), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1142: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1084
            lv1318 = R.call_tir(cls.matmul19, (lv1316, lv1142), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1143: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1085
            lv1320 = R.call_tir(cls.matmul22, (inp_2, lv1143), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1144: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1086
            lv1322 = R.call_tir(cls.matmul22, (inp_2, lv1144), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv378 = R.call_tir(cls.fused_reshape30_transpose22, (lv1318,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv379_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1320,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv380 = R.call_tir(cls.fused_reshape32_transpose26, (lv1322,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv381_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv378, lv379_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1334 = R.call_tir(cls.softmax4, (lv381_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1335 = R.call_tir(cls.matmul24, (lv1334, lv380), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv382 = R.call_tir(cls.fused_transpose24_reshape31, (lv1335,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1145: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1087
            lv1146: R.Tensor((1280,), dtype="float32") = transformed_param_214
            lv383_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv382, lv1145, lv1146, lv377_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1147: R.Tensor((1280,), dtype="float32") = transformed_param_222
            lv1148: R.Tensor((1280,), dtype="float32") = transformed_param_221
            lv1343 = R.call_tir(cls.layer_norm2, (lv383_1, lv1147, lv1148), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1149_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1088
            lv1150: R.Tensor((10240,), dtype="float32") = transformed_param_215
            lv384 = R.call_tir(cls.fused_matmul25_add25, (lv1343, lv1149_1, lv1150), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv385 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv384,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1151: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1089
            lv1152: R.Tensor((1280,), dtype="float32") = transformed_param_216
            lv386 = R.call_tir(cls.fused_matmul26_add23_add24, (lv385, lv1151, lv1152, lv383_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1153: R.Tensor((1280,), dtype="float32") = transformed_param_228
            lv1154: R.Tensor((1280,), dtype="float32") = transformed_param_227
            lv1356 = R.call_tir(cls.layer_norm2, (lv386, lv1153, lv1154), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1155_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1090
            lv1358 = R.call_tir(cls.matmul19, (lv1356, lv1155_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1156: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1091
            lv1360 = R.call_tir(cls.matmul19, (lv1356, lv1156), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1157_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1092
            lv1362 = R.call_tir(cls.matmul19, (lv1356, lv1157_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv387 = R.call_tir(cls.fused_reshape30_transpose22, (lv1358,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv388 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1360,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv389 = R.call_tir(cls.fused_reshape30_transpose22, (lv1362,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv390 = R.call_tir(cls.fused_matmul20_multiply8, (lv387, lv388, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1374 = R.call_tir(cls.softmax3, (lv390,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1375 = R.call_tir(cls.matmul21, (lv1374, lv389), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv391 = R.call_tir(cls.fused_transpose24_reshape31, (lv1375,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1158: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1093
            lv1159_1: R.Tensor((1280,), dtype="float32") = transformed_param_223
            lv392 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv391, lv1158, lv1159_1, lv386), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1160: R.Tensor((1280,), dtype="float32") = transformed_param_230
            lv1161_1: R.Tensor((1280,), dtype="float32") = transformed_param_229
            lv1383 = R.call_tir(cls.layer_norm2, (lv392, lv1160, lv1161_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1162: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1094
            lv1385 = R.call_tir(cls.matmul19, (lv1383, lv1162), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1163: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1095
            lv1387 = R.call_tir(cls.matmul22, (inp_2, lv1163), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1164: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1096
            lv1389 = R.call_tir(cls.matmul22, (inp_2, lv1164), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv393 = R.call_tir(cls.fused_reshape30_transpose22, (lv1385,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv394 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1387,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv395_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv1389,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv396_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv393, lv394, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1401 = R.call_tir(cls.softmax4, (lv396_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1402 = R.call_tir(cls.matmul24, (lv1401, lv395_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv397 = R.call_tir(cls.fused_transpose24_reshape31, (lv1402,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1165: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1097
            lv1166: R.Tensor((1280,), dtype="float32") = transformed_param_224
            lv398 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv397, lv1165, lv1166, lv392), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1167: R.Tensor((1280,), dtype="float32") = transformed_param_232
            lv1168: R.Tensor((1280,), dtype="float32") = transformed_param_231
            lv1410 = R.call_tir(cls.layer_norm2, (lv398, lv1167, lv1168), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1169: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1098
            lv1170: R.Tensor((10240,), dtype="float32") = transformed_param_225
            lv399 = R.call_tir(cls.fused_matmul25_add25, (lv1410, lv1169, lv1170), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv400 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv399,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1171: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1099
            lv1172: R.Tensor((1280,), dtype="float32") = transformed_param_226
            lv401 = R.call_tir(cls.fused_matmul26_add23_add24, (lv400, lv1171, lv1172, lv398), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1173_1: R.Tensor((1280,), dtype="float32") = transformed_param_238
            lv1174_1: R.Tensor((1280,), dtype="float32") = transformed_param_237
            lv1423 = R.call_tir(cls.layer_norm2, (lv401, lv1173_1, lv1174_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1175: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1100
            lv1425 = R.call_tir(cls.matmul19, (lv1423, lv1175), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1176: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1101
            lv1427 = R.call_tir(cls.matmul19, (lv1423, lv1176), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1177: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1102
            lv1429 = R.call_tir(cls.matmul19, (lv1423, lv1177), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv402 = R.call_tir(cls.fused_reshape30_transpose22, (lv1425,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv403 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1427,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv404_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1429,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv405 = R.call_tir(cls.fused_matmul20_multiply8, (lv402, lv403, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1441 = R.call_tir(cls.softmax3, (lv405,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1442 = R.call_tir(cls.matmul21, (lv1441, lv404_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv406 = R.call_tir(cls.fused_transpose24_reshape31, (lv1442,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1178: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1103
            lv1179: R.Tensor((1280,), dtype="float32") = transformed_param_233
            lv407 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv406, lv1178, lv1179, lv401), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1180: R.Tensor((1280,), dtype="float32") = transformed_param_240
            lv1181: R.Tensor((1280,), dtype="float32") = transformed_param_239
            lv1450 = R.call_tir(cls.layer_norm2, (lv407, lv1180, lv1181), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1182_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1104
            lv1452 = R.call_tir(cls.matmul19, (lv1450, lv1182_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1183: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1105
            lv1454 = R.call_tir(cls.matmul22, (inp_2, lv1183), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1184_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1106
            lv1456 = R.call_tir(cls.matmul22, (inp_2, lv1184_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv408 = R.call_tir(cls.fused_reshape30_transpose22, (lv1452,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv409 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1454,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv410 = R.call_tir(cls.fused_reshape32_transpose26, (lv1456,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv411 = R.call_tir(cls.fused_matmul23_multiply9, (lv408, lv409, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1468 = R.call_tir(cls.softmax4, (lv411,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1469 = R.call_tir(cls.matmul24, (lv1468, lv410), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv412 = R.call_tir(cls.fused_transpose24_reshape31, (lv1469,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1185: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1107
            lv1186_1: R.Tensor((1280,), dtype="float32") = transformed_param_234
            lv413 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv412, lv1185, lv1186_1, lv407), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1187: R.Tensor((1280,), dtype="float32") = transformed_param_242
            lv1188_1: R.Tensor((1280,), dtype="float32") = transformed_param_241
            lv1477 = R.call_tir(cls.layer_norm2, (lv413, lv1187, lv1188_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1189: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1108
            lv1190: R.Tensor((10240,), dtype="float32") = transformed_param_235
            lv414 = R.call_tir(cls.fused_matmul25_add25, (lv1477, lv1189, lv1190), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv415 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv414,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1191: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1109
            lv1192: R.Tensor((1280,), dtype="float32") = transformed_param_236
            lv416 = R.call_tir(cls.fused_matmul26_add23_add24, (lv415, lv1191, lv1192, lv413), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1193: R.Tensor((1280,), dtype="float32") = transformed_param_248
            lv1194: R.Tensor((1280,), dtype="float32") = transformed_param_247
            lv1490 = R.call_tir(cls.layer_norm2, (lv416, lv1193, lv1194), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1195: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1110
            lv1492 = R.call_tir(cls.matmul19, (lv1490, lv1195), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1196: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1111
            lv1494 = R.call_tir(cls.matmul19, (lv1490, lv1196), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1197: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1112
            lv1496 = R.call_tir(cls.matmul19, (lv1490, lv1197), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv417 = R.call_tir(cls.fused_reshape30_transpose22, (lv1492,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv418 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1494,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv419 = R.call_tir(cls.fused_reshape30_transpose22, (lv1496,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv420 = R.call_tir(cls.fused_matmul20_multiply8, (lv417, lv418, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1508 = R.call_tir(cls.softmax3, (lv420,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1509 = R.call_tir(cls.matmul21, (lv1508, lv419), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv421 = R.call_tir(cls.fused_transpose24_reshape31, (lv1509,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1198: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1113
            lv1199: R.Tensor((1280,), dtype="float32") = transformed_param_243
            lv422 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv421, lv1198, lv1199, lv416), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1200_1: R.Tensor((1280,), dtype="float32") = transformed_param_250
            lv1201_1: R.Tensor((1280,), dtype="float32") = transformed_param_249
            lv1517 = R.call_tir(cls.layer_norm2, (lv422, lv1200_1, lv1201_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1202: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1114
            lv1519 = R.call_tir(cls.matmul19, (lv1517, lv1202), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1203: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1115
            lv1521 = R.call_tir(cls.matmul22, (inp_2, lv1203), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1204: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1116
            lv1523 = R.call_tir(cls.matmul22, (inp_2, lv1204), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv423 = R.call_tir(cls.fused_reshape30_transpose22, (lv1519,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv424 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1521,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv425 = R.call_tir(cls.fused_reshape32_transpose26, (lv1523,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv426 = R.call_tir(cls.fused_matmul23_multiply9, (lv423, lv424, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1535 = R.call_tir(cls.softmax4, (lv426,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1536 = R.call_tir(cls.matmul24, (lv1535, lv425), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv427 = R.call_tir(cls.fused_transpose24_reshape31, (lv1536,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1205: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1117
            lv1206: R.Tensor((1280,), dtype="float32") = transformed_param_244
            lv428 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv427, lv1205, lv1206, lv422), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1207: R.Tensor((1280,), dtype="float32") = transformed_param_252
            lv1208: R.Tensor((1280,), dtype="float32") = transformed_param_251
            lv1544 = R.call_tir(cls.layer_norm2, (lv428, lv1207, lv1208), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1209_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1118
            lv1210: R.Tensor((10240,), dtype="float32") = transformed_param_245
            lv429 = R.call_tir(cls.fused_matmul25_add25, (lv1544, lv1209_1, lv1210), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv430 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv429,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1211: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1119
            lv1212: R.Tensor((1280,), dtype="float32") = transformed_param_246
            lv431_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv430, lv1211, lv1212, lv428), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1213: R.Tensor((1280,), dtype="float32") = transformed_param_258
            lv1214: R.Tensor((1280,), dtype="float32") = transformed_param_257
            lv1557 = R.call_tir(cls.layer_norm2, (lv431_1, lv1213, lv1214), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1215: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1120
            lv1559 = R.call_tir(cls.matmul19, (lv1557, lv1215), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1216: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1121
            lv1561 = R.call_tir(cls.matmul19, (lv1557, lv1216), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1217: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1122
            lv1563 = R.call_tir(cls.matmul19, (lv1557, lv1217), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv432 = R.call_tir(cls.fused_reshape30_transpose22, (lv1559,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv433 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1561,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv434 = R.call_tir(cls.fused_reshape30_transpose22, (lv1563,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv435 = R.call_tir(cls.fused_matmul20_multiply8, (lv432, lv433, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1575 = R.call_tir(cls.softmax3, (lv435,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1576 = R.call_tir(cls.matmul21, (lv1575, lv434), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv436_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1576,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1218: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1123
            lv1219: R.Tensor((1280,), dtype="float32") = transformed_param_253
            lv437 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv436_1, lv1218, lv1219, lv431_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1220: R.Tensor((1280,), dtype="float32") = transformed_param_260
            lv1221: R.Tensor((1280,), dtype="float32") = transformed_param_259
            lv1584 = R.call_tir(cls.layer_norm2, (lv437, lv1220, lv1221), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1222_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1124
            lv1586 = R.call_tir(cls.matmul19, (lv1584, lv1222_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1223: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1125
            lv1588 = R.call_tir(cls.matmul22, (inp_2, lv1223), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1224_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1126
            lv1590 = R.call_tir(cls.matmul22, (inp_2, lv1224_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv438 = R.call_tir(cls.fused_reshape30_transpose22, (lv1586,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv439 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1588,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv440 = R.call_tir(cls.fused_reshape32_transpose26, (lv1590,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv441 = R.call_tir(cls.fused_matmul23_multiply9, (lv438, lv439, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1602 = R.call_tir(cls.softmax4, (lv441,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1603 = R.call_tir(cls.matmul24, (lv1602, lv440), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv442 = R.call_tir(cls.fused_transpose24_reshape31, (lv1603,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1225: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1127
            lv1226_1: R.Tensor((1280,), dtype="float32") = transformed_param_254
            lv443 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv442, lv1225, lv1226_1, lv437), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1227: R.Tensor((1280,), dtype="float32") = transformed_param_262
            lv1228_1: R.Tensor((1280,), dtype="float32") = transformed_param_261
            lv1611 = R.call_tir(cls.layer_norm2, (lv443, lv1227, lv1228_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1229: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1128
            lv1230: R.Tensor((10240,), dtype="float32") = transformed_param_255
            lv444 = R.call_tir(cls.fused_matmul25_add25, (lv1611, lv1229, lv1230), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv445 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv444,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1231: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1129
            lv1232: R.Tensor((1280,), dtype="float32") = transformed_param_256
            lv446 = R.call_tir(cls.fused_matmul26_add23_add24, (lv445, lv1231, lv1232, lv443), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1233: R.Tensor((1280,), dtype="float32") = transformed_param_268
            lv1234: R.Tensor((1280,), dtype="float32") = transformed_param_267
            lv1624 = R.call_tir(cls.layer_norm2, (lv446, lv1233, lv1234), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1235: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1130
            lv1626 = R.call_tir(cls.matmul19, (lv1624, lv1235), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1236: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1131
            lv1628 = R.call_tir(cls.matmul19, (lv1624, lv1236), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1237: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1132
            lv1630 = R.call_tir(cls.matmul19, (lv1624, lv1237), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv447 = R.call_tir(cls.fused_reshape30_transpose22, (lv1626,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv448_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1628,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv449 = R.call_tir(cls.fused_reshape30_transpose22, (lv1630,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv450 = R.call_tir(cls.fused_matmul20_multiply8, (lv447, lv448_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1642 = R.call_tir(cls.softmax3, (lv450,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1643 = R.call_tir(cls.matmul21, (lv1642, lv449), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv451 = R.call_tir(cls.fused_transpose24_reshape31, (lv1643,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1238: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1133
            lv1239: R.Tensor((1280,), dtype="float32") = transformed_param_263
            lv452 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv451, lv1238, lv1239, lv446), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1240_1: R.Tensor((1280,), dtype="float32") = transformed_param_270
            lv1241_1: R.Tensor((1280,), dtype="float32") = transformed_param_269
            lv1651 = R.call_tir(cls.layer_norm2, (lv452, lv1240_1, lv1241_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1242: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1134
            lv1653 = R.call_tir(cls.matmul19, (lv1651, lv1242), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1243: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1135
            lv1655 = R.call_tir(cls.matmul22, (inp_2, lv1243), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1244: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1136
            lv1657 = R.call_tir(cls.matmul22, (inp_2, lv1244), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv453 = R.call_tir(cls.fused_reshape30_transpose22, (lv1653,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv454_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1655,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv455 = R.call_tir(cls.fused_reshape32_transpose26, (lv1657,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv456_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv453, lv454_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1669 = R.call_tir(cls.softmax4, (lv456_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1670 = R.call_tir(cls.matmul24, (lv1669, lv455), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv457 = R.call_tir(cls.fused_transpose24_reshape31, (lv1670,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1245: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1137
            lv1246: R.Tensor((1280,), dtype="float32") = transformed_param_264
            lv458_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv457, lv1245, lv1246, lv452), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1247: R.Tensor((1280,), dtype="float32") = transformed_param_272
            lv1248: R.Tensor((1280,), dtype="float32") = transformed_param_271
            lv1678 = R.call_tir(cls.layer_norm2, (lv458_1, lv1247, lv1248), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1249_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1138
            lv1250: R.Tensor((10240,), dtype="float32") = transformed_param_265
            lv459 = R.call_tir(cls.fused_matmul25_add25, (lv1678, lv1249_1, lv1250), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv460_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv459,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1251_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1139
            lv1252: R.Tensor((1280,), dtype="float32") = transformed_param_266
            lv461 = R.call_tir(cls.fused_matmul26_add23_add24, (lv460_1, lv1251_1, lv1252, lv458_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1253_1: R.Tensor((1280,), dtype="float32") = transformed_param_278
            lv1254: R.Tensor((1280,), dtype="float32") = transformed_param_277
            lv1691 = R.call_tir(cls.layer_norm2, (lv461, lv1253_1, lv1254), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1255_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1140
            lv1693 = R.call_tir(cls.matmul19, (lv1691, lv1255_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1256: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1141
            lv1695 = R.call_tir(cls.matmul19, (lv1691, lv1256), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1257: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1142
            lv1697 = R.call_tir(cls.matmul19, (lv1691, lv1257), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv462 = R.call_tir(cls.fused_reshape30_transpose22, (lv1693,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv463 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1695,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv464 = R.call_tir(cls.fused_reshape30_transpose22, (lv1697,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv465 = R.call_tir(cls.fused_matmul20_multiply8, (lv462, lv463, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1709 = R.call_tir(cls.softmax3, (lv465,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1710 = R.call_tir(cls.matmul21, (lv1709, lv464), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv466 = R.call_tir(cls.fused_transpose24_reshape31, (lv1710,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1258: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1143
            lv1259: R.Tensor((1280,), dtype="float32") = transformed_param_273
            lv467 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv466, lv1258, lv1259, lv461), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1260: R.Tensor((1280,), dtype="float32") = transformed_param_280
            lv1261: R.Tensor((1280,), dtype="float32") = transformed_param_279
            lv1718 = R.call_tir(cls.layer_norm2, (lv467, lv1260, lv1261), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1262: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1144
            lv1720 = R.call_tir(cls.matmul19, (lv1718, lv1262), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1263: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1145
            lv1722 = R.call_tir(cls.matmul22, (inp_2, lv1263), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1264: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1146
            lv1724 = R.call_tir(cls.matmul22, (inp_2, lv1264), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv468 = R.call_tir(cls.fused_reshape30_transpose22, (lv1720,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv469 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1722,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv470 = R.call_tir(cls.fused_reshape32_transpose26, (lv1724,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv471 = R.call_tir(cls.fused_matmul23_multiply9, (lv468, lv469, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1736 = R.call_tir(cls.softmax4, (lv471,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1737 = R.call_tir(cls.matmul24, (lv1736, lv470), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv472_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1737,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1265: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1147
            lv1266: R.Tensor((1280,), dtype="float32") = transformed_param_274
            lv473_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv472_1, lv1265, lv1266, lv467), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1267_1: R.Tensor((1280,), dtype="float32") = transformed_param_282
            lv1268_1: R.Tensor((1280,), dtype="float32") = transformed_param_281
            lv1745 = R.call_tir(cls.layer_norm2, (lv473_1, lv1267_1, lv1268_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1269: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1148
            lv1270: R.Tensor((10240,), dtype="float32") = transformed_param_275
            lv474 = R.call_tir(cls.fused_matmul25_add25, (lv1745, lv1269, lv1270), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv475 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv474,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1271: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1149
            lv1272: R.Tensor((1280,), dtype="float32") = transformed_param_276
            lv476 = R.call_tir(cls.fused_matmul26_add23_add24, (lv475, lv1271, lv1272, lv473_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1273: R.Tensor((1280,), dtype="float32") = transformed_param_288
            lv1274: R.Tensor((1280,), dtype="float32") = transformed_param_287
            lv1758 = R.call_tir(cls.layer_norm2, (lv476, lv1273, lv1274), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1275: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1150
            lv1760 = R.call_tir(cls.matmul19, (lv1758, lv1275), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1276_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1151
            lv1762 = R.call_tir(cls.matmul19, (lv1758, lv1276_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1277: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1152
            lv1764 = R.call_tir(cls.matmul19, (lv1758, lv1277), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv477 = R.call_tir(cls.fused_reshape30_transpose22, (lv1760,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv478 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1762,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv479 = R.call_tir(cls.fused_reshape30_transpose22, (lv1764,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv480 = R.call_tir(cls.fused_matmul20_multiply8, (lv477, lv478, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1776 = R.call_tir(cls.softmax3, (lv480,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1777 = R.call_tir(cls.matmul21, (lv1776, lv479), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv481_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1777,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1278: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1153
            lv1279: R.Tensor((1280,), dtype="float32") = transformed_param_283
            lv482 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv481_1, lv1278, lv1279, lv476), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1280: R.Tensor((1280,), dtype="float32") = transformed_param_290
            lv1281: R.Tensor((1280,), dtype="float32") = transformed_param_289
            lv1785 = R.call_tir(cls.layer_norm2, (lv482, lv1280, lv1281), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1282: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1154
            lv1787 = R.call_tir(cls.matmul19, (lv1785, lv1282), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1283: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1155
            lv1789 = R.call_tir(cls.matmul22, (inp_2, lv1283), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1284: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1156
            lv1791 = R.call_tir(cls.matmul22, (inp_2, lv1284), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv483_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv1787,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv484 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1789,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv485_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv1791,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv486 = R.call_tir(cls.fused_matmul23_multiply9, (lv483_1, lv484, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1803 = R.call_tir(cls.softmax4, (lv486,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1804 = R.call_tir(cls.matmul24, (lv1803, lv485_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv487_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv1804,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1285: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1157
            lv1286: R.Tensor((1280,), dtype="float32") = transformed_param_284
            lv488 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv487_1, lv1285, lv1286, lv482), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1287: R.Tensor((1280,), dtype="float32") = transformed_param_292
            lv1288: R.Tensor((1280,), dtype="float32") = transformed_param_291
            lv1812 = R.call_tir(cls.layer_norm2, (lv488, lv1287, lv1288), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1289_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1158
            lv1290: R.Tensor((10240,), dtype="float32") = transformed_param_285
            lv489 = R.call_tir(cls.fused_matmul25_add25, (lv1812, lv1289_1, lv1290), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv490 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv489,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1291_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1159
            lv1292: R.Tensor((1280,), dtype="float32") = transformed_param_286
            lv491 = R.call_tir(cls.fused_matmul26_add23_add24, (lv490, lv1291_1, lv1292, lv488), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1293_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1160
            lv1294: R.Tensor((1280,), dtype="float32") = transformed_param_192
            lv492 = R.call_tir(cls.fused_matmul19_add23, (lv491, lv1293_1, lv1294), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv493 = R.call_tir(cls.fused_reshape33_transpose29_add22, (lv492, lv339), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1295_1: R.Tensor((1280,), dtype="float32") = transformed_param_415
            lv1296: R.Tensor((1280,), dtype="float32") = transformed_param_414
            lv494 = R.call_tir(cls.fused_group_norm5_silu5, (lv493, lv1295_1, lv1296), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1836 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1297: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1162
            lv1298: R.Tensor((1280,), dtype="float32") = transformed_param_418
            lv495 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv1836, lv1297, lv1298), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1841 = R.call_tir(cls.reshape28, (lv495,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1299: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_412
            lv1300: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1161
            lv496 = R.call_tir(cls.fused_conv2d8_add20_add21, (lv494, lv1299, lv1300, lv1841), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1301: R.Tensor((1280,), dtype="float32") = transformed_param_417
            lv1302: R.Tensor((1280,), dtype="float32") = transformed_param_416
            lv497 = R.call_tir(cls.fused_group_norm5_silu5, (lv496, lv1301, lv1302), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1303: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_413
            lv1304: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1163
            lv498 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv497, lv1303, lv1304, lv493), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1305: R.Tensor((1280,), dtype="float32") = transformed_param_309
            lv1306: R.Tensor((1280,), dtype="float32") = transformed_param_308
            lv1850 = R.call_tir(cls.group_norm6, (lv498, lv1305, lv1306), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv499_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv1850,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1307_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1164
            lv1308_1: R.Tensor((1280,), dtype="float32") = transformed_param_310
            lv500_1 = R.call_tir(cls.fused_matmul19_add23, (lv499_1, lv1307_1, lv1308_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1309: R.Tensor((1280,), dtype="float32") = transformed_param_317
            lv1310: R.Tensor((1280,), dtype="float32") = transformed_param_316
            lv1856 = R.call_tir(cls.layer_norm2, (lv500_1, lv1309, lv1310), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1311: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1165
            lv1858 = R.call_tir(cls.matmul19, (lv1856, lv1311), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1312: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1166
            lv1860 = R.call_tir(cls.matmul19, (lv1856, lv1312), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1313: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1167
            lv1862 = R.call_tir(cls.matmul19, (lv1856, lv1313), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv501 = R.call_tir(cls.fused_reshape30_transpose22, (lv1858,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv502 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1860,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv503 = R.call_tir(cls.fused_reshape30_transpose22, (lv1862,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv504 = R.call_tir(cls.fused_matmul20_multiply8, (lv501, lv502, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1874 = R.call_tir(cls.softmax3, (lv504,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1875 = R.call_tir(cls.matmul21, (lv1874, lv503), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv505 = R.call_tir(cls.fused_transpose24_reshape31, (lv1875,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1314: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1168
            lv1315: R.Tensor((1280,), dtype="float32") = transformed_param_312
            lv506 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv505, lv1314, lv1315, lv500_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1316_1: R.Tensor((1280,), dtype="float32") = transformed_param_319
            lv1317: R.Tensor((1280,), dtype="float32") = transformed_param_318
            lv1883 = R.call_tir(cls.layer_norm2, (lv506, lv1316_1, lv1317), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1318_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1169
            lv1885 = R.call_tir(cls.matmul19, (lv1883, lv1318_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1319: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1170
            lv1887 = R.call_tir(cls.matmul22, (inp_2, lv1319), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1320_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1171
            lv1889 = R.call_tir(cls.matmul22, (inp_2, lv1320_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv507 = R.call_tir(cls.fused_reshape30_transpose22, (lv1885,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv508_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1887,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv509 = R.call_tir(cls.fused_reshape32_transpose26, (lv1889,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv510 = R.call_tir(cls.fused_matmul23_multiply9, (lv507, lv508_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1901 = R.call_tir(cls.softmax4, (lv510,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1902 = R.call_tir(cls.matmul24, (lv1901, lv509), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv511 = R.call_tir(cls.fused_transpose24_reshape31, (lv1902,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1321: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1172
            lv1322_1: R.Tensor((1280,), dtype="float32") = transformed_param_313
            lv512 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv511, lv1321, lv1322_1, lv506), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1323: R.Tensor((1280,), dtype="float32") = transformed_param_321
            lv1324: R.Tensor((1280,), dtype="float32") = transformed_param_320
            lv1910 = R.call_tir(cls.layer_norm2, (lv512, lv1323, lv1324), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1325: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1173
            lv1326: R.Tensor((10240,), dtype="float32") = transformed_param_314
            lv513 = R.call_tir(cls.fused_matmul25_add25, (lv1910, lv1325, lv1326), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv514 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv513,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1327: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1174
            lv1328: R.Tensor((1280,), dtype="float32") = transformed_param_315
            lv515 = R.call_tir(cls.fused_matmul26_add23_add24, (lv514, lv1327, lv1328, lv512), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1329: R.Tensor((1280,), dtype="float32") = transformed_param_327
            lv1330: R.Tensor((1280,), dtype="float32") = transformed_param_326
            lv1923 = R.call_tir(cls.layer_norm2, (lv515, lv1329, lv1330), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1331: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1175
            lv1925 = R.call_tir(cls.matmul19, (lv1923, lv1331), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1332: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1176
            lv1927 = R.call_tir(cls.matmul19, (lv1923, lv1332), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1333: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1177
            lv1929 = R.call_tir(cls.matmul19, (lv1923, lv1333), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv516 = R.call_tir(cls.fused_reshape30_transpose22, (lv1925,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv517 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1927,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv518 = R.call_tir(cls.fused_reshape30_transpose22, (lv1929,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv519 = R.call_tir(cls.fused_matmul20_multiply8, (lv516, lv517, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1941 = R.call_tir(cls.softmax3, (lv519,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1942 = R.call_tir(cls.matmul21, (lv1941, lv518), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv520 = R.call_tir(cls.fused_transpose24_reshape31, (lv1942,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1334_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1178
            lv1335_1: R.Tensor((1280,), dtype="float32") = transformed_param_322
            lv521_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv520, lv1334_1, lv1335_1, lv515), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1336: R.Tensor((1280,), dtype="float32") = transformed_param_329
            lv1337: R.Tensor((1280,), dtype="float32") = transformed_param_328
            lv1950 = R.call_tir(cls.layer_norm2, (lv521_1, lv1336, lv1337), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1338: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1179
            lv1952 = R.call_tir(cls.matmul19, (lv1950, lv1338), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1339: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1180
            lv1954 = R.call_tir(cls.matmul22, (inp_2, lv1339), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1340: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1181
            lv1956 = R.call_tir(cls.matmul22, (inp_2, lv1340), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv522 = R.call_tir(cls.fused_reshape30_transpose22, (lv1952,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv523_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv1954,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv524 = R.call_tir(cls.fused_reshape32_transpose26, (lv1956,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv525_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv522, lv523_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1968 = R.call_tir(cls.softmax4, (lv525_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1969 = R.call_tir(cls.matmul24, (lv1968, lv524), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv526 = R.call_tir(cls.fused_transpose24_reshape31, (lv1969,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1341: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1182
            lv1342: R.Tensor((1280,), dtype="float32") = transformed_param_323
            lv527_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv526, lv1341, lv1342, lv521_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1343_1: R.Tensor((1280,), dtype="float32") = transformed_param_331
            lv1344: R.Tensor((1280,), dtype="float32") = transformed_param_330
            lv1977 = R.call_tir(cls.layer_norm2, (lv527_1, lv1343_1, lv1344), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1345: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1183
            lv1346: R.Tensor((10240,), dtype="float32") = transformed_param_324
            lv528 = R.call_tir(cls.fused_matmul25_add25, (lv1977, lv1345, lv1346), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv529 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv528,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1347: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1184
            lv1348: R.Tensor((1280,), dtype="float32") = transformed_param_325
            lv530 = R.call_tir(cls.fused_matmul26_add23_add24, (lv529, lv1347, lv1348, lv527_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1349: R.Tensor((1280,), dtype="float32") = transformed_param_337
            lv1350: R.Tensor((1280,), dtype="float32") = transformed_param_336
            lv1990 = R.call_tir(cls.layer_norm2, (lv530, lv1349, lv1350), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1351: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1185
            lv1992 = R.call_tir(cls.matmul19, (lv1990, lv1351), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1352: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1186
            lv1994 = R.call_tir(cls.matmul19, (lv1990, lv1352), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1353: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1187
            lv1996 = R.call_tir(cls.matmul19, (lv1990, lv1353), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv531 = R.call_tir(cls.fused_reshape30_transpose22, (lv1992,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv532 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv1994,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv533 = R.call_tir(cls.fused_reshape30_transpose22, (lv1996,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv534 = R.call_tir(cls.fused_matmul20_multiply8, (lv531, lv532, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2008 = R.call_tir(cls.softmax3, (lv534,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2009 = R.call_tir(cls.matmul21, (lv2008, lv533), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv535 = R.call_tir(cls.fused_transpose24_reshape31, (lv2009,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1354: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1188
            lv1355: R.Tensor((1280,), dtype="float32") = transformed_param_332
            lv536 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv535, lv1354, lv1355, lv530), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1356_1: R.Tensor((1280,), dtype="float32") = transformed_param_339
            lv1357: R.Tensor((1280,), dtype="float32") = transformed_param_338
            lv2017 = R.call_tir(cls.layer_norm2, (lv536, lv1356_1, lv1357), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1358_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1189
            lv2019 = R.call_tir(cls.matmul19, (lv2017, lv1358_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1359: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1190
            lv2021 = R.call_tir(cls.matmul22, (inp_2, lv1359), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1360_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1191
            lv2023 = R.call_tir(cls.matmul22, (inp_2, lv1360_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv537 = R.call_tir(cls.fused_reshape30_transpose22, (lv2019,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv538 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2021,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv539_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv2023,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv540_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv537, lv538, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2035 = R.call_tir(cls.softmax4, (lv540_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2036 = R.call_tir(cls.matmul24, (lv2035, lv539_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv541 = R.call_tir(cls.fused_transpose24_reshape31, (lv2036,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1361: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1192
            lv1362_1: R.Tensor((1280,), dtype="float32") = transformed_param_333
            lv542 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv541, lv1361, lv1362_1, lv536), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1363: R.Tensor((1280,), dtype="float32") = transformed_param_341
            lv1364: R.Tensor((1280,), dtype="float32") = transformed_param_340
            lv2044 = R.call_tir(cls.layer_norm2, (lv542, lv1363, lv1364), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1365: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1193
            lv1366: R.Tensor((10240,), dtype="float32") = transformed_param_334
            lv543 = R.call_tir(cls.fused_matmul25_add25, (lv2044, lv1365, lv1366), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv544 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv543,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1367: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1194
            lv1368: R.Tensor((1280,), dtype="float32") = transformed_param_335
            lv545 = R.call_tir(cls.fused_matmul26_add23_add24, (lv544, lv1367, lv1368, lv542), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1369: R.Tensor((1280,), dtype="float32") = transformed_param_347
            lv1370: R.Tensor((1280,), dtype="float32") = transformed_param_346
            lv2057 = R.call_tir(cls.layer_norm2, (lv545, lv1369, lv1370), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1371: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1195
            lv2059 = R.call_tir(cls.matmul19, (lv2057, lv1371), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1372: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1196
            lv2061 = R.call_tir(cls.matmul19, (lv2057, lv1372), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1373: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1197
            lv2063 = R.call_tir(cls.matmul19, (lv2057, lv1373), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv546 = R.call_tir(cls.fused_reshape30_transpose22, (lv2059,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv547 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv548_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv549 = R.call_tir(cls.fused_matmul20_multiply8, (lv546, lv547, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2075 = R.call_tir(cls.softmax3, (lv549,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2076 = R.call_tir(cls.matmul21, (lv2075, lv548_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv550_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1374_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1198
            lv1375_1: R.Tensor((1280,), dtype="float32") = transformed_param_342
            lv551 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv550_1, lv1374_1, lv1375_1, lv545), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1376: R.Tensor((1280,), dtype="float32") = transformed_param_349
            lv1377: R.Tensor((1280,), dtype="float32") = transformed_param_348
            lv2084 = R.call_tir(cls.layer_norm2, (lv551, lv1376, lv1377), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1378: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1199
            lv2086 = R.call_tir(cls.matmul19, (lv2084, lv1378), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1379: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1200
            lv2088 = R.call_tir(cls.matmul22, (inp_2, lv1379), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1380: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1201
            lv2090 = R.call_tir(cls.matmul22, (inp_2, lv1380), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv552_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv553 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv554_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv2090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv555 = R.call_tir(cls.fused_matmul23_multiply9, (lv552_1, lv553, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2102 = R.call_tir(cls.softmax4, (lv555,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2103 = R.call_tir(cls.matmul24, (lv2102, lv554_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv556 = R.call_tir(cls.fused_transpose24_reshape31, (lv2103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1381: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1202
            lv1382: R.Tensor((1280,), dtype="float32") = transformed_param_343
            lv557 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv556, lv1381, lv1382, lv551), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1383_1: R.Tensor((1280,), dtype="float32") = transformed_param_351
            lv1384: R.Tensor((1280,), dtype="float32") = transformed_param_350
            lv2111 = R.call_tir(cls.layer_norm2, (lv557, lv1383_1, lv1384), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1385_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1203
            lv1386: R.Tensor((10240,), dtype="float32") = transformed_param_344
            lv558 = R.call_tir(cls.fused_matmul25_add25, (lv2111, lv1385_1, lv1386), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv559 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv558,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1387_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1204
            lv1388: R.Tensor((1280,), dtype="float32") = transformed_param_345
            lv560 = R.call_tir(cls.fused_matmul26_add23_add24, (lv559, lv1387_1, lv1388, lv557), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1389_1: R.Tensor((1280,), dtype="float32") = transformed_param_357
            lv1390: R.Tensor((1280,), dtype="float32") = transformed_param_356
            lv2124 = R.call_tir(cls.layer_norm2, (lv560, lv1389_1, lv1390), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1391: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1205
            lv2126 = R.call_tir(cls.matmul19, (lv2124, lv1391), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1392: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1206
            lv2128 = R.call_tir(cls.matmul19, (lv2124, lv1392), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1393: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1207
            lv2130 = R.call_tir(cls.matmul19, (lv2124, lv1393), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv561 = R.call_tir(cls.fused_reshape30_transpose22, (lv2126,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv562 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2128,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv563 = R.call_tir(cls.fused_reshape30_transpose22, (lv2130,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv564 = R.call_tir(cls.fused_matmul20_multiply8, (lv561, lv562, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2142 = R.call_tir(cls.softmax3, (lv564,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2143 = R.call_tir(cls.matmul21, (lv2142, lv563), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv565 = R.call_tir(cls.fused_transpose24_reshape31, (lv2143,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1394: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1208
            lv1395: R.Tensor((1280,), dtype="float32") = transformed_param_352
            lv566_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv565, lv1394, lv1395, lv560), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1396: R.Tensor((1280,), dtype="float32") = transformed_param_359
            lv1397: R.Tensor((1280,), dtype="float32") = transformed_param_358
            lv2151 = R.call_tir(cls.layer_norm2, (lv566_1, lv1396, lv1397), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1398: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1209
            lv2153 = R.call_tir(cls.matmul19, (lv2151, lv1398), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1399: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1210
            lv2155 = R.call_tir(cls.matmul22, (inp_2, lv1399), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1400: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1211
            lv2157 = R.call_tir(cls.matmul22, (inp_2, lv1400), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv567_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2153,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv568 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2155,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv569 = R.call_tir(cls.fused_reshape32_transpose26, (lv2157,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv570 = R.call_tir(cls.fused_matmul23_multiply9, (lv567_1, lv568, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2169 = R.call_tir(cls.softmax4, (lv570,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2170 = R.call_tir(cls.matmul24, (lv2169, lv569), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv571 = R.call_tir(cls.fused_transpose24_reshape31, (lv2170,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1401_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1212
            lv1402_1: R.Tensor((1280,), dtype="float32") = transformed_param_353
            lv572 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv571, lv1401_1, lv1402_1, lv566_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1403: R.Tensor((1280,), dtype="float32") = transformed_param_361
            lv1404: R.Tensor((1280,), dtype="float32") = transformed_param_360
            lv2178 = R.call_tir(cls.layer_norm2, (lv572, lv1403, lv1404), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1405: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1213
            lv1406: R.Tensor((10240,), dtype="float32") = transformed_param_354
            lv573 = R.call_tir(cls.fused_matmul25_add25, (lv2178, lv1405, lv1406), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv574 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv573,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1407: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1214
            lv1408: R.Tensor((1280,), dtype="float32") = transformed_param_355
            lv575_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv574, lv1407, lv1408, lv572), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1409: R.Tensor((1280,), dtype="float32") = transformed_param_367
            lv1410_1: R.Tensor((1280,), dtype="float32") = transformed_param_366
            lv2191 = R.call_tir(cls.layer_norm2, (lv575_1, lv1409, lv1410_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1411: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1215
            lv2193 = R.call_tir(cls.matmul19, (lv2191, lv1411), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1412: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1216
            lv2195 = R.call_tir(cls.matmul19, (lv2191, lv1412), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1413: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1217
            lv2197 = R.call_tir(cls.matmul19, (lv2191, lv1413), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv576 = R.call_tir(cls.fused_reshape30_transpose22, (lv2193,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv577 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2195,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv578 = R.call_tir(cls.fused_reshape30_transpose22, (lv2197,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv579 = R.call_tir(cls.fused_matmul20_multiply8, (lv576, lv577, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2209 = R.call_tir(cls.softmax3, (lv579,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2210 = R.call_tir(cls.matmul21, (lv2209, lv578), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv580 = R.call_tir(cls.fused_transpose24_reshape31, (lv2210,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1414: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1218
            lv1415: R.Tensor((1280,), dtype="float32") = transformed_param_362
            lv581 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv580, lv1414, lv1415, lv575_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1416: R.Tensor((1280,), dtype="float32") = transformed_param_369
            lv1417: R.Tensor((1280,), dtype="float32") = transformed_param_368
            lv2218 = R.call_tir(cls.layer_norm2, (lv581, lv1416, lv1417), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1418: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1219
            lv2220 = R.call_tir(cls.matmul19, (lv2218, lv1418), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1419: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1220
            lv2222 = R.call_tir(cls.matmul22, (inp_2, lv1419), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1420: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1221
            lv2224 = R.call_tir(cls.matmul22, (inp_2, lv1420), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv582 = R.call_tir(cls.fused_reshape30_transpose22, (lv2220,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv583 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2222,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv584 = R.call_tir(cls.fused_reshape32_transpose26, (lv2224,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv585 = R.call_tir(cls.fused_matmul23_multiply9, (lv582, lv583, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2236 = R.call_tir(cls.softmax4, (lv585,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2237 = R.call_tir(cls.matmul24, (lv2236, lv584), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv586 = R.call_tir(cls.fused_transpose24_reshape31, (lv2237,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1421: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1222
            lv1422: R.Tensor((1280,), dtype="float32") = transformed_param_363
            lv587 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv586, lv1421, lv1422, lv581), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1423_1: R.Tensor((1280,), dtype="float32") = transformed_param_371
            lv1424: R.Tensor((1280,), dtype="float32") = transformed_param_370
            lv2245 = R.call_tir(cls.layer_norm2, (lv587, lv1423_1, lv1424), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1425_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1223
            lv1426: R.Tensor((10240,), dtype="float32") = transformed_param_364
            lv588_1 = R.call_tir(cls.fused_matmul25_add25, (lv2245, lv1425_1, lv1426), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv589 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv588_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1427_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1224
            lv1428: R.Tensor((1280,), dtype="float32") = transformed_param_365
            lv590_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv589, lv1427_1, lv1428, lv587), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1429_1: R.Tensor((1280,), dtype="float32") = transformed_param_377
            lv1430: R.Tensor((1280,), dtype="float32") = transformed_param_376
            lv2258 = R.call_tir(cls.layer_norm2, (lv590_1, lv1429_1, lv1430), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1431: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1225
            lv2260 = R.call_tir(cls.matmul19, (lv2258, lv1431), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1432: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1226
            lv2262 = R.call_tir(cls.matmul19, (lv2258, lv1432), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1433: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1227
            lv2264 = R.call_tir(cls.matmul19, (lv2258, lv1433), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv591 = R.call_tir(cls.fused_reshape30_transpose22, (lv2260,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv592_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2262,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv593 = R.call_tir(cls.fused_reshape30_transpose22, (lv2264,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv594_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv591, lv592_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2276 = R.call_tir(cls.softmax3, (lv594_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2277 = R.call_tir(cls.matmul21, (lv2276, lv593), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv595 = R.call_tir(cls.fused_transpose24_reshape31, (lv2277,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1434: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1228
            lv1435: R.Tensor((1280,), dtype="float32") = transformed_param_372
            lv596 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv595, lv1434, lv1435, lv590_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1436: R.Tensor((1280,), dtype="float32") = transformed_param_379
            lv1437: R.Tensor((1280,), dtype="float32") = transformed_param_378
            lv2285 = R.call_tir(cls.layer_norm2, (lv596, lv1436, lv1437), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1438: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1229
            lv2287 = R.call_tir(cls.matmul19, (lv2285, lv1438), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1439: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1230
            lv2289 = R.call_tir(cls.matmul22, (inp_2, lv1439), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1440: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1231
            lv2291 = R.call_tir(cls.matmul22, (inp_2, lv1440), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv597 = R.call_tir(cls.fused_reshape30_transpose22, (lv2287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv598 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2289,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv599 = R.call_tir(cls.fused_reshape32_transpose26, (lv2291,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv600 = R.call_tir(cls.fused_matmul23_multiply9, (lv597, lv598, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2303 = R.call_tir(cls.softmax4, (lv600,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2304 = R.call_tir(cls.matmul24, (lv2303, lv599), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv601 = R.call_tir(cls.fused_transpose24_reshape31, (lv2304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1441_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1232
            lv1442_1: R.Tensor((1280,), dtype="float32") = transformed_param_373
            lv602 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv601, lv1441_1, lv1442_1, lv596), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1443: R.Tensor((1280,), dtype="float32") = transformed_param_381
            lv1444: R.Tensor((1280,), dtype="float32") = transformed_param_380
            lv2312 = R.call_tir(cls.layer_norm2, (lv602, lv1443, lv1444), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1445: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1233
            lv1446: R.Tensor((10240,), dtype="float32") = transformed_param_374
            lv603 = R.call_tir(cls.fused_matmul25_add25, (lv2312, lv1445, lv1446), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv604 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv603,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1447: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1234
            lv1448: R.Tensor((1280,), dtype="float32") = transformed_param_375
            lv605 = R.call_tir(cls.fused_matmul26_add23_add24, (lv604, lv1447, lv1448, lv602), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1449: R.Tensor((1280,), dtype="float32") = transformed_param_387
            lv1450_1: R.Tensor((1280,), dtype="float32") = transformed_param_386
            lv2325 = R.call_tir(cls.layer_norm2, (lv605, lv1449, lv1450_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1451: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1235
            lv2327 = R.call_tir(cls.matmul19, (lv2325, lv1451), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1452_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1236
            lv2329 = R.call_tir(cls.matmul19, (lv2325, lv1452_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1453: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1237
            lv2331 = R.call_tir(cls.matmul19, (lv2325, lv1453), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv606_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2327,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv607_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2329,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv608 = R.call_tir(cls.fused_reshape30_transpose22, (lv2331,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv609 = R.call_tir(cls.fused_matmul20_multiply8, (lv606_1, lv607_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2343 = R.call_tir(cls.softmax3, (lv609,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2344 = R.call_tir(cls.matmul21, (lv2343, lv608), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv610 = R.call_tir(cls.fused_transpose24_reshape31, (lv2344,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1454_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1238
            lv1455: R.Tensor((1280,), dtype="float32") = transformed_param_382
            lv611 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv610, lv1454_1, lv1455, lv605), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1456_1: R.Tensor((1280,), dtype="float32") = transformed_param_389
            lv1457: R.Tensor((1280,), dtype="float32") = transformed_param_388
            lv2352 = R.call_tir(cls.layer_norm2, (lv611, lv1456_1, lv1457), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1458: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1239
            lv2354 = R.call_tir(cls.matmul19, (lv2352, lv1458), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1459: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1240
            lv2356 = R.call_tir(cls.matmul22, (inp_2, lv1459), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1460: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1241
            lv2358 = R.call_tir(cls.matmul22, (inp_2, lv1460), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv612 = R.call_tir(cls.fused_reshape30_transpose22, (lv2354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv613 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2356,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv614 = R.call_tir(cls.fused_reshape32_transpose26, (lv2358,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv615_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv612, lv613, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2370 = R.call_tir(cls.softmax4, (lv615_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2371 = R.call_tir(cls.matmul24, (lv2370, lv614), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv616 = R.call_tir(cls.fused_transpose24_reshape31, (lv2371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1461: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1242
            lv1462: R.Tensor((1280,), dtype="float32") = transformed_param_383
            lv617_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv616, lv1461, lv1462, lv611), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1463: R.Tensor((1280,), dtype="float32") = transformed_param_391
            lv1464: R.Tensor((1280,), dtype="float32") = transformed_param_390
            lv2379 = R.call_tir(cls.layer_norm2, (lv617_1, lv1463, lv1464), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1465: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1243
            lv1466: R.Tensor((10240,), dtype="float32") = transformed_param_384
            lv618 = R.call_tir(cls.fused_matmul25_add25, (lv2379, lv1465, lv1466), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv619_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv618,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1467: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1244
            lv1468_1: R.Tensor((1280,), dtype="float32") = transformed_param_385
            lv620 = R.call_tir(cls.fused_matmul26_add23_add24, (lv619_1, lv1467, lv1468_1, lv617_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1469_1: R.Tensor((1280,), dtype="float32") = transformed_param_397
            lv1470: R.Tensor((1280,), dtype="float32") = transformed_param_396
            lv2392 = R.call_tir(cls.layer_norm2, (lv620, lv1469_1, lv1470), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1471: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1245
            lv2394 = R.call_tir(cls.matmul19, (lv2392, lv1471), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1472: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1246
            lv2396 = R.call_tir(cls.matmul19, (lv2392, lv1472), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1473: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1247
            lv2398 = R.call_tir(cls.matmul19, (lv2392, lv1473), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv621_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2394,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv622 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2396,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv623 = R.call_tir(cls.fused_reshape30_transpose22, (lv2398,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv624 = R.call_tir(cls.fused_matmul20_multiply8, (lv621_1, lv622, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2410 = R.call_tir(cls.softmax3, (lv624,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2411 = R.call_tir(cls.matmul21, (lv2410, lv623), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv625 = R.call_tir(cls.fused_transpose24_reshape31, (lv2411,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1474: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1248
            lv1475: R.Tensor((1280,), dtype="float32") = transformed_param_392
            lv626 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv625, lv1474, lv1475, lv620), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1476: R.Tensor((1280,), dtype="float32") = transformed_param_399
            lv1477_1: R.Tensor((1280,), dtype="float32") = transformed_param_398
            lv2419 = R.call_tir(cls.layer_norm2, (lv626, lv1476, lv1477_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1478: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1249
            lv2421 = R.call_tir(cls.matmul19, (lv2419, lv1478), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1479: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1250
            lv2423 = R.call_tir(cls.matmul22, (inp_2, lv1479), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1480: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1251
            lv2425 = R.call_tir(cls.matmul22, (inp_2, lv1480), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv627 = R.call_tir(cls.fused_reshape30_transpose22, (lv2421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv628 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2423,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv629 = R.call_tir(cls.fused_reshape32_transpose26, (lv2425,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv630 = R.call_tir(cls.fused_matmul23_multiply9, (lv627, lv628, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2437 = R.call_tir(cls.softmax4, (lv630,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2438 = R.call_tir(cls.matmul24, (lv2437, lv629), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv631 = R.call_tir(cls.fused_transpose24_reshape31, (lv2438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1481: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1252
            lv1482: R.Tensor((1280,), dtype="float32") = transformed_param_393
            lv632 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv631, lv1481, lv1482, lv626), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1483: R.Tensor((1280,), dtype="float32") = transformed_param_401
            lv1484: R.Tensor((1280,), dtype="float32") = transformed_param_400
            lv2446 = R.call_tir(cls.layer_norm2, (lv632, lv1483, lv1484), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1485: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1253
            lv1486: R.Tensor((10240,), dtype="float32") = transformed_param_394
            lv633_1 = R.call_tir(cls.fused_matmul25_add25, (lv2446, lv1485, lv1486), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv634_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv633_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1487: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1254
            lv1488: R.Tensor((1280,), dtype="float32") = transformed_param_395
            lv635 = R.call_tir(cls.fused_matmul26_add23_add24, (lv634_1, lv1487, lv1488, lv632), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1489: R.Tensor((1280,), dtype="float32") = transformed_param_407
            lv1490_1: R.Tensor((1280,), dtype="float32") = transformed_param_406
            lv2459 = R.call_tir(cls.layer_norm2, (lv635, lv1489, lv1490_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1491: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1255
            lv2461 = R.call_tir(cls.matmul19, (lv2459, lv1491), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1492_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1256
            lv2463 = R.call_tir(cls.matmul19, (lv2459, lv1492_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1493: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1257
            lv2465 = R.call_tir(cls.matmul19, (lv2459, lv1493), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv636 = R.call_tir(cls.fused_reshape30_transpose22, (lv2461,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv637 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2463,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv638 = R.call_tir(cls.fused_reshape30_transpose22, (lv2465,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv639 = R.call_tir(cls.fused_matmul20_multiply8, (lv636, lv637, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2477 = R.call_tir(cls.softmax3, (lv639,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2478 = R.call_tir(cls.matmul21, (lv2477, lv638), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv640 = R.call_tir(cls.fused_transpose24_reshape31, (lv2478,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1494_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1258
            lv1495: R.Tensor((1280,), dtype="float32") = transformed_param_402
            lv641 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv640, lv1494_1, lv1495, lv635), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1496_1: R.Tensor((1280,), dtype="float32") = transformed_param_409
            lv1497: R.Tensor((1280,), dtype="float32") = transformed_param_408
            lv2486 = R.call_tir(cls.layer_norm2, (lv641, lv1496_1, lv1497), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1498: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1259
            lv2488 = R.call_tir(cls.matmul19, (lv2486, lv1498), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1499: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1260
            lv2490 = R.call_tir(cls.matmul22, (inp_2, lv1499), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1500: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1261
            lv2492 = R.call_tir(cls.matmul22, (inp_2, lv1500), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv642_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv643 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2490,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv644 = R.call_tir(cls.fused_reshape32_transpose26, (lv2492,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv645 = R.call_tir(cls.fused_matmul23_multiply9, (lv642_1, lv643, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2504 = R.call_tir(cls.softmax4, (lv645,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2505 = R.call_tir(cls.matmul24, (lv2504, lv644), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv646 = R.call_tir(cls.fused_transpose24_reshape31, (lv2505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1501: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1262
            lv1502: R.Tensor((1280,), dtype="float32") = transformed_param_403
            lv647 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv646, lv1501, lv1502, lv641), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1503: R.Tensor((1280,), dtype="float32") = transformed_param_411
            lv1504: R.Tensor((1280,), dtype="float32") = transformed_param_410
            lv2513 = R.call_tir(cls.layer_norm2, (lv647, lv1503, lv1504), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1505: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1263
            lv1506: R.Tensor((10240,), dtype="float32") = transformed_param_404
            lv648 = R.call_tir(cls.fused_matmul25_add25, (lv2513, lv1505, lv1506), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv649 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv648,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1507: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1264
            lv1508_1: R.Tensor((1280,), dtype="float32") = transformed_param_405
            lv650 = R.call_tir(cls.fused_matmul26_add23_add24, (lv649, lv1507, lv1508_1, lv647), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1509_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1265
            lv1510: R.Tensor((1280,), dtype="float32") = transformed_param_311
            lv651 = R.call_tir(cls.fused_matmul19_add23, (lv650, lv1509_1, lv1510), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv652 = R.call_tir(cls.fused_reshape33_transpose29_add22, (lv651, lv498), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1511: R.Tensor((1280,), dtype="float32") = transformed_param_422
            lv1512: R.Tensor((1280,), dtype="float32") = transformed_param_421
            lv653 = R.call_tir(cls.fused_group_norm5_silu5, (lv652, lv1511, lv1512), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv2537 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1513: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1267
            lv1514: R.Tensor((1280,), dtype="float32") = transformed_param_425
            lv654 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv2537, lv1513, lv1514), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2542 = R.call_tir(cls.reshape28, (lv654,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1515: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_419
            lv1516: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1266
            lv655_1 = R.call_tir(cls.fused_conv2d8_add20_add21, (lv653, lv1515, lv1516, lv2542), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1517_1: R.Tensor((1280,), dtype="float32") = transformed_param_424
            lv1518: R.Tensor((1280,), dtype="float32") = transformed_param_423
            lv656 = R.call_tir(cls.fused_group_norm5_silu5, (lv655_1, lv1517_1, lv1518), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1519_1: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_420
            lv1520: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1268
            lv657_1 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv656, lv1519_1, lv1520, lv652), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv2551 = R.call_tir(cls.concatenate4, (lv657_1, lv493), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv1521_1: R.Tensor((2560,), dtype="float32") = transformed_param_744
            lv1522: R.Tensor((2560,), dtype="float32") = transformed_param_743
            lv658 = R.call_tir(cls.fused_group_norm7_silu6, (lv2551, lv1521_1, lv1522), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv2557 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1523_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1270
            lv1524: R.Tensor((1280,), dtype="float32") = transformed_param_747
            lv659_1 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv2557, lv1523_1, lv1524), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2562 = R.call_tir(cls.reshape28, (lv659_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1525: R.Tensor((1280, 2560, 3, 3), dtype="float32") = transformed_param_740
            lv1526: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1269
            lv660 = R.call_tir(cls.fused_conv2d10_add20_add21, (lv658, lv1525, lv1526, lv2562), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1527: R.Tensor((1280,), dtype="float32") = transformed_param_746
            lv1528: R.Tensor((1280,), dtype="float32") = transformed_param_745
            lv661_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv660, lv1527, lv1528), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1529: R.Tensor((1280, 2560, 1, 1), dtype="float32") = transformed_param_742
            lv1530: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1272
            lv662 = R.call_tir(cls.fused_conv2d11_add20, (lv2551, lv1529, lv1530), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1531: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_741
            lv1532: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1271
            lv663 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv661_1, lv1531, lv1532, lv662), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1533: R.Tensor((1280,), dtype="float32") = transformed_param_429
            lv1534: R.Tensor((1280,), dtype="float32") = transformed_param_428
            lv2574 = R.call_tir(cls.group_norm6, (lv663, lv1533, lv1534), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv664 = R.call_tir(cls.fused_transpose21_reshape29, (lv2574,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1535_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1273
            lv1536_1: R.Tensor((1280,), dtype="float32") = transformed_param_430
            lv665 = R.call_tir(cls.fused_matmul19_add23, (lv664, lv1535_1, lv1536_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1537: R.Tensor((1280,), dtype="float32") = transformed_param_437
            lv1538: R.Tensor((1280,), dtype="float32") = transformed_param_436
            lv2580 = R.call_tir(cls.layer_norm2, (lv665, lv1537, lv1538), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1539: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1274
            lv2582 = R.call_tir(cls.matmul19, (lv2580, lv1539), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1540: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1275
            lv2584 = R.call_tir(cls.matmul19, (lv2580, lv1540), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1541: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1276
            lv2586 = R.call_tir(cls.matmul19, (lv2580, lv1541), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv666 = R.call_tir(cls.fused_reshape30_transpose22, (lv2582,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv667 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2584,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv668 = R.call_tir(cls.fused_reshape30_transpose22, (lv2586,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv669 = R.call_tir(cls.fused_matmul20_multiply8, (lv666, lv667, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2598 = R.call_tir(cls.softmax3, (lv669,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2599 = R.call_tir(cls.matmul21, (lv2598, lv668), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv670 = R.call_tir(cls.fused_transpose24_reshape31, (lv2599,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1542: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1277
            lv1543: R.Tensor((1280,), dtype="float32") = transformed_param_432
            lv671 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv670, lv1542, lv1543, lv665), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1544_1: R.Tensor((1280,), dtype="float32") = transformed_param_439
            lv1545: R.Tensor((1280,), dtype="float32") = transformed_param_438
            lv2607 = R.call_tir(cls.layer_norm2, (lv671, lv1544_1, lv1545), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1546: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1278
            lv2609 = R.call_tir(cls.matmul19, (lv2607, lv1546), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1547: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1279
            lv2611 = R.call_tir(cls.matmul22, (inp_2, lv1547), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1548: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1280
            lv2613 = R.call_tir(cls.matmul22, (inp_2, lv1548), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv672 = R.call_tir(cls.fused_reshape30_transpose22, (lv2609,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv673_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2611,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv674_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv2613,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv675 = R.call_tir(cls.fused_matmul23_multiply9, (lv672, lv673_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2625 = R.call_tir(cls.softmax4, (lv675,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2626 = R.call_tir(cls.matmul24, (lv2625, lv674_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv676 = R.call_tir(cls.fused_transpose24_reshape31, (lv2626,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1549: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1281
            lv1550: R.Tensor((1280,), dtype="float32") = transformed_param_433
            lv677 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv676, lv1549, lv1550, lv671), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1551: R.Tensor((1280,), dtype="float32") = transformed_param_441
            lv1552: R.Tensor((1280,), dtype="float32") = transformed_param_440
            lv2634 = R.call_tir(cls.layer_norm2, (lv677, lv1551, lv1552), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1553: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1282
            lv1554: R.Tensor((10240,), dtype="float32") = transformed_param_434
            lv678 = R.call_tir(cls.fused_matmul25_add25, (lv2634, lv1553, lv1554), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv679 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv678,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1555: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1283
            lv1556: R.Tensor((1280,), dtype="float32") = transformed_param_435
            lv680 = R.call_tir(cls.fused_matmul26_add23_add24, (lv679, lv1555, lv1556, lv677), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1557_1: R.Tensor((1280,), dtype="float32") = transformed_param_447
            lv1558: R.Tensor((1280,), dtype="float32") = transformed_param_446
            lv2647 = R.call_tir(cls.layer_norm2, (lv680, lv1557_1, lv1558), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1559_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1284
            lv2649 = R.call_tir(cls.matmul19, (lv2647, lv1559_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1560: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1285
            lv2651 = R.call_tir(cls.matmul19, (lv2647, lv1560), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1561_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1286
            lv2653 = R.call_tir(cls.matmul19, (lv2647, lv1561_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv681 = R.call_tir(cls.fused_reshape30_transpose22, (lv2649,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv682_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2651,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv683 = R.call_tir(cls.fused_reshape30_transpose22, (lv2653,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv684_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv681, lv682_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2665 = R.call_tir(cls.softmax3, (lv684_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2666 = R.call_tir(cls.matmul21, (lv2665, lv683), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv685 = R.call_tir(cls.fused_transpose24_reshape31, (lv2666,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1562: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1287
            lv1563_1: R.Tensor((1280,), dtype="float32") = transformed_param_442
            lv686_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv685, lv1562, lv1563_1, lv680), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1564: R.Tensor((1280,), dtype="float32") = transformed_param_449
            lv1565: R.Tensor((1280,), dtype="float32") = transformed_param_448
            lv2674 = R.call_tir(cls.layer_norm2, (lv686_1, lv1564, lv1565), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1566: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1288
            lv2676 = R.call_tir(cls.matmul19, (lv2674, lv1566), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1567: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1289
            lv2678 = R.call_tir(cls.matmul22, (inp_2, lv1567), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1568: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1290
            lv2680 = R.call_tir(cls.matmul22, (inp_2, lv1568), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv687 = R.call_tir(cls.fused_reshape30_transpose22, (lv2676,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv688_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2678,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv689 = R.call_tir(cls.fused_reshape32_transpose26, (lv2680,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv690 = R.call_tir(cls.fused_matmul23_multiply9, (lv687, lv688_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2692 = R.call_tir(cls.softmax4, (lv690,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2693 = R.call_tir(cls.matmul24, (lv2692, lv689), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv691 = R.call_tir(cls.fused_transpose24_reshape31, (lv2693,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1569: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1291
            lv1570: R.Tensor((1280,), dtype="float32") = transformed_param_443
            lv692 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv691, lv1569, lv1570, lv686_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1571: R.Tensor((1280,), dtype="float32") = transformed_param_451
            lv1572: R.Tensor((1280,), dtype="float32") = transformed_param_450
            lv2701 = R.call_tir(cls.layer_norm2, (lv692, lv1571, lv1572), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1573: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1292
            lv1574: R.Tensor((10240,), dtype="float32") = transformed_param_444
            lv693 = R.call_tir(cls.fused_matmul25_add25, (lv2701, lv1573, lv1574), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv694 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv693,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1575_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1293
            lv1576_1: R.Tensor((1280,), dtype="float32") = transformed_param_445
            lv695 = R.call_tir(cls.fused_matmul26_add23_add24, (lv694, lv1575_1, lv1576_1, lv692), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1577: R.Tensor((1280,), dtype="float32") = transformed_param_457
            lv1578: R.Tensor((1280,), dtype="float32") = transformed_param_456
            lv2714 = R.call_tir(cls.layer_norm2, (lv695, lv1577, lv1578), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1579: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1294
            lv2716 = R.call_tir(cls.matmul19, (lv2714, lv1579), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1580: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1295
            lv2718 = R.call_tir(cls.matmul19, (lv2714, lv1580), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1581: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1296
            lv2720 = R.call_tir(cls.matmul19, (lv2714, lv1581), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv696 = R.call_tir(cls.fused_reshape30_transpose22, (lv2716,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv697 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2718,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv698 = R.call_tir(cls.fused_reshape30_transpose22, (lv2720,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv699 = R.call_tir(cls.fused_matmul20_multiply8, (lv696, lv697, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2732 = R.call_tir(cls.softmax3, (lv699,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2733 = R.call_tir(cls.matmul21, (lv2732, lv698), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv700_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2733,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1582: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1297
            lv1583: R.Tensor((1280,), dtype="float32") = transformed_param_452
            lv701_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv700_1, lv1582, lv1583, lv695), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1584_1: R.Tensor((1280,), dtype="float32") = transformed_param_459
            lv1585: R.Tensor((1280,), dtype="float32") = transformed_param_458
            lv2741 = R.call_tir(cls.layer_norm2, (lv701_1, lv1584_1, lv1585), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1586_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1298
            lv2743 = R.call_tir(cls.matmul19, (lv2741, lv1586_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1587: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1299
            lv2745 = R.call_tir(cls.matmul22, (inp_2, lv1587), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1588_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1300
            lv2747 = R.call_tir(cls.matmul22, (inp_2, lv1588_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv702 = R.call_tir(cls.fused_reshape30_transpose22, (lv2743,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv703 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2745,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv704 = R.call_tir(cls.fused_reshape32_transpose26, (lv2747,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv705 = R.call_tir(cls.fused_matmul23_multiply9, (lv702, lv703, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2759 = R.call_tir(cls.softmax4, (lv705,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2760 = R.call_tir(cls.matmul24, (lv2759, lv704), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv706 = R.call_tir(cls.fused_transpose24_reshape31, (lv2760,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1589: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1301
            lv1590_1: R.Tensor((1280,), dtype="float32") = transformed_param_453
            lv707 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv706, lv1589, lv1590_1, lv701_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1591: R.Tensor((1280,), dtype="float32") = transformed_param_461
            lv1592: R.Tensor((1280,), dtype="float32") = transformed_param_460
            lv2768 = R.call_tir(cls.layer_norm2, (lv707, lv1591, lv1592), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1593: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1302
            lv1594: R.Tensor((10240,), dtype="float32") = transformed_param_454
            lv708 = R.call_tir(cls.fused_matmul25_add25, (lv2768, lv1593, lv1594), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv709_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv708,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1595: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1303
            lv1596: R.Tensor((1280,), dtype="float32") = transformed_param_455
            lv710 = R.call_tir(cls.fused_matmul26_add23_add24, (lv709_1, lv1595, lv1596, lv707), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1597: R.Tensor((1280,), dtype="float32") = transformed_param_467
            lv1598: R.Tensor((1280,), dtype="float32") = transformed_param_466
            lv2781 = R.call_tir(cls.layer_norm2, (lv710, lv1597, lv1598), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1599: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1304
            lv2783 = R.call_tir(cls.matmul19, (lv2781, lv1599), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1600: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1305
            lv2785 = R.call_tir(cls.matmul19, (lv2781, lv1600), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1601: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1306
            lv2787 = R.call_tir(cls.matmul19, (lv2781, lv1601), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv711 = R.call_tir(cls.fused_reshape30_transpose22, (lv2783,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv712 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2785,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv713_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2787,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv714_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv711, lv712, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2799 = R.call_tir(cls.softmax3, (lv714_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2800 = R.call_tir(cls.matmul21, (lv2799, lv713_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv715_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2800,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1602_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1307
            lv1603_1: R.Tensor((1280,), dtype="float32") = transformed_param_462
            lv716_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv715_1, lv1602_1, lv1603_1, lv710), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1604: R.Tensor((1280,), dtype="float32") = transformed_param_469
            lv1605: R.Tensor((1280,), dtype="float32") = transformed_param_468
            lv2808 = R.call_tir(cls.layer_norm2, (lv716_1, lv1604, lv1605), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1606: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1308
            lv2810 = R.call_tir(cls.matmul19, (lv2808, lv1606), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1607: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1309
            lv2812 = R.call_tir(cls.matmul22, (inp_2, lv1607), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1608: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1310
            lv2814 = R.call_tir(cls.matmul22, (inp_2, lv1608), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv717_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2810,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv718_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2812,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv719_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv2814,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv720_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv717_1, lv718_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2826 = R.call_tir(cls.softmax4, (lv720_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2827 = R.call_tir(cls.matmul24, (lv2826, lv719_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv721_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2827,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1609: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1311
            lv1610: R.Tensor((1280,), dtype="float32") = transformed_param_463
            lv722_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv721_1, lv1609, lv1610, lv716_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1611_1: R.Tensor((1280,), dtype="float32") = transformed_param_471
            lv1612: R.Tensor((1280,), dtype="float32") = transformed_param_470
            lv2835 = R.call_tir(cls.layer_norm2, (lv722_2, lv1611_1, lv1612), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1613: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1312
            lv1614: R.Tensor((10240,), dtype="float32") = transformed_param_464
            lv723_1 = R.call_tir(cls.fused_matmul25_add25, (lv2835, lv1613, lv1614), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv724_2 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv723_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1615: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1313
            lv1616: R.Tensor((1280,), dtype="float32") = transformed_param_465
            lv725_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv724_2, lv1615, lv1616, lv722_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1617: R.Tensor((1280,), dtype="float32") = transformed_param_477
            lv1618: R.Tensor((1280,), dtype="float32") = transformed_param_476
            lv2848 = R.call_tir(cls.layer_norm2, (lv725_1, lv1617, lv1618), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1619: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1314
            lv2850 = R.call_tir(cls.matmul19, (lv2848, lv1619), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1620: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1315
            lv2852 = R.call_tir(cls.matmul19, (lv2848, lv1620), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1621: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1316
            lv2854 = R.call_tir(cls.matmul19, (lv2848, lv1621), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv726_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2850,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv727_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2852,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv728_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2854,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv729_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv726_2, lv727_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2866 = R.call_tir(cls.softmax3, (lv729_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2867 = R.call_tir(cls.matmul21, (lv2866, lv728_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv730_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2867,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1622: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1317
            lv1623: R.Tensor((1280,), dtype="float32") = transformed_param_472
            lv731_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv730_1, lv1622, lv1623, lv725_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1624_1: R.Tensor((1280,), dtype="float32") = transformed_param_479
            lv1625: R.Tensor((1280,), dtype="float32") = transformed_param_478
            lv2875 = R.call_tir(cls.layer_norm2, (lv731_1, lv1624_1, lv1625), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1626_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1318
            lv2877 = R.call_tir(cls.matmul19, (lv2875, lv1626_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1627: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1319
            lv2879 = R.call_tir(cls.matmul22, (inp_2, lv1627), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1628_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1320
            lv2881 = R.call_tir(cls.matmul22, (inp_2, lv1628_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv732_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2877,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv733_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2879,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv734_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv2881,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv735_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv732_1, lv733_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2893 = R.call_tir(cls.softmax4, (lv735_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2894 = R.call_tir(cls.matmul24, (lv2893, lv734_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv736_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2894,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1629: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1321
            lv1630_1: R.Tensor((1280,), dtype="float32") = transformed_param_473
            lv737_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv736_1, lv1629, lv1630_1, lv731_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1631: R.Tensor((1280,), dtype="float32") = transformed_param_481
            lv1632: R.Tensor((1280,), dtype="float32") = transformed_param_480
            lv2902 = R.call_tir(cls.layer_norm2, (lv737_1, lv1631, lv1632), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1633: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1322
            lv1634: R.Tensor((10240,), dtype="float32") = transformed_param_474
            lv738_1 = R.call_tir(cls.fused_matmul25_add25, (lv2902, lv1633, lv1634), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv739_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv738_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1635: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1323
            lv1636: R.Tensor((1280,), dtype="float32") = transformed_param_475
            lv740_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv739_1, lv1635, lv1636, lv737_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1637: R.Tensor((1280,), dtype="float32") = transformed_param_487
            lv1638: R.Tensor((1280,), dtype="float32") = transformed_param_486
            lv2915 = R.call_tir(cls.layer_norm2, (lv740_2, lv1637, lv1638), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1639: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1324
            lv2917 = R.call_tir(cls.matmul19, (lv2915, lv1639), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1640: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1325
            lv2919 = R.call_tir(cls.matmul19, (lv2915, lv1640), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1641: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1326
            lv2921 = R.call_tir(cls.matmul19, (lv2915, lv1641), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv741_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv2917,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv742_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2919,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv743_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2921,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv744_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv741_2, lv742_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2933 = R.call_tir(cls.softmax3, (lv744_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2934 = R.call_tir(cls.matmul21, (lv2933, lv743_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv745_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv2934,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1642_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1327
            lv1643_1: R.Tensor((1280,), dtype="float32") = transformed_param_482
            lv746_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv745_1, lv1642_1, lv1643_1, lv740_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1644: R.Tensor((1280,), dtype="float32") = transformed_param_489
            lv1645: R.Tensor((1280,), dtype="float32") = transformed_param_488
            lv2942 = R.call_tir(cls.layer_norm2, (lv746_1, lv1644, lv1645), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1646: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1328
            lv2944 = R.call_tir(cls.matmul19, (lv2942, lv1646), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1647: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1329
            lv2946 = R.call_tir(cls.matmul22, (inp_2, lv1647), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1648: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1330
            lv2948 = R.call_tir(cls.matmul22, (inp_2, lv1648), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv747_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2944,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv748_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv2946,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv749_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv2948,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv750_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv747_1, lv748_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2960 = R.call_tir(cls.softmax4, (lv750_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2961 = R.call_tir(cls.matmul24, (lv2960, lv749_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv751_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv2961,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1649: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1331
            lv1650: R.Tensor((1280,), dtype="float32") = transformed_param_483
            lv752_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv751_2, lv1649, lv1650, lv746_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1651_1: R.Tensor((1280,), dtype="float32") = transformed_param_491
            lv1652: R.Tensor((1280,), dtype="float32") = transformed_param_490
            lv2969 = R.call_tir(cls.layer_norm2, (lv752_1, lv1651_1, lv1652), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1653_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1332
            lv1654: R.Tensor((10240,), dtype="float32") = transformed_param_484
            lv753_2 = R.call_tir(cls.fused_matmul25_add25, (lv2969, lv1653_1, lv1654), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv754_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv753_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1655_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1333
            lv1656: R.Tensor((1280,), dtype="float32") = transformed_param_485
            lv755_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv754_1, lv1655_1, lv1656, lv752_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1657_1: R.Tensor((1280,), dtype="float32") = transformed_param_497
            lv1658: R.Tensor((1280,), dtype="float32") = transformed_param_496
            lv2982 = R.call_tir(cls.layer_norm2, (lv755_2, lv1657_1, lv1658), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1659: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1334
            lv2984 = R.call_tir(cls.matmul19, (lv2982, lv1659), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1660: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1335
            lv2986 = R.call_tir(cls.matmul19, (lv2982, lv1660), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1661: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1336
            lv2988 = R.call_tir(cls.matmul19, (lv2982, lv1661), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv756_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2984,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv757_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv2986,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv758_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv2988,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv759_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv756_1, lv757_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3000 = R.call_tir(cls.softmax3, (lv759_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3001 = R.call_tir(cls.matmul21, (lv3000, lv758_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv760_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3001,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1662: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1337
            lv1663: R.Tensor((1280,), dtype="float32") = transformed_param_492
            lv761_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv760_1, lv1662, lv1663, lv755_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1664: R.Tensor((1280,), dtype="float32") = transformed_param_499
            lv1665: R.Tensor((1280,), dtype="float32") = transformed_param_498
            lv3009 = R.call_tir(cls.layer_norm2, (lv761_1, lv1664, lv1665), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1666: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1338
            lv3011 = R.call_tir(cls.matmul19, (lv3009, lv1666), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1667: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1339
            lv3013 = R.call_tir(cls.matmul22, (inp_2, lv1667), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1668: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1340
            lv3015 = R.call_tir(cls.matmul22, (inp_2, lv1668), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv762_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3011,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv763_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3013,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv764_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3015,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv765_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv762_1, lv763_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3027 = R.call_tir(cls.softmax4, (lv765_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3028 = R.call_tir(cls.matmul24, (lv3027, lv764_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv766_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3028,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1669_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1341
            lv1670_1: R.Tensor((1280,), dtype="float32") = transformed_param_493
            lv767_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv766_1, lv1669_1, lv1670_1, lv761_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1671: R.Tensor((1280,), dtype="float32") = transformed_param_501
            lv1672: R.Tensor((1280,), dtype="float32") = transformed_param_500
            lv3036 = R.call_tir(cls.layer_norm2, (lv767_2, lv1671, lv1672), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1673: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1342
            lv1674: R.Tensor((10240,), dtype="float32") = transformed_param_494
            lv768_2 = R.call_tir(cls.fused_matmul25_add25, (lv3036, lv1673, lv1674), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv769_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv768_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1675: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1343
            lv1676: R.Tensor((1280,), dtype="float32") = transformed_param_495
            lv770_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv769_1, lv1675, lv1676, lv767_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1677: R.Tensor((1280,), dtype="float32") = transformed_param_507
            lv1678_1: R.Tensor((1280,), dtype="float32") = transformed_param_506
            lv3049 = R.call_tir(cls.layer_norm2, (lv770_1, lv1677, lv1678_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1679: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1344
            lv3051 = R.call_tir(cls.matmul19, (lv3049, lv1679), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1680: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1345
            lv3053 = R.call_tir(cls.matmul19, (lv3049, lv1680), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1681: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1346
            lv3055 = R.call_tir(cls.matmul19, (lv3049, lv1681), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv771_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3051,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv772_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3053,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv773_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3055,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv774_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv771_1, lv772_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3067 = R.call_tir(cls.softmax3, (lv774_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3068 = R.call_tir(cls.matmul21, (lv3067, lv773_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv775_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3068,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1682: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1347
            lv1683: R.Tensor((1280,), dtype="float32") = transformed_param_502
            lv776_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv775_1, lv1682, lv1683, lv770_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1684: R.Tensor((1280,), dtype="float32") = transformed_param_509
            lv1685: R.Tensor((1280,), dtype="float32") = transformed_param_508
            lv3076 = R.call_tir(cls.layer_norm2, (lv776_2, lv1684, lv1685), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1686: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1348
            lv3078 = R.call_tir(cls.matmul19, (lv3076, lv1686), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1687: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1349
            lv3080 = R.call_tir(cls.matmul22, (inp_2, lv1687), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1688: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1350
            lv3082 = R.call_tir(cls.matmul22, (inp_2, lv1688), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv777_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3078,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv778_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3080,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv779_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3082,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv780_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv777_1, lv778_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3094 = R.call_tir(cls.softmax4, (lv780_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3095 = R.call_tir(cls.matmul24, (lv3094, lv779_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv781_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3095,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1689: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1351
            lv1690: R.Tensor((1280,), dtype="float32") = transformed_param_503
            lv782_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv781_1, lv1689, lv1690, lv776_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1691_1: R.Tensor((1280,), dtype="float32") = transformed_param_511
            lv1692: R.Tensor((1280,), dtype="float32") = transformed_param_510
            lv3103 = R.call_tir(cls.layer_norm2, (lv782_1, lv1691_1, lv1692), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1693_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1352
            lv1694: R.Tensor((10240,), dtype="float32") = transformed_param_504
            lv783_1 = R.call_tir(cls.fused_matmul25_add25, (lv3103, lv1693_1, lv1694), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv784_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv783_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1695_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1353
            lv1696: R.Tensor((1280,), dtype="float32") = transformed_param_505
            lv785_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv784_1, lv1695_1, lv1696, lv782_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1697_1: R.Tensor((1280,), dtype="float32") = transformed_param_517
            lv1698: R.Tensor((1280,), dtype="float32") = transformed_param_516
            lv3116 = R.call_tir(cls.layer_norm2, (lv785_1, lv1697_1, lv1698), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1699: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1354
            lv3118 = R.call_tir(cls.matmul19, (lv3116, lv1699), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1700: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1355
            lv3120 = R.call_tir(cls.matmul19, (lv3116, lv1700), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1701: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1356
            lv3122 = R.call_tir(cls.matmul19, (lv3116, lv1701), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv786_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3118,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv787_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3120,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv788_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3122,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv789_2 = R.call_tir(cls.fused_matmul20_multiply8, (lv786_1, lv787_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3134 = R.call_tir(cls.softmax3, (lv789_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3135 = R.call_tir(cls.matmul21, (lv3134, lv788_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv790_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3135,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1702: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1357
            lv1703: R.Tensor((1280,), dtype="float32") = transformed_param_512
            lv791_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv790_1, lv1702, lv1703, lv785_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1704: R.Tensor((1280,), dtype="float32") = transformed_param_519
            lv1705: R.Tensor((1280,), dtype="float32") = transformed_param_518
            lv3143 = R.call_tir(cls.layer_norm2, (lv791_2, lv1704, lv1705), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1706: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1358
            lv3145 = R.call_tir(cls.matmul19, (lv3143, lv1706), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1707: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1359
            lv3147 = R.call_tir(cls.matmul22, (inp_2, lv1707), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1708: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1360
            lv3149 = R.call_tir(cls.matmul22, (inp_2, lv1708), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv792_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3145,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv793_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3147,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv794_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3149,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv795_2 = R.call_tir(cls.fused_matmul23_multiply9, (lv792_1, lv793_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3161 = R.call_tir(cls.softmax4, (lv795_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3162 = R.call_tir(cls.matmul24, (lv3161, lv794_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv796_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3162,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1709_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1361
            lv1710_1: R.Tensor((1280,), dtype="float32") = transformed_param_513
            lv797_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv796_1, lv1709_1, lv1710_1, lv791_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1711: R.Tensor((1280,), dtype="float32") = transformed_param_521
            lv1712: R.Tensor((1280,), dtype="float32") = transformed_param_520
            lv3170 = R.call_tir(cls.layer_norm2, (lv797_1, lv1711, lv1712), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1713: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1362
            lv1714: R.Tensor((10240,), dtype="float32") = transformed_param_514
            lv798_1 = R.call_tir(cls.fused_matmul25_add25, (lv3170, lv1713, lv1714), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv799_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv798_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1715: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1363
            lv1716: R.Tensor((1280,), dtype="float32") = transformed_param_515
            lv800_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv799_1, lv1715, lv1716, lv797_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1717: R.Tensor((1280,), dtype="float32") = transformed_param_527
            lv1718_1: R.Tensor((1280,), dtype="float32") = transformed_param_526
            lv3183 = R.call_tir(cls.layer_norm2, (lv800_1, lv1717, lv1718_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1719: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1364
            lv3185 = R.call_tir(cls.matmul19, (lv3183, lv1719), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1720_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1365
            lv3187 = R.call_tir(cls.matmul19, (lv3183, lv1720_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1721: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1366
            lv3189 = R.call_tir(cls.matmul19, (lv3183, lv1721), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv801_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3185,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv802_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3187,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv803_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3189,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv804_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv801_1, lv802_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3201 = R.call_tir(cls.softmax3, (lv804_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3202 = R.call_tir(cls.matmul21, (lv3201, lv803_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv805_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3202,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1722_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1367
            lv1723: R.Tensor((1280,), dtype="float32") = transformed_param_522
            lv806_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv805_1, lv1722_1, lv1723, lv800_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1724_1: R.Tensor((1280,), dtype="float32") = transformed_param_529
            lv1725: R.Tensor((1280,), dtype="float32") = transformed_param_528
            lv3210 = R.call_tir(cls.layer_norm2, (lv806_1, lv1724_1, lv1725), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1726: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1368
            lv3212 = R.call_tir(cls.matmul19, (lv3210, lv1726), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1727: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1369
            lv3214 = R.call_tir(cls.matmul22, (inp_2, lv1727), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1728: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1370
            lv3216 = R.call_tir(cls.matmul22, (inp_2, lv1728), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv807_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3212,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv808_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3214,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv809_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3216,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv810_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv807_2, lv808_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3228 = R.call_tir(cls.softmax4, (lv810_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3229 = R.call_tir(cls.matmul24, (lv3228, lv809_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv811_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3229,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1729: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1371
            lv1730: R.Tensor((1280,), dtype="float32") = transformed_param_523
            lv812_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv811_1, lv1729, lv1730, lv806_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1731: R.Tensor((1280,), dtype="float32") = transformed_param_531
            lv1732: R.Tensor((1280,), dtype="float32") = transformed_param_530
            lv3237 = R.call_tir(cls.layer_norm2, (lv812_1, lv1731, lv1732), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1733: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1372
            lv1734: R.Tensor((10240,), dtype="float32") = transformed_param_524
            lv813_1 = R.call_tir(cls.fused_matmul25_add25, (lv3237, lv1733, lv1734), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv814_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv813_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1735: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1373
            lv1736_1: R.Tensor((1280,), dtype="float32") = transformed_param_525
            lv815_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv814_1, lv1735, lv1736_1, lv812_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1737_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1374
            lv1738: R.Tensor((1280,), dtype="float32") = transformed_param_431
            lv816_2 = R.call_tir(cls.fused_matmul19_add23, (lv815_1, lv1737_1, lv1738), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv817_1 = R.call_tir(cls.fused_reshape33_transpose29_add22_concatenate4, (lv816_2, lv663, lv334), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv1739: R.Tensor((2560,), dtype="float32") = transformed_param_752
            lv1740: R.Tensor((2560,), dtype="float32") = transformed_param_751
            lv818_2 = R.call_tir(cls.fused_group_norm7_silu6, (lv817_1, lv1739, lv1740), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv3262 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1741: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1376
            lv1742: R.Tensor((1280,), dtype="float32") = transformed_param_755
            lv819_1 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv3262, lv1741, lv1742), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv3267 = R.call_tir(cls.reshape28, (lv819_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1743: R.Tensor((1280, 2560, 3, 3), dtype="float32") = transformed_param_748
            lv1744: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1375
            lv820_2 = R.call_tir(cls.fused_conv2d10_add20_add21, (lv818_2, lv1743, lv1744, lv3267), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1745_1: R.Tensor((1280,), dtype="float32") = transformed_param_754
            lv1746: R.Tensor((1280,), dtype="float32") = transformed_param_753
            lv821_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv820_2, lv1745_1, lv1746), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1747: R.Tensor((1280, 2560, 1, 1), dtype="float32") = transformed_param_750
            lv1748: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1378
            lv822_2 = R.call_tir(cls.fused_conv2d11_add20, (lv817_1, lv1747, lv1748), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1749: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_749
            lv1750: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1377
            lv823_1 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv821_1, lv1749, lv1750, lv822_2), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1751: R.Tensor((1280,), dtype="float32") = transformed_param_533
            lv1752: R.Tensor((1280,), dtype="float32") = transformed_param_532
            lv3279 = R.call_tir(cls.group_norm6, (lv823_1, lv1751, lv1752), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv824_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv3279,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1753: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1379
            lv1754: R.Tensor((1280,), dtype="float32") = transformed_param_534
            lv825_1 = R.call_tir(cls.fused_matmul19_add23, (lv824_1, lv1753, lv1754), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1755: R.Tensor((1280,), dtype="float32") = transformed_param_541
            lv1756: R.Tensor((1280,), dtype="float32") = transformed_param_540
            lv3285 = R.call_tir(cls.layer_norm2, (lv825_1, lv1755, lv1756), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1757: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1380
            lv3287 = R.call_tir(cls.matmul19, (lv3285, lv1757), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1758_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1381
            lv3289 = R.call_tir(cls.matmul19, (lv3285, lv1758_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1759: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1382
            lv3291 = R.call_tir(cls.matmul19, (lv3285, lv1759), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv826_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv827_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3289,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv828_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3291,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv829_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv826_1, lv827_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3303 = R.call_tir(cls.softmax3, (lv829_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3304 = R.call_tir(cls.matmul21, (lv3303, lv828_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv830_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1760_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1383
            lv1761: R.Tensor((1280,), dtype="float32") = transformed_param_536
            lv831_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv830_1, lv1760_1, lv1761, lv825_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1762_1: R.Tensor((1280,), dtype="float32") = transformed_param_543
            lv1763: R.Tensor((1280,), dtype="float32") = transformed_param_542
            lv3312 = R.call_tir(cls.layer_norm2, (lv831_1, lv1762_1, lv1763), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1764_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1384
            lv3314 = R.call_tir(cls.matmul19, (lv3312, lv1764_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1765: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1385
            lv3316 = R.call_tir(cls.matmul22, (inp_2, lv1765), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1766: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1386
            lv3318 = R.call_tir(cls.matmul22, (inp_2, lv1766), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv832_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3314,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv833_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3316,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv834_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv3318,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv835_2 = R.call_tir(cls.fused_matmul23_multiply9, (lv832_1, lv833_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3330 = R.call_tir(cls.softmax4, (lv835_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3331 = R.call_tir(cls.matmul24, (lv3330, lv834_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv836_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3331,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1767: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1387
            lv1768: R.Tensor((1280,), dtype="float32") = transformed_param_537
            lv837_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv836_1, lv1767, lv1768, lv831_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1769: R.Tensor((1280,), dtype="float32") = transformed_param_545
            lv1770: R.Tensor((1280,), dtype="float32") = transformed_param_544
            lv3339 = R.call_tir(cls.layer_norm2, (lv837_1, lv1769, lv1770), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1771: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1388
            lv1772: R.Tensor((10240,), dtype="float32") = transformed_param_538
            lv838_1 = R.call_tir(cls.fused_matmul25_add25, (lv3339, lv1771, lv1772), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv839_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv838_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1773: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1389
            lv1774: R.Tensor((1280,), dtype="float32") = transformed_param_539
            lv840_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv839_1, lv1773, lv1774, lv837_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1775: R.Tensor((1280,), dtype="float32") = transformed_param_551
            lv1776_1: R.Tensor((1280,), dtype="float32") = transformed_param_550
            lv3352 = R.call_tir(cls.layer_norm2, (lv840_1, lv1775, lv1776_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1777_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1390
            lv3354 = R.call_tir(cls.matmul19, (lv3352, lv1777_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1778: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1391
            lv3356 = R.call_tir(cls.matmul19, (lv3352, lv1778), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1779: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1392
            lv3358 = R.call_tir(cls.matmul19, (lv3352, lv1779), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv841_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv842_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3356,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv843_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3358,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv844_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv841_1, lv842_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3370 = R.call_tir(cls.softmax3, (lv844_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3371 = R.call_tir(cls.matmul21, (lv3370, lv843_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv845_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1780: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1393
            lv1781: R.Tensor((1280,), dtype="float32") = transformed_param_546
            lv846_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv845_1, lv1780, lv1781, lv840_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1782: R.Tensor((1280,), dtype="float32") = transformed_param_553
            lv1783: R.Tensor((1280,), dtype="float32") = transformed_param_552
            lv3379 = R.call_tir(cls.layer_norm2, (lv846_1, lv1782, lv1783), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1784: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1394
            lv3381 = R.call_tir(cls.matmul19, (lv3379, lv1784), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1785_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1395
            lv3383 = R.call_tir(cls.matmul22, (inp_2, lv1785_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1786: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1396
            lv3385 = R.call_tir(cls.matmul22, (inp_2, lv1786), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv847_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3381,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv848_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3383,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv849_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3385,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv850_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv847_1, lv848_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3397 = R.call_tir(cls.softmax4, (lv850_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3398 = R.call_tir(cls.matmul24, (lv3397, lv849_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv851_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3398,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1787_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1397
            lv1788: R.Tensor((1280,), dtype="float32") = transformed_param_547
            lv852_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv851_1, lv1787_1, lv1788, lv846_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1789_1: R.Tensor((1280,), dtype="float32") = transformed_param_555
            lv1790: R.Tensor((1280,), dtype="float32") = transformed_param_554
            lv3406 = R.call_tir(cls.layer_norm2, (lv852_1, lv1789_1, lv1790), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1791_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1398
            lv1792: R.Tensor((10240,), dtype="float32") = transformed_param_548
            lv853_1 = R.call_tir(cls.fused_matmul25_add25, (lv3406, lv1791_1, lv1792), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv854_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv853_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1793: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1399
            lv1794: R.Tensor((1280,), dtype="float32") = transformed_param_549
            lv855_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv854_1, lv1793, lv1794, lv852_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1795: R.Tensor((1280,), dtype="float32") = transformed_param_561
            lv1796: R.Tensor((1280,), dtype="float32") = transformed_param_560
            lv3419 = R.call_tir(cls.layer_norm2, (lv855_1, lv1795, lv1796), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1797: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1400
            lv3421 = R.call_tir(cls.matmul19, (lv3419, lv1797), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1798: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1401
            lv3423 = R.call_tir(cls.matmul19, (lv3419, lv1798), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1799: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1402
            lv3425 = R.call_tir(cls.matmul19, (lv3419, lv1799), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv856_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv857_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3423,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv858_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3425,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv859_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv856_2, lv857_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3437 = R.call_tir(cls.softmax3, (lv859_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3438 = R.call_tir(cls.matmul21, (lv3437, lv858_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv860_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1800: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1403
            lv1801: R.Tensor((1280,), dtype="float32") = transformed_param_556
            lv861_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv860_2, lv1800, lv1801, lv855_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1802: R.Tensor((1280,), dtype="float32") = transformed_param_563
            lv1803_1: R.Tensor((1280,), dtype="float32") = transformed_param_562
            lv3446 = R.call_tir(cls.layer_norm2, (lv861_1, lv1802, lv1803_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1804_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1404
            lv3448 = R.call_tir(cls.matmul19, (lv3446, lv1804_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1805: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1405
            lv3450 = R.call_tir(cls.matmul22, (inp_2, lv1805), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1806: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1406
            lv3452 = R.call_tir(cls.matmul22, (inp_2, lv1806), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv862_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3448,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv863_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3450,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv864_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3452,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv865_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv862_2, lv863_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3464 = R.call_tir(cls.softmax4, (lv865_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3465 = R.call_tir(cls.matmul24, (lv3464, lv864_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv866_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3465,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1807: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1407
            lv1808: R.Tensor((1280,), dtype="float32") = transformed_param_557
            lv867_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv866_1, lv1807, lv1808, lv861_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1809: R.Tensor((1280,), dtype="float32") = transformed_param_565
            lv1810: R.Tensor((1280,), dtype="float32") = transformed_param_564
            lv3473 = R.call_tir(cls.layer_norm2, (lv867_1, lv1809, lv1810), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1811: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1408
            lv1812_1: R.Tensor((10240,), dtype="float32") = transformed_param_558
            lv868_1 = R.call_tir(cls.fused_matmul25_add25, (lv3473, lv1811, lv1812_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv869_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv868_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1813: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1409
            lv1814: R.Tensor((1280,), dtype="float32") = transformed_param_559
            lv870_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv869_1, lv1813, lv1814, lv867_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1815: R.Tensor((1280,), dtype="float32") = transformed_param_571
            lv1816: R.Tensor((1280,), dtype="float32") = transformed_param_570
            lv3486 = R.call_tir(cls.layer_norm2, (lv870_1, lv1815, lv1816), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1817: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1410
            lv3488 = R.call_tir(cls.matmul19, (lv3486, lv1817), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1818: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1411
            lv3490 = R.call_tir(cls.matmul19, (lv3486, lv1818), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1819: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1412
            lv3492 = R.call_tir(cls.matmul19, (lv3486, lv1819), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv871_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv872_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3490,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv873_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3492,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv874_2 = R.call_tir(cls.fused_matmul20_multiply8, (lv871_1, lv872_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3504 = R.call_tir(cls.softmax3, (lv874_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3505 = R.call_tir(cls.matmul21, (lv3504, lv873_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv875_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1820: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1413
            lv1821: R.Tensor((1280,), dtype="float32") = transformed_param_566
            lv876_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv875_2, lv1820, lv1821, lv870_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1822: R.Tensor((1280,), dtype="float32") = transformed_param_573
            lv1823: R.Tensor((1280,), dtype="float32") = transformed_param_572
            lv3513 = R.call_tir(cls.layer_norm2, (lv876_1, lv1822, lv1823), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1824: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1414
            lv3515 = R.call_tir(cls.matmul19, (lv3513, lv1824), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1825: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1415
            lv3517 = R.call_tir(cls.matmul22, (inp_2, lv1825), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1826: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1416
            lv3519 = R.call_tir(cls.matmul22, (inp_2, lv1826), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv877_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3515,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv878_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3517,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv879_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3519,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv880_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv877_1, lv878_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3531 = R.call_tir(cls.softmax4, (lv880_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3532 = R.call_tir(cls.matmul24, (lv3531, lv879_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv881_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3532,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1827: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1417
            lv1828: R.Tensor((1280,), dtype="float32") = transformed_param_567
            lv882_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv881_1, lv1827, lv1828, lv876_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1829: R.Tensor((1280,), dtype="float32") = transformed_param_575
            lv1830: R.Tensor((1280,), dtype="float32") = transformed_param_574
            lv3540 = R.call_tir(cls.layer_norm2, (lv882_1, lv1829, lv1830), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1831: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1418
            lv1832: R.Tensor((10240,), dtype="float32") = transformed_param_568
            lv883_2 = R.call_tir(cls.fused_matmul25_add25, (lv3540, lv1831, lv1832), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv884_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv883_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1833: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1419
            lv1834: R.Tensor((1280,), dtype="float32") = transformed_param_569
            lv885_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv884_1, lv1833, lv1834, lv882_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1835: R.Tensor((1280,), dtype="float32") = transformed_param_581
            lv1836_1: R.Tensor((1280,), dtype="float32") = transformed_param_580
            lv3553 = R.call_tir(cls.layer_norm2, (lv885_2, lv1835, lv1836_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1837: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1420
            lv3555 = R.call_tir(cls.matmul19, (lv3553, lv1837), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1838: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1421
            lv3557 = R.call_tir(cls.matmul19, (lv3553, lv1838), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1839: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1422
            lv3559 = R.call_tir(cls.matmul19, (lv3553, lv1839), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv886_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3555,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv887_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3557,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv888_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3559,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv889_2 = R.call_tir(cls.fused_matmul20_multiply8, (lv886_1, lv887_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3571 = R.call_tir(cls.softmax3, (lv889_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3572 = R.call_tir(cls.matmul21, (lv3571, lv888_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv890_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3572,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1840: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1423
            lv1841_1: R.Tensor((1280,), dtype="float32") = transformed_param_576
            lv891_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv890_1, lv1840, lv1841_1, lv885_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1842: R.Tensor((1280,), dtype="float32") = transformed_param_583
            lv1843: R.Tensor((1280,), dtype="float32") = transformed_param_582
            lv3580 = R.call_tir(cls.layer_norm2, (lv891_1, lv1842, lv1843), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1844: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1424
            lv3582 = R.call_tir(cls.matmul19, (lv3580, lv1844), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1845: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1425
            lv3584 = R.call_tir(cls.matmul22, (inp_2, lv1845), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1846: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1426
            lv3586 = R.call_tir(cls.matmul22, (inp_2, lv1846), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv892_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3582,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv893_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3584,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv894_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3586,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv895_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv892_1, lv893_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3598 = R.call_tir(cls.softmax4, (lv895_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3599 = R.call_tir(cls.matmul24, (lv3598, lv894_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv896_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3599,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1847: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1427
            lv1848: R.Tensor((1280,), dtype="float32") = transformed_param_577
            lv897_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv896_1, lv1847, lv1848, lv891_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1849: R.Tensor((1280,), dtype="float32") = transformed_param_585
            lv1850_1: R.Tensor((1280,), dtype="float32") = transformed_param_584
            lv3607 = R.call_tir(cls.layer_norm2, (lv897_1, lv1849, lv1850_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1851: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1428
            lv1852: R.Tensor((10240,), dtype="float32") = transformed_param_578
            lv898_1 = R.call_tir(cls.fused_matmul25_add25, (lv3607, lv1851, lv1852), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv899_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv898_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1853: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1429
            lv1854: R.Tensor((1280,), dtype="float32") = transformed_param_579
            lv900_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv899_1, lv1853, lv1854, lv897_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1855: R.Tensor((1280,), dtype="float32") = transformed_param_591
            lv1856_1: R.Tensor((1280,), dtype="float32") = transformed_param_590
            lv3620 = R.call_tir(cls.layer_norm2, (lv900_1, lv1855, lv1856_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1857: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1430
            lv3622 = R.call_tir(cls.matmul19, (lv3620, lv1857), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1858_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1431
            lv3624 = R.call_tir(cls.matmul19, (lv3620, lv1858_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1859: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1432
            lv3626 = R.call_tir(cls.matmul19, (lv3620, lv1859), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv901_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3622,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv902_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3624,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv903_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3626,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv904_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv901_2, lv902_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3638 = R.call_tir(cls.softmax3, (lv904_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3639 = R.call_tir(cls.matmul21, (lv3638, lv903_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv905_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3639,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1860_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1433
            lv1861: R.Tensor((1280,), dtype="float32") = transformed_param_586
            lv906_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv905_1, lv1860_1, lv1861, lv900_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1862_1: R.Tensor((1280,), dtype="float32") = transformed_param_593
            lv1863: R.Tensor((1280,), dtype="float32") = transformed_param_592
            lv3647 = R.call_tir(cls.layer_norm2, (lv906_1, lv1862_1, lv1863), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1864: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1434
            lv3649 = R.call_tir(cls.matmul19, (lv3647, lv1864), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1865: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1435
            lv3651 = R.call_tir(cls.matmul22, (inp_2, lv1865), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1866: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1436
            lv3653 = R.call_tir(cls.matmul22, (inp_2, lv1866), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv907_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3649,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv908_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3651,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv909_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3653,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv910_2 = R.call_tir(cls.fused_matmul23_multiply9, (lv907_1, lv908_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3665 = R.call_tir(cls.softmax4, (lv910_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3666 = R.call_tir(cls.matmul24, (lv3665, lv909_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv911_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3666,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1867: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1437
            lv1868: R.Tensor((1280,), dtype="float32") = transformed_param_587
            lv912_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv911_1, lv1867, lv1868, lv906_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1869: R.Tensor((1280,), dtype="float32") = transformed_param_595
            lv1870: R.Tensor((1280,), dtype="float32") = transformed_param_594
            lv3674 = R.call_tir(cls.layer_norm2, (lv912_1, lv1869, lv1870), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1871: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1438
            lv1872: R.Tensor((10240,), dtype="float32") = transformed_param_588
            lv913_1 = R.call_tir(cls.fused_matmul25_add25, (lv3674, lv1871, lv1872), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv914_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv913_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1873: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1439
            lv1874_1: R.Tensor((1280,), dtype="float32") = transformed_param_589
            lv915_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv914_1, lv1873, lv1874_1, lv912_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1875_1: R.Tensor((1280,), dtype="float32") = transformed_param_601
            lv1876: R.Tensor((1280,), dtype="float32") = transformed_param_600
            lv3687 = R.call_tir(cls.layer_norm2, (lv915_1, lv1875_1, lv1876), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1877: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1440
            lv3689 = R.call_tir(cls.matmul19, (lv3687, lv1877), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1878: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1441
            lv3691 = R.call_tir(cls.matmul19, (lv3687, lv1878), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1879: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1442
            lv3693 = R.call_tir(cls.matmul19, (lv3687, lv1879), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv916_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3689,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv917_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3691,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv918_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3693,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv919_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv916_1, lv917_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3705 = R.call_tir(cls.softmax3, (lv919_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3706 = R.call_tir(cls.matmul21, (lv3705, lv918_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv920_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3706,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1880: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1443
            lv1881: R.Tensor((1280,), dtype="float32") = transformed_param_596
            lv921_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv920_1, lv1880, lv1881, lv915_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1882: R.Tensor((1280,), dtype="float32") = transformed_param_603
            lv1883_1: R.Tensor((1280,), dtype="float32") = transformed_param_602
            lv3714 = R.call_tir(cls.layer_norm2, (lv921_1, lv1882, lv1883_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1884: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1444
            lv3716 = R.call_tir(cls.matmul19, (lv3714, lv1884), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1885_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1445
            lv3718 = R.call_tir(cls.matmul22, (inp_2, lv1885_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1886: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1446
            lv3720 = R.call_tir(cls.matmul22, (inp_2, lv1886), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv922_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3716,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv923_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3718,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv924_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3720,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv925_2 = R.call_tir(cls.fused_matmul23_multiply9, (lv922_1, lv923_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3732 = R.call_tir(cls.softmax4, (lv925_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3733 = R.call_tir(cls.matmul24, (lv3732, lv924_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv926_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3733,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1887_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1447
            lv1888: R.Tensor((1280,), dtype="float32") = transformed_param_597
            lv927_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv926_1, lv1887_1, lv1888, lv921_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1889_1: R.Tensor((1280,), dtype="float32") = transformed_param_605
            lv1890: R.Tensor((1280,), dtype="float32") = transformed_param_604
            lv3741 = R.call_tir(cls.layer_norm2, (lv927_2, lv1889_1, lv1890), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1891: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1448
            lv1892: R.Tensor((10240,), dtype="float32") = transformed_param_598
            lv928_1 = R.call_tir(cls.fused_matmul25_add25, (lv3741, lv1891, lv1892), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv929_2 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv928_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1893: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1449
            lv1894: R.Tensor((1280,), dtype="float32") = transformed_param_599
            lv930_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv929_2, lv1893, lv1894, lv927_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1895: R.Tensor((1280,), dtype="float32") = transformed_param_611
            lv1896: R.Tensor((1280,), dtype="float32") = transformed_param_610
            lv3754 = R.call_tir(cls.layer_norm2, (lv930_1, lv1895, lv1896), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1897: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1450
            lv3756 = R.call_tir(cls.matmul19, (lv3754, lv1897), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1898: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1451
            lv3758 = R.call_tir(cls.matmul19, (lv3754, lv1898), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1899: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1452
            lv3760 = R.call_tir(cls.matmul19, (lv3754, lv1899), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv931_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3756,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv932_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3758,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv933_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3760,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv934_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv931_1, lv932_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3772 = R.call_tir(cls.softmax3, (lv934_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3773 = R.call_tir(cls.matmul21, (lv3772, lv933_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv935_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3773,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1900: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1453
            lv1901_1: R.Tensor((1280,), dtype="float32") = transformed_param_606
            lv936_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv935_1, lv1900, lv1901_1, lv930_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1902_1: R.Tensor((1280,), dtype="float32") = transformed_param_613
            lv1903: R.Tensor((1280,), dtype="float32") = transformed_param_612
            lv3781 = R.call_tir(cls.layer_norm2, (lv936_1, lv1902_1, lv1903), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1904: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1454
            lv3783 = R.call_tir(cls.matmul19, (lv3781, lv1904), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1905: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1455
            lv3785 = R.call_tir(cls.matmul22, (inp_2, lv1905), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1906: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1456
            lv3787 = R.call_tir(cls.matmul22, (inp_2, lv1906), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv937_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3783,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv938_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3785,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv939_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv3787,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv940_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv937_1, lv938_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3799 = R.call_tir(cls.softmax4, (lv940_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3800 = R.call_tir(cls.matmul24, (lv3799, lv939_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv941_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3800,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1907: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1457
            lv1908: R.Tensor((1280,), dtype="float32") = transformed_param_607
            lv942_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv941_2, lv1907, lv1908, lv936_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1909: R.Tensor((1280,), dtype="float32") = transformed_param_615
            lv1910_1: R.Tensor((1280,), dtype="float32") = transformed_param_614
            lv3808 = R.call_tir(cls.layer_norm2, (lv942_2, lv1909, lv1910_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1911: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1458
            lv1912: R.Tensor((10240,), dtype="float32") = transformed_param_608
            lv943_1 = R.call_tir(cls.fused_matmul25_add25, (lv3808, lv1911, lv1912), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv944_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv943_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1913: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1459
            lv1914: R.Tensor((1280,), dtype="float32") = transformed_param_609
            lv945_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv944_1, lv1913, lv1914, lv942_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1915: R.Tensor((1280,), dtype="float32") = transformed_param_621
            lv1916: R.Tensor((1280,), dtype="float32") = transformed_param_620
            lv3821 = R.call_tir(cls.layer_norm2, (lv945_1, lv1915, lv1916), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1917: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1460
            lv3823 = R.call_tir(cls.matmul19, (lv3821, lv1917), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1918: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1461
            lv3825 = R.call_tir(cls.matmul19, (lv3821, lv1918), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1919: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1462
            lv3827 = R.call_tir(cls.matmul19, (lv3821, lv1919), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv946_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3823,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv947_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3825,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv948_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3827,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv949_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv946_1, lv947_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3839 = R.call_tir(cls.softmax3, (lv949_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3840 = R.call_tir(cls.matmul21, (lv3839, lv948_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv950_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3840,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1920: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1463
            lv1921: R.Tensor((1280,), dtype="float32") = transformed_param_616
            lv951_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv950_2, lv1920, lv1921, lv945_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1922: R.Tensor((1280,), dtype="float32") = transformed_param_623
            lv1923_1: R.Tensor((1280,), dtype="float32") = transformed_param_622
            lv3848 = R.call_tir(cls.layer_norm2, (lv951_1, lv1922, lv1923_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1924: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1464
            lv3850 = R.call_tir(cls.matmul19, (lv3848, lv1924), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1925_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1465
            lv3852 = R.call_tir(cls.matmul22, (inp_2, lv1925_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1926: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1466
            lv3854 = R.call_tir(cls.matmul22, (inp_2, lv1926), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv952_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv3850,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv953_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3852,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv954_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv3854,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv955_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv952_2, lv953_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3866 = R.call_tir(cls.softmax4, (lv955_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3867 = R.call_tir(cls.matmul24, (lv3866, lv954_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv956_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv3867,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1927_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1467
            lv1928: R.Tensor((1280,), dtype="float32") = transformed_param_617
            lv957_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv956_2, lv1927_1, lv1928, lv951_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1929_1: R.Tensor((1280,), dtype="float32") = transformed_param_625
            lv1930: R.Tensor((1280,), dtype="float32") = transformed_param_624
            lv3875 = R.call_tir(cls.layer_norm2, (lv957_1, lv1929_1, lv1930), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1931: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1468
            lv1932: R.Tensor((10240,), dtype="float32") = transformed_param_618
            lv958_1 = R.call_tir(cls.fused_matmul25_add25, (lv3875, lv1931, lv1932), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv959_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv958_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1933: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1469
            lv1934: R.Tensor((1280,), dtype="float32") = transformed_param_619
            lv960_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv959_1, lv1933, lv1934, lv957_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1935: R.Tensor((1280,), dtype="float32") = transformed_param_631
            lv1936: R.Tensor((1280,), dtype="float32") = transformed_param_630
            lv3888 = R.call_tir(cls.layer_norm2, (lv960_1, lv1935, lv1936), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1937: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1470
            lv3890 = R.call_tir(cls.matmul19, (lv3888, lv1937), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1938: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1471
            lv3892 = R.call_tir(cls.matmul19, (lv3888, lv1938), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1939: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1472
            lv3894 = R.call_tir(cls.matmul19, (lv3888, lv1939), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv961_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3890,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv962_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3892,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv963_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3894,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv964_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv961_1, lv962_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3906 = R.call_tir(cls.softmax3, (lv964_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3907 = R.call_tir(cls.matmul21, (lv3906, lv963_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv965_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3907,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1940: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1473
            lv1941_1: R.Tensor((1280,), dtype="float32") = transformed_param_626
            lv966_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv965_1, lv1940, lv1941_1, lv960_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1942_1: R.Tensor((1280,), dtype="float32") = transformed_param_633
            lv1943: R.Tensor((1280,), dtype="float32") = transformed_param_632
            lv3915 = R.call_tir(cls.layer_norm2, (lv966_1, lv1942_1, lv1943), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1944: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1474
            lv3917 = R.call_tir(cls.matmul19, (lv3915, lv1944), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1945: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1475
            lv3919 = R.call_tir(cls.matmul22, (inp_2, lv1945), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1946: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1476
            lv3921 = R.call_tir(cls.matmul22, (inp_2, lv1946), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv967_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3917,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv968_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv3919,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv969_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv3921,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv970_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv967_1, lv968_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3933 = R.call_tir(cls.softmax4, (lv970_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3934 = R.call_tir(cls.matmul24, (lv3933, lv969_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv971_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv3934,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1947: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1477
            lv1948: R.Tensor((1280,), dtype="float32") = transformed_param_627
            lv972_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv971_1, lv1947, lv1948, lv966_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1949: R.Tensor((1280,), dtype="float32") = transformed_param_635
            lv1950_1: R.Tensor((1280,), dtype="float32") = transformed_param_634
            lv3942 = R.call_tir(cls.layer_norm2, (lv972_1, lv1949, lv1950_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1951: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1478
            lv1952_1: R.Tensor((10240,), dtype="float32") = transformed_param_628
            lv973_1 = R.call_tir(cls.fused_matmul25_add25, (lv3942, lv1951, lv1952_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv974_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv973_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1953: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1479
            lv1954_1: R.Tensor((1280,), dtype="float32") = transformed_param_629
            lv975_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv974_1, lv1953, lv1954_1, lv972_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1955: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1480
            lv1956_1: R.Tensor((1280,), dtype="float32") = transformed_param_535
            lv976_1 = R.call_tir(cls.fused_matmul19_add23, (lv975_1, lv1955, lv1956_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv977_2 = R.call_tir(cls.fused_reshape33_transpose29_add22_concatenate5, (lv976_1, lv823_1, lv174), out_sinfo=R.Tensor((2, 1920, 32, 32), dtype="float32"))
            lv1957: R.Tensor((1920,), dtype="float32") = transformed_param_760
            lv1958: R.Tensor((1920,), dtype="float32") = transformed_param_759
            lv978_1 = R.call_tir(cls.fused_group_norm8_silu7, (lv977_2, lv1957, lv1958), out_sinfo=R.Tensor((2, 1920, 32, 32), dtype="float32"))
            lv3967 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1959: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1482
            lv1960: R.Tensor((1280,), dtype="float32") = transformed_param_763
            lv979_1 = R.call_tir(cls.fused_matmul7_add5_strided_slice8, (lv3967, lv1959, lv1960), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv3972 = R.call_tir(cls.reshape28, (lv979_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1961: R.Tensor((1280, 1920, 3, 3), dtype="float32") = transformed_param_756
            lv1962: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1481
            lv980_1 = R.call_tir(cls.fused_conv2d12_add20_add21, (lv978_1, lv1961, lv1962, lv3972), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1963: R.Tensor((1280,), dtype="float32") = transformed_param_762
            lv1964: R.Tensor((1280,), dtype="float32") = transformed_param_761
            lv981_1 = R.call_tir(cls.fused_group_norm5_silu5, (lv980_1, lv1963, lv1964), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1965: R.Tensor((1280, 1920, 1, 1), dtype="float32") = transformed_param_758
            lv1966: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1484
            lv982_1 = R.call_tir(cls.fused_conv2d13_add20, (lv977_2, lv1965, lv1966), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1967: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_757
            lv1968_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1483
            lv983_1 = R.call_tir(cls.fused_conv2d8_add20_add22_divide4, (lv981_1, lv1967, lv1968_1, lv982_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1969_1: R.Tensor((1280,), dtype="float32") = transformed_param_637
            lv1970: R.Tensor((1280,), dtype="float32") = transformed_param_636
            lv3984 = R.call_tir(cls.group_norm6, (lv983_1, lv1969_1, lv1970), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv984_1 = R.call_tir(cls.fused_transpose21_reshape29, (lv3984,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1971: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1485
            lv1972: R.Tensor((1280,), dtype="float32") = transformed_param_638
            lv985_1 = R.call_tir(cls.fused_matmul19_add23, (lv984_1, lv1971, lv1972), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1973: R.Tensor((1280,), dtype="float32") = transformed_param_645
            lv1974: R.Tensor((1280,), dtype="float32") = transformed_param_644
            lv3990 = R.call_tir(cls.layer_norm2, (lv985_1, lv1973, lv1974), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1975: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1486
            lv3992 = R.call_tir(cls.matmul19, (lv3990, lv1975), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1976: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1487
            lv3994 = R.call_tir(cls.matmul19, (lv3990, lv1976), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1977_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1488
            lv3996 = R.call_tir(cls.matmul19, (lv3990, lv1977_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv986_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3992,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv987_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv3994,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv988_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv3996,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv989_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv986_1, lv987_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4008 = R.call_tir(cls.softmax3, (lv989_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4009 = R.call_tir(cls.matmul21, (lv4008, lv988_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv990_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4009,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1978: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1489
            lv1979: R.Tensor((1280,), dtype="float32") = transformed_param_640
            lv991_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv990_2, lv1978, lv1979, lv985_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1980: R.Tensor((1280,), dtype="float32") = transformed_param_647
            lv1981: R.Tensor((1280,), dtype="float32") = transformed_param_646
            lv4017 = R.call_tir(cls.layer_norm2, (lv991_1, lv1980, lv1981), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1982: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1490
            lv4019 = R.call_tir(cls.matmul19, (lv4017, lv1982), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1983: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1491
            lv4021 = R.call_tir(cls.matmul22, (inp_2, lv1983), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1984: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1492
            lv4023 = R.call_tir(cls.matmul22, (inp_2, lv1984), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv992_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4019,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv993_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4021,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv994_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv4023,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv995_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv992_2, lv993_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4035 = R.call_tir(cls.softmax4, (lv995_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4036 = R.call_tir(cls.matmul24, (lv4035, lv994_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv996_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4036,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1985: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1493
            lv1986: R.Tensor((1280,), dtype="float32") = transformed_param_641
            lv997_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv996_2, lv1985, lv1986, lv991_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1987: R.Tensor((1280,), dtype="float32") = transformed_param_649
            lv1988: R.Tensor((1280,), dtype="float32") = transformed_param_648
            lv4044 = R.call_tir(cls.layer_norm2, (lv997_1, lv1987, lv1988), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1989: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1494
            lv1990_1: R.Tensor((10240,), dtype="float32") = transformed_param_642
            lv998_1 = R.call_tir(cls.fused_matmul25_add25, (lv4044, lv1989, lv1990_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv999_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv998_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1991: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1495
            lv1992_1: R.Tensor((1280,), dtype="float32") = transformed_param_643
            lv1000_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv999_1, lv1991, lv1992_1, lv997_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1993: R.Tensor((1280,), dtype="float32") = transformed_param_655
            lv1994_1: R.Tensor((1280,), dtype="float32") = transformed_param_654
            lv4057 = R.call_tir(cls.layer_norm2, (lv1000_1, lv1993, lv1994_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1995: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1496
            lv4059 = R.call_tir(cls.matmul19, (lv4057, lv1995), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1996_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1497
            lv4061 = R.call_tir(cls.matmul19, (lv4057, lv1996_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1997: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1498
            lv4063 = R.call_tir(cls.matmul19, (lv4057, lv1997), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1001_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4059,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1002_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1003_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1004_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1001_1, lv1002_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4075 = R.call_tir(cls.softmax3, (lv1004_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4076 = R.call_tir(cls.matmul21, (lv4075, lv1003_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1005_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1998: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1499
            lv1999: R.Tensor((1280,), dtype="float32") = transformed_param_650
            lv1006_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1005_1, lv1998, lv1999, lv1000_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2000: R.Tensor((1280,), dtype="float32") = transformed_param_657
            lv2001: R.Tensor((1280,), dtype="float32") = transformed_param_656
            lv4084 = R.call_tir(cls.layer_norm2, (lv1006_1, lv2000, lv2001), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2002: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1500
            lv4086 = R.call_tir(cls.matmul19, (lv4084, lv2002), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2003: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1501
            lv4088 = R.call_tir(cls.matmul22, (inp_2, lv2003), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2004: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1502
            lv4090 = R.call_tir(cls.matmul22, (inp_2, lv2004), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1007_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1008_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1009_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv4090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1010_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1007_1, lv1008_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4102 = R.call_tir(cls.softmax4, (lv1010_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4103 = R.call_tir(cls.matmul24, (lv4102, lv1009_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1011_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2005: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1503
            lv2006: R.Tensor((1280,), dtype="float32") = transformed_param_651
            lv1012_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1011_1, lv2005, lv2006, lv1006_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2007: R.Tensor((1280,), dtype="float32") = transformed_param_659
            lv2008_1: R.Tensor((1280,), dtype="float32") = transformed_param_658
            lv4111 = R.call_tir(cls.layer_norm2, (lv1012_1, lv2007, lv2008_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2009_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1504
            lv2010: R.Tensor((10240,), dtype="float32") = transformed_param_652
            lv1013_1 = R.call_tir(cls.fused_matmul25_add25, (lv4111, lv2009_1, lv2010), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1014_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1013_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2011: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1505
            lv2012: R.Tensor((1280,), dtype="float32") = transformed_param_653
            lv1015_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1014_1, lv2011, lv2012, lv1012_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2013: R.Tensor((1280,), dtype="float32") = transformed_param_665
            lv2014: R.Tensor((1280,), dtype="float32") = transformed_param_664
            lv4124 = R.call_tir(cls.layer_norm2, (lv1015_1, lv2013, lv2014), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2015: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1506
            lv4126 = R.call_tir(cls.matmul19, (lv4124, lv2015), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2016: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1507
            lv4128 = R.call_tir(cls.matmul19, (lv4124, lv2016), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2017_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1508
            lv4130 = R.call_tir(cls.matmul19, (lv4124, lv2017_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1016_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4126,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1017_2 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4128,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1018_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4130,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1019_2 = R.call_tir(cls.fused_matmul20_multiply8, (lv1016_1, lv1017_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4142 = R.call_tir(cls.softmax3, (lv1019_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4143 = R.call_tir(cls.matmul21, (lv4142, lv1018_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1020_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4143,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2018: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1509
            lv2019_1: R.Tensor((1280,), dtype="float32") = transformed_param_660
            lv1021_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1020_1, lv2018, lv2019_1, lv1015_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2020: R.Tensor((1280,), dtype="float32") = transformed_param_667
            lv2021_1: R.Tensor((1280,), dtype="float32") = transformed_param_666
            lv4151 = R.call_tir(cls.layer_norm2, (lv1021_2, lv2020, lv2021_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2022: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1510
            lv4153 = R.call_tir(cls.matmul19, (lv4151, lv2022), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2023_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1511
            lv4155 = R.call_tir(cls.matmul22, (inp_2, lv2023_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2024: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1512
            lv4157 = R.call_tir(cls.matmul22, (inp_2, lv2024), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1022_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4153,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1023_2 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4155,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1024_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4157,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1025_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1022_1, lv1023_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4169 = R.call_tir(cls.softmax4, (lv1025_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4170 = R.call_tir(cls.matmul24, (lv4169, lv1024_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1026_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4170,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2025: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1513
            lv2026: R.Tensor((1280,), dtype="float32") = transformed_param_661
            lv1027_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1026_1, lv2025, lv2026, lv1021_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2027: R.Tensor((1280,), dtype="float32") = transformed_param_669
            lv2028: R.Tensor((1280,), dtype="float32") = transformed_param_668
            lv4178 = R.call_tir(cls.layer_norm2, (lv1027_1, lv2027, lv2028), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2029: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1514
            lv2030: R.Tensor((10240,), dtype="float32") = transformed_param_662
            lv1028_1 = R.call_tir(cls.fused_matmul25_add25, (lv4178, lv2029, lv2030), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1029_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1028_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2031: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1515
            lv2032: R.Tensor((1280,), dtype="float32") = transformed_param_663
            lv1030_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1029_1, lv2031, lv2032, lv1027_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2033: R.Tensor((1280,), dtype="float32") = transformed_param_675
            lv2034: R.Tensor((1280,), dtype="float32") = transformed_param_674
            lv4191 = R.call_tir(cls.layer_norm2, (lv1030_1, lv2033, lv2034), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2035_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1516
            lv4193 = R.call_tir(cls.matmul19, (lv4191, lv2035_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2036_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1517
            lv4195 = R.call_tir(cls.matmul19, (lv4191, lv2036_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2037: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1518
            lv4197 = R.call_tir(cls.matmul19, (lv4191, lv2037), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1031_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4193,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1032_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4195,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1033_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4197,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1034_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1031_1, lv1032_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4209 = R.call_tir(cls.softmax3, (lv1034_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4210 = R.call_tir(cls.matmul21, (lv4209, lv1033_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1035_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4210,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2038: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1519
            lv2039: R.Tensor((1280,), dtype="float32") = transformed_param_670
            lv1036_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1035_2, lv2038, lv2039, lv1030_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2040: R.Tensor((1280,), dtype="float32") = transformed_param_677
            lv2041: R.Tensor((1280,), dtype="float32") = transformed_param_676
            lv4218 = R.call_tir(cls.layer_norm2, (lv1036_2, lv2040, lv2041), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2042: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1520
            lv4220 = R.call_tir(cls.matmul19, (lv4218, lv2042), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2043: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1521
            lv4222 = R.call_tir(cls.matmul22, (inp_2, lv2043), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2044_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1522
            lv4224 = R.call_tir(cls.matmul22, (inp_2, lv2044_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1037_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4220,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1038_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4222,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1039_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4224,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1040_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1037_1, lv1038_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4236 = R.call_tir(cls.softmax4, (lv1040_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4237 = R.call_tir(cls.matmul24, (lv4236, lv1039_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1041_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4237,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2045: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1523
            lv2046: R.Tensor((1280,), dtype="float32") = transformed_param_671
            lv1042_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1041_1, lv2045, lv2046, lv1036_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2047: R.Tensor((1280,), dtype="float32") = transformed_param_679
            lv2048: R.Tensor((1280,), dtype="float32") = transformed_param_678
            lv4245 = R.call_tir(cls.layer_norm2, (lv1042_1, lv2047, lv2048), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2049: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1524
            lv2050: R.Tensor((10240,), dtype="float32") = transformed_param_672
            lv1043_1 = R.call_tir(cls.fused_matmul25_add25, (lv4245, lv2049, lv2050), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1044_2 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1043_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2051: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1525
            lv2052: R.Tensor((1280,), dtype="float32") = transformed_param_673
            lv1045_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1044_2, lv2051, lv2052, lv1042_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2053: R.Tensor((1280,), dtype="float32") = transformed_param_685
            lv2054: R.Tensor((1280,), dtype="float32") = transformed_param_684
            lv4258 = R.call_tir(cls.layer_norm2, (lv1045_1, lv2053, lv2054), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2055: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1526
            lv4260 = R.call_tir(cls.matmul19, (lv4258, lv2055), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2056: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1527
            lv4262 = R.call_tir(cls.matmul19, (lv4258, lv2056), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2057_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1528
            lv4264 = R.call_tir(cls.matmul19, (lv4258, lv2057_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1046_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4260,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1047_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4262,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1048_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4264,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1049_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1046_1, lv1047_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4276 = R.call_tir(cls.softmax3, (lv1049_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4277 = R.call_tir(cls.matmul21, (lv4276, lv1048_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1050_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4277,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2058: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1529
            lv2059_1: R.Tensor((1280,), dtype="float32") = transformed_param_680
            lv1051_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1050_1, lv2058, lv2059_1, lv1045_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2060: R.Tensor((1280,), dtype="float32") = transformed_param_687
            lv2061_1: R.Tensor((1280,), dtype="float32") = transformed_param_686
            lv4285 = R.call_tir(cls.layer_norm2, (lv1051_1, lv2060, lv2061_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2062: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1530
            lv4287 = R.call_tir(cls.matmul19, (lv4285, lv2062), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2063_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1531
            lv4289 = R.call_tir(cls.matmul22, (inp_2, lv2063_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2064: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1532
            lv4291 = R.call_tir(cls.matmul22, (inp_2, lv2064), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1052_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1053_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4289,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1054_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4291,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1055_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1052_1, lv1053_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4303 = R.call_tir(cls.softmax4, (lv1055_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4304 = R.call_tir(cls.matmul24, (lv4303, lv1054_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1056_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2065: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1533
            lv2066: R.Tensor((1280,), dtype="float32") = transformed_param_681
            lv1057_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1056_1, lv2065, lv2066, lv1051_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2067: R.Tensor((1280,), dtype="float32") = transformed_param_689
            lv2068: R.Tensor((1280,), dtype="float32") = transformed_param_688
            lv4312 = R.call_tir(cls.layer_norm2, (lv1057_2, lv2067, lv2068), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2069: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1534
            lv2070: R.Tensor((10240,), dtype="float32") = transformed_param_682
            lv1058_1 = R.call_tir(cls.fused_matmul25_add25, (lv4312, lv2069, lv2070), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1059_2 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1058_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2071: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1535
            lv2072: R.Tensor((1280,), dtype="float32") = transformed_param_683
            lv1060_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1059_2, lv2071, lv2072, lv1057_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2073: R.Tensor((1280,), dtype="float32") = transformed_param_695
            lv2074: R.Tensor((1280,), dtype="float32") = transformed_param_694
            lv4325 = R.call_tir(cls.layer_norm2, (lv1060_1, lv2073, lv2074), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2075_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1536
            lv4327 = R.call_tir(cls.matmul19, (lv4325, lv2075_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2076_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1537
            lv4329 = R.call_tir(cls.matmul19, (lv4325, lv2076_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2077: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1538
            lv4331 = R.call_tir(cls.matmul19, (lv4325, lv2077), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1061_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4327,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1062_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4329,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1063_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4331,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1064_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1061_2, lv1062_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4343 = R.call_tir(cls.softmax3, (lv1064_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4344 = R.call_tir(cls.matmul21, (lv4343, lv1063_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1065_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4344,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2078: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1539
            lv2079: R.Tensor((1280,), dtype="float32") = transformed_param_690
            lv1066_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1065_1, lv2078, lv2079, lv1060_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2080: R.Tensor((1280,), dtype="float32") = transformed_param_697
            lv2081: R.Tensor((1280,), dtype="float32") = transformed_param_696
            lv4352 = R.call_tir(cls.layer_norm2, (lv1066_1, lv2080, lv2081), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2082: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1540
            lv4354 = R.call_tir(cls.matmul19, (lv4352, lv2082), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2083: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1541
            lv4356 = R.call_tir(cls.matmul22, (inp_2, lv2083), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2084_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1542
            lv4358 = R.call_tir(cls.matmul22, (inp_2, lv2084_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1067_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1068_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4356,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1069_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4358,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1070_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1067_1, lv1068_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4370 = R.call_tir(cls.softmax4, (lv1070_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4371 = R.call_tir(cls.matmul24, (lv4370, lv1069_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1071_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2085: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1543
            lv2086_1: R.Tensor((1280,), dtype="float32") = transformed_param_691
            lv1072_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1071_1, lv2085, lv2086_1, lv1066_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2087: R.Tensor((1280,), dtype="float32") = transformed_param_699
            lv2088_1: R.Tensor((1280,), dtype="float32") = transformed_param_698
            lv4379 = R.call_tir(cls.layer_norm2, (lv1072_1, lv2087, lv2088_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2089: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1544
            lv2090_1: R.Tensor((10240,), dtype="float32") = transformed_param_692
            lv1073_1 = R.call_tir(cls.fused_matmul25_add25, (lv4379, lv2089, lv2090_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1074_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1073_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2091: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1545
            lv2092: R.Tensor((1280,), dtype="float32") = transformed_param_693
            lv1075_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1074_1, lv2091, lv2092, lv1072_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2093: R.Tensor((1280,), dtype="float32") = transformed_param_705
            lv2094: R.Tensor((1280,), dtype="float32") = transformed_param_704
            lv4392 = R.call_tir(cls.layer_norm2, (lv1075_2, lv2093, lv2094), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2095: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1546
            lv4394 = R.call_tir(cls.matmul19, (lv4392, lv2095), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2096: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1547
            lv4396 = R.call_tir(cls.matmul19, (lv4392, lv2096), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2097: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1548
            lv4398 = R.call_tir(cls.matmul19, (lv4392, lv2097), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1076_2 = R.call_tir(cls.fused_reshape30_transpose22, (lv4394,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1077_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4396,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1078_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4398,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1079_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1076_2, lv1077_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4410 = R.call_tir(cls.softmax3, (lv1079_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4411 = R.call_tir(cls.matmul21, (lv4410, lv1078_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1080_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4411,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2098: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1549
            lv2099: R.Tensor((1280,), dtype="float32") = transformed_param_700
            lv1081_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1080_1, lv2098, lv2099, lv1075_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2100: R.Tensor((1280,), dtype="float32") = transformed_param_707
            lv2101: R.Tensor((1280,), dtype="float32") = transformed_param_706
            lv4419 = R.call_tir(cls.layer_norm2, (lv1081_1, lv2100, lv2101), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2102_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1550
            lv4421 = R.call_tir(cls.matmul19, (lv4419, lv2102_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2103_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1551
            lv4423 = R.call_tir(cls.matmul22, (inp_2, lv2103_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2104: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1552
            lv4425 = R.call_tir(cls.matmul22, (inp_2, lv2104), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1082_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1083_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4423,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1084_2 = R.call_tir(cls.fused_reshape32_transpose26, (lv4425,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1085_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1082_1, lv1083_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4437 = R.call_tir(cls.softmax4, (lv1085_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4438 = R.call_tir(cls.matmul24, (lv4437, lv1084_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1086_2 = R.call_tir(cls.fused_transpose24_reshape31, (lv4438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2105: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1553
            lv2106: R.Tensor((1280,), dtype="float32") = transformed_param_701
            lv1087_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1086_2, lv2105, lv2106, lv1081_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2107: R.Tensor((1280,), dtype="float32") = transformed_param_709
            lv2108: R.Tensor((1280,), dtype="float32") = transformed_param_708
            lv4446 = R.call_tir(cls.layer_norm2, (lv1087_1, lv2107, lv2108), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2109: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1554
            lv2110: R.Tensor((10240,), dtype="float32") = transformed_param_702
            lv1088_2 = R.call_tir(cls.fused_matmul25_add25, (lv4446, lv2109, lv2110), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1089_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1088_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2111_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1555
            lv2112: R.Tensor((1280,), dtype="float32") = transformed_param_703
            lv1090_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1089_1, lv2111_1, lv2112, lv1087_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2113: R.Tensor((1280,), dtype="float32") = transformed_param_715
            lv2114: R.Tensor((1280,), dtype="float32") = transformed_param_714
            lv4459 = R.call_tir(cls.layer_norm2, (lv1090_2, lv2113, lv2114), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2115: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1556
            lv4461 = R.call_tir(cls.matmul19, (lv4459, lv2115), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2116: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1557
            lv4463 = R.call_tir(cls.matmul19, (lv4459, lv2116), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2117: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1558
            lv4465 = R.call_tir(cls.matmul19, (lv4459, lv2117), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1091_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4461,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1092_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4463,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1093_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4465,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1094_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1091_1, lv1092_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4477 = R.call_tir(cls.softmax3, (lv1094_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4478 = R.call_tir(cls.matmul21, (lv4477, lv1093_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1095_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4478,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2118: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1559
            lv2119: R.Tensor((1280,), dtype="float32") = transformed_param_710
            lv1096_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1095_1, lv2118, lv2119, lv1090_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2120: R.Tensor((1280,), dtype="float32") = transformed_param_717
            lv2121: R.Tensor((1280,), dtype="float32") = transformed_param_716
            lv4486 = R.call_tir(cls.layer_norm2, (lv1096_1, lv2120, lv2121), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2122: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1560
            lv4488 = R.call_tir(cls.matmul19, (lv4486, lv2122), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2123: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1561
            lv4490 = R.call_tir(cls.matmul22, (inp_2, lv2123), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2124_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1562
            lv4492 = R.call_tir(cls.matmul22, (inp_2, lv2124_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1097_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1098_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4490,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1099_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4492,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1100_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1097_1, lv1098_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4504 = R.call_tir(cls.softmax4, (lv1100_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4505 = R.call_tir(cls.matmul24, (lv4504, lv1099_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1101_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2125: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1563
            lv2126_1: R.Tensor((1280,), dtype="float32") = transformed_param_711
            lv1102_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1101_1, lv2125, lv2126_1, lv1096_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2127: R.Tensor((1280,), dtype="float32") = transformed_param_719
            lv2128_1: R.Tensor((1280,), dtype="float32") = transformed_param_718
            lv4513 = R.call_tir(cls.layer_norm2, (lv1102_2, lv2127, lv2128_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2129: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1564
            lv2130_1: R.Tensor((10240,), dtype="float32") = transformed_param_712
            lv1103_2 = R.call_tir(cls.fused_matmul25_add25, (lv4513, lv2129, lv2130_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1104_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1103_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2131: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1565
            lv2132: R.Tensor((1280,), dtype="float32") = transformed_param_713
            lv1105_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1104_1, lv2131, lv2132, lv1102_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2133: R.Tensor((1280,), dtype="float32") = transformed_param_725
            lv2134: R.Tensor((1280,), dtype="float32") = transformed_param_724
            lv4526 = R.call_tir(cls.layer_norm2, (lv1105_1, lv2133, lv2134), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2135: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1566
            lv4528 = R.call_tir(cls.matmul19, (lv4526, lv2135), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2136: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1567
            lv4530 = R.call_tir(cls.matmul19, (lv4526, lv2136), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2137: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1568
            lv4532 = R.call_tir(cls.matmul19, (lv4526, lv2137), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1106_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4528,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1107_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4530,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1108_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4532,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1109_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1106_1, lv1107_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4544 = R.call_tir(cls.softmax3, (lv1109_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4545 = R.call_tir(cls.matmul21, (lv4544, lv1108_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1110_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4545,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2138: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1569
            lv2139: R.Tensor((1280,), dtype="float32") = transformed_param_720
            lv1111_2 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1110_1, lv2138, lv2139, lv1105_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2140: R.Tensor((1280,), dtype="float32") = transformed_param_727
            lv2141: R.Tensor((1280,), dtype="float32") = transformed_param_726
            lv4553 = R.call_tir(cls.layer_norm2, (lv1111_2, lv2140, lv2141), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2142_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1570
            lv4555 = R.call_tir(cls.matmul19, (lv4553, lv2142_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2143_1: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1571
            lv4557 = R.call_tir(cls.matmul22, (inp_2, lv2143_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2144: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1572
            lv4559 = R.call_tir(cls.matmul22, (inp_2, lv2144), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1112_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4555,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1113_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4557,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1114_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4559,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1115_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1112_1, lv1113_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4571 = R.call_tir(cls.softmax4, (lv1115_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4572 = R.call_tir(cls.matmul24, (lv4571, lv1114_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1116_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4572,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2145: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1573
            lv2146: R.Tensor((1280,), dtype="float32") = transformed_param_721
            lv1117_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1116_1, lv2145, lv2146, lv1111_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2147: R.Tensor((1280,), dtype="float32") = transformed_param_729
            lv2148: R.Tensor((1280,), dtype="float32") = transformed_param_728
            lv4580 = R.call_tir(cls.layer_norm2, (lv1117_1, lv2147, lv2148), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2149: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1574
            lv2150: R.Tensor((10240,), dtype="float32") = transformed_param_722
            lv1118_1 = R.call_tir(cls.fused_matmul25_add25, (lv4580, lv2149, lv2150), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1119_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1118_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2151_1: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1575
            lv2152: R.Tensor((1280,), dtype="float32") = transformed_param_723
            lv1120_1 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1119_1, lv2151_1, lv2152, lv1117_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2153_1: R.Tensor((1280,), dtype="float32") = transformed_param_735
            lv2154: R.Tensor((1280,), dtype="float32") = transformed_param_734
            lv4593 = R.call_tir(cls.layer_norm2, (lv1120_1, lv2153_1, lv2154), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2155_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1576
            lv4595 = R.call_tir(cls.matmul19, (lv4593, lv2155_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2156: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1577
            lv4597 = R.call_tir(cls.matmul19, (lv4593, lv2156), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2157_1: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1578
            lv4599 = R.call_tir(cls.matmul19, (lv4593, lv2157_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1121_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4595,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1122_1 = R.call_tir(cls.fused_reshape30_transpose22_transpose23, (lv4597,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1123_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4599,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1124_1 = R.call_tir(cls.fused_matmul20_multiply8, (lv1121_1, lv1122_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4611 = R.call_tir(cls.softmax3, (lv1124_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4612 = R.call_tir(cls.matmul21, (lv4611, lv1123_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1125_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4612,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2158: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1579
            lv2159: R.Tensor((1280,), dtype="float32") = transformed_param_730
            lv1126_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1125_1, lv2158, lv2159, lv1120_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2160: R.Tensor((1280,), dtype="float32") = transformed_param_737
            lv2161: R.Tensor((1280,), dtype="float32") = transformed_param_736
            lv4620 = R.call_tir(cls.layer_norm2, (lv1126_1, lv2160, lv2161), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2162: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1580
            lv4622 = R.call_tir(cls.matmul19, (lv4620, lv2162), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2163: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1581
            lv4624 = R.call_tir(cls.matmul22, (inp_2, lv2163), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2164: R.Tensor((2048, 1280), dtype="float32") = transformed_param_1582
            lv4626 = R.call_tir(cls.matmul22, (inp_2, lv2164), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1127_1 = R.call_tir(cls.fused_reshape30_transpose22, (lv4622,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1128_1 = R.call_tir(cls.fused_reshape32_transpose26_transpose27, (lv4624,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1129_1 = R.call_tir(cls.fused_reshape32_transpose26, (lv4626,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1130_1 = R.call_tir(cls.fused_matmul23_multiply9, (lv1127_1, lv1128_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4638 = R.call_tir(cls.softmax4, (lv1130_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4639 = R.call_tir(cls.matmul24, (lv4638, lv1129_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1131_1 = R.call_tir(cls.fused_transpose24_reshape31, (lv4639,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2165: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1583
            lv2166: R.Tensor((1280,), dtype="float32") = transformed_param_731
            lv1132_1 = R.call_tir(cls.fused_matmul19_add23_divide5_add24, (lv1131_1, lv2165, lv2166, lv1126_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2167: R.Tensor((1280,), dtype="float32") = transformed_param_739
            lv2168: R.Tensor((1280,), dtype="float32") = transformed_param_738
            lv4647 = R.call_tir(cls.layer_norm2, (lv1132_1, lv2167, lv2168), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2169_1: R.Tensor((1280, 10240), dtype="float32") = transformed_param_1584
            lv2170_1: R.Tensor((10240,), dtype="float32") = transformed_param_732
            lv1133_1 = R.call_tir(cls.fused_matmul25_add25, (lv4647, lv2169_1, lv2170_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1134_1 = R.call_tir(cls.fused_split1_gelu2_multiply10, (lv1133_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2171: R.Tensor((5120, 1280), dtype="float32") = transformed_param_1585
            lv2172: R.Tensor((1280,), dtype="float32") = transformed_param_733
            lv1135_2 = R.call_tir(cls.fused_matmul26_add23_add24, (lv1134_1, lv2171, lv2172, lv1132_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2173: R.Tensor((1280, 1280), dtype="float32") = transformed_param_1586
            lv2174: R.Tensor((1280,), dtype="float32") = transformed_param_639
            lv1136_1 = R.call_tir(cls.fused_matmul19_add23, (lv1135_2, lv2173, lv2174), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1137_1 = R.call_tir(cls.fused_reshape33_transpose29_add22_resize2d, (lv1136_1, lv983_1), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv2175: R.Tensor((1280, 1280, 3, 3), dtype="float32") = transformed_param_764
            lv2176: R.Tensor((1, 1280, 1, 1), dtype="float32") = transformed_param_1587
            lv1138_1 = R.call_tir(cls.fused_conv2d14_add26, (lv1137_1, lv2175, lv2176), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv4670 = R.call_tir(cls.concatenate6, (lv1138_1, lv173), out_sinfo=R.Tensor((2, 1920, 64, 64), dtype="float32"))
            lv2177: R.Tensor((1920,), dtype="float32") = transformed_param_841
            lv2178_1: R.Tensor((1920,), dtype="float32") = transformed_param_840
            lv1139_1 = R.call_tir(cls.fused_group_norm9_silu8, (lv4670, lv2177, lv2178_1), out_sinfo=R.Tensor((2, 1920, 64, 64), dtype="float32"))
            lv4676 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2179: R.Tensor((1280, 640), dtype="float32") = transformed_param_1589
            lv2180: R.Tensor((640,), dtype="float32") = transformed_param_844
            lv1140_2 = R.call_tir(cls.fused_matmul10_add13_strided_slice7, (lv4676, lv2179, lv2180), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv4681 = R.call_tir(cls.reshape21, (lv1140_2,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2181: R.Tensor((640, 1920, 3, 3), dtype="float32") = transformed_param_837
            lv2182: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1588
            lv1141_1 = R.call_tir(cls.fused_conv2d15_add12_add14, (lv1139_1, lv2181, lv2182, lv4681), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2183: R.Tensor((640,), dtype="float32") = transformed_param_843
            lv2184: R.Tensor((640,), dtype="float32") = transformed_param_842
            lv1142_1 = R.call_tir(cls.fused_group_norm2_silu3, (lv1141_1, lv2183, lv2184), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2185: R.Tensor((640, 1920, 1, 1), dtype="float32") = transformed_param_839
            lv2186: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1591
            lv1143_1 = R.call_tir(cls.fused_conv2d16_add12, (lv4670, lv2185, lv2186), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2187: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_838
            lv2188: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1590
            lv1144_1 = R.call_tir(cls.fused_conv2d4_add12_add15_divide1, (lv1142_1, lv2187, lv2188, lv1143_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2189: R.Tensor((640,), dtype="float32") = transformed_param_766
            lv2190: R.Tensor((640,), dtype="float32") = transformed_param_765
            lv4693 = R.call_tir(cls.group_norm3, (lv1144_1, lv2189, lv2190), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1145_1 = R.call_tir(cls.fused_transpose10_reshape22, (lv4693,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2191_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1592
            lv2192: R.Tensor((640,), dtype="float32") = transformed_param_767
            lv1146_1 = R.call_tir(cls.fused_matmul11_add16, (lv1145_1, lv2191_1, lv2192), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2193_1: R.Tensor((640,), dtype="float32") = transformed_param_774
            lv2194: R.Tensor((640,), dtype="float32") = transformed_param_773
            lv4699 = R.call_tir(cls.layer_norm1, (lv1146_1, lv2193_1, lv2194), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2195_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1593
            lv4701 = R.call_tir(cls.matmul11, (lv4699, lv2195_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2196: R.Tensor((640, 640), dtype="float32") = transformed_param_1594
            lv4703 = R.call_tir(cls.matmul11, (lv4699, lv2196), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2197_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1595
            lv4705 = R.call_tir(cls.matmul11, (lv4699, lv2197_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1147_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4701,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1148_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4703,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1149_2 = R.call_tir(cls.fused_reshape23_transpose12, (lv4705,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1150_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1147_1, lv1148_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4717 = R.call_tir(cls.softmax1, (lv1150_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4718 = R.call_tir(cls.matmul13, (lv4717, lv1149_2), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1151_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4718,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2198: R.Tensor((640, 640), dtype="float32") = transformed_param_1596
            lv2199: R.Tensor((640,), dtype="float32") = transformed_param_769
            lv1152_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1151_1, lv2198, lv2199, lv1146_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2200: R.Tensor((640,), dtype="float32") = transformed_param_776
            lv2201: R.Tensor((640,), dtype="float32") = transformed_param_775
            lv4726 = R.call_tir(cls.layer_norm1, (lv1152_1, lv2200, lv2201), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2202: R.Tensor((640, 640), dtype="float32") = transformed_param_1597
            lv4728 = R.call_tir(cls.matmul11, (lv4726, lv2202), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2203: R.Tensor((2048, 640), dtype="float32") = transformed_param_1598
            lv4730 = R.call_tir(cls.matmul14, (inp_2, lv2203), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2204: R.Tensor((2048, 640), dtype="float32") = transformed_param_1599
            lv4732 = R.call_tir(cls.matmul14, (inp_2, lv2204), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1153_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4728,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1154_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4730,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1155_2 = R.call_tir(cls.fused_reshape25_transpose16, (lv4732,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1156_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv1153_1, lv1154_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4744 = R.call_tir(cls.softmax2, (lv1156_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4745 = R.call_tir(cls.matmul16, (lv4744, lv1155_2), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1157_2 = R.call_tir(cls.fused_transpose14_reshape24, (lv4745,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2205: R.Tensor((640, 640), dtype="float32") = transformed_param_1600
            lv2206: R.Tensor((640,), dtype="float32") = transformed_param_770
            lv1158_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1157_2, lv2205, lv2206, lv1152_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2207: R.Tensor((640,), dtype="float32") = transformed_param_778
            lv2208: R.Tensor((640,), dtype="float32") = transformed_param_777
            lv4753 = R.call_tir(cls.layer_norm1, (lv1158_1, lv2207, lv2208), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2209_1: R.Tensor((640, 5120), dtype="float32") = transformed_param_1601
            lv2210_1: R.Tensor((5120,), dtype="float32") = transformed_param_771
            lv1159_2 = R.call_tir(cls.fused_matmul17_add18, (lv4753, lv2209_1, lv2210_1), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1160_1 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1159_2,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2211: R.Tensor((2560, 640), dtype="float32") = transformed_param_1602
            lv2212: R.Tensor((640,), dtype="float32") = transformed_param_772
            lv1161_2 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1160_1, lv2211, lv2212, lv1158_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2213: R.Tensor((640,), dtype="float32") = transformed_param_784
            lv2214: R.Tensor((640,), dtype="float32") = transformed_param_783
            lv4766 = R.call_tir(cls.layer_norm1, (lv1161_2, lv2213, lv2214), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2215: R.Tensor((640, 640), dtype="float32") = transformed_param_1603
            lv4768 = R.call_tir(cls.matmul11, (lv4766, lv2215), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2216: R.Tensor((640, 640), dtype="float32") = transformed_param_1604
            lv4770 = R.call_tir(cls.matmul11, (lv4766, lv2216), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2217: R.Tensor((640, 640), dtype="float32") = transformed_param_1605
            lv4772 = R.call_tir(cls.matmul11, (lv4766, lv2217), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1162_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4768,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1163_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4770,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1164_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4772,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1165_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1162_1, lv1163_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4784 = R.call_tir(cls.softmax1, (lv1165_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4785 = R.call_tir(cls.matmul13, (lv4784, lv1164_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1166_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4785,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2218_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1606
            lv2219: R.Tensor((640,), dtype="float32") = transformed_param_779
            lv1167_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1166_1, lv2218_1, lv2219, lv1161_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2220_1: R.Tensor((640,), dtype="float32") = transformed_param_786
            lv2221: R.Tensor((640,), dtype="float32") = transformed_param_785
            lv4793 = R.call_tir(cls.layer_norm1, (lv1167_1, lv2220_1, lv2221), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2222_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1607
            lv4795 = R.call_tir(cls.matmul11, (lv4793, lv2222_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2223: R.Tensor((2048, 640), dtype="float32") = transformed_param_1608
            lv4797 = R.call_tir(cls.matmul14, (inp_2, lv2223), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2224_1: R.Tensor((2048, 640), dtype="float32") = transformed_param_1609
            lv4799 = R.call_tir(cls.matmul14, (inp_2, lv2224_1), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1168_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4795,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1169_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4797,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1170_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4799,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1171_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv1168_1, lv1169_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4811 = R.call_tir(cls.softmax2, (lv1171_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4812 = R.call_tir(cls.matmul16, (lv4811, lv1170_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1172_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4812,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2225: R.Tensor((640, 640), dtype="float32") = transformed_param_1610
            lv2226: R.Tensor((640,), dtype="float32") = transformed_param_780
            lv1173_2 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1172_1, lv2225, lv2226, lv1167_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2227: R.Tensor((640,), dtype="float32") = transformed_param_788
            lv2228: R.Tensor((640,), dtype="float32") = transformed_param_787
            lv4820 = R.call_tir(cls.layer_norm1, (lv1173_2, lv2227, lv2228), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2229: R.Tensor((640, 5120), dtype="float32") = transformed_param_1611
            lv2230: R.Tensor((5120,), dtype="float32") = transformed_param_781
            lv1174_2 = R.call_tir(cls.fused_matmul17_add18, (lv4820, lv2229, lv2230), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1175_1 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1174_2,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2231: R.Tensor((2560, 640), dtype="float32") = transformed_param_1612
            lv2232: R.Tensor((640,), dtype="float32") = transformed_param_782
            lv1176_1 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1175_1, lv2231, lv2232, lv1173_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2233: R.Tensor((640, 640), dtype="float32") = transformed_param_1613
            lv2234: R.Tensor((640,), dtype="float32") = transformed_param_768
            lv1177_1 = R.call_tir(cls.fused_matmul11_add16, (lv1176_1, lv2233, lv2234), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1178_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_concatenate7, (lv1177_1, lv1144_1, lv134), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv2235: R.Tensor((1280,), dtype="float32") = transformed_param_849
            lv2236_1: R.Tensor((1280,), dtype="float32") = transformed_param_848
            lv1179_1 = R.call_tir(cls.fused_group_norm10_silu9, (lv1178_1, lv2235, lv2236_1), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv4845 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2237_1: R.Tensor((1280, 640), dtype="float32") = transformed_param_1615
            lv2238: R.Tensor((640,), dtype="float32") = transformed_param_852
            lv1180_1 = R.call_tir(cls.fused_matmul10_add13_strided_slice7, (lv4845, lv2237_1, lv2238), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv4850 = R.call_tir(cls.reshape21, (lv1180_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2239: R.Tensor((640, 1280, 3, 3), dtype="float32") = transformed_param_845
            lv2240: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1614
            lv1181_1 = R.call_tir(cls.fused_conv2d17_add12_add14, (lv1179_1, lv2239, lv2240, lv4850), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2241: R.Tensor((640,), dtype="float32") = transformed_param_851
            lv2242: R.Tensor((640,), dtype="float32") = transformed_param_850
            lv1182_2 = R.call_tir(cls.fused_group_norm2_silu3, (lv1181_1, lv2241, lv2242), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2243: R.Tensor((640, 1280, 1, 1), dtype="float32") = transformed_param_847
            lv2244: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1617
            lv1183_1 = R.call_tir(cls.fused_conv2d18_add12, (lv1178_1, lv2243, lv2244), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2245_1: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_846
            lv2246: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1616
            lv1184_2 = R.call_tir(cls.fused_conv2d4_add12_add15_divide1, (lv1182_2, lv2245_1, lv2246, lv1183_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2247: R.Tensor((640,), dtype="float32") = transformed_param_790
            lv2248: R.Tensor((640,), dtype="float32") = transformed_param_789
            lv4862 = R.call_tir(cls.group_norm3, (lv1184_2, lv2247, lv2248), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1185_1 = R.call_tir(cls.fused_transpose10_reshape22, (lv4862,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2249: R.Tensor((640, 640), dtype="float32") = transformed_param_1618
            lv2250: R.Tensor((640,), dtype="float32") = transformed_param_791
            lv1186_2 = R.call_tir(cls.fused_matmul11_add16, (lv1185_1, lv2249, lv2250), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2251: R.Tensor((640,), dtype="float32") = transformed_param_798
            lv2252: R.Tensor((640,), dtype="float32") = transformed_param_797
            lv4868 = R.call_tir(cls.layer_norm1, (lv1186_2, lv2251, lv2252), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2253: R.Tensor((640, 640), dtype="float32") = transformed_param_1619
            lv4870 = R.call_tir(cls.matmul11, (lv4868, lv2253), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2254: R.Tensor((640, 640), dtype="float32") = transformed_param_1620
            lv4872 = R.call_tir(cls.matmul11, (lv4868, lv2254), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2255: R.Tensor((640, 640), dtype="float32") = transformed_param_1621
            lv4874 = R.call_tir(cls.matmul11, (lv4868, lv2255), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1187_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4870,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1188_2 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4872,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1189_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4874,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1190_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1187_1, lv1188_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4886 = R.call_tir(cls.softmax1, (lv1190_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4887 = R.call_tir(cls.matmul13, (lv4886, lv1189_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1191_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4887,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2256: R.Tensor((640, 640), dtype="float32") = transformed_param_1622
            lv2257: R.Tensor((640,), dtype="float32") = transformed_param_793
            lv1192_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1191_1, lv2256, lv2257, lv1186_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2258_1: R.Tensor((640,), dtype="float32") = transformed_param_800
            lv2259: R.Tensor((640,), dtype="float32") = transformed_param_799
            lv4895 = R.call_tir(cls.layer_norm1, (lv1192_1, lv2258_1, lv2259), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2260_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1623
            lv4897 = R.call_tir(cls.matmul11, (lv4895, lv2260_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2261: R.Tensor((2048, 640), dtype="float32") = transformed_param_1624
            lv4899 = R.call_tir(cls.matmul14, (inp_2, lv2261), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2262_1: R.Tensor((2048, 640), dtype="float32") = transformed_param_1625
            lv4901 = R.call_tir(cls.matmul14, (inp_2, lv2262_1), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1193_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4897,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1194_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4899,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1195_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4901,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1196_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv1193_1, lv1194_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4913 = R.call_tir(cls.softmax2, (lv1196_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4914 = R.call_tir(cls.matmul16, (lv4913, lv1195_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1197_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4914,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2263: R.Tensor((640, 640), dtype="float32") = transformed_param_1626
            lv2264_1: R.Tensor((640,), dtype="float32") = transformed_param_794
            lv1198_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1197_1, lv2263, lv2264_1, lv1192_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2265: R.Tensor((640,), dtype="float32") = transformed_param_802
            lv2266: R.Tensor((640,), dtype="float32") = transformed_param_801
            lv4922 = R.call_tir(cls.layer_norm1, (lv1198_1, lv2265, lv2266), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2267: R.Tensor((640, 5120), dtype="float32") = transformed_param_1627
            lv2268: R.Tensor((5120,), dtype="float32") = transformed_param_795
            lv1199_1 = R.call_tir(cls.fused_matmul17_add18, (lv4922, lv2267, lv2268), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1200_2 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1199_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2269: R.Tensor((2560, 640), dtype="float32") = transformed_param_1628
            lv2270: R.Tensor((640,), dtype="float32") = transformed_param_796
            lv1201_2 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1200_2, lv2269, lv2270, lv1198_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2271: R.Tensor((640,), dtype="float32") = transformed_param_808
            lv2272: R.Tensor((640,), dtype="float32") = transformed_param_807
            lv4935 = R.call_tir(cls.layer_norm1, (lv1201_2, lv2271, lv2272), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2273: R.Tensor((640, 640), dtype="float32") = transformed_param_1629
            lv4937 = R.call_tir(cls.matmul11, (lv4935, lv2273), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2274: R.Tensor((640, 640), dtype="float32") = transformed_param_1630
            lv4939 = R.call_tir(cls.matmul11, (lv4935, lv2274), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2275: R.Tensor((640, 640), dtype="float32") = transformed_param_1631
            lv4941 = R.call_tir(cls.matmul11, (lv4935, lv2275), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1202_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4937,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1203_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv4939,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1204_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4941,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1205_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1202_1, lv1203_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4953 = R.call_tir(cls.softmax1, (lv1205_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4954 = R.call_tir(cls.matmul13, (lv4953, lv1204_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1206_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4954,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2276_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1632
            lv2277_1: R.Tensor((640,), dtype="float32") = transformed_param_803
            lv1207_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1206_1, lv2276_1, lv2277_1, lv1201_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2278: R.Tensor((640,), dtype="float32") = transformed_param_810
            lv2279: R.Tensor((640,), dtype="float32") = transformed_param_809
            lv4962 = R.call_tir(cls.layer_norm1, (lv1207_1, lv2278, lv2279), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2280: R.Tensor((640, 640), dtype="float32") = transformed_param_1633
            lv4964 = R.call_tir(cls.matmul11, (lv4962, lv2280), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2281: R.Tensor((2048, 640), dtype="float32") = transformed_param_1634
            lv4966 = R.call_tir(cls.matmul14, (inp_2, lv2281), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2282: R.Tensor((2048, 640), dtype="float32") = transformed_param_1635
            lv4968 = R.call_tir(cls.matmul14, (inp_2, lv2282), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1208_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv4964,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1209_2 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv4966,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1210_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv4968,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1211_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv1208_1, lv1209_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4980 = R.call_tir(cls.softmax2, (lv1211_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4981 = R.call_tir(cls.matmul16, (lv4980, lv1210_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1212_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv4981,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2283: R.Tensor((640, 640), dtype="float32") = transformed_param_1636
            lv2284: R.Tensor((640,), dtype="float32") = transformed_param_804
            lv1213_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1212_1, lv2283, lv2284, lv1207_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2285_1: R.Tensor((640,), dtype="float32") = transformed_param_812
            lv2286: R.Tensor((640,), dtype="float32") = transformed_param_811
            lv4989 = R.call_tir(cls.layer_norm1, (lv1213_1, lv2285_1, lv2286), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2287_1: R.Tensor((640, 5120), dtype="float32") = transformed_param_1637
            lv2288: R.Tensor((5120,), dtype="float32") = transformed_param_805
            lv1214_1 = R.call_tir(cls.fused_matmul17_add18, (lv4989, lv2287_1, lv2288), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1215_1 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1214_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2289_1: R.Tensor((2560, 640), dtype="float32") = transformed_param_1638
            lv2290: R.Tensor((640,), dtype="float32") = transformed_param_806
            lv1216_1 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1215_1, lv2289_1, lv2290, lv1213_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2291_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1639
            lv2292: R.Tensor((640,), dtype="float32") = transformed_param_792
            lv1217_1 = R.call_tir(cls.fused_matmul11_add16, (lv1216_1, lv2291_1, lv2292), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1218_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_concatenate8, (lv1217_1, lv1184_2, lv94), out_sinfo=R.Tensor((2, 960, 64, 64), dtype="float32"))
            lv2293: R.Tensor((960,), dtype="float32") = transformed_param_857
            lv2294: R.Tensor((960,), dtype="float32") = transformed_param_856
            lv1219_1 = R.call_tir(cls.fused_group_norm11_silu10, (lv1218_1, lv2293, lv2294), out_sinfo=R.Tensor((2, 960, 64, 64), dtype="float32"))
            lv5014 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2295: R.Tensor((1280, 640), dtype="float32") = transformed_param_1641
            lv2296: R.Tensor((640,), dtype="float32") = transformed_param_860
            lv1220_1 = R.call_tir(cls.fused_matmul10_add13_strided_slice7, (lv5014, lv2295, lv2296), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv5019 = R.call_tir(cls.reshape21, (lv1220_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2297: R.Tensor((640, 960, 3, 3), dtype="float32") = transformed_param_853
            lv2298: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1640
            lv1221_1 = R.call_tir(cls.fused_conv2d19_add12_add14, (lv1219_1, lv2297, lv2298, lv5019), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2299: R.Tensor((640,), dtype="float32") = transformed_param_859
            lv2300: R.Tensor((640,), dtype="float32") = transformed_param_858
            lv1222_2 = R.call_tir(cls.fused_group_norm2_silu3, (lv1221_1, lv2299, lv2300), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2301: R.Tensor((640, 960, 1, 1), dtype="float32") = transformed_param_855
            lv2302: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1643
            lv1223_1 = R.call_tir(cls.fused_conv2d20_add12, (lv1218_1, lv2301, lv2302), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2303_1: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_854
            lv2304_1: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1642
            lv1224_2 = R.call_tir(cls.fused_conv2d4_add12_add15_divide1, (lv1222_2, lv2303_1, lv2304_1, lv1223_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2305: R.Tensor((640,), dtype="float32") = transformed_param_814
            lv2306: R.Tensor((640,), dtype="float32") = transformed_param_813
            lv5031 = R.call_tir(cls.group_norm3, (lv1224_2, lv2305, lv2306), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1225_1 = R.call_tir(cls.fused_transpose10_reshape22, (lv5031,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2307: R.Tensor((640, 640), dtype="float32") = transformed_param_1644
            lv2308: R.Tensor((640,), dtype="float32") = transformed_param_815
            lv1226_2 = R.call_tir(cls.fused_matmul11_add16, (lv1225_1, lv2307, lv2308), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2309: R.Tensor((640,), dtype="float32") = transformed_param_822
            lv2310: R.Tensor((640,), dtype="float32") = transformed_param_821
            lv5037 = R.call_tir(cls.layer_norm1, (lv1226_2, lv2309, lv2310), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2311: R.Tensor((640, 640), dtype="float32") = transformed_param_1645
            lv5039 = R.call_tir(cls.matmul11, (lv5037, lv2311), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2312_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1646
            lv5041 = R.call_tir(cls.matmul11, (lv5037, lv2312_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2313: R.Tensor((640, 640), dtype="float32") = transformed_param_1647
            lv5043 = R.call_tir(cls.matmul11, (lv5037, lv2313), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1227_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5039,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1228_2 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv5041,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1229_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5043,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1230_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1227_1, lv1228_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5055 = R.call_tir(cls.softmax1, (lv1230_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5056 = R.call_tir(cls.matmul13, (lv5055, lv1229_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1231_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5056,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2314: R.Tensor((640, 640), dtype="float32") = transformed_param_1648
            lv2315: R.Tensor((640,), dtype="float32") = transformed_param_817
            lv1232_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1231_1, lv2314, lv2315, lv1226_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2316: R.Tensor((640,), dtype="float32") = transformed_param_824
            lv2317: R.Tensor((640,), dtype="float32") = transformed_param_823
            lv5064 = R.call_tir(cls.layer_norm1, (lv1232_1, lv2316, lv2317), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2318: R.Tensor((640, 640), dtype="float32") = transformed_param_1649
            lv5066 = R.call_tir(cls.matmul11, (lv5064, lv2318), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2319: R.Tensor((2048, 640), dtype="float32") = transformed_param_1650
            lv5068 = R.call_tir(cls.matmul14, (inp_2, lv2319), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2320: R.Tensor((2048, 640), dtype="float32") = transformed_param_1651
            lv5070 = R.call_tir(cls.matmul14, (inp_2, lv2320), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1233_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5066,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1234_1 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv5068,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1235_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv5070,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1236_1 = R.call_tir(cls.fused_matmul15_multiply6, (lv1233_1, lv1234_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5082 = R.call_tir(cls.softmax2, (lv1236_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5083 = R.call_tir(cls.matmul16, (lv5082, lv1235_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1237_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5083,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2321: R.Tensor((640, 640), dtype="float32") = transformed_param_1652
            lv2322: R.Tensor((640,), dtype="float32") = transformed_param_818
            lv1238_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1237_1, lv2321, lv2322, lv1232_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2323: R.Tensor((640,), dtype="float32") = transformed_param_826
            lv2324: R.Tensor((640,), dtype="float32") = transformed_param_825
            lv5091 = R.call_tir(cls.layer_norm1, (lv1238_1, lv2323, lv2324), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2325_1: R.Tensor((640, 5120), dtype="float32") = transformed_param_1653
            lv2326: R.Tensor((5120,), dtype="float32") = transformed_param_819
            lv1239_1 = R.call_tir(cls.fused_matmul17_add18, (lv5091, lv2325_1, lv2326), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1240_2 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1239_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2327_1: R.Tensor((2560, 640), dtype="float32") = transformed_param_1654
            lv2328: R.Tensor((640,), dtype="float32") = transformed_param_820
            lv1241_2 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1240_2, lv2327_1, lv2328, lv1238_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2329_1: R.Tensor((640,), dtype="float32") = transformed_param_832
            lv2330: R.Tensor((640,), dtype="float32") = transformed_param_831
            lv5104 = R.call_tir(cls.layer_norm1, (lv1241_2, lv2329_1, lv2330), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2331_1: R.Tensor((640, 640), dtype="float32") = transformed_param_1655
            lv5106 = R.call_tir(cls.matmul11, (lv5104, lv2331_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2332: R.Tensor((640, 640), dtype="float32") = transformed_param_1656
            lv5108 = R.call_tir(cls.matmul11, (lv5104, lv2332), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2333: R.Tensor((640, 640), dtype="float32") = transformed_param_1657
            lv5110 = R.call_tir(cls.matmul11, (lv5104, lv2333), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1242_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5106,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1243_1 = R.call_tir(cls.fused_reshape23_transpose12_transpose13, (lv5108,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1244_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5110,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1245_1 = R.call_tir(cls.fused_matmul12_multiply5, (lv1242_1, lv1243_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5122 = R.call_tir(cls.softmax1, (lv1245_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5123 = R.call_tir(cls.matmul13, (lv5122, lv1244_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1246_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5123,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2334: R.Tensor((640, 640), dtype="float32") = transformed_param_1658
            lv2335: R.Tensor((640,), dtype="float32") = transformed_param_827
            lv1247_1 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1246_1, lv2334, lv2335, lv1241_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2336: R.Tensor((640,), dtype="float32") = transformed_param_834
            lv2337: R.Tensor((640,), dtype="float32") = transformed_param_833
            lv5131 = R.call_tir(cls.layer_norm1, (lv1247_1, lv2336, lv2337), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2338: R.Tensor((640, 640), dtype="float32") = transformed_param_1659
            lv5133 = R.call_tir(cls.matmul11, (lv5131, lv2338), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2339: R.Tensor((2048, 640), dtype="float32") = transformed_param_1660
            lv5135 = R.call_tir(cls.matmul14, (inp_2, lv2339), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2340: R.Tensor((2048, 640), dtype="float32") = transformed_param_1661
            lv5137 = R.call_tir(cls.matmul14, (inp_2, lv2340), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1248_1 = R.call_tir(cls.fused_reshape23_transpose12, (lv5133,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1249_2 = R.call_tir(cls.fused_reshape25_transpose16_transpose17, (lv5135,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1250_1 = R.call_tir(cls.fused_reshape25_transpose16, (lv5137,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1251_2 = R.call_tir(cls.fused_matmul15_multiply6, (lv1248_1, lv1249_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5149 = R.call_tir(cls.softmax2, (lv1251_2,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5150 = R.call_tir(cls.matmul16, (lv5149, lv1250_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1252_1 = R.call_tir(cls.fused_transpose14_reshape24, (lv5150,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2341: R.Tensor((640, 640), dtype="float32") = transformed_param_1662
            lv2342: R.Tensor((640,), dtype="float32") = transformed_param_828
            lv1253_2 = R.call_tir(cls.fused_matmul11_add16_divide3_add17, (lv1252_1, lv2341, lv2342, lv1247_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2343_1: R.Tensor((640,), dtype="float32") = transformed_param_836
            lv2344_1: R.Tensor((640,), dtype="float32") = transformed_param_835
            lv5158 = R.call_tir(cls.layer_norm1, (lv1253_2, lv2343_1, lv2344_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2345: R.Tensor((640, 5120), dtype="float32") = transformed_param_1663
            lv2346: R.Tensor((5120,), dtype="float32") = transformed_param_829
            lv1254_1 = R.call_tir(cls.fused_matmul17_add18, (lv5158, lv2345, lv2346), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1255_2 = R.call_tir(cls.fused_split_gelu1_multiply7, (lv1254_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2347: R.Tensor((2560, 640), dtype="float32") = transformed_param_1664
            lv2348: R.Tensor((640,), dtype="float32") = transformed_param_830
            lv1256_1 = R.call_tir(cls.fused_matmul18_add16_add17, (lv1255_2, lv2347, lv2348, lv1253_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2349: R.Tensor((640, 640), dtype="float32") = transformed_param_1665
            lv2350: R.Tensor((640,), dtype="float32") = transformed_param_816
            lv1257_1 = R.call_tir(cls.fused_matmul11_add16, (lv1256_1, lv2349, lv2350), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1258_1 = R.call_tir(cls.fused_reshape26_transpose20_add15_resize2d1, (lv1257_1, lv1224_2), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2351: R.Tensor((640, 640, 3, 3), dtype="float32") = transformed_param_861
            lv2352_1: R.Tensor((1, 640, 1, 1), dtype="float32") = transformed_param_1666
            lv1259_1 = R.call_tir(cls.fused_conv2d21_add27, (lv1258_1, lv2351, lv2352_1), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5181 = R.call_tir(cls.concatenate9, (lv1259_1, lv93), out_sinfo=R.Tensor((2, 960, 128, 128), dtype="float32"))
            lv2353: R.Tensor((960,), dtype="float32") = transformed_param_866
            lv2354_1: R.Tensor((960,), dtype="float32") = transformed_param_865
            lv1260_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv5181, lv2353, lv2354_1), out_sinfo=R.Tensor((2, 960, 128, 128), dtype="float32"))
            lv5187 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2355: R.Tensor((1280, 320), dtype="float32") = transformed_param_1668
            lv2356_1: R.Tensor((320,), dtype="float32") = transformed_param_869
            lv1261_1 = R.call_tir(cls.fused_matmul9_add8_cast4, (lv5187, lv2355, lv2356_1), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5192 = R.call_tir(cls.reshape19, (lv1261_1,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2357: R.Tensor((320, 960, 3, 3), dtype="float32") = transformed_param_862
            lv2358_1: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1667
            lv1262_1 = R.call_tir(cls.fused_conv2d22_add7_add9, (lv1260_1, lv2357, lv2358_1, lv5192), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2359: R.Tensor((320,), dtype="float32") = transformed_param_868
            lv2360: R.Tensor((320,), dtype="float32") = transformed_param_867
            lv1263_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1262_1, lv2359, lv2360), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2361: R.Tensor((320, 960, 1, 1), dtype="float32") = transformed_param_864
            lv2362: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1670
            lv1264_1 = R.call_tir(cls.fused_conv2d23_add7, (lv5181, lv2361, lv2362), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2363: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_863
            lv2364: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1669
            lv1265_1 = R.call_tir(cls.fused_conv2d1_add7_add10_divide, (lv1263_1, lv2363, lv2364, lv1264_1), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv5204 = R.call_tir(cls.concatenate10, (lv1265_1, lv88), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2365: R.Tensor((640,), dtype="float32") = transformed_param_874
            lv2366: R.Tensor((640,), dtype="float32") = transformed_param_873
            lv1266_1 = R.call_tir(cls.fused_group_norm13_silu12, (lv5204, lv2365, lv2366), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5210 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2367: R.Tensor((1280, 320), dtype="float32") = transformed_param_1672
            lv2368: R.Tensor((320,), dtype="float32") = transformed_param_877
            lv1267_2 = R.call_tir(cls.fused_matmul9_add8_cast4, (lv5210, lv2367, lv2368), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5215 = R.call_tir(cls.reshape19, (lv1267_2,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2369: R.Tensor((320, 640, 3, 3), dtype="float32") = transformed_param_870
            lv2370_1: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1671
            lv1268_2 = R.call_tir(cls.fused_conv2d24_add7_add9, (lv1266_1, lv2369, lv2370_1, lv5215), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2371_1: R.Tensor((320,), dtype="float32") = transformed_param_876
            lv2372: R.Tensor((320,), dtype="float32") = transformed_param_875
            lv1269_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1268_2, lv2371_1, lv2372), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2373: R.Tensor((320, 640, 1, 1), dtype="float32") = transformed_param_872
            lv2374: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1674
            lv1270_1 = R.call_tir(cls.fused_conv2d25_add7, (lv5204, lv2373, lv2374), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2375: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_871
            lv2376: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1673
            lv1271_1 = R.call_tir(cls.fused_conv2d1_add7_add10_divide, (lv1269_1, lv2375, lv2376, lv1270_1), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv5227 = R.call_tir(cls.concatenate10, (lv1271_1, lv83), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2377: R.Tensor((640,), dtype="float32") = transformed_param_882
            lv2378: R.Tensor((640,), dtype="float32") = transformed_param_881
            lv1272_1 = R.call_tir(cls.fused_group_norm13_silu12, (lv5227, lv2377, lv2378), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5233 = R.call_tir(cls.silu, (lv82,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2379_1: R.Tensor((1280, 320), dtype="float32") = transformed_param_1676
            lv2380: R.Tensor((320,), dtype="float32") = transformed_param_885
            lv1273_1 = R.call_tir(cls.fused_matmul9_add8_cast4, (lv5233, lv2379_1, lv2380), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5238 = R.call_tir(cls.reshape19, (lv1273_1,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2381: R.Tensor((320, 640, 3, 3), dtype="float32") = transformed_param_878
            lv2382: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1675
            lv1274_1 = R.call_tir(cls.fused_conv2d24_add7_add9, (lv1272_1, lv2381, lv2382, lv5238), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2383: R.Tensor((320,), dtype="float32") = transformed_param_884
            lv2384: R.Tensor((320,), dtype="float32") = transformed_param_883
            lv1275_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1274_1, lv2383, lv2384), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2385: R.Tensor((320, 640, 1, 1), dtype="float32") = transformed_param_880
            lv2386: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1678
            lv1276_2 = R.call_tir(cls.fused_conv2d25_add7, (lv5227, lv2385, lv2386), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2387: R.Tensor((320, 320, 3, 3), dtype="float32") = transformed_param_879
            lv2388: R.Tensor((1, 320, 1, 1), dtype="float32") = transformed_param_1677
            lv1277_1 = R.call_tir(cls.fused_conv2d1_add7_add10_divide, (lv1275_1, lv2387, lv2388, lv1276_2), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2389: R.Tensor((320,), dtype="float32") = transformed_param_4
            lv2390: R.Tensor((320,), dtype="float32") = transformed_param_3
            lv1278_1 = R.call_tir(cls.fused_group_norm_silu1, (lv1277_1, lv2389, lv2390), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2391: R.Tensor((4, 320, 3, 3), dtype="float32") = transformed_param_5
            lv2392_1: R.Tensor((1, 4, 1, 1), dtype="float32") = transformed_param_1679
            lv1279_1 = R.call_tir(cls.fused_conv2d26_add28, (lv1278_1, lv2391, lv2392_1), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
            lv1280_1 = R.call_tir(cls.fused_split2_subtract_multiply11_add29, (lv1279_1,), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            gv: R.Tensor((1, 4, 128, 128), dtype="float32") = lv1280_1
            R.output(gv)
        return gv

    @R.function
    def vae(inp_0: R.Tensor((1, 4, 128, 128), dtype="float32"), transformed_param_0: R.Tensor((512, 4, 3, 3), dtype="float32"), transformed_param_1: R.Tensor((128,), dtype="float32"), transformed_param_2: R.Tensor((128,), dtype="float32"), transformed_param_3: R.Tensor((3, 128, 3, 3), dtype="float32"), transformed_param_4: R.Tensor((512,), dtype="float32"), transformed_param_5: R.Tensor((512,), dtype="float32"), transformed_param_6: R.Tensor((512,), dtype="float32"), transformed_param_7: R.Tensor((512,), dtype="float32"), transformed_param_8: R.Tensor((512,), dtype="float32"), transformed_param_9: R.Tensor((512,), dtype="float32"), transformed_param_10: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_11: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_12: R.Tensor((512,), dtype="float32"), transformed_param_13: R.Tensor((512,), dtype="float32"), transformed_param_14: R.Tensor((512,), dtype="float32"), transformed_param_15: R.Tensor((512,), dtype="float32"), transformed_param_16: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_17: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_18: R.Tensor((512,), dtype="float32"), transformed_param_19: R.Tensor((512,), dtype="float32"), transformed_param_20: R.Tensor((512,), dtype="float32"), transformed_param_21: R.Tensor((512,), dtype="float32"), transformed_param_22: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_23: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_24: R.Tensor((512,), dtype="float32"), transformed_param_25: R.Tensor((512,), dtype="float32"), transformed_param_26: R.Tensor((512,), dtype="float32"), transformed_param_27: R.Tensor((512,), dtype="float32"), transformed_param_28: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_29: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_30: R.Tensor((512,), dtype="float32"), transformed_param_31: R.Tensor((512,), dtype="float32"), transformed_param_32: R.Tensor((512,), dtype="float32"), transformed_param_33: R.Tensor((512,), dtype="float32"), transformed_param_34: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_35: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_36: R.Tensor((512,), dtype="float32"), transformed_param_37: R.Tensor((512,), dtype="float32"), transformed_param_38: R.Tensor((512,), dtype="float32"), transformed_param_39: R.Tensor((512,), dtype="float32"), transformed_param_40: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_41: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_42: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_43: R.Tensor((512,), dtype="float32"), transformed_param_44: R.Tensor((512,), dtype="float32"), transformed_param_45: R.Tensor((512,), dtype="float32"), transformed_param_46: R.Tensor((512,), dtype="float32"), transformed_param_47: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_48: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_49: R.Tensor((512,), dtype="float32"), transformed_param_50: R.Tensor((512,), dtype="float32"), transformed_param_51: R.Tensor((512,), dtype="float32"), transformed_param_52: R.Tensor((512,), dtype="float32"), transformed_param_53: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_54: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_55: R.Tensor((512,), dtype="float32"), transformed_param_56: R.Tensor((512,), dtype="float32"), transformed_param_57: R.Tensor((512,), dtype="float32"), transformed_param_58: R.Tensor((512,), dtype="float32"), transformed_param_59: R.Tensor((512, 512, 3, 3), dtype="float32"), transformed_param_60: R.Tensor((256, 512, 3, 3), dtype="float32"), transformed_param_61: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_62: R.Tensor((256, 512, 1, 1), dtype="float32"), transformed_param_63: R.Tensor((512,), dtype="float32"), transformed_param_64: R.Tensor((512,), dtype="float32"), transformed_param_65: R.Tensor((256,), dtype="float32"), transformed_param_66: R.Tensor((256,), dtype="float32"), transformed_param_67: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_68: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_69: R.Tensor((256,), dtype="float32"), transformed_param_70: R.Tensor((256,), dtype="float32"), transformed_param_71: R.Tensor((256,), dtype="float32"), transformed_param_72: R.Tensor((256,), dtype="float32"), transformed_param_73: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_74: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_75: R.Tensor((256,), dtype="float32"), transformed_param_76: R.Tensor((256,), dtype="float32"), transformed_param_77: R.Tensor((256,), dtype="float32"), transformed_param_78: R.Tensor((256,), dtype="float32"), transformed_param_79: R.Tensor((256, 256, 3, 3), dtype="float32"), transformed_param_80: R.Tensor((128, 256, 3, 3), dtype="float32"), transformed_param_81: R.Tensor((128, 128, 3, 3), dtype="float32"), transformed_param_82: R.Tensor((128, 256, 1, 1), dtype="float32"), transformed_param_83: R.Tensor((256,), dtype="float32"), transformed_param_84: R.Tensor((256,), dtype="float32"), transformed_param_85: R.Tensor((128,), dtype="float32"), transformed_param_86: R.Tensor((128,), dtype="float32"), transformed_param_87: R.Tensor((128, 128, 3, 3), dtype="float32"), transformed_param_88: R.Tensor((128, 128, 3, 3), dtype="float32"), transformed_param_89: R.Tensor((128,), dtype="float32"), transformed_param_90: R.Tensor((128,), dtype="float32"), transformed_param_91: R.Tensor((128,), dtype="float32"), transformed_param_92: R.Tensor((128,), dtype="float32"), transformed_param_93: R.Tensor((128, 128, 3, 3), dtype="float32"), transformed_param_94: R.Tensor((128, 128, 3, 3), dtype="float32"), transformed_param_95: R.Tensor((128,), dtype="float32"), transformed_param_96: R.Tensor((128,), dtype="float32"), transformed_param_97: R.Tensor((128,), dtype="float32"), transformed_param_98: R.Tensor((128,), dtype="float32"), transformed_param_99: R.Tensor((4, 4, 1, 1), dtype="float32"), transformed_param_100: R.Tensor((1, 4, 1, 1), dtype="float32"), transformed_param_101: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_102: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_103: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_104: R.Tensor((512, 512), dtype="float32"), transformed_param_105: R.Tensor((512, 512), dtype="float32"), transformed_param_106: R.Tensor((512, 512), dtype="float32"), transformed_param_107: R.Tensor((512, 512), dtype="float32"), transformed_param_108: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_109: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_110: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_111: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_112: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_113: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_114: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_115: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_116: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_117: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_118: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_119: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_120: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_121: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_122: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_123: R.Tensor((1, 512, 1, 1), dtype="float32"), transformed_param_124: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_125: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_126: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_127: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_128: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_129: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_130: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_131: R.Tensor((1, 256, 1, 1), dtype="float32"), transformed_param_132: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_133: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_134: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_135: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_136: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_137: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_138: R.Tensor((1, 128, 1, 1), dtype="float32"), transformed_param_139: R.Tensor((1, 3, 1, 1), dtype="float32")) -> R.Tensor((1, 1024, 1024, 3), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.multiply12, (inp_0,), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            lv2393: R.Tensor((4, 4, 1, 1), dtype="float32") = transformed_param_99
            lv2394: R.Tensor((1, 4, 1, 1), dtype="float32") = transformed_param_100
            lv_1 = R.call_tir(cls.fused_conv2d27_add30, (lv, lv2393, lv2394), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            lv2395: R.Tensor((512, 4, 3, 3), dtype="float32") = transformed_param_0
            lv2396: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_101
            lv1 = R.call_tir(cls.fused_conv2d28_add31, (lv_1, lv2395, lv2396), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2397: R.Tensor((512,), dtype="float32") = transformed_param_13
            lv2398: R.Tensor((512,), dtype="float32") = transformed_param_12
            lv2 = R.call_tir(cls.fused_group_norm14_silu13, (lv1, lv2397, lv2398), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2399: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_10
            lv2400: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_102
            lv3 = R.call_tir(cls.fused_conv2d29_add31, (lv2, lv2399, lv2400), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2401: R.Tensor((512,), dtype="float32") = transformed_param_15
            lv2402: R.Tensor((512,), dtype="float32") = transformed_param_14
            lv4 = R.call_tir(cls.fused_group_norm14_silu13, (lv3, lv2401, lv2402), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2403: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_11
            lv2404: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_103
            lv5 = R.call_tir(cls.fused_conv2d29_add31_add32_divide6, (lv4, lv2403, lv2404, lv1), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv6 = R.call_tir(cls.fused_reshape36_transpose30_transpose31, (lv5,), out_sinfo=R.Tensor((1, 512, 16384), dtype="float32"))
            lv2405: R.Tensor((512,), dtype="float32") = transformed_param_5
            lv2406: R.Tensor((512,), dtype="float32") = transformed_param_4
            lv22 = R.call_tir(cls.group_norm15, (lv6, lv2405, lv2406), out_sinfo=R.Tensor((1, 512, 16384), dtype="float32"))
            lv23 = R.call_tir(cls.transpose30, (lv22,), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2407: R.Tensor((512, 512), dtype="float32") = transformed_param_104
            lv2408: R.Tensor((512,), dtype="float32") = transformed_param_8
            lv7 = R.call_tir(cls.fused_matmul27_add33, (lv23, lv2407, lv2408), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2409: R.Tensor((512, 512), dtype="float32") = transformed_param_105
            lv2410: R.Tensor((512,), dtype="float32") = transformed_param_6
            lv8 = R.call_tir(cls.fused_matmul27_add33, (lv23, lv2409, lv2410), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2411: R.Tensor((512, 512), dtype="float32") = transformed_param_106
            lv2412: R.Tensor((512,), dtype="float32") = transformed_param_9
            lv9 = R.call_tir(cls.fused_matmul27_add33, (lv23, lv2411, lv2412), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv10 = R.call_tir(cls.fused_reshape37_transpose33, (lv7,), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv11 = R.call_tir(cls.fused_reshape37_transpose33_transpose34, (lv8,), out_sinfo=R.Tensor((1, 1, 512, 16384), dtype="float32"))
            lv12 = R.call_tir(cls.fused_reshape37_transpose33, (lv9,), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv13 = R.call_tir(cls.fused_matmul28_multiply13, (lv10, lv11, R.const(0.044194173067808151, "float32")), out_sinfo=R.Tensor((1, 1, 16384, 16384), dtype="float32"))
            lv44 = R.call_tir(cls.softmax5, (lv13,), out_sinfo=R.Tensor((1, 1, 16384, 16384), dtype="float32"))
            lv45 = R.call_tir(cls.matmul29, (lv44, lv12), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv14 = R.call_tir(cls.fused_transpose35_reshape38, (lv45,), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2413: R.Tensor((512, 512), dtype="float32") = transformed_param_107
            lv2414: R.Tensor((512,), dtype="float32") = transformed_param_7
            lv15 = R.call_tir(cls.fused_matmul27_add33, (lv14, lv2413, lv2414), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv16 = R.call_tir(cls.fused_transpose31_reshape39_add32_divide6, (lv15, lv5), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2415: R.Tensor((512,), dtype="float32") = transformed_param_19
            lv2416: R.Tensor((512,), dtype="float32") = transformed_param_18
            lv17 = R.call_tir(cls.fused_group_norm14_silu13, (lv16, lv2415, lv2416), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2417: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_16
            lv2418: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_108
            lv18 = R.call_tir(cls.fused_conv2d29_add31, (lv17, lv2417, lv2418), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2419: R.Tensor((512,), dtype="float32") = transformed_param_21
            lv2420: R.Tensor((512,), dtype="float32") = transformed_param_20
            lv19 = R.call_tir(cls.fused_group_norm14_silu13, (lv18, lv2419, lv2420), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2421: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_17
            lv2422: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_109
            lv20 = R.call_tir(cls.fused_conv2d29_add31_add32_divide6_divide6, (lv19, lv2421, lv2422, lv16), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2423: R.Tensor((512,), dtype="float32") = transformed_param_25
            lv2424: R.Tensor((512,), dtype="float32") = transformed_param_24
            lv21 = R.call_tir(cls.fused_group_norm14_silu13, (lv20, lv2423, lv2424), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2425: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_22
            lv2426: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_110
            lv22_1 = R.call_tir(cls.fused_conv2d29_add31, (lv21, lv2425, lv2426), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2427: R.Tensor((512,), dtype="float32") = transformed_param_27
            lv2428: R.Tensor((512,), dtype="float32") = transformed_param_26
            lv23_1 = R.call_tir(cls.fused_group_norm14_silu13, (lv22_1, lv2427, lv2428), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2429: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_23
            lv2430: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_111
            lv24 = R.call_tir(cls.fused_conv2d29_add31_add32_divide6, (lv23_1, lv2429, lv2430, lv20), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2431: R.Tensor((512,), dtype="float32") = transformed_param_31
            lv2432: R.Tensor((512,), dtype="float32") = transformed_param_30
            lv25 = R.call_tir(cls.fused_group_norm14_silu13, (lv24, lv2431, lv2432), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2433: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_28
            lv2434: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_112
            lv26 = R.call_tir(cls.fused_conv2d29_add31, (lv25, lv2433, lv2434), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2435: R.Tensor((512,), dtype="float32") = transformed_param_33
            lv2436: R.Tensor((512,), dtype="float32") = transformed_param_32
            lv27 = R.call_tir(cls.fused_group_norm14_silu13, (lv26, lv2435, lv2436), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2437: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_29
            lv2438: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_113
            lv28 = R.call_tir(cls.fused_conv2d29_add31_add32_divide6, (lv27, lv2437, lv2438, lv24), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2439: R.Tensor((512,), dtype="float32") = transformed_param_37
            lv2440: R.Tensor((512,), dtype="float32") = transformed_param_36
            lv29 = R.call_tir(cls.fused_group_norm14_silu13, (lv28, lv2439, lv2440), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2441: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_34
            lv2442: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_114
            lv30 = R.call_tir(cls.fused_conv2d29_add31, (lv29, lv2441, lv2442), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2443: R.Tensor((512,), dtype="float32") = transformed_param_39
            lv2444: R.Tensor((512,), dtype="float32") = transformed_param_38
            lv31 = R.call_tir(cls.fused_group_norm14_silu13, (lv30, lv2443, lv2444), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2445: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_35
            lv2446: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_115
            lv32 = R.call_tir(cls.fused_conv2d29_add31_add32_divide6, (lv31, lv2445, lv2446, lv28), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv104 = R.call_tir(cls.resize2d2, (lv32,), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2447: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_40
            lv2448: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_116
            # lv33 = R.call_tir(cls.fused_conv2d30_add34, (lv104, lv2447, lv2448), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv33 = lv104
            lv2449: R.Tensor((512,), dtype="float32") = transformed_param_44
            lv2450: R.Tensor((512,), dtype="float32") = transformed_param_43
            lv34 = R.call_tir(cls.fused_group_norm16_silu14, (lv33, lv2449, lv2450), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2451: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_41
            lv2452: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_117
            # lv35 = R.call_tir(cls.fused_conv2d30_add34, (lv34, lv2451, lv2452), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv35 = lv34
            lv2453: R.Tensor((512,), dtype="float32") = transformed_param_46
            lv2454: R.Tensor((512,), dtype="float32") = transformed_param_45
            lv36 = R.call_tir(cls.fused_group_norm16_silu14, (lv35, lv2453, lv2454), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2455: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_42
            lv2456: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_118
            # lv37 = R.call_tir(cls.fused_conv2d30_add34_add35_divide7, (lv36, lv2455, lv2456, lv33), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv37 = lv36
            lv2457: R.Tensor((512,), dtype="float32") = transformed_param_50
            lv2458: R.Tensor((512,), dtype="float32") = transformed_param_49
            lv38 = R.call_tir(cls.fused_group_norm16_silu14, (lv37, lv2457, lv2458), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2459: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_47
            lv2460: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_119
            # lv39 = R.call_tir(cls.fused_conv2d30_add34, (lv38, lv2459, lv2460), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv39 = lv38
            lv2461: R.Tensor((512,), dtype="float32") = transformed_param_52
            lv2462: R.Tensor((512,), dtype="float32") = transformed_param_51
            lv40 = R.call_tir(cls.fused_group_norm16_silu14, (lv39, lv2461, lv2462), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2463: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_48
            lv2464: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_120
            # lv41 = R.call_tir(cls.fused_conv2d30_add34_add35_divide7, (lv40, lv2463, lv2464, lv37), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv41 = lv40
            lv2465: R.Tensor((512,), dtype="float32") = transformed_param_56
            lv2466: R.Tensor((512,), dtype="float32") = transformed_param_55
            lv42 = R.call_tir(cls.fused_group_norm16_silu14, (lv41, lv2465, lv2466), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2467: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_53
            lv2468: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_121
            # lv43 = R.call_tir(cls.fused_conv2d30_add34, (lv42, lv2467, lv2468), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv43 = lv42
            lv2469: R.Tensor((512,), dtype="float32") = transformed_param_58
            lv2470: R.Tensor((512,), dtype="float32") = transformed_param_57
            lv44_1 = R.call_tir(cls.fused_group_norm16_silu14, (lv43, lv2469, lv2470), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2471: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_54
            lv2472: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_122
            # lv45_1 = R.call_tir(cls.fused_conv2d30_add34_add35_divide7, (lv44_1, lv2471, lv2472, lv41), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv45_1 = lv44_1
            lv144 = R.call_tir(cls.resize2d3, (lv45_1,), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv2473: R.Tensor((512, 512, 3, 3), dtype="float32") = transformed_param_59
            lv2474: R.Tensor((1, 512, 1, 1), dtype="float32") = transformed_param_123
            # lv46 = R.call_tir(cls.fused_conv2d31_add36, (lv144, lv2473, lv2474), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv46 = lv144
            lv2475: R.Tensor((512,), dtype="float32") = transformed_param_64
            lv2476: R.Tensor((512,), dtype="float32") = transformed_param_63
            lv47 = R.call_tir(cls.fused_group_norm17_silu15, (lv46, lv2475, lv2476), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv2477: R.Tensor((256, 512, 3, 3), dtype="float32") = transformed_param_60
            lv2478: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_124
            lv48 = R.call_tir(cls.fused_conv2d32_add37, (lv47, lv2477, lv2478), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2479: R.Tensor((256,), dtype="float32") = transformed_param_66
            lv2480: R.Tensor((256,), dtype="float32") = transformed_param_65
            lv49 = R.call_tir(cls.fused_group_norm18_silu16, (lv48, lv2479, lv2480), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2481: R.Tensor((256, 512, 1, 1), dtype="float32") = transformed_param_62
            lv2482: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_126
            lv50 = R.call_tir(cls.fused_conv2d34_add37, (lv46, lv2481, lv2482), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2483: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_61
            lv2484: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_125
            # lv51 = R.call_tir(cls.fused_conv2d33_add37_add38_divide8, (lv49, lv2483, lv2484, lv50), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv51 = lv49
            lv2485: R.Tensor((256,), dtype="float32") = transformed_param_70
            lv2486: R.Tensor((256,), dtype="float32") = transformed_param_69
            lv52 = R.call_tir(cls.fused_group_norm18_silu16, (lv51, lv2485, lv2486), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2487: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_67
            lv2488: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_127
            # lv53 = R.call_tir(cls.fused_conv2d33_add37, (lv52, lv2487, lv2488), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv53 = lv52
            lv2489: R.Tensor((256,), dtype="float32") = transformed_param_72
            lv2490: R.Tensor((256,), dtype="float32") = transformed_param_71
            lv54 = R.call_tir(cls.fused_group_norm18_silu16, (lv53, lv2489, lv2490), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2491: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_68
            lv2492: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_128
            # lv55 = R.call_tir(cls.fused_conv2d33_add37_add38_divide8, (lv54, lv2491, lv2492, lv51), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv55 = lv54
            lv2493: R.Tensor((256,), dtype="float32") = transformed_param_76
            lv2494: R.Tensor((256,), dtype="float32") = transformed_param_75
            lv56 = R.call_tir(cls.fused_group_norm18_silu16, (lv55, lv2493, lv2494), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2495: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_73
            lv2496: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_129
            # lv57 = R.call_tir(cls.fused_conv2d33_add37, (lv56, lv2495, lv2496), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv57 = lv56
            lv2497: R.Tensor((256,), dtype="float32") = transformed_param_78
            lv2498: R.Tensor((256,), dtype="float32") = transformed_param_77
            lv58 = R.call_tir(cls.fused_group_norm18_silu16, (lv57, lv2497, lv2498), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2499: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_74
            lv2500: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_130
            # lv59 = R.call_tir(cls.fused_conv2d33_add37_add38_divide8, (lv58, lv2499, lv2500, lv55), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv59 = lv58
            lv187 = R.call_tir(cls.resize2d4, (lv59,), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv2501: R.Tensor((256, 256, 3, 3), dtype="float32") = transformed_param_79
            lv2502: R.Tensor((1, 256, 1, 1), dtype="float32") = transformed_param_131
            # lv60 = R.call_tir(cls.fused_conv2d35_add39, (lv187, lv2501, lv2502), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv60 = lv187
            lv2503: R.Tensor((256,), dtype="float32") = transformed_param_84
            lv2504: R.Tensor((256,), dtype="float32") = transformed_param_83
            lv61 = R.call_tir(cls.fused_group_norm19_silu17, (lv60, lv2503, lv2504), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv2505: R.Tensor((128, 256, 3, 3), dtype="float32") = transformed_param_80
            lv2506: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_132
            # lv62 = R.call_tir(cls.fused_conv2d36_add40, (lv61, lv2505, lv2506), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv62 = lv61
            lv2507: R.Tensor((128,), dtype="float32") = transformed_param_86
            lv2508: R.Tensor((128,), dtype="float32") = transformed_param_85
            lv63 = R.call_tir(cls.fused_group_norm20_silu18, (lv62, lv2507, lv2508), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2509: R.Tensor((128, 256, 1, 1), dtype="float32") = transformed_param_82
            lv2510: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_134
            lv64 = R.call_tir(cls.fused_conv2d38_add40, (lv60, lv2509, lv2510), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2511: R.Tensor((128, 128, 3, 3), dtype="float32") = transformed_param_81
            lv2512: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_133
            # lv65 = R.call_tir(cls.fused_conv2d37_add40_add41_divide9, (lv63, lv2511, lv2512, lv64), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv65 = lv63
            lv2513: R.Tensor((128,), dtype="float32") = transformed_param_90
            lv2514: R.Tensor((128,), dtype="float32") = transformed_param_89
            lv66 = R.call_tir(cls.fused_group_norm20_silu18, (lv65, lv2513, lv2514), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2515: R.Tensor((128, 128, 3, 3), dtype="float32") = transformed_param_87
            lv2516: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_135
            # lv67 = R.call_tir(cls.fused_conv2d37_add40, (lv66, lv2515, lv2516), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv67 = lv66
            lv2517: R.Tensor((128,), dtype="float32") = transformed_param_92
            lv2518: R.Tensor((128,), dtype="float32") = transformed_param_91
            lv68 = R.call_tir(cls.fused_group_norm20_silu18, (lv67, lv2517, lv2518), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2519: R.Tensor((128, 128, 3, 3), dtype="float32") = transformed_param_88
            lv2520: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_136
            # lv69 = R.call_tir(cls.fused_conv2d37_add40_add41_divide9, (lv68, lv2519, lv2520, lv65), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv69 = lv68
            lv2521: R.Tensor((128,), dtype="float32") = transformed_param_96
            lv2522: R.Tensor((128,), dtype="float32") = transformed_param_95
            lv70 = R.call_tir(cls.fused_group_norm20_silu18, (lv69, lv2521, lv2522), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2523: R.Tensor((128, 128, 3, 3), dtype="float32") = transformed_param_93
            lv2524: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_137
            # lv71 = R.call_tir(cls.fused_conv2d37_add40, (lv70, lv2523, lv2524), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv71 = lv70
            lv2525: R.Tensor((128,), dtype="float32") = transformed_param_98
            lv2526: R.Tensor((128,), dtype="float32") = transformed_param_97
            lv72 = R.call_tir(cls.fused_group_norm20_silu18, (lv71, lv2525, lv2526), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2527: R.Tensor((128, 128, 3, 3), dtype="float32") = transformed_param_94
            lv2528: R.Tensor((1, 128, 1, 1), dtype="float32") = transformed_param_138
            # lv73 = R.call_tir(cls.fused_conv2d37_add40_add41_divide9, (lv72, lv2527, lv2528, lv69), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv73 = lv72
            lv2529: R.Tensor((128,), dtype="float32") = transformed_param_2
            lv2530: R.Tensor((128,), dtype="float32") = transformed_param_1
            lv74 = R.call_tir(cls.fused_group_norm20_silu18, (lv73, lv2529, lv2530), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2531: R.Tensor((3, 128, 3, 3), dtype="float32") = transformed_param_3
            lv2532: R.Tensor((1, 3, 1, 1), dtype="float32") = transformed_param_139
            lv75 = R.call_tir(cls.fused_conv2d39_add42_divide10_add43_tir_clip, (lv74, lv2531, lv2532), out_sinfo=R.Tensor((1, 3, 1024, 1024), dtype="float32"))
            lv76 = R.call_tir(cls.fused_transpose36_multiply14_tir_round, (lv75,), out_sinfo=R.Tensor((1, 1024, 1024, 3), dtype="float32"))
            gv: R.Tensor((1, 1024, 1024, 3), dtype="float32") = lv76
            R.output(gv)
        return gv

mod = Module

def tune(mod: tvm.IRModule) -> None:
    from tvm import meta_schedule as ms

    ms.relax_integration.tune_relax(
        mod=mod,
        target=tvm.target.Target("apple/m1-gpu-restricted"),
        params={},
        builder=ms.builder.LocalBuilder(
            max_workers=6,
            timeout_sec = 300
        ),
        runner=ms.runner.LocalRunner(timeout_sec = 300),
        work_dir="log_db_tuning",
        max_trials_global=96500,
        max_trials_per_task=500,
        strategy=ms.search_strategy.EvolutionarySearch(init_min_unmeasured=10, max_fail_count=20),
    )


tune(mod)