import tvm
metadata = tvm.ir.load_json("""{
  \"root\": 1, 
  \"nodes\": [
    {
      \"type_key\": \"\"
    }, 
    {
      \"type_key\": \"Map\", 
      \"keys\": [
        \"relax.expr.Constant\"
      ], 
      \"data\": [2]
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [3, 14, 25, 34]
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"13\", 
        \"data\": \"0\", 
        \"span\": \"0\", 
        \"struct_info_\": \"4\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"5\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"12\", 
        \"span\": \"0\", 
        \"struct_info_\": \"11\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [7, 8, 9, 10]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"6\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"24\", 
        \"data\": \"1\", 
        \"span\": \"0\", 
        \"struct_info_\": \"15\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"shape\": \"16\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"23\", 
        \"span\": \"0\", 
        \"struct_info_\": \"22\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [18, 19, 20, 21]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"77\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\", 
        \"values\": \"17\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"4\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"33\", 
        \"data\": \"2\", 
        \"span\": \"0\", 
        \"struct_info_\": \"26\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"27\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"32\", 
        \"span\": \"0\", 
        \"struct_info_\": \"31\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [29, 30]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"160\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"28\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.Constant\", 
      \"attrs\": {
        \"_checked_type_\": \"42\", 
        \"data\": \"3\", 
        \"span\": \"0\", 
        \"struct_info_\": \"35\"
      }
    }, 
    {
      \"type_key\": \"relax.TensorStructInfo\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"shape\": \"36\", 
        \"span\": \"0\", 
        \"vdevice\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.expr.ShapeExpr\", 
      \"attrs\": {
        \"_checked_type_\": \"41\", 
        \"span\": \"0\", 
        \"struct_info_\": \"40\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"Array\", 
      \"data\": [38, 39]
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"1\"
      }
    }, 
    {
      \"type_key\": \"IntImm\", 
      \"attrs\": {
        \"dtype\": \"int64\", 
        \"span\": \"0\", 
        \"value\": \"128\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeStructInfo\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\", 
        \"values\": \"37\"
      }
    }, 
    {
      \"type_key\": \"relax.ShapeType\", 
      \"attrs\": {
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }, 
    {
      \"type_key\": \"relax.DynTensorType\", 
      \"attrs\": {
        \"dtype\": \"float32\", 
        \"ndim\": \"2\", 
        \"span\": \"0\"
      }
    }
  ], 
  \"b64ndarrays\": [
    \"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\", 
    \"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\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAKAAAAAAAAAAgAIAAAAAAAAAAIA/+a1xPwUpZD+sZVc/GFlLPxH5Pz/vOzU/lhgrP2yGIT9QfRg/mvUPPwvoBz/PTQA/4UDyPrez5D6a6Nc+tNTLPsJtwD4ZqrU+l4CrPpvooT4C2pg+HE2QPqg6iD7Mm4A+ItRyPro+ZT7Ya1g+nFBMPrviQD6HGDY+1ugrPgZLIj7sNhk+0qQQPneNCD756QA+wGfzPRTK5T1o79g9zMzMPflXwT03h7Y9VVGsPa2toj0NlJk9wPyQPXjgiD1XOIE9s/tzPcFVZj1Ec1k9SUlNPYHNQT0q9jY9FbosPZIQIz1p8Rk94VQRPaozCT3ihgE9BJD0PMLh5jxx99k8FMbNPFFDwjxjZbc8EyOtPK1zozz7Tpo8Oa2RPBKHiTyd1YE8qCR1PCBuZzzxe1o8J0NOPGO5Qjzf1Dc8U4wtPArXIzzHrBo8wwUSPKzaCTyKJAI8rbn1O8j65zvCANs7isDOO8IvwzuaRLg7zfWtO6M6pDvOCps7iF6SO3Uuijunc4I7Dk92O82HaDvdhVs7Mz5PO2mmQzuetDg7jV8uO3OeJDsNaRs7grcSO3WCCjvwwgI7weT2OigV6TpQC9w6NbzPOlkdxDrmJLk6iMmuOoUCpTqCx5s6rhCTOqjWijpuEoM633p3OtmiaToTkVw6cDpQOoqURDptlTk6yTMvOtVmJTo1Jhw6GWoTOg8rCzobYgM6QRH4Odkw6jkhF905BbnQOQsMxTk+Bro5UJ6vOWHLpTkhhZw5scOTOaR/izn1sYM5Dah4OS6/ajmPnV057TdROdODRTlTdzo5DAkwOSUwJjlC5Bw5gB0UOW3UCzkIAgQ5PT/5OOpN6zhAJN44\", 
    \"P6G0lvBAXt0AAAAAAAAAAAEAAAAAAAAAAgAAAAIgAQABAAAAAAAAAIAAAAAAAAAAAAIAAAAAAAAAAIA/+DluP9avXT+sS04/Efk/PwalMj/gPSY/K7MaP5r1Dz/u9gU/zlP5PmAE6D6a6Nc+I+vIPhv4uj7//K0+m+ihPuqqlj4DNYw+CHmCPiLUcj42+GE+7UdSPnyuQz6HGDY+CXQpPj+wHT6QvRI+d40IPt8k/j3Vf+w9ZBTcPczMzD3HlL49eFmxPVcJpT0NlJk9bOqOPUz+hD0RhXc9wVVmPeNXVj1Adkc9GJ05PRW6LD0bvCA9SJMVPcswCz3ihgE9dxHxPNFU4DyowdA8TkPCPJHGtDyJOag8loucPDmtkTwJkIc8ME18PObIajzxe1o8tVBLPA4zPTxQEDA8CtcjPAZ3GDwu4Q08dwcEPK259TtFquQ7FcrUOwoExjuaRLg7gnmrO8yRnzuvfZQ7dS6KO3yWgDsNUm87erReOzM+TzvC2kA7DXczO1MBJzsNaRs72J4QO22UBjvwePo6KBXpOnXm2DpZ18k669O7Oo3Jrjr3pqI6C1yXOtnZjDpuEoM6ovFzOuMBYzokP1M6ipREOp3uNjpEOyo6omkeOhRqEzoBLgk6rE//OeSV7TkhF905k73NOdZ0vzn7KbI5YculOaBImjl1ko85pJqFOQ2oeDmMZGc54lNXOb9gSDlTdzo5KoUtORl5ITkmQxY5bdQLOSgfAjndLPI4jlzhOA==\"
  ], 
  \"attrs\": {\"tvm_version\": \"0.15.dev0\"}
}""")
from tvm.script import ir as I
from tvm.script import tir as T
from tvm.script import relax as R

@I.ir_module
class Module:
    @T.prim_func(private=True)
    def add19(A: T.Buffer((), "float32"), T_add: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_add"):
            vi = T.axis.spatial(1, T.int64(0))
            T.reads(A[()])
            T.writes(T_add[()])
            T_add[()] = A[()] + T.float32(1)

    @T.prim_func(private=True)
    def add20(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] + B[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def argmax(A: T.Buffer((T.int32(1), T.int32(77)), "int32"), A_red: T.Buffer((T.int64(1),), "int32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int32(1),), "int32")
        A_red_temp_v1 = T.alloc_buffer((T.int32(1),), "int32")
        for ax0, k1 in T.grid(T.int32(1), T.int32(77)):
            with T.block("A_red_temp"):
                v_ax0, v_k1 = T.axis.remap("SR", [ax0, k1])
                T.reads(A[v_ax0, v_k1])
                T.writes(A_red_temp_v0[v_ax0], A_red_temp_v1[v_ax0])
                with T.init():
                    A_red_temp_v0[v_ax0] = T.int32(-1)
                    A_red_temp_v1[v_ax0] = -2147483647
                v_A_red_temp_v0: T.int32 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1] or A_red_temp_v1[v_ax0] == A[v_ax0, v_k1] and A_red_temp_v0[v_ax0] < v_k1, A_red_temp_v0[v_ax0], v_k1)
                v_A_red_temp_v1: T.int32 = T.Select(A_red_temp_v1[v_ax0] > A[v_ax0, v_k1], A_red_temp_v1[v_ax0], A[v_ax0, v_k1])
                A_red_temp_v0[v_ax0] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0] = v_A_red_temp_v1
        for ax0 in range(T.int32(1)):
            with T.block("A_red"):
                v_ax0 = T.axis.spatial(T.int32(1), ax0)
                T.reads(A_red_temp_v0[v_ax0])
                T.writes(A_red[v_ax0])
                A_red[v_ax0] = A_red_temp_v0[v_ax0]

    @T.prim_func(private=True)
    def cast(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), compute: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(A[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = A[v_i0, v_i1]

    @T.prim_func(private=True)
    def concatenate(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])
                T.writes(T_concat[v_ax0, v_ax1])
                T_concat[v_ax0, v_ax1] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1], A[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def concatenate1(A: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(77), T.int64(2048)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate12(A: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, B[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate13(A: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(320) <= v_ax1, B[v_ax0, v_ax1 - T.int64(320), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate2(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1) <= v_ax0, B[v_ax0 - T.int64(1), v_ax1, v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate3(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(77), T.int64(2048)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(2048)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2])
                T_concat[v_ax0, v_ax1, v_ax2] = T.if_then_else(T.int64(768) <= v_ax2, B[v_ax0, v_ax1, v_ax2 - T.int64(768)], A[v_ax0, v_ax1, v_ax2])

    @T.prim_func(private=True)
    def concatenate7(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def concatenate9(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), T_concat: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, B[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], A[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def divide6(A: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((), "float32"), T_divide: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                T.writes(T_divide[v_ax0, v_ax1, v_ax2, v_ax3])
                T_divide[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] / B[()]

    @T.prim_func(private=True)
    def fused_broadcast_to1_strided_slice1_reshape28_cast3_multiply8_multiply9_tir_sin_tir_cos_concatenate4_strided_slice2_reshape29_strided_slice3_reshape29_concatenate4_cast4(inp_1: T.Buffer((), "int32"), param_0: T.Buffer((T.int64(1), T.int64(160)), "float32"), var_compute_intermediate: T.Buffer((T.int64(2), T.int64(320)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_broadcast_to_intermediate = T.alloc_buffer((T.int64(2),), "int32")
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(2),), "int32")
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1)), "int32")
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_compute_intermediate_3 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_concat_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(2), T.int64(160)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320)))
        for ax0 in range(T.int64(2)):
            with T.block("T_broadcast_to"):
                v_ax0 = T.axis.spatial(T.int64(2), ax0)
                T.reads(inp_1[()])
                T.writes(var_T_broadcast_to_intermediate[v_ax0])
                var_T_broadcast_to_intermediate[v_ax0] = inp_1[()]
        for ax0 in range(T.int64(2)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0 = T.axis.spatial(T.int64(2), ax0)
                T.reads(var_T_broadcast_to_intermediate[v_ax0])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_broadcast_to_intermediate[v_ax0]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(2)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(2)]
        for i0, i1 in T.grid(T.int64(2), T.int64(1)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1])
                T.writes(var_compute_intermediate_1[v_i0, v_i1])
                var_compute_intermediate_1[v_i0, v_i1] = T.Cast("float32", var_T_reshape_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_1[v_ax0, T.int64(0)], param_0[T.int64(0), v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate_1[v_ax0, T.int64(0)] * param_0[T.int64(0), v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("compute_1"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_2[v_i0, v_i1])
                var_compute_intermediate_2[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0, i1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("compute_2"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_3[v_i0, v_i1])
                var_compute_intermediate_3[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_compute_intermediate_3[v_ax0, v_ax1 - T.int64(160)], var_compute_intermediate_2[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_strided_slice_with_axes_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)])
                T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1 + T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_strided_slice_with_axes_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(160)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)])
                T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(160) + v_ax0) % T.int64(2), v_ax1 % T.int64(160)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_concat_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(160) <= v_ax1, var_T_reshape_intermediate_2[v_ax0, v_ax1 - T.int64(160)], var_T_reshape_intermediate_1[v_ax0, v_ax1])
        for i0, i1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("compute_3"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_concat_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_concat_intermediate_1[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_cast_reshape10(lv: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(lv[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = lv[v_i0, v_i1]
        for ax0 in range(T.int64(77)):
            with T.block("T_reshape"):
                v_ax0 = T.axis.spatial(T.int64(77), ax0)
                T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_conv2d10_add10(lv207: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_1_conv1_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv209: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv207[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv209[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d10_add10_add11_divide4(lv197: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv2_weight: T.Buffer((T.int64(128), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv199: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), lv203: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv197[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv199[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv203[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv203[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d11_add10(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv202: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv190[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv190[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(256), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv202[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d12_add12_divide5_add13_tir_clip(lv231: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_conv_out_weight: T.Buffer((T.int64(3), T.int64(128), T.int64(3), T.int64(3)), "float32"), lv233: T.Buffer((T.int64(1), T.int64(3), T.int64(1), T.int64(1)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv231[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv233[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(0.5)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + T.float32(0.5)
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.max(T.min(var_T_add_intermediate_1[v_i0, v_i1, v_i2, v_i3], T.float32(1)), T.float32(0))

    @T.prim_func(private=True)
    def fused_conv2d13_add27(inp_0: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), unet_conv_in_weight: T.Buffer((T.int64(320), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv47: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(4), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(4), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), inp_0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv47[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv47[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d14_add27_add29(lv50: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv52: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv59: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv50[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv52[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv52[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv59[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d14_add27_add30_divide7(lv62: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_conv2_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv64: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv48: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv62[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_0_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv64[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv64[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv48[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv48[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d15_add31(lv86: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_downsamplers_0_conv_weight: T.Buffer((T.int64(320), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv88: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv86[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_0_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv88[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv88[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d16_add32_add34(lv91: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv93: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv100: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv91[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv93[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv93[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv100[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d17_add32_add34(lv259: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv261: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv268: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv259[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv261[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv261[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv268[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d17_add32_add35_divide8(lv103: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv105: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv109: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv103[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv105[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv105[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv109[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv109[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d18_add32(lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv108: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv89[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv89[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(320), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv108[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv108[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d19_add39(lv422: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_downsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv424: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv422[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx], unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy * T.int64(2) + v_ry, v_xx * T.int64(2) + v_rx] * unet_down_blocks_1_downsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv424[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv424[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d1_add1(lv3: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), vae_decoder_conv_in_weight: T.Buffer((T.int64(512), T.int64(4), T.int64(3), T.int64(3)), "float32"), lv5: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(4), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv3[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_conv_in_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d20_add40_add41(lv427: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv429: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv436: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv427[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv429[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv429[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv436[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d21_add40_add41(lv1131: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv1133: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv1140: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv1131[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv1133[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv1133[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv1140[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d21_add40_add42_divide10(lv439: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv441: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv445: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv439[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv441[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv441[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv445[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv445[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d22_add40(lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv444: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv425[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv425[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_down_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv444[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv444[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d23_add40_add41(lv2553: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_conv1_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(3), T.int64(3)), "float32"), lv2555: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv2562: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv2553[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(2560), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2555[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2555[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv2562[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d24_add40(lv2551: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(2560), T.int64(1), T.int64(1)), "float32"), lv2570: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv2551[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv2551[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(2560), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2570[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2570[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d25_add40_add41(lv3963: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_conv1_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv3965: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv3972: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(34), T.int64(34)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(34), T.int64(34)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(33) and T.int64(1) <= v_i3 and v_i3 < T.int64(33), lv3963[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1920), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3965[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3965[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv3972[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d26_add40(lv3961: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(1280), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv3980: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv3961[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv3961[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32), T.int64(1920), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3980[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3980[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d27_add46(lv4666: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(1280), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4668: T.Buffer((T.int64(1), T.int64(1280), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4666[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4668[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4668[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d28_add32_add34(lv4672: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_conv1_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(3), T.int64(3)), "float32"), lv4674: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4681: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4672[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1920), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4674[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4674[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4681[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d29_add32(lv4670: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1920), T.int64(1), T.int64(1)), "float32"), lv4689: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4670[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4670[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1920), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4689[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4689[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d2_add1(lv8: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_conv1_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv10: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv8[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv10[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d2_add1_add2_divide(lv13: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv15: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv13[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv15[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv6[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv6[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d2_add1_add2_divide_divide(lv61: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_1_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv63: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv54: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_divide_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv61[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_mid_block_resnets_1_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv63[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv54[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv54[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_divide_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d30_add32_add34(lv4841: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_conv1_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(3), T.int64(3)), "float32"), lv4843: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv4850: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv4841[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1280), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4843[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4843[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv4850[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d31_add32(lv4839: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(1280), T.int64(1), T.int64(1)), "float32"), lv4858: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv4839[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv4839[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(1280), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4858[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4858[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d32_add32_add34(lv5010: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_conv1_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5012: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5019: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(66), T.int64(66)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(66), T.int64(66)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(65) and T.int64(1) <= v_i3 and v_i3 < T.int64(65), lv5010[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(960), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5012[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5012[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5019[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d33_add32(lv5008: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_conv_shortcut_weight: T.Buffer((T.int64(640), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5027: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5008[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5008[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64), T.int64(960), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_resnets_2_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5027[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5027[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d34_add47(lv5177: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(640), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5179: T.Buffer((T.int64(1), T.int64(640), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5177[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5179[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5179[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d35_add27_add29(lv5183: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(3), T.int64(3)), "float32"), lv5185: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5192: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5183[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(960), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5185[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5185[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5192[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d36_add27(lv5181: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(960), T.int64(1), T.int64(1)), "float32"), lv5200: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5181[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5181[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(960), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5200[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5200[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d37_add27_add29(lv5206: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(3), T.int64(3)), "float32"), lv5208: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), lv5215: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5206[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(640), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5208[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5208[T.int64(0), v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + lv5215[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d38_add27(lv5204: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_conv_shortcut_weight: T.Buffer((T.int64(320), T.int64(640), T.int64(1), T.int64(1)), "float32"), lv5223: T.Buffer((T.int64(1), T.int64(320), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5204[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv5204[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_up_blocks_2_resnets_1_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5223[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5223[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d39_add48(lv5251: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_conv_out_weight: T.Buffer((T.int64(4), T.int64(320), T.int64(3), T.int64(3)), "float32"), lv5253: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(130), T.int64(130)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(130), T.int64(130)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(129) and T.int64(1) <= v_i3 and v_i3 < T.int64(129), lv5251[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128), T.int64(320), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * unet_conv_out_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5253[T.int64(0), v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5253[T.int64(0), v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d3_add4(lv104: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_0_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv106: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(258), T.int64(258)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv104[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_0_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv106[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d3_add4_add5_divide2(lv114: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_1_resnets_0_conv2_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv116: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(258), T.int64(258)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(258), T.int64(258)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(257) and T.int64(1) <= v_i3 and v_i3 < T.int64(257), lv114[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv116[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv107[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv107[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d4_add6(lv144: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_1_upsamplers_0_conv_weight: T.Buffer((T.int64(512), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv146: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv144[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_1_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv146[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d5_add7(lv149: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv1_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(3), T.int64(3)), "float32"), lv151: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv149[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(512), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv151[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d6_add7(lv164: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_1_conv1_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv166: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv164[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_1_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv166[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d6_add7_add8_divide3(lv154: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv2_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv156: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), lv160: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(514), T.int64(514)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(514), T.int64(514)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(513) and T.int64(1) <= v_i3 and v_i3 < T.int64(513), lv154[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv2_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv156[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv160[v_ax0, v_ax1, v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv160[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_conv2d7_add7(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight: T.Buffer((T.int64(256), T.int64(512), T.int64(1), T.int64(1)), "float32"), lv159: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv147[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv147[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512), T.int64(512), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_resnets_0_conv_shortcut_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv159[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d8_add9(lv187: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_2_upsamplers_0_conv_weight: T.Buffer((T.int64(256), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv189: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv187[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_2_upsamplers_0_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv189[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d9_add10(lv192: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_conv1_weight: T.Buffer((T.int64(128), T.int64(256), T.int64(3), T.int64(3)), "float32"), lv194: T.Buffer((T.int64(1), T.int64(128), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1026), T.int64(1026)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(1025) and T.int64(1) <= v_i3 and v_i3 < T.int64(1025), lv192[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_decoder_up_blocks_3_resnets_0_conv1_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv194[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_conv2d_add(lv: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), vae_post_quant_conv_weight: T.Buffer((T.int64(4), T.int64(4), T.int64(1), T.int64(1)), "float32"), lv2: T.Buffer((T.int64(1), T.int64(4), T.int64(1), T.int64(1)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_conv2d_nchw_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(lv[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = lv[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128), T.int64(4), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx])
                T.writes(var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] = var_conv2d_nchw_intermediate[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * vae_post_quant_conv_weight[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_conv2d_nchw_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2[v_ax0, v_ax1, T.int64(0), T.int64(0)]

    @T.prim_func(private=True)
    def fused_group_norm11_silu10(lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv425[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv425[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(640), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.8828125000000003e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(20), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm12_silu11(lv437: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), unet_down_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(1280),), "float32"), unet_down_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv437[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv437[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm14_silu12(lv2551: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(2560),), "float32"), unet_up_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(2560),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(80)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv2551[((v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(2560) + v_ax0) % T.int64(2), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv2551[((v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(2560) + v_ax0) % T.int64(2), (v_ax1 * T.int64(80) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(2560), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(80)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(80)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(80) + v_ax1) % T.int64(2560)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(80), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(2560) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(80), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(2560) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(2560) // T.int64(80), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(80), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm15_silu13(lv3961: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32"), unet_up_blocks_0_resnets_2_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_0_resnets_2_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv3961[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv3961[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_0_resnets_2_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.6276041666666666e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(60), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm16_silu14(lv4670: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(1920),), "float32"), unet_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(1920),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(60)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1920), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv4670[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4670[((v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1920) + v_ax0) % T.int64(2), (v_ax1 * T.int64(60) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1920), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(60)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(60) + v_ax1) % T.int64(1920)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(60), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.0690104166666666e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(60), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1920) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1920) // T.int64(60), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(60), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm17_silu15(lv4839: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_1_norm1_weight: T.Buffer((T.int64(1280),), "float32"), unet_up_blocks_1_resnets_1_norm1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv4839[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv4839[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_weight[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_1_norm1_bias[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(40), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(40), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm18_silu16(lv5008: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32"), unet_up_blocks_1_resnets_2_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_1_resnets_2_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5008[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5008[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(960), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_1_resnets_2_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(8.1380208333333332e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(30), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm19_silu17(lv5181: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(960),), "float32"), unet_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(960),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(30)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(960), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5181[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(960), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5181[((v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(960) + v_ax0) % T.int64(2), (v_ax1 * T.int64(30) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(960), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(30)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(30) + v_ax1) % T.int64(960)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(30), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.0345052083333333e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(30), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(960) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(960) // T.int64(30), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(30), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm20_silu18(lv5204: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32"), unet_up_blocks_2_resnets_1_norm1_weight: T.Buffer((T.int64(640),), "float32"), unet_up_blocks_2_resnets_1_norm1_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv5204[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(640), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv5204[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(640), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_up_blocks_2_resnets_1_norm1_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.0517578125000002e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(20), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(20), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm2_silu1(lv107: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv107[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(256) + v_ax3) // T.int64(256) + v_ax2) % T.int64(512), (v_ax4 // T.int64(256) + v_ax3) % T.int64(256), v_ax4 % T.int64(256)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(256), T.int64(256)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(9.5367431640625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(256) + v_ax2) // T.int64(256) + v_ax1) % T.int64(16), (v_ax3 // T.int64(256) + v_ax2) % T.int64(256), v_ax3 % T.int64(256)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm3_silu2(lv147: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(512), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv147[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(512), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(512), T.int64(512)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(16), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(16), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm4_silu3(lv152: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_2_resnets_0_norm2_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv152[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(512) + v_ax3) // T.int64(512) + v_ax2) % T.int64(256), (v_ax4 // T.int64(512) + v_ax3) % T.int64(512), v_ax4 % T.int64(512)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_2_resnets_0_norm2_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(512), T.int64(512)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(4.76837158203125e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(512) + v_ax2) // T.int64(512) + v_ax1) % T.int64(8), (v_ax3 // T.int64(512) + v_ax2) % T.int64(512), v_ax3 % T.int64(512)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(512), T.int64(512)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm5_silu4(lv190: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_weight: T.Buffer((T.int64(256),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm1_bias: T.Buffer((T.int64(256),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(8)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        compute = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(256), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv190[T.int64(0), (v_ax1 * T.int64(8) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(256), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_weight[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(8)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm1_bias[(v_ax0 * T.int64(8) + v_ax1) % T.int64(256)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(8), T.int64(1024), T.int64(1024)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.1920928955078125e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(8), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(256) // T.int64(8), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(8), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm6_silu5(lv195: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_weight: T.Buffer((T.int64(128),), "float32"), vae_decoder_up_blocks_3_resnets_0_norm2_bias: T.Buffer((T.int64(128),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(4)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        compute = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(128), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv195[T.int64(0), (v_ax1 * T.int64(4) + (v_ax4 // T.int64(1024) + v_ax3) // T.int64(1024) + v_ax2) % T.int64(128), (v_ax4 // T.int64(1024) + v_ax3) % T.int64(1024), v_ax4 % T.int64(1024)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(4)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_weight[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(4)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_up_blocks_3_resnets_0_norm2_bias[(v_ax0 * T.int64(4) + v_ax1) % T.int64(128)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(1024), T.int64(1024)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.384185791015625e-07)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(4), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(128) // T.int64(4), ((v_ax3 // T.int64(1024) + v_ax2) // T.int64(1024) + v_ax1) % T.int64(4), (v_ax3 // T.int64(1024) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1024)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(128), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm7_silu7(lv48: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32"), unet_down_blocks_0_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_0_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv48[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(320), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv48[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(320), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_0_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(6.1035156250000003e-06)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(10), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(10), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm8_silu8(lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_norm1_weight: T.Buffer((T.int64(320),), "float32"), unet_down_blocks_1_resnets_0_norm1_bias: T.Buffer((T.int64(320),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(10)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv89[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv89[((v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 * T.int64(10) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(320), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_weight[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(10)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm1_bias[(v_ax0 * T.int64(10) + v_ax1) % T.int64(320)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(10), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(320) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(320) // T.int64(10), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(10), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm9_silu9(lv101: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), unet_down_blocks_1_resnets_0_norm2_weight: T.Buffer((T.int64(640),), "float32"), unet_down_blocks_1_resnets_0_norm2_bias: T.Buffer((T.int64(640),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        compute = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv101[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv101[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_weight[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = unet_down_blocks_1_resnets_0_norm2_bias[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(1.0000000000000001e-05)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_group_norm_silu(lv6: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), vae_decoder_mid_block_resnets_0_norm1_weight: T.Buffer((T.int64(512),), "float32"), vae_decoder_mid_block_resnets_0_norm1_bias: T.Buffer((T.int64(512),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_1 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        compute = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = lv6[T.int64(0), (v_ax1 * T.int64(16) + (v_ax4 // T.int64(128) + v_ax3) // T.int64(128) + v_ax2) % T.int64(512), (v_ax4 // T.int64(128) + v_ax3) % T.int64(128), v_ax4 % T.int64(128)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_1[v_ax0, v_ax1])
                T_reshape_1[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_weight[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = vae_decoder_mid_block_resnets_0_norm1_bias[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(128), T.int64(128)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_1[v_ax1, v_ax2], T_reshape_2[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.814697265625e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_1[v_ax1, v_ax2] + T_reshape_2[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[T.int64(0), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(512) // T.int64(16), ((v_ax3 // T.int64(128) + v_ax2) // T.int64(128) + v_ax1) % T.int64(16), (v_ax3 // T.int64(128) + v_ax2) % T.int64(128), v_ax3 % T.int64(128)]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(compute[v_i0, v_i1, v_i2, v_i3])
                compute[v_i0, v_i1, v_i2, v_i3] = T.sigmoid(var_T_reshape_intermediate[v_i0, v_i1, v_i2, v_i3])
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], compute[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * compute[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_matmul12_add24_multiply6_tir_sigmoid_multiply7(lv55: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv56: T.Buffer((T.int64(768), T.int64(3072)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(3072),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(3072)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(3072), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv55[v_i0, v_i1, v_k], lv56[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv55[v_i0, v_i1, v_k] * lv56[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = T.float32(1.7020000219345093) * var_T_add_intermediate[v_ax0, v_ax1, v_ax2]
        for i0, i1, i2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2])
                var_compute_intermediate[v_i0, v_i1, v_i2] = T.sigmoid(var_T_multiply_intermediate_1[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(3072)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], var_compute_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * var_compute_intermediate[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul13_add22_add21(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(3072)), "float32"), lv62: T.Buffer((T.int64(3072), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(768),), "float32"), lv54: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(3072)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv54[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv54[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul14_add25_silu6(lv14: T.Buffer((T.int64(2), T.int64(320)), "float32"), lv15: T.Buffer((T.int64(320), T.int64(1280)), "float32"), unet_time_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(320)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv14[v_i0, v_k], lv15[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv14[v_i0, v_k] * lv15[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_1_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_1_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul15_add25(lv41: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv42: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_add_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv41[v_i0, v_k], lv42[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv41[v_i0, v_k] * lv42[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_2_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_2_bias[v_ax1]

    @T.prim_func(private=True)
    def fused_matmul15_add25_add26(lv18: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv19: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_time_embedding_linear_2_bias: T.Buffer((T.int64(1280),), "float32"), lv44: T.Buffer((T.int64(2), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv18[v_i0, v_k], lv19[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv18[v_i0, v_k] * lv19[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_time_embedding_linear_2_bias[v_ax1])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1])
                var_T_add_intermediate_1[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_time_embedding_linear_2_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1], lv44[v_ax0, v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_T_add_intermediate_1[v_ax0, v_ax1] + lv44[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul15_add25_strided_slice8(lv431: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv432: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv431[v_i0, v_k], lv432[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv431[v_i0, v_k] * lv432[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_2_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul16_add25_silu6(lv37: T.Buffer((T.int64(2), T.int64(2816)), "float32"), lv38: T.Buffer((T.int64(2816), T.int64(1280)), "float32"), unet_add_embedding_linear_1_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(1280), T.int64(2816)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv37[v_i0, v_k], lv38[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv37[v_i0, v_k] * lv38[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_add_embedding_linear_1_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_add_embedding_linear_1_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(var_T_add_intermediate[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul17_add28_cast4(lv54: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv55: T.Buffer((T.int64(1280), T.int64(320)), "float32"), unet_down_blocks_0_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(320),), "float32"), var_compute_intermediate: T.Buffer((T.int64(2), T.int64(320)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(320)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(320), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv54[v_i0, v_k], lv55[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv54[v_i0, v_k] * lv55[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_0_resnets_0_time_emb_proj_bias[v_ax1]
        for i0, i1 in T.grid(T.int64(2), T.int64(320)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_add_intermediate[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_add_intermediate[v_i0, v_i1]

    @T.prim_func(private=True)
    def fused_matmul18_add33_strided_slice7(lv95: T.Buffer((T.int64(2), T.int64(1280)), "float32"), lv96: T.Buffer((T.int64(1280), T.int64(640)), "float32"), unet_down_blocks_1_resnets_0_time_emb_proj_bias: T.Buffer((T.int64(640),), "float32"), var_T_strided_slice_with_axes_intermediate: T.Buffer((T.int64(2), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(640)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640)))
        for i0, i1, k in T.grid(T.int64(2), T.int64(640), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(lv95[v_i0, v_k], lv96[v_k, v_i1])
                T.writes(var_matmul_intermediate[v_i0, v_i1])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1] = var_matmul_intermediate[v_i0, v_i1] + lv95[v_i0, v_k] * lv96[v_k, v_i1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1], unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1])
                var_T_add_intermediate[v_ax0, v_ax1] = var_matmul_intermediate[v_ax0, v_ax1] + unet_down_blocks_1_resnets_0_time_emb_proj_bias[v_ax1]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(640)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = var_T_add_intermediate[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def fused_matmul19_add36(lv114: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv115: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_proj_in_bias: T.Buffer((T.int64(640),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv114[v_i0, v_i1, v_k], lv115[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv114[v_i0, v_i1, v_k] * lv115[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul19_add36_divide9_add37(lv139: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv140: T.Buffer((T.int64(640), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(640),), "float32"), lv117: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv139[v_i0, v_i1, v_k], lv140[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv139[v_i0, v_i1, v_k] * lv140[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv117[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv117[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul1_multiply1(lv34: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv41: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(16384)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)))
        for i0, i1, i2, i3, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384), T.int64(512)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv34[v_i0, v_i1, v_i2, v_k], lv41[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv34[v_i0, v_i1, v_i2, v_k] * lv41[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul20_multiply12(lv126: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), lv133: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(4096)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv126[v_i0, v_i1, v_i2, v_k], lv133[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv126[v_i0, v_i1, v_i2, v_k] * lv133[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul23_multiply13(lv153: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), lv160: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv153[v_i0, v_i1, v_i2, v_k], lv160[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv153[v_i0, v_i1, v_i2, v_k] * lv160[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul25_add38(lv172: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv173: T.Buffer((T.int64(640), T.int64(5120)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(5120),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(5120)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(5120), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv172[v_i0, v_i1, v_k], lv173[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv172[v_i0, v_i1, v_k] * lv173[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul26_add36_add37(lv180: T.Buffer((T.int64(2), T.int64(4096), T.int64(2560)), "float32"), lv181: T.Buffer((T.int64(2560), T.int64(640)), "float32"), unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(640),), "float32"), lv171: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(640)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(2560)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv180[v_i0, v_i1, v_k], lv181[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv180[v_i0, v_i1, v_k] * lv181[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv171[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv171[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul27_add43(lv450: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv451: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_proj_in_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv450[v_i0, v_i1, v_k], lv451[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv450[v_i0, v_i1, v_k] * lv451[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_proj_in_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul27_add43_divide11_add44(lv475: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv476: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias: T.Buffer((T.int64(1280),), "float32"), lv453: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_divide_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv475[v_i0, v_i1, v_k], lv476[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv475[v_i0, v_i1, v_k] * lv476[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2], lv453[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_divide_intermediate[v_ax0, v_ax1, v_ax2] + lv453[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul28_multiply15(lv462: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), lv469: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(1024)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv462[v_i0, v_i1, v_i2, v_k], lv469[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv462[v_i0, v_i1, v_i2, v_k] * lv469[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul31_multiply16(lv489: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), lv496: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(77)), "float32"), param_0: T.Buffer((), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)))
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(lv489[v_i0, v_i1, v_i2, v_k], lv496[v_i0, v_i1, v_k, v_i3])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] = var_matmul_intermediate[v_i0, v_i1, v_i2, v_i3] + lv489[v_i0, v_i1, v_i2, v_k] * lv496[v_i0, v_i1, v_k, v_i3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], param_0[()])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * param_0[()]

    @T.prim_func(private=True)
    def fused_matmul33_add45(lv508: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv509: T.Buffer((T.int64(1280), T.int64(10240)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias: T.Buffer((T.int64(10240),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(10240)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(10240)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(10240), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv508[v_i0, v_i1, v_k], lv509[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv508[v_i0, v_i1, v_k] * lv509[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(10240)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul34_add43_add44(lv516: T.Buffer((T.int64(2), T.int64(1024), T.int64(5120)), "float32"), lv517: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias: T.Buffer((T.int64(1280),), "float32"), lv507: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(5120)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv516[v_i0, v_i1, v_k], lv517[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv516[v_i0, v_i1, v_k] * lv517[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2], lv507[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] + lv507[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul3_add16(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv26: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul3_add16_add14(lv52: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv53: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(1280),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv52[v_i0, v_i1, v_k], lv53[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv52[v_i0, v_i1, v_k] * lv53[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul3_add16_multiply3(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv22: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(1280),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_matmul6_add18_gelu(lv57: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), lv58: T.Buffer((T.int64(1280), T.int64(5120)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc1_bias: T.Buffer((T.int64(5120),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(5120)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(5120), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv57[v_i0, v_i1, v_k], lv58[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv57[v_i0, v_i1, v_k] * lv58[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc1_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(5120)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul7_add16_add14(lv61: T.Buffer((T.int64(1), T.int64(77), T.int64(5120)), "float32"), lv62: T.Buffer((T.int64(5120), T.int64(1280)), "float32"), self_clip_text_model_encoder_layers_0_mlp_fc2_bias: T.Buffer((T.int64(1280),), "float32"), lv56: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(1280), T.int64(5120)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv61[v_i0, v_i1, v_k], lv62[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv61[v_i0, v_i1, v_k] * lv62[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_mlp_fc2_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv56[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv56[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul9_add22(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv26: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv26[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv26[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_k_proj_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_matmul9_add22_add21(lv50: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv51: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias: T.Buffer((T.int64(768),), "float32"), lv9: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv50[v_i0, v_i1, v_k], lv51[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv50[v_i0, v_i1, v_k] * lv51[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_out_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv9[v_ax0, v_ax1, v_ax2], var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = lv9[v_ax0, v_ax1, v_ax2] + var_T_add_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_matmul9_add22_multiply5(lv21: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), lv22: T.Buffer((T.int64(768), T.int64(768)), "float32"), self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias: T.Buffer((T.int64(768),), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(77), T.int64(768), T.int64(768)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv21[v_i0, v_i1, v_k], lv22[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv21[v_i0, v_i1, v_k] * lv22[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + self_clip_text_model_encoder_layers_0_self_attn_q_proj_bias[v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2] * T.float32(0.125)

    @T.prim_func(private=True)
    def fused_matmul_add3(lv23: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv24: T.Buffer((T.int64(512), T.int64(512)), "float32"), vae_decoder_mid_block_attentions_0_to_q_bias: T.Buffer((T.int64(512),), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(512)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(16384), T.int64(512), T.int64(512)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(lv23[v_i0, v_i1, v_k], lv24[v_k, v_i2])
                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])
                with T.init():
                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float32(0)
                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv23[v_i0, v_i1, v_k] * lv24[v_k, v_i2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_matmul_intermediate[v_ax0, v_ax1, v_ax2], vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_matmul_intermediate[v_ax0, v_ax1, v_ax2] + vae_decoder_mid_block_attentions_0_to_q_bias[v_ax2]

    @T.prim_func(private=True)
    def fused_reshape11_reshape11_add14(lv3: T.Buffer((T.int64(77), T.int64(1280)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(1280)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(1280)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape14_transpose8_reshape15(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape14_transpose8_reshape15_transpose9(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape16_add17_reshape17(lv42: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape16_reshape17(lv46: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv46[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(20), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape18_transpose10_reshape19(lv49: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(20), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv49[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(77), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape21_reshape21_add21(lv3: T.Buffer((T.int64(77), T.int64(768)), "float32"), lv7: T.Buffer((T.int64(77), T.int64(768)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(768)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv3[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = lv7[(v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2], var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] + var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape22_transpose14_reshape23(lv33: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv33[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape22_transpose14_reshape23_transpose15(lv28: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv28[T.int64(0), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(768) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(768)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[T.int64(0), ((v_ax2 // T.int64(64) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(64) + v_ax1) % T.int64(77), v_ax2 % T.int64(64)]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape24_add23_reshape25(lv42: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(1), T.int64(77), T.int64(77)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(77)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv42[((v_ax3 // T.int64(77) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(77) + v_ax2) % T.int64(77), v_ax3 % T.int64(77)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], param_0[v_ax0, T.int64(0), v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] + param_0[v_ax0, T.int64(0), v_ax2, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_add_intermediate[T.int64(0), ((v_ax2 // T.int64(77) + v_ax1) // T.int64(77) + v_ax0) % T.int64(12), (v_ax2 // T.int64(77) + v_ax1) % T.int64(77), v_ax2 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_reshape26_transpose16_reshape27(lv47: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(12), T.int64(77), T.int64(64)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(77), T.int64(12), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(12), T.int64(77), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv47[((v_ax3 // T.int64(64) + v_ax2) // T.int64(77) + v_ax1) % T.int64(12), (v_ax3 // T.int64(64) + v_ax2) % T.int64(77), v_ax3 % T.int64(64)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(77), T.int64(12), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate_1[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(768) + v_ax1) % T.int64(77), v_ax2 % T.int64(768) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_reshape2_transpose_transpose1(lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(16384)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(512)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv18[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512), v_ax2 % T.int64(16384) // T.int64(128), v_ax2 % T.int64(128)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = lv18[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512), v_ax2 % T.int64(16384) // T.int64(128), v_ax2 % T.int64(128)]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate_1[v_ax0, v_ax2, v_ax1]

    @T.prim_func(private=True)
    def fused_reshape30_strided_slice4_reshape31_cast5_multiply10_multiply11_tir_sin1_tir_cos1_concatenate5_strided_slice5_reshape32_strided_slice6_reshape32_concatenate5_reshape33_concatenate6(inp_4: T.Buffer((T.int64(2), T.int64(6)), "float32"), param_0: T.Buffer((T.int64(1), T.int64(128)), "float32"), inp_3: T.Buffer((T.int64(2), T.int64(1280)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(2816)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(12),))
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(12),))
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(1)))
        var_compute_intermediate = T.alloc_buffer((T.int64(12), T.int64(1)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_compute_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_compute_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_concat_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(256)))
        var_T_strided_slice_with_axes_intermediate_1 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_reshape_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_strided_slice_with_axes_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_reshape_intermediate_3 = T.alloc_buffer((T.int64(12), T.int64(128)))
        var_T_concat_intermediate_2 = T.alloc_buffer((T.int64(12), T.int64(256)))
        var_T_reshape_intermediate_4 = T.alloc_buffer((T.int64(2), T.int64(1536)))
        for ax0 in range(T.int64(12)):
            with T.block("T_reshape"):
                v_ax0 = T.axis.spatial(T.int64(12), ax0)
                T.reads(inp_4[v_ax0 % T.int64(12) // T.int64(6), v_ax0 % T.int64(6)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = inp_4[v_ax0 % T.int64(12) // T.int64(6), v_ax0 % T.int64(6)]
        for ax0 in range(T.int64(12)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0 = T.axis.spatial(T.int64(12), ax0)
                T.reads(var_T_reshape_intermediate[v_ax0])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0])
                var_T_strided_slice_with_axes_intermediate[v_ax0] = var_T_reshape_intermediate[v_ax0]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(1)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(12)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[(v_ax0 + v_ax1) % T.int64(12)]
        for i0, i1 in T.grid(T.int64(12), T.int64(1)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate[v_ax0, T.int64(0)], param_0[T.int64(0), v_ax1])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1])
                var_T_multiply_intermediate[v_ax0, v_ax1] = var_compute_intermediate[v_ax0, T.int64(0)] * param_0[T.int64(0), v_ax1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_multiply_intermediate[v_ax0, v_ax1])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1])
                var_T_multiply_intermediate_1[v_ax0, v_ax1] = var_T_multiply_intermediate[v_ax0, v_ax1]
        for i0, i1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("compute_1"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_1[v_i0, v_i1])
                var_compute_intermediate_1[v_i0, v_i1] = T.sin(var_T_multiply_intermediate_1[v_i0, v_i1])
        for i0, i1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("compute_2"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_multiply_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate_2[v_i0, v_i1])
                var_compute_intermediate_2[v_i0, v_i1] = T.cos(var_T_multiply_intermediate_1[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(12), T.int64(256)):
            with T.block("T_concat"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_1[v_ax0, v_ax1])
                var_T_concat_intermediate_1[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_compute_intermediate_2[v_ax0, v_ax1 - T.int64(128)], var_compute_intermediate_1[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_strided_slice_with_axes_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)])
                T.writes(var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_1[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1 + T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)])
                T.writes(var_T_reshape_intermediate_2[v_ax0, v_ax1])
                var_T_reshape_intermediate_2[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_1[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_strided_slice_with_axes_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_1[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate_2[v_ax0, v_ax1] = var_T_concat_intermediate_1[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(128)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)])
                T.writes(var_T_reshape_intermediate_3[v_ax0, v_ax1])
                var_T_reshape_intermediate_3[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate_2[(v_ax1 // T.int64(128) + v_ax0) % T.int64(12), v_ax1 % T.int64(128)]
        for ax0, ax1 in T.grid(T.int64(12), T.int64(256)):
            with T.block("T_concat_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate_2[v_ax0, v_ax1])
                var_T_concat_intermediate_2[v_ax0, v_ax1] = T.if_then_else(T.int64(128) <= v_ax1, var_T_reshape_intermediate_3[v_ax0, v_ax1 - T.int64(128)], var_T_reshape_intermediate_2[v_ax0, v_ax1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1536)):
            with T.block("T_reshape_4"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_concat_intermediate_2[(v_ax0 * T.int64(6) + v_ax1 // T.int64(256)) % T.int64(12), v_ax1 % T.int64(256)])
                T.writes(var_T_reshape_intermediate_4[v_ax0, v_ax1])
                var_T_reshape_intermediate_4[v_ax0, v_ax1] = var_T_concat_intermediate_2[(v_ax0 * T.int64(6) + v_ax1 // T.int64(256)) % T.int64(12), v_ax1 % T.int64(256)]
        for ax0, ax1 in T.grid(T.int64(2), T.int64(2816)):
            with T.block("T_concat_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1])
                var_T_concat_intermediate[v_ax0, v_ax1] = T.if_then_else(T.int64(1280) <= v_ax1, var_T_reshape_intermediate_4[v_ax0, v_ax1 - T.int64(1280)], inp_3[v_ax0, v_ax1])

    @T.prim_func(private=True)
    def fused_reshape39_transpose25(lv120: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv120[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv120[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape39_transpose25_transpose26(lv122: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(4096)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv122[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv122[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(4096), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(64), T.int64(4096)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape3_transpose3(lv26: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv26[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape3_transpose3_transpose4(lv29: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv29[T.int64(0), (v_ax3 // T.int64(512) + v_ax1 + v_ax2) % T.int64(16384), v_ax3 % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape41_transpose29(lv151: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv151[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv151[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape41_transpose29_transpose30(lv149: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(10), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(10), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(10), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv149[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv149[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(640) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(10), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape42_transpose33_add35(lv254: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv111: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv254[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv254[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv111[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv111[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape42_transpose33_add35_concatenate10(lv4835: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv4692: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), lv257: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv4835[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4835[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4692[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4692[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv257[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape42_transpose33_add35_concatenate11(lv5004: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv4861: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), lv89: T.Buffer((T.int64(2), T.int64(320), T.int64(64), T.int64(64)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(960), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5004[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5004[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv4861[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv4861[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(960), T.int64(64), T.int64(64)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(640) <= v_ax1, lv89[v_ax0, v_ax1 - T.int64(640), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape42_transpose33_add35_resize2d4(lv5173: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), lv5030: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_resize_intermediate: T.Buffer((T.int64(2), T.int64(640), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5173[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5173[((v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax1 * T.int64(64) + v_ax3 // T.int64(640) + v_ax2) % T.int64(4096), v_ax3 % T.int64(640)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv5030[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv5030[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(640), T.int64(128), T.int64(128)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))])
                T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(63)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(63)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape46_transpose35(lv456: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv456[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv456[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape46_transpose35_transpose36(lv458: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(1024)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv458[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv458[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(1024), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(64), T.int64(1024)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape48_transpose39(lv487: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv487[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv487[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape48_transpose39_transpose40(lv485: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32"), var_T_transpose_intermediate: T.Buffer((T.int64(2), T.int64(20), T.int64(64), T.int64(77)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(77), T.int64(20), T.int64(64)))
        var_T_transpose_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(77), T.int64(20), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv485[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv485[(((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) // T.int64(77) + v_ax0) % T.int64(2), ((v_ax2 * T.int64(64) + v_ax3) // T.int64(1280) + v_ax1) % T.int64(77), (v_ax2 * T.int64(64) + v_ax3) % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(77), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(20), T.int64(64), T.int64(77)):
            with T.block("T_transpose_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate_1[v_ax0, v_ax1, v_ax3, v_ax2]

    @T.prim_func(private=True)
    def fused_reshape49_transpose42_add42(lv1126: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv447: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv1126[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv1126[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv447[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv447[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_reshape49_transpose42_add42_concatenate7(lv3252: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv2573: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), lv1129: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(2560), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv3252[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3252[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv2573[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv2573[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2560), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv1129[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape49_transpose42_add42_concatenate8(lv3957: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv3278: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), lv425: T.Buffer((T.int64(2), T.int64(640), T.int64(32), T.int64(32)), "float32"), var_T_concat_intermediate: T.Buffer((T.int64(2), T.int64(1920), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv3957[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv3957[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3278[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3278[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1920), T.int64(32), T.int64(32)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_concat_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(1280) <= v_ax1, lv425[v_ax0, v_ax1 - T.int64(1280), v_ax2, v_ax3], var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])

    @T.prim_func(private=True)
    def fused_reshape49_transpose42_add42_resize2d3(lv4662: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), lv3983: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_resize_intermediate: T.Buffer((T.int64(2), T.int64(1280), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv4662[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv4662[((v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax1 * T.int64(32) + v_ax3 // T.int64(1280) + v_ax2) % T.int64(1024), v_ax3 % T.int64(1280)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax2, v_ax3, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv3983[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv3983[v_ax0, v_ax1, v_ax2, v_ax3]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(1280), T.int64(64), T.int64(64)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))])
                T.writes(var_resize_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_resize_intermediate[v_i0, v_i1, v_i2, v_i3] = var_T_add_intermediate[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(31)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(31)), T.int64(0))]

    @T.prim_func(private=True)
    def fused_reshape9_cast_reshape10(inp_0: T.Buffer((T.int64(1), T.int64(77)), "int32"), var_T_reshape_intermediate: T.Buffer((T.int64(77),), "int32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_reshape_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        var_compute_intermediate = T.alloc_buffer((T.int64(1), T.int64(77)), "int32")
        for ax0, ax1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(inp_0[T.int64(0), v_ax1 % T.int64(77)])
                T.writes(var_T_reshape_intermediate_1[v_ax0, v_ax1])
                var_T_reshape_intermediate_1[v_ax0, v_ax1] = inp_0[T.int64(0), v_ax1 % T.int64(77)]
        for i0, i1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(var_T_reshape_intermediate_1[v_i0, v_i1])
                T.writes(var_compute_intermediate[v_i0, v_i1])
                var_compute_intermediate[v_i0, v_i1] = var_T_reshape_intermediate_1[v_i0, v_i1]
        for ax0 in range(T.int64(77)):
            with T.block("T_reshape_1"):
                v_ax0 = T.axis.spatial(T.int64(77), ax0)
                T.reads(var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)])
                T.writes(var_T_reshape_intermediate[v_ax0])
                var_T_reshape_intermediate[v_ax0] = var_compute_intermediate[T.int64(0), v_ax0 % T.int64(77)]

    @T.prim_func(private=True)
    def fused_split1_gelu2_multiply17(lv511: T.Buffer((T.int64(2), T.int64(1024), T.int64(10240)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(5120)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_multiply = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        compute = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_multiply_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        T_add = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(5120)))
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv511[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv511[v_ax0, v_ax1, v_ax2 + T.int64(5120)]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(5120)):
            with T.block("T_multiply_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_split2_subtract1_multiply18_add20(lv5254: T.Buffer((T.int64(2), T.int64(4), T.int64(128), T.int64(128)), "float32"), var_T_add_intermediate: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_subtract_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5254[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv5254[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv5254[v_ax0 + T.int64(1), v_ax1, v_ax2, v_ax3])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] = lv5254[v_ax0 + T.int64(1), v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_subtract"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3], var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2, v_ax3] - var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(5) * var_T_subtract_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_split_gelu1_multiply14(lv175: T.Buffer((T.int64(2), T.int64(4096), T.int64(5120)), "float32"), var_T_multiply_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(2560)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_split_sections_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        var_T_split_sections_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_multiply = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        compute = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_multiply_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        T_add = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        var_T_multiply_intermediate_1 = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(2560)))
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_split_sections"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv175[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_split_sections_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)])
                T.writes(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] = lv175[v_ax0, v_ax1, v_ax2 + T.int64(2560)]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2])
                T_multiply[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T.float32(0.70710678118654757)
        for i0, i1, i2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("compute"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_multiply[v_i0, v_i1, v_i2])
                T.writes(compute[v_i0, v_i1, v_i2])
                compute[v_i0, v_i1, v_i2] = T.erf(T_multiply[v_i0, v_i1, v_i2])
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(compute[v_ax0, v_ax1, v_ax2])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T_multiply_1[v_ax0, v_ax1, v_ax2] = compute[v_ax0, v_ax1, v_ax2] * T.float32(0.5)
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2])
                T.writes(T_add[v_ax0, v_ax1, v_ax2])
                T_add[v_ax0, v_ax1, v_ax2] = T.float32(0.5) + T_multiply_1[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2], T_add[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate_1[v_ax0, v_ax1, v_ax2] * T_add[v_ax0, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(2560)):
            with T.block("T_multiply_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2], var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2] = var_T_split_sections_intermediate[v_ax0, v_ax1, v_ax2] * var_T_multiply_intermediate_1[v_ax0, v_ax1, v_ax2]

    @T.prim_func(private=True)
    def fused_strided_slice_reshape20(lv1465: T.Buffer((T.int64(1), T.int64(1280)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_strided_slice_with_axes_intermediate = T.alloc_buffer((T.int64(1), T.int64(1280)))
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_strided_slice_with_axes"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(lv1465[v_ax0, v_ax1])
                T.writes(var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1])
                var_T_strided_slice_with_axes_intermediate[v_ax0, v_ax1] = lv1465[v_ax0, v_ax1]
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1])
                var_T_reshape_intermediate[v_ax0, v_ax1] = var_T_strided_slice_with_axes_intermediate[T.int64(0), v_ax1 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose1_reshape5_add2_divide(lv50: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32"), lv18: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), var_T_divide_intermediate: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(16384)))
        var_T_reshape_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        var_T_add_intermediate = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)))
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(lv50[v_ax0, v_ax2, v_ax1])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2] = lv50[v_ax0, v_ax2, v_ax1]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(128) + v_ax3) // T.int64(16384) + v_ax1) % T.int64(512), (v_ax2 * T.int64(128) + v_ax3) % T.int64(16384)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[T.int64(0), ((v_ax2 * T.int64(128) + v_ax3) // T.int64(16384) + v_ax1) % T.int64(512), (v_ax2 * T.int64(128) + v_ax3) % T.int64(16384)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3], lv18[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] + lv18[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(128), T.int64(128)):
            with T.block("T_divide"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_divide_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_add_intermediate[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def fused_transpose23_reshape38(lv112: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(64), T.int64(64), T.int64(640)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(64), T.int64(64), T.int64(640)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv112[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv112[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096) // T.int64(64), (v_ax2 // T.int64(640) + v_ax1) % T.int64(64), v_ax2 % T.int64(640)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096) // T.int64(64), (v_ax2 // T.int64(640) + v_ax1) % T.int64(64), v_ax2 % T.int64(640)]

    @T.prim_func(private=True)
    def fused_transpose27_reshape40(lv137: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(4096), T.int64(10), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(4096), T.int64(10), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv137[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv137[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(640) + v_ax1) // T.int64(4096) + v_ax0) % T.int64(2), (v_ax2 // T.int64(640) + v_ax1) % T.int64(4096), v_ax2 % T.int64(640) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose34_reshape45(lv448: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(32), T.int64(1280)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(32), T.int64(32), T.int64(1280)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv448[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv448[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(32), v_ax2 % T.int64(1280)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024) // T.int64(32), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(32), v_ax2 % T.int64(1280)]

    @T.prim_func(private=True)
    def fused_transpose37_reshape47(lv473: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(2), T.int64(1024), T.int64(20), T.int64(64)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1024), T.int64(20), T.int64(64)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv473[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv473[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[((v_ax2 // T.int64(1280) + v_ax1) // T.int64(1024) + v_ax0) % T.int64(2), (v_ax2 // T.int64(1280) + v_ax1) % T.int64(1024), v_ax2 % T.int64(1280) // T.int64(64), v_ax2 % T.int64(64)]

    @T.prim_func(private=True)
    def fused_transpose5_reshape4(lv45: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), var_T_reshape_intermediate: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(16384), T.int64(1), T.int64(512)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16384), T.int64(1), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv45[v_ax0, v_ax2, v_ax1, v_ax3])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv45[v_ax0, v_ax2, v_ax1, v_ax3]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(16384), T.int64(0), v_ax2 % T.int64(512)])
                T.writes(var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2])
                var_T_reshape_intermediate[v_ax0, v_ax1, v_ax2] = var_T_transpose_intermediate[T.int64(0), (v_ax2 // T.int64(512) + v_ax1) % T.int64(16384), T.int64(0), v_ax2 % T.int64(512)]

    @T.prim_func(private=True)
    def fused_transpose6_multiply2_tir_round(lv237: T.Buffer((T.int64(1), T.int64(3), T.int64(1024), T.int64(1024)), "float32"), var_compute_intermediate: T.Buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        var_T_transpose_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)))
        var_T_multiply_intermediate = T.alloc_buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(lv237[v_ax0, v_ax3, v_ax1, v_ax2])
                T.writes(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = lv237[v_ax0, v_ax3, v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3])
                var_T_multiply_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] = var_T_transpose_intermediate[v_ax0, v_ax1, v_ax2, v_ax3] * T.float32(255)
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)):
            with T.block("compute"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])
                T.writes(var_compute_intermediate[v_i0, v_i1, v_i2, v_i3])
                var_compute_intermediate[v_i0, v_i1, v_i2, v_i3] = T.round(var_T_multiply_intermediate[v_i0, v_i1, v_i2, v_i3])

    @T.prim_func(private=True)
    def group_norm1(A: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32"), B: T.Buffer((T.int64(512),), "float32"), C: T.Buffer((T.int64(512),), "float32"), T_reshape: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16384)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(16)))
        T_group_norm = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16384)))
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(16384) + v_ax2) % T.int64(512), v_ax3 % T.int64(16384)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] = A[T.int64(0), (v_ax1 * T.int64(16) + v_ax3 // T.int64(16384) + v_ax2) % T.int64(512), v_ax3 % T.int64(16384)]
        for ax0, ax1, k2, k3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3 = T.axis.remap("SSRR", [ax0, ax1, k2, k3])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(16)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(16) + v_ax1) % T.int64(512)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16384)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(3.814697265625e-06) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(3.814697265625e-06)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(512), T.int64(16384)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(T_group_norm[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(16), v_ax2 % T.int64(16384)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2])
                T_reshape[v_ax0, v_ax1, v_ax2] = T_group_norm[T.int64(0), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(512) // T.int64(16), (v_ax2 // T.int64(16384) + v_ax1) % T.int64(16), v_ax2 % T.int64(16384)]

    @T.prim_func(private=True)
    def group_norm10(A: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(640), T.int64(64), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(20)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(A[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[((v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 * T.int64(20) + (v_ax4 // T.int64(64) + v_ax3) // T.int64(64) + v_ax2) % T.int64(640), (v_ax4 // T.int64(64) + v_ax3) % T.int64(64), v_ax4 % T.int64(64)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(20)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(20) + v_ax1) % T.int64(640)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(20), T.int64(64), T.int64(64)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(1.2207031250000001e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(64), T.int64(64)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) // T.int64(640) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(640) // T.int64(20), ((v_ax3 // T.int64(64) + v_ax2) // T.int64(64) + v_ax1) % T.int64(20), (v_ax3 // T.int64(64) + v_ax2) % T.int64(64), v_ax3 % T.int64(64)]

    @T.prim_func(private=True)
    def group_norm13(A: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(1280), T.int64(32), T.int64(32)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_reshape_1 = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(32)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(32)))
        T_reshape_2 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_reshape_3 = T.alloc_buffer((T.int64(32), T.int64(40)))
        T_group_norm = T.alloc_buffer((T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)))
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(A[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)])
                T.writes(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = A[((v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 * T.int64(40) + (v_ax4 // T.int64(32) + v_ax3) // T.int64(32) + v_ax2) % T.int64(1280), (v_ax4 // T.int64(32) + v_ax3) % T.int64(32), v_ax4 % T.int64(32)]
        for ax0, ax1, k2, k3, k4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2, v_k3, v_k4 = T.axis.remap("SSRRR", [ax0, ax1, k2, k3, k4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4] * T_reshape_1[v_ax0, v_ax1, v_k2, v_k3, v_k4]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_1"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_2[v_ax0, v_ax1])
                T_reshape_2[v_ax0, v_ax1] = B[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1 in T.grid(T.int64(32), T.int64(40)):
            with T.block("T_reshape_2"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)])
                T.writes(T_reshape_3[v_ax0, v_ax1])
                T_reshape_3[v_ax0, v_ax1] = C[(v_ax0 * T.int64(40) + v_ax1) % T.int64(1280)]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(2), T.int64(32), T.int64(40), T.int64(32), T.int64(32)):
            with T.block("T_group_norm"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], T_reshape_2[v_ax1, v_ax2], T_reshape_3[v_ax1, v_ax2])
                T.writes(T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_group_norm[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = (T_reshape_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(2.4414062500000001e-05)) + T.float32(9.9999999999999995e-07)) * T_reshape_2[v_ax1, v_ax2] + T_reshape_3[v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(32), T.int64(32)):
            with T.block("T_reshape_3"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = T_group_norm[(((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) // T.int64(1280) + v_ax0) % T.int64(2), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(1280) // T.int64(40), ((v_ax3 // T.int64(32) + v_ax2) // T.int64(32) + v_ax1) % T.int64(40), (v_ax3 // T.int64(32) + v_ax2) % T.int64(32), v_ax3 % T.int64(32)]

    @T.prim_func(private=True)
    def layer_norm(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0, ax1, k2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(1280)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm1(A: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32"), B: T.Buffer((T.int64(768),), "float32"), C: T.Buffer((T.int64(768),), "float32"), T_layer_norm: T.Buffer((T.int64(1), T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(1), T.int64(77)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(1), T.int64(77)))
        for ax0, ax1, k2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(77), T.int64(768)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0013020833333333333) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0013020833333333333)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm2(A: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), B: T.Buffer((T.int64(640),), "float32"), C: T.Buffer((T.int64(640),), "float32"), T_layer_norm: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(4096)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(4096)))
        for ax0, ax1, k2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(4096), T.int64(640)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.0015625000000000001) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.0015625000000000001)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def layer_norm3(A: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280),), "float32"), C: T.Buffer((T.int64(1280),), "float32"), T_layer_norm: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        A_red_temp_v0 = T.alloc_buffer((T.int64(2), T.int64(1024)))
        A_red_temp_v1 = T.alloc_buffer((T.int64(2), T.int64(1024)))
        for ax0, ax1, k2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("A_red_temp"):
                v_ax0, v_ax1, v_k2 = T.axis.remap("SSR", [ax0, ax1, k2])
                T.reads(A[v_ax0, v_ax1, v_k2])
                T.writes(A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1])
                with T.init():
                    A_red_temp_v0[v_ax0, v_ax1] = T.float32(0)
                    A_red_temp_v1[v_ax0, v_ax1] = T.float32(0)
                v_A_red_temp_v0: T.float32 = A_red_temp_v0[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2]
                v_A_red_temp_v1: T.float32 = A_red_temp_v1[v_ax0, v_ax1] + A[v_ax0, v_ax1, v_k2] * A[v_ax0, v_ax1, v_k2]
                A_red_temp_v0[v_ax0, v_ax1] = v_A_red_temp_v0
                A_red_temp_v1[v_ax0, v_ax1] = v_A_red_temp_v1
        for ax0, ax1, ax2 in T.grid(T.int64(2), T.int64(1024), T.int64(1280)):
            with T.block("T_layer_norm"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax1, v_ax2], A_red_temp_v0[v_ax0, v_ax1], A_red_temp_v1[v_ax0, v_ax1], B[v_ax2], C[v_ax2])
                T.writes(T_layer_norm[v_ax0, v_ax1, v_ax2])
                T_layer_norm[v_ax0, v_ax1, v_ax2] = (A[v_ax0, v_ax1, v_ax2] - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) * T.rsqrt(A_red_temp_v1[v_ax0, v_ax1] * T.float32(0.00078125000000000004) - A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004) * (A_red_temp_v0[v_ax0, v_ax1] * T.float32(0.00078125000000000004)) + T.float32(1.0000000000000001e-05)) * B[v_ax2] + C[v_ax2]

    @T.prim_func(private=True)
    def matmul10(A: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(12), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(12), T.int64(77), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul11(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(12), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(12), T.int64(77), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul19(A: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32"), B: T.Buffer((T.int64(640), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(4096), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(4096), T.int64(640), T.int64(640)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul2(A: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32"), B: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(512), T.int64(16384)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul21(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32"), B: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64), T.int64(4096)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul22(A: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(640)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(77), T.int64(640)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(77), T.int64(640), T.int64(2048)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul24(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32"), B: T.Buffer((T.int64(2), T.int64(10), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul27(A: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(1024), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(1024), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul29(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32"), B: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64), T.int64(1024)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul30(A: T.Buffer((T.int64(2), T.int64(77), T.int64(2048)), "float32"), B: T.Buffer((T.int64(2048), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(77), T.int64(1280), T.int64(2048)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_k, v_i2]

    @T.prim_func(private=True)
    def matmul32(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32"), B: T.Buffer((T.int64(2), T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_i3, v_k = T.axis.remap("SSSSR", [i0, i1, i2, i3, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k], B[v_i0, v_i1, v_k, v_i3])
                T.writes(matmul[v_i0, v_i1, v_i2, v_i3])
                with T.init():
                    matmul[v_i0, v_i1, v_i2, v_i3] = T.float32(0)
                matmul[v_i0, v_i1, v_i2, v_i3] = matmul[v_i0, v_i1, v_i2, v_i3] + A[v_i0, v_i1, v_i2, v_k] * B[v_i0, v_i1, v_k, v_i3]

    @T.prim_func(private=True)
    def matmul4(A: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), B: T.Buffer((T.int64(20), T.int64(64), T.int64(77)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(20), T.int64(77), T.int64(77), T.int64(64)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul5(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), B: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32"), matmul: T.Buffer((T.int64(20), T.int64(77), T.int64(64)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, k in T.grid(T.int64(20), T.int64(77), T.int64(64), T.int64(77)):
            with T.block("matmul"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_k], B[v_i0, v_k, v_i2])
                T.writes(matmul[v_i0, v_i1, v_i2])
                with T.init():
                    matmul[v_i0, v_i1, v_i2] = T.float32(0)
                matmul[v_i0, v_i1, v_i2] = matmul[v_i0, v_i1, v_i2] + A[v_i0, v_i1, v_k] * B[v_i0, v_k, v_i2]

    @T.prim_func(private=True)
    def matmul8(A: T.Buffer((T.int64(1), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1280), T.int64(1280)), "float32"), matmul: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, k in T.grid(T.int64(1), T.int64(1280), T.int64(1280)):
            with T.block("matmul"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_k], B[v_k, v_i1])
                T.writes(matmul[v_i0, v_i1])
                with T.init():
                    matmul[v_i0, v_i1] = T.float32(0)
                matmul[v_i0, v_i1] = matmul[v_i0, v_i1] + A[v_i0, v_k] * B[v_k, v_i1]

    @T.prim_func(private=True)
    def multiply(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(7.6775431632995605) * A[v_ax0, v_ax1, v_ax2, v_ax3]

    @T.prim_func(private=True)
    def multiply4(A: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32"), B: T.Buffer((), "float32"), T_multiply: T.Buffer((T.int64(1), T.int64(4), T.int64(128), T.int64(128)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(128), T.int64(128)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[v_ax0, v_ax1, v_ax2, v_ax3], B[()])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = A[v_ax0, v_ax1, v_ax2, v_ax3] * B[()]

    @T.prim_func(private=True)
    def power(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_power"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads(A[()])
            T.writes(T_power[()])
            T_power[()] = T.pow(A[()], T.float32(2))

    @T.prim_func(private=True)
    def power1(A: T.Buffer((), "float32"), T_power: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_power"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads(A[()])
            T.writes(T_power[()])
            T_power[()] = T.pow(A[()], T.float32(0.5))

    @T.prim_func(private=True)
    def reshape35(A: T.Buffer((T.int64(2), T.int64(320)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(320), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(320), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(320) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(320)]

    @T.prim_func(private=True)
    def reshape37(A: T.Buffer((T.int64(2), T.int64(640)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(640), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(640), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(640) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(640)]

    @T.prim_func(private=True)
    def reshape44(A: T.Buffer((T.int64(2), T.int64(1280)), "float32"), T_reshape: T.Buffer((T.int64(2), T.int64(1280), T.int64(1), T.int64(1)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1280), T.int64(1), T.int64(1)):
            with T.block("T_reshape"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(A[((v_ax1 + v_ax2 + v_ax3) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)])
                T.writes(T_reshape[v_ax0, v_ax1, v_ax2, v_ax3])
                T_reshape[v_ax0, v_ax1, v_ax2, v_ax3] = A[((v_ax1 + v_ax2 + v_ax3) // T.int64(1280) + v_ax0) % T.int64(2), (v_ax1 + v_ax2 + v_ax3) % T.int64(1280)]

    @T.prim_func(private=True)
    def reshape9(A: T.Buffer((T.int64(1), T.int64(77)), "int32"), T_reshape: T.Buffer((T.int64(1), T.int64(77)), "int32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(1), T.int64(77)):
            with T.block("T_reshape"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[T.int64(0), v_ax1 % T.int64(77)])
                T.writes(T_reshape[v_ax0, v_ax1])
                T_reshape[v_ax0, v_ax1] = A[T.int64(0), v_ax1 % T.int64(77)]

    @T.prim_func(private=True)
    def resize2d(A: T.Buffer((T.int64(1), T.int64(512), T.int64(128), T.int64(128)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(256), T.int64(256)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(127)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(127)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d1(A: T.Buffer((T.int64(1), T.int64(512), T.int64(256), T.int64(256)), "float32"), resize: T.Buffer((T.int64(1), T.int64(512), T.int64(512), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(512), T.int64(512)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(255)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(255)), T.int64(0))]

    @T.prim_func(private=True)
    def resize2d2(A: T.Buffer((T.int64(1), T.int64(256), T.int64(512), T.int64(512)), "float32"), resize: T.Buffer((T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(1024), T.int64(1024)):
            with T.block("resize"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(511)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(511)), T.int64(0))])
                T.writes(resize[v_i0, v_i1, v_i2, v_i3])
                resize[v_i0, v_i1, v_i2, v_i3] = A[v_i0, v_i1, T.max(T.min(T.Div(v_i2, T.int64(2)), T.int64(511)), T.int64(0)), T.max(T.min(T.Div(v_i3, T.int64(2)), T.int64(511)), T.int64(0))]

    @T.prim_func(private=True)
    def silu6(A: T.Buffer((T.int64(2), T.int64(1280)), "float32"), T_multiply: T.Buffer((T.int64(2), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        compute = T.alloc_buffer((T.int64(2), T.int64(1280)))
        for i0, i1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("compute"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(A[v_i0, v_i1])
                T.writes(compute[v_i0, v_i1])
                compute[v_i0, v_i1] = T.sigmoid(A[v_i0, v_i1])
        for ax0, ax1 in T.grid(T.int64(2), T.int64(1280)):
            with T.block("T_multiply"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[v_ax0, v_ax1], compute[v_ax0, v_ax1])
                T.writes(T_multiply[v_ax0, v_ax1])
                T_multiply[v_ax0, v_ax1] = A[v_ax0, v_ax1] * compute[v_ax0, v_ax1]

    @T.prim_func(private=True)
    def softmax(A: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384)))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(16384)))
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(1), T.int64(16384), T.int64(16384)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax1(A: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(20), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(20), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(20), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(20), T.int64(77)))
        for i0, i1, k in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_i1, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0, i1, i2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0, i1, k in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0, i1, i2 in T.grid(T.int64(20), T.int64(77), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                T.block_attr({"axis": 2})
                T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def softmax2(A: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(12), T.int64(77), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(12), T.int64(77)))
        T_softmax_exp = T.alloc_buffer((T.int64(12), T.int64(77), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(12), T.int64(77)))
        for i0, i1, k in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(A[v_i0, v_i1, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1] = T.max(T_softmax_maxelem[v_i0, v_i1], A[v_i0, v_i1, v_k])
        for i0, i1, i2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(A[v_i0, v_i1, v_i2], T_softmax_maxelem[v_i0, v_i1])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2])
                T_softmax_exp[v_i0, v_i1, v_i2] = T.exp(A[v_i0, v_i1, v_i2] - T_softmax_maxelem[v_i0, v_i1])
        for i0, i1, k in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_k = T.axis.remap("SSR", [i0, i1, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1] = T_softmax_expsum[v_i0, v_i1] + T_softmax_exp[v_i0, v_i1, v_k]
        for i0, i1, i2 in T.grid(T.int64(12), T.int64(77), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [i0, i1, i2])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2], T_softmax_expsum[v_i0, v_i1])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2])
                T.block_attr({"axis": 2})
                T_softmax_norm[v_i0, v_i1, v_i2] = T_softmax_exp[v_i0, v_i1, v_i2] / T_softmax_expsum[v_i0, v_i1]

    @T.prim_func(private=True)
    def softmax3(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(4096)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax4(A: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(10), T.int64(4096)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(10), T.int64(4096), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax5(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(1024)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def softmax6(A: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32"), T_softmax_norm: T.Buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)), "float32")):
        T.func_attr({"op_pattern": 4, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        T_softmax_exp = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024), T.int64(77)))
        T_softmax_expsum = T.alloc_buffer((T.int64(2), T.int64(20), T.int64(1024)))
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(A[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_maxelem[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_maxelem[v_i0, v_i1, v_i2] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0, v_i1, v_i2] = T.max(T_softmax_maxelem[v_i0, v_i1, v_i2], A[v_i0, v_i1, v_i2, v_k])
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(A[v_i0, v_i1, v_i2, v_i3], T_softmax_maxelem[v_i0, v_i1, v_i2])
                T.writes(T_softmax_exp[v_i0, v_i1, v_i2, v_i3])
                T_softmax_exp[v_i0, v_i1, v_i2, v_i3] = T.exp(A[v_i0, v_i1, v_i2, v_i3] - T_softmax_maxelem[v_i0, v_i1, v_i2])
        for i0, i1, i2, k in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_expsum"):
                v_i0, v_i1, v_i2, v_k = T.axis.remap("SSSR", [i0, i1, i2, k])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_k])
                T.writes(T_softmax_expsum[v_i0, v_i1, v_i2])
                with T.init():
                    T_softmax_expsum[v_i0, v_i1, v_i2] = T.float32(0)
                T_softmax_expsum[v_i0, v_i1, v_i2] = T_softmax_expsum[v_i0, v_i1, v_i2] + T_softmax_exp[v_i0, v_i1, v_i2, v_k]
        for i0, i1, i2, i3 in T.grid(T.int64(2), T.int64(20), T.int64(1024), T.int64(77)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(T_softmax_exp[v_i0, v_i1, v_i2, v_i3], T_softmax_expsum[v_i0, v_i1, v_i2])
                T.writes(T_softmax_norm[v_i0, v_i1, v_i2, v_i3])
                T.block_attr({"axis": 3})
                T_softmax_norm[v_i0, v_i1, v_i2, v_i3] = T_softmax_exp[v_i0, v_i1, v_i2, v_i3] / T_softmax_expsum[v_i0, v_i1, v_i2]

    @T.prim_func(private=True)
    def squeeze(A: T.Buffer((T.int64(1), T.int64(77), T.int64(1280)), "float32"), T_squeeze: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 1, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(1280)):
            with T.block("T_squeeze"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[T.int64(0), v_ax0, v_ax1])
                T.writes(T_squeeze[v_ax0, v_ax1])
                T_squeeze[v_ax0, v_ax1] = A[T.int64(0), v_ax0, v_ax1]

    @T.prim_func(private=True)
    def subtract(A: T.Buffer((), "float32"), B: T.Buffer((), "float32"), T_subtract: T.Buffer((), "float32")):
        T.func_attr({"op_pattern": 0, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        with T.block("T_subtract"):
            vi = T.axis.spatial(1, T.int64(0))
            T.reads(A[()], B[()])
            T.writes(T_subtract[()])
            T_subtract[()] = A[()] - B[()]

    @T.prim_func(private=True)
    def take(A: T.Buffer((T.int64(49408), T.int64(1280)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(1280)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take2(A: T.Buffer((T.int64(77), T.int64(1280)), "float32"), B: T.Buffer((T.int64(1),), "int32"), T_take: T.Buffer((T.int64(1), T.int64(1280)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1280)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def take3(A: T.Buffer((T.int64(49408), T.int64(768)), "float32"), B: T.Buffer((T.int64(77),), "int32"), T_take: T.Buffer((T.int64(77), T.int64(768)), "float32")):
        T.func_attr({"op_pattern": 8, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1 in T.grid(T.int64(77), T.int64(768)):
            with T.block("T_take"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(A[B[v_ax0], v_ax1], B[v_ax0])
                T.writes(T_take[v_ax0, v_ax1])
                T_take[v_ax0, v_ax1] = A[B[v_ax0], v_ax1]

    @T.prim_func(private=True)
    def tir_image_to_rgba(A: T.Buffer((T.int64(1), T.int64(1024), T.int64(1024), T.int64(3)), "float32"), image_to_rgba: T.Buffer((T.int64(1024), T.int64(1024)), "uint32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for y, x in T.grid(T.int64(1024), T.int64(1024)):
            with T.block("image_to_rgba"):
                v_y, v_x = T.axis.remap("SS", [y, x])
                T.reads(A[T.int64(0), v_y, v_x, T.int64(0):T.int64(3)])
                T.writes(image_to_rgba[v_y, v_x])
                image_to_rgba[v_y, v_x] = T.bitwise_or(T.bitwise_or(T.bitwise_or(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(0)]), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(1)]), T.uint32(8))), T.shift_left(T.Cast("uint32", A[T.int64(0), v_y, v_x, T.int64(2)]), T.uint32(16))), T.uint32(4278190080))

    @T.prim_func(private=True)
    def transpose(A: T.Buffer((T.int64(1), T.int64(512), T.int64(16384)), "float32"), T_transpose: T.Buffer((T.int64(1), T.int64(16384), T.int64(512)), "float32")):
        T.func_attr({"op_pattern": 2, "tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16384), T.int64(512)):
            with T.block("T_transpose"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(A[v_ax0, v_ax2, v_ax1])
                T.writes(T_transpose[v_ax0, v_ax1, v_ax2])
                T_transpose[v_ax0, v_ax1, v_ax2] = A[v_ax0, v_ax2, v_ax1]

    @R.function
    def cat_latents(latents: R.Tensor((1, 4, 128, 128), dtype="float32")) -> R.Tensor((2, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate2, (latents, latents), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
        return gv

    @R.function
    def clip(inp_0: R.Tensor((1, 77), dtype="int32"), model_params: R.Tuple(R.Tensor((49408, 768), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((3072,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((768,), dtype="float32"), R.Tensor((77, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 768), dtype="float32"), R.Tensor((768, 3072), dtype="float32"), R.Tensor((3072, 768), dtype="float32"))) -> R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv464 = R.call_tir(cls.fused_reshape9_cast_reshape10, (inp_0,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv517: R.Tensor((49408, 768), dtype="float32") = model_params[0]
            lv3 = R.call_tir(cls.take3, (lv517, lv464), out_sinfo=R.Tensor((77, 768), dtype="float32"))
            lv518: R.Tensor((77, 768), dtype="float32") = model_params[123]
            lv465 = R.call_tir(cls.fused_reshape21_reshape21_add21, (lv3, lv518), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv519: R.Tensor((768,), dtype="float32") = model_params[2]
            lv520: R.Tensor((768,), dtype="float32") = model_params[1]
            lv21 = R.call_tir(cls.layer_norm1, (lv465, lv519, lv520), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv521: R.Tensor((768, 768), dtype="float32") = model_params[124]
            lv522: R.Tensor((768,), dtype="float32") = model_params[9]
            lv466 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv21, lv521, lv522), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv523: R.Tensor((768, 768), dtype="float32") = model_params[125]
            lv524: R.Tensor((768,), dtype="float32") = model_params[7]
            lv467 = R.call_tir(cls.fused_matmul9_add22, (lv21, lv523, lv524), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv468 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv467,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv525: R.Tensor((768, 768), dtype="float32") = model_params[126]
            lv526: R.Tensor((768,), dtype="float32") = model_params[10]
            lv469 = R.call_tir(cls.fused_matmul9_add22, (lv21, lv525, lv526), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv470 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv469,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv471 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv466,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul10, (lv471, lv468), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv472 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv42, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax2, (lv472,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv47 = R.call_tir(cls.matmul11, (lv46, lv470), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv473 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv47,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv527: R.Tensor((768, 768), dtype="float32") = model_params[127]
            lv528: R.Tensor((768,), dtype="float32") = model_params[8]
            lv474 = R.call_tir(cls.fused_matmul9_add22_add21, (lv473, lv527, lv528, lv465), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv529: R.Tensor((768,), dtype="float32") = model_params[4]
            lv530: R.Tensor((768,), dtype="float32") = model_params[3]
            lv55 = R.call_tir(cls.layer_norm1, (lv474, lv529, lv530), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv531: R.Tensor((768, 3072), dtype="float32") = model_params[128]
            lv532: R.Tensor((3072,), dtype="float32") = model_params[5]
            lv475 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv55, lv531, lv532), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv533: R.Tensor((3072, 768), dtype="float32") = model_params[129]
            lv534: R.Tensor((768,), dtype="float32") = model_params[6]
            lv476 = R.call_tir(cls.fused_matmul13_add22_add21, (lv475, lv533, lv534, lv474), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv535: R.Tensor((768,), dtype="float32") = model_params[32]
            lv536: R.Tensor((768,), dtype="float32") = model_params[31]
            lv66 = R.call_tir(cls.layer_norm1, (lv476, lv535, lv536), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv537: R.Tensor((768, 768), dtype="float32") = model_params[130]
            lv538: R.Tensor((768,), dtype="float32") = model_params[39]
            lv477 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv66, lv537, lv538), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv539: R.Tensor((768, 768), dtype="float32") = model_params[131]
            lv540: R.Tensor((768,), dtype="float32") = model_params[37]
            lv478 = R.call_tir(cls.fused_matmul9_add22, (lv66, lv539, lv540), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv479 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv478,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv541: R.Tensor((768, 768), dtype="float32") = model_params[132]
            lv542: R.Tensor((768,), dtype="float32") = model_params[40]
            lv480 = R.call_tir(cls.fused_matmul9_add22, (lv66, lv541, lv542), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv481 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv480,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv482 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv477,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul10, (lv482, lv479), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv483 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv87, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax2, (lv483,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv92 = R.call_tir(cls.matmul11, (lv91, lv481), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv484 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv92,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv543: R.Tensor((768, 768), dtype="float32") = model_params[133]
            lv544: R.Tensor((768,), dtype="float32") = model_params[38]
            lv485 = R.call_tir(cls.fused_matmul9_add22_add21, (lv484, lv543, lv544, lv476), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv545: R.Tensor((768,), dtype="float32") = model_params[34]
            lv546: R.Tensor((768,), dtype="float32") = model_params[33]
            lv100 = R.call_tir(cls.layer_norm1, (lv485, lv545, lv546), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv547: R.Tensor((768, 3072), dtype="float32") = model_params[134]
            lv548: R.Tensor((3072,), dtype="float32") = model_params[35]
            lv486 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv100, lv547, lv548), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv549: R.Tensor((3072, 768), dtype="float32") = model_params[135]
            lv550: R.Tensor((768,), dtype="float32") = model_params[36]
            lv487 = R.call_tir(cls.fused_matmul13_add22_add21, (lv486, lv549, lv550, lv485), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv551: R.Tensor((768,), dtype="float32") = model_params[42]
            lv552: R.Tensor((768,), dtype="float32") = model_params[41]
            lv111 = R.call_tir(cls.layer_norm1, (lv487, lv551, lv552), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv553: R.Tensor((768, 768), dtype="float32") = model_params[136]
            lv554: R.Tensor((768,), dtype="float32") = model_params[49]
            lv488 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv111, lv553, lv554), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv555: R.Tensor((768, 768), dtype="float32") = model_params[137]
            lv556: R.Tensor((768,), dtype="float32") = model_params[47]
            lv489 = R.call_tir(cls.fused_matmul9_add22, (lv111, lv555, lv556), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv490 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv489,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv557: R.Tensor((768, 768), dtype="float32") = model_params[138]
            lv558: R.Tensor((768,), dtype="float32") = model_params[50]
            lv491 = R.call_tir(cls.fused_matmul9_add22, (lv111, lv557, lv558), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv492 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv491,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv493 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv488,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul10, (lv493, lv490), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv494 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv132, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax2, (lv494,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv137 = R.call_tir(cls.matmul11, (lv136, lv492), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv495 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv137,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv559: R.Tensor((768, 768), dtype="float32") = model_params[139]
            lv560: R.Tensor((768,), dtype="float32") = model_params[48]
            lv496 = R.call_tir(cls.fused_matmul9_add22_add21, (lv495, lv559, lv560, lv487), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv561: R.Tensor((768,), dtype="float32") = model_params[44]
            lv562: R.Tensor((768,), dtype="float32") = model_params[43]
            lv145 = R.call_tir(cls.layer_norm1, (lv496, lv561, lv562), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv563: R.Tensor((768, 3072), dtype="float32") = model_params[140]
            lv564: R.Tensor((3072,), dtype="float32") = model_params[45]
            lv497 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv145, lv563, lv564), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv565: R.Tensor((3072, 768), dtype="float32") = model_params[141]
            lv566: R.Tensor((768,), dtype="float32") = model_params[46]
            lv498 = R.call_tir(cls.fused_matmul13_add22_add21, (lv497, lv565, lv566, lv496), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv567: R.Tensor((768,), dtype="float32") = model_params[52]
            lv568: R.Tensor((768,), dtype="float32") = model_params[51]
            lv156 = R.call_tir(cls.layer_norm1, (lv498, lv567, lv568), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv569: R.Tensor((768, 768), dtype="float32") = model_params[142]
            lv570: R.Tensor((768,), dtype="float32") = model_params[59]
            lv499 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv156, lv569, lv570), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv571: R.Tensor((768, 768), dtype="float32") = model_params[143]
            lv572: R.Tensor((768,), dtype="float32") = model_params[57]
            lv500 = R.call_tir(cls.fused_matmul9_add22, (lv156, lv571, lv572), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv501 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv500,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv573: R.Tensor((768, 768), dtype="float32") = model_params[144]
            lv574: R.Tensor((768,), dtype="float32") = model_params[60]
            lv502 = R.call_tir(cls.fused_matmul9_add22, (lv156, lv573, lv574), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv503 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv502,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv504 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv499,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv177 = R.call_tir(cls.matmul10, (lv504, lv501), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv505 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv177, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv181 = R.call_tir(cls.softmax2, (lv505,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv182 = R.call_tir(cls.matmul11, (lv181, lv503), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv506 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv182,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv575: R.Tensor((768, 768), dtype="float32") = model_params[145]
            lv576: R.Tensor((768,), dtype="float32") = model_params[58]
            lv507 = R.call_tir(cls.fused_matmul9_add22_add21, (lv506, lv575, lv576, lv498), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv577: R.Tensor((768,), dtype="float32") = model_params[54]
            lv578: R.Tensor((768,), dtype="float32") = model_params[53]
            lv190 = R.call_tir(cls.layer_norm1, (lv507, lv577, lv578), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv579: R.Tensor((768, 3072), dtype="float32") = model_params[146]
            lv580: R.Tensor((3072,), dtype="float32") = model_params[55]
            lv508 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv190, lv579, lv580), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv581: R.Tensor((3072, 768), dtype="float32") = model_params[147]
            lv582: R.Tensor((768,), dtype="float32") = model_params[56]
            lv509 = R.call_tir(cls.fused_matmul13_add22_add21, (lv508, lv581, lv582, lv507), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv583: R.Tensor((768,), dtype="float32") = model_params[62]
            lv584: R.Tensor((768,), dtype="float32") = model_params[61]
            lv201 = R.call_tir(cls.layer_norm1, (lv509, lv583, lv584), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv585: R.Tensor((768, 768), dtype="float32") = model_params[148]
            lv586: R.Tensor((768,), dtype="float32") = model_params[69]
            lv510 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv201, lv585, lv586), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv587: R.Tensor((768, 768), dtype="float32") = model_params[149]
            lv588: R.Tensor((768,), dtype="float32") = model_params[67]
            lv511 = R.call_tir(cls.fused_matmul9_add22, (lv201, lv587, lv588), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv512 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv511,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv589: R.Tensor((768, 768), dtype="float32") = model_params[150]
            lv590: R.Tensor((768,), dtype="float32") = model_params[70]
            lv513 = R.call_tir(cls.fused_matmul9_add22, (lv201, lv589, lv590), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv514 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv513,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv515 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv510,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.matmul10, (lv515, lv512), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv516 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv222, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv226 = R.call_tir(cls.softmax2, (lv516,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv227 = R.call_tir(cls.matmul11, (lv226, lv514), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv517_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv227,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv591: R.Tensor((768, 768), dtype="float32") = model_params[151]
            lv592: R.Tensor((768,), dtype="float32") = model_params[68]
            lv518_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv517_1, lv591, lv592, lv509), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv593: R.Tensor((768,), dtype="float32") = model_params[64]
            lv594: R.Tensor((768,), dtype="float32") = model_params[63]
            lv235 = R.call_tir(cls.layer_norm1, (lv518_1, lv593, lv594), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv595: R.Tensor((768, 3072), dtype="float32") = model_params[152]
            lv596: R.Tensor((3072,), dtype="float32") = model_params[65]
            lv519_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv235, lv595, lv596), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv597: R.Tensor((3072, 768), dtype="float32") = model_params[153]
            lv598: R.Tensor((768,), dtype="float32") = model_params[66]
            lv520_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv519_1, lv597, lv598, lv518_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv599: R.Tensor((768,), dtype="float32") = model_params[72]
            lv600: R.Tensor((768,), dtype="float32") = model_params[71]
            lv246 = R.call_tir(cls.layer_norm1, (lv520_1, lv599, lv600), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv601: R.Tensor((768, 768), dtype="float32") = model_params[154]
            lv602: R.Tensor((768,), dtype="float32") = model_params[79]
            lv521_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv246, lv601, lv602), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv603: R.Tensor((768, 768), dtype="float32") = model_params[155]
            lv604: R.Tensor((768,), dtype="float32") = model_params[77]
            lv522_1 = R.call_tir(cls.fused_matmul9_add22, (lv246, lv603, lv604), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv523_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv522_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv605: R.Tensor((768, 768), dtype="float32") = model_params[156]
            lv606: R.Tensor((768,), dtype="float32") = model_params[80]
            lv524_1 = R.call_tir(cls.fused_matmul9_add22, (lv246, lv605, lv606), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv525_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv524_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv526_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv521_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.matmul10, (lv526_1, lv523_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv527_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv267, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv271 = R.call_tir(cls.softmax2, (lv527_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv272 = R.call_tir(cls.matmul11, (lv271, lv525_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv528_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv272,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv607: R.Tensor((768, 768), dtype="float32") = model_params[157]
            lv608: R.Tensor((768,), dtype="float32") = model_params[78]
            lv529_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv528_1, lv607, lv608, lv520_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv609: R.Tensor((768,), dtype="float32") = model_params[74]
            lv610: R.Tensor((768,), dtype="float32") = model_params[73]
            lv280 = R.call_tir(cls.layer_norm1, (lv529_1, lv609, lv610), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv611: R.Tensor((768, 3072), dtype="float32") = model_params[158]
            lv612: R.Tensor((3072,), dtype="float32") = model_params[75]
            lv530_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv280, lv611, lv612), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv613: R.Tensor((3072, 768), dtype="float32") = model_params[159]
            lv614: R.Tensor((768,), dtype="float32") = model_params[76]
            lv531_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv530_1, lv613, lv614, lv529_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv615: R.Tensor((768,), dtype="float32") = model_params[82]
            lv616: R.Tensor((768,), dtype="float32") = model_params[81]
            lv291 = R.call_tir(cls.layer_norm1, (lv531_1, lv615, lv616), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv617: R.Tensor((768, 768), dtype="float32") = model_params[160]
            lv618: R.Tensor((768,), dtype="float32") = model_params[89]
            lv532_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv291, lv617, lv618), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv619: R.Tensor((768, 768), dtype="float32") = model_params[161]
            lv620: R.Tensor((768,), dtype="float32") = model_params[87]
            lv533_1 = R.call_tir(cls.fused_matmul9_add22, (lv291, lv619, lv620), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv534_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv533_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv621: R.Tensor((768, 768), dtype="float32") = model_params[162]
            lv622: R.Tensor((768,), dtype="float32") = model_params[90]
            lv535_1 = R.call_tir(cls.fused_matmul9_add22, (lv291, lv621, lv622), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv536_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv535_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv537_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv532_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul10, (lv537_1, lv534_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv538_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv312, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax2, (lv538_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv317 = R.call_tir(cls.matmul11, (lv316, lv536_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv539_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv317,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv623: R.Tensor((768, 768), dtype="float32") = model_params[163]
            lv624: R.Tensor((768,), dtype="float32") = model_params[88]
            lv540_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv539_1, lv623, lv624, lv531_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv625: R.Tensor((768,), dtype="float32") = model_params[84]
            lv626: R.Tensor((768,), dtype="float32") = model_params[83]
            lv325 = R.call_tir(cls.layer_norm1, (lv540_1, lv625, lv626), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv627: R.Tensor((768, 3072), dtype="float32") = model_params[164]
            lv628: R.Tensor((3072,), dtype="float32") = model_params[85]
            lv541_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv325, lv627, lv628), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv629: R.Tensor((3072, 768), dtype="float32") = model_params[165]
            lv630: R.Tensor((768,), dtype="float32") = model_params[86]
            lv542_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv541_1, lv629, lv630, lv540_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv631: R.Tensor((768,), dtype="float32") = model_params[92]
            lv632: R.Tensor((768,), dtype="float32") = model_params[91]
            lv336 = R.call_tir(cls.layer_norm1, (lv542_1, lv631, lv632), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv633: R.Tensor((768, 768), dtype="float32") = model_params[166]
            lv634: R.Tensor((768,), dtype="float32") = model_params[99]
            lv543_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv336, lv633, lv634), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv635: R.Tensor((768, 768), dtype="float32") = model_params[167]
            lv636: R.Tensor((768,), dtype="float32") = model_params[97]
            lv544_1 = R.call_tir(cls.fused_matmul9_add22, (lv336, lv635, lv636), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv545_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv544_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv637: R.Tensor((768, 768), dtype="float32") = model_params[168]
            lv638: R.Tensor((768,), dtype="float32") = model_params[100]
            lv546_1 = R.call_tir(cls.fused_matmul9_add22, (lv336, lv637, lv638), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv547_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv546_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv548_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv543_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul10, (lv548_1, lv545_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv549_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv357, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax2, (lv549_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv362 = R.call_tir(cls.matmul11, (lv361, lv547_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv550_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv362,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv639: R.Tensor((768, 768), dtype="float32") = model_params[169]
            lv640: R.Tensor((768,), dtype="float32") = model_params[98]
            lv551_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv550_1, lv639, lv640, lv542_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv641: R.Tensor((768,), dtype="float32") = model_params[94]
            lv642: R.Tensor((768,), dtype="float32") = model_params[93]
            lv370 = R.call_tir(cls.layer_norm1, (lv551_1, lv641, lv642), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv643: R.Tensor((768, 3072), dtype="float32") = model_params[170]
            lv644: R.Tensor((3072,), dtype="float32") = model_params[95]
            lv552_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv370, lv643, lv644), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv645: R.Tensor((3072, 768), dtype="float32") = model_params[171]
            lv646: R.Tensor((768,), dtype="float32") = model_params[96]
            lv553_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv552_1, lv645, lv646, lv551_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv647: R.Tensor((768,), dtype="float32") = model_params[102]
            lv648: R.Tensor((768,), dtype="float32") = model_params[101]
            lv381 = R.call_tir(cls.layer_norm1, (lv553_1, lv647, lv648), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv649: R.Tensor((768, 768), dtype="float32") = model_params[172]
            lv650: R.Tensor((768,), dtype="float32") = model_params[109]
            lv554_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv381, lv649, lv650), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv651: R.Tensor((768, 768), dtype="float32") = model_params[173]
            lv652: R.Tensor((768,), dtype="float32") = model_params[107]
            lv555_1 = R.call_tir(cls.fused_matmul9_add22, (lv381, lv651, lv652), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv556_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv555_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv653: R.Tensor((768, 768), dtype="float32") = model_params[174]
            lv654: R.Tensor((768,), dtype="float32") = model_params[110]
            lv557_1 = R.call_tir(cls.fused_matmul9_add22, (lv381, lv653, lv654), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv558_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv557_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv559_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv554_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul10, (lv559_1, lv556_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv560_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv402, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax2, (lv560_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv407 = R.call_tir(cls.matmul11, (lv406, lv558_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv561_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv407,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv655: R.Tensor((768, 768), dtype="float32") = model_params[175]
            lv656: R.Tensor((768,), dtype="float32") = model_params[108]
            lv562_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv561_1, lv655, lv656, lv553_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv657: R.Tensor((768,), dtype="float32") = model_params[104]
            lv658: R.Tensor((768,), dtype="float32") = model_params[103]
            lv415 = R.call_tir(cls.layer_norm1, (lv562_1, lv657, lv658), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv659: R.Tensor((768, 3072), dtype="float32") = model_params[176]
            lv660: R.Tensor((3072,), dtype="float32") = model_params[105]
            lv563_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv415, lv659, lv660), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv661: R.Tensor((3072, 768), dtype="float32") = model_params[177]
            lv662: R.Tensor((768,), dtype="float32") = model_params[106]
            lv564_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv563_1, lv661, lv662, lv562_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv663: R.Tensor((768,), dtype="float32") = model_params[112]
            lv664: R.Tensor((768,), dtype="float32") = model_params[111]
            lv426 = R.call_tir(cls.layer_norm1, (lv564_1, lv663, lv664), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv665: R.Tensor((768, 768), dtype="float32") = model_params[178]
            lv666: R.Tensor((768,), dtype="float32") = model_params[119]
            lv565_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv426, lv665, lv666), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv667: R.Tensor((768, 768), dtype="float32") = model_params[179]
            lv668: R.Tensor((768,), dtype="float32") = model_params[117]
            lv566_1 = R.call_tir(cls.fused_matmul9_add22, (lv426, lv667, lv668), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv567_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv566_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv669: R.Tensor((768, 768), dtype="float32") = model_params[180]
            lv670: R.Tensor((768,), dtype="float32") = model_params[120]
            lv568_1 = R.call_tir(cls.fused_matmul9_add22, (lv426, lv669, lv670), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv569_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv568_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv570_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv565_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul10, (lv570_1, lv567_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv571_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv447, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax2, (lv571_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv452 = R.call_tir(cls.matmul11, (lv451, lv569_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv572_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv452,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv671: R.Tensor((768, 768), dtype="float32") = model_params[181]
            lv672: R.Tensor((768,), dtype="float32") = model_params[118]
            lv573_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv572_1, lv671, lv672, lv564_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv673: R.Tensor((768,), dtype="float32") = model_params[114]
            lv674: R.Tensor((768,), dtype="float32") = model_params[113]
            lv460 = R.call_tir(cls.layer_norm1, (lv573_1, lv673, lv674), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv675: R.Tensor((768, 3072), dtype="float32") = model_params[182]
            lv676: R.Tensor((3072,), dtype="float32") = model_params[115]
            lv574_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv460, lv675, lv676), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv677: R.Tensor((3072, 768), dtype="float32") = model_params[183]
            lv678: R.Tensor((768,), dtype="float32") = model_params[116]
            lv575_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv574_1, lv677, lv678, lv573_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv679: R.Tensor((768,), dtype="float32") = model_params[12]
            lv680: R.Tensor((768,), dtype="float32") = model_params[11]
            lv471_1 = R.call_tir(cls.layer_norm1, (lv575_1, lv679, lv680), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv681: R.Tensor((768, 768), dtype="float32") = model_params[184]
            lv682: R.Tensor((768,), dtype="float32") = model_params[19]
            lv576_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv471_1, lv681, lv682), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv683: R.Tensor((768, 768), dtype="float32") = model_params[185]
            lv684: R.Tensor((768,), dtype="float32") = model_params[17]
            lv577_1 = R.call_tir(cls.fused_matmul9_add22, (lv471_1, lv683, lv684), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv578_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv577_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv685: R.Tensor((768, 768), dtype="float32") = model_params[186]
            lv686: R.Tensor((768,), dtype="float32") = model_params[20]
            lv579_1 = R.call_tir(cls.fused_matmul9_add22, (lv471_1, lv685, lv686), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv580_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv579_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv581_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv576_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv492_1 = R.call_tir(cls.matmul10, (lv581_1, lv578_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv582_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv492_1, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv496_1 = R.call_tir(cls.softmax2, (lv582_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv497_1 = R.call_tir(cls.matmul11, (lv496_1, lv580_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv583_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv497_1,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv687: R.Tensor((768, 768), dtype="float32") = model_params[187]
            lv688: R.Tensor((768,), dtype="float32") = model_params[18]
            lv584_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv583_1, lv687, lv688, lv575_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv689: R.Tensor((768,), dtype="float32") = model_params[14]
            lv690: R.Tensor((768,), dtype="float32") = model_params[13]
            lv505_1 = R.call_tir(cls.layer_norm1, (lv584_1, lv689, lv690), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv691: R.Tensor((768, 3072), dtype="float32") = model_params[188]
            lv692: R.Tensor((3072,), dtype="float32") = model_params[15]
            lv585_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv505_1, lv691, lv692), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv693: R.Tensor((3072, 768), dtype="float32") = model_params[189]
            lv694: R.Tensor((768,), dtype="float32") = model_params[16]
            lv586_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv585_1, lv693, lv694, lv584_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv695: R.Tensor((768,), dtype="float32") = model_params[22]
            lv696: R.Tensor((768,), dtype="float32") = model_params[21]
            lv516_1 = R.call_tir(cls.layer_norm1, (lv586_1, lv695, lv696), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv697: R.Tensor((768, 768), dtype="float32") = model_params[190]
            lv698: R.Tensor((768,), dtype="float32") = model_params[29]
            lv587_1 = R.call_tir(cls.fused_matmul9_add22_multiply5, (lv516_1, lv697, lv698), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv699: R.Tensor((768, 768), dtype="float32") = model_params[191]
            lv700: R.Tensor((768,), dtype="float32") = model_params[27]
            lv588_1 = R.call_tir(cls.fused_matmul9_add22, (lv516_1, lv699, lv700), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv589_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23_transpose15, (lv588_1,), out_sinfo=R.Tensor((12, 64, 77), dtype="float32"))
            lv701: R.Tensor((768, 768), dtype="float32") = model_params[192]
            lv702: R.Tensor((768,), dtype="float32") = model_params[30]
            lv590_1 = R.call_tir(cls.fused_matmul9_add22, (lv516_1, lv701, lv702), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv591_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv590_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv592_1 = R.call_tir(cls.fused_reshape22_transpose14_reshape23, (lv587_1,), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv537_2 = R.call_tir(cls.matmul10, (lv592_1, lv589_1), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv593_1 = R.call_tir(cls.fused_reshape24_add23_reshape25, (lv537_2, metadata["relax.expr.Constant"][0]), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv541_2 = R.call_tir(cls.softmax2, (lv593_1,), out_sinfo=R.Tensor((12, 77, 77), dtype="float32"))
            lv542_2 = R.call_tir(cls.matmul11, (lv541_2, lv591_1), out_sinfo=R.Tensor((12, 77, 64), dtype="float32"))
            lv594_1 = R.call_tir(cls.fused_reshape26_transpose16_reshape27, (lv542_2,), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv703: R.Tensor((768, 768), dtype="float32") = model_params[193]
            lv704: R.Tensor((768,), dtype="float32") = model_params[28]
            lv595_1 = R.call_tir(cls.fused_matmul9_add22_add21, (lv594_1, lv703, lv704, lv586_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv705: R.Tensor((768,), dtype="float32") = model_params[24]
            lv706: R.Tensor((768,), dtype="float32") = model_params[23]
            lv550_2 = R.call_tir(cls.layer_norm1, (lv595_1, lv705, lv706), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv707: R.Tensor((768, 3072), dtype="float32") = model_params[194]
            lv708: R.Tensor((3072,), dtype="float32") = model_params[25]
            lv596_1 = R.call_tir(cls.fused_matmul12_add24_multiply6_tir_sigmoid_multiply7, (lv550_2, lv707, lv708), out_sinfo=R.Tensor((1, 77, 3072), dtype="float32"))
            lv709: R.Tensor((3072, 768), dtype="float32") = model_params[195]
            lv710: R.Tensor((768,), dtype="float32") = model_params[26]
            lv597_1 = R.call_tir(cls.fused_matmul13_add22_add21, (lv596_1, lv709, lv710, lv595_1), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            lv711: R.Tensor((768,), dtype="float32") = model_params[122]
            lv712: R.Tensor((768,), dtype="float32") = model_params[121]
            lv561_2 = R.call_tir(cls.layer_norm1, (lv597_1, lv711, lv712), out_sinfo=R.Tensor((1, 77, 768), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 768), dtype="float32"), R.Tensor((1, 77, 768), dtype="float32")) = lv586_1, lv561_2
            R.output(gv)
        return gv

    @R.function
    def clip2(inp_0: R.Tensor((1, 77), dtype="int32"), model_params: R.Tuple(R.Tensor((49408, 1280), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((77, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 5120), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"))) -> R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")):
        R.func_attr({"global_symbol": "subgraph_0", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.reshape9, (inp_0,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv_1 = R.call_tir(cls.fused_cast_reshape10, (lv,), out_sinfo=R.Tensor((77,), dtype="int32"))
            lv_2: R.Tensor((49408, 1280), dtype="float32") = model_params[0]
            lv3 = R.call_tir(cls.take, (lv_2, lv_1), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv1: R.Tensor((77, 1280), dtype="float32") = model_params[323]
            lv1_1 = R.call_tir(cls.fused_reshape11_reshape11_add14, (lv3, lv1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv2: R.Tensor((1280,), dtype="float32") = model_params[2]
            lv3_1: R.Tensor((1280,), dtype="float32") = model_params[1]
            lv21 = R.call_tir(cls.layer_norm, (lv1_1, lv2, lv3_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv4: R.Tensor((1280, 1280), dtype="float32") = model_params[324]
            lv5: R.Tensor((1280,), dtype="float32") = model_params[9]
            lv2_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv21, lv4, lv5), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv6: R.Tensor((1280, 1280), dtype="float32") = model_params[325]
            lv7: R.Tensor((1280,), dtype="float32") = model_params[7]
            lv3_2 = R.call_tir(cls.fused_matmul3_add16, (lv21, lv6, lv7), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv4_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv3_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv8: R.Tensor((1280, 1280), dtype="float32") = model_params[326]
            lv9: R.Tensor((1280,), dtype="float32") = model_params[10]
            lv5_1 = R.call_tir(cls.fused_matmul3_add16, (lv21, lv8, lv9), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv6_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv5_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv7_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv2_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv42 = R.call_tir(cls.matmul4, (lv7_1, lv4_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv8_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv42, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv46 = R.call_tir(cls.softmax1, (lv8_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv9_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv46,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv49 = R.call_tir(cls.matmul5, (lv9_1, lv6_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv10 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv49,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv10_1: R.Tensor((1280, 1280), dtype="float32") = model_params[327]
            lv11: R.Tensor((1280,), dtype="float32") = model_params[8]
            lv11_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv10, lv10_1, lv11, lv1_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv12: R.Tensor((1280,), dtype="float32") = model_params[4]
            lv13: R.Tensor((1280,), dtype="float32") = model_params[3]
            lv57 = R.call_tir(cls.layer_norm, (lv11_1, lv12, lv13), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv14: R.Tensor((1280, 5120), dtype="float32") = model_params[328]
            lv15: R.Tensor((5120,), dtype="float32") = model_params[5]
            lv12_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv57, lv14, lv15), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv16: R.Tensor((5120, 1280), dtype="float32") = model_params[329]
            lv17: R.Tensor((1280,), dtype="float32") = model_params[6]
            lv13_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv12_1, lv16, lv17, lv11_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv18: R.Tensor((1280,), dtype="float32") = model_params[112]
            lv19: R.Tensor((1280,), dtype="float32") = model_params[111]
            lv66 = R.call_tir(cls.layer_norm, (lv13_1, lv18, lv19), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv20: R.Tensor((1280, 1280), dtype="float32") = model_params[330]
            lv21_1: R.Tensor((1280,), dtype="float32") = model_params[119]
            lv14_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv66, lv20, lv21_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv22: R.Tensor((1280, 1280), dtype="float32") = model_params[331]
            lv23: R.Tensor((1280,), dtype="float32") = model_params[117]
            lv15_1 = R.call_tir(cls.fused_matmul3_add16, (lv66, lv22, lv23), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv16_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv15_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv24: R.Tensor((1280, 1280), dtype="float32") = model_params[332]
            lv25: R.Tensor((1280,), dtype="float32") = model_params[120]
            lv17_1 = R.call_tir(cls.fused_matmul3_add16, (lv66, lv24, lv25), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv18_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv17_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv19_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv14_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv87 = R.call_tir(cls.matmul4, (lv19_1, lv16_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv20_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv87, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv91 = R.call_tir(cls.softmax1, (lv20_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv21_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv91,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv94 = R.call_tir(cls.matmul5, (lv21_2, lv18_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv22_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv94,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv26: R.Tensor((1280, 1280), dtype="float32") = model_params[333]
            lv27: R.Tensor((1280,), dtype="float32") = model_params[118]
            lv23_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv22_1, lv26, lv27, lv13_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv28: R.Tensor((1280,), dtype="float32") = model_params[114]
            lv29: R.Tensor((1280,), dtype="float32") = model_params[113]
            lv102 = R.call_tir(cls.layer_norm, (lv23_1, lv28, lv29), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv30: R.Tensor((1280, 5120), dtype="float32") = model_params[334]
            lv31: R.Tensor((5120,), dtype="float32") = model_params[115]
            lv24_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv102, lv30, lv31), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv32: R.Tensor((5120, 1280), dtype="float32") = model_params[335]
            lv33: R.Tensor((1280,), dtype="float32") = model_params[116]
            lv25_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv24_1, lv32, lv33, lv23_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv34: R.Tensor((1280,), dtype="float32") = model_params[222]
            lv35: R.Tensor((1280,), dtype="float32") = model_params[221]
            lv111 = R.call_tir(cls.layer_norm, (lv25_1, lv34, lv35), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv36: R.Tensor((1280, 1280), dtype="float32") = model_params[336]
            lv37: R.Tensor((1280,), dtype="float32") = model_params[229]
            lv26_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv111, lv36, lv37), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv38: R.Tensor((1280, 1280), dtype="float32") = model_params[337]
            lv39: R.Tensor((1280,), dtype="float32") = model_params[227]
            lv27_1 = R.call_tir(cls.fused_matmul3_add16, (lv111, lv38, lv39), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv28_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv27_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv40: R.Tensor((1280, 1280), dtype="float32") = model_params[338]
            lv41: R.Tensor((1280,), dtype="float32") = model_params[230]
            lv29_1 = R.call_tir(cls.fused_matmul3_add16, (lv111, lv40, lv41), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv30_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv29_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv31_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv26_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv132 = R.call_tir(cls.matmul4, (lv31_1, lv28_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv32_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv132, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv136 = R.call_tir(cls.softmax1, (lv32_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv33_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv136,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv139 = R.call_tir(cls.matmul5, (lv33_1, lv30_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv34_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv139,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv42_1: R.Tensor((1280, 1280), dtype="float32") = model_params[339]
            lv43: R.Tensor((1280,), dtype="float32") = model_params[228]
            lv35_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv34_1, lv42_1, lv43, lv25_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv44: R.Tensor((1280,), dtype="float32") = model_params[224]
            lv45: R.Tensor((1280,), dtype="float32") = model_params[223]
            lv147 = R.call_tir(cls.layer_norm, (lv35_1, lv44, lv45), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv46_1: R.Tensor((1280, 5120), dtype="float32") = model_params[340]
            lv47: R.Tensor((5120,), dtype="float32") = model_params[225]
            lv36_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv147, lv46_1, lv47), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv48: R.Tensor((5120, 1280), dtype="float32") = model_params[341]
            lv49_1: R.Tensor((1280,), dtype="float32") = model_params[226]
            lv37_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv36_1, lv48, lv49_1, lv35_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv50: R.Tensor((1280,), dtype="float32") = model_params[252]
            lv51: R.Tensor((1280,), dtype="float32") = model_params[251]
            lv156 = R.call_tir(cls.layer_norm, (lv37_1, lv50, lv51), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv52: R.Tensor((1280, 1280), dtype="float32") = model_params[342]
            lv53: R.Tensor((1280,), dtype="float32") = model_params[259]
            lv38_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv156, lv52, lv53), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv54: R.Tensor((1280, 1280), dtype="float32") = model_params[343]
            lv55: R.Tensor((1280,), dtype="float32") = model_params[257]
            lv39_1 = R.call_tir(cls.fused_matmul3_add16, (lv156, lv54, lv55), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv40_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv39_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv56: R.Tensor((1280, 1280), dtype="float32") = model_params[344]
            lv57_1: R.Tensor((1280,), dtype="float32") = model_params[260]
            lv41_1 = R.call_tir(cls.fused_matmul3_add16, (lv156, lv56, lv57_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv42_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv41_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv43_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv38_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv177 = R.call_tir(cls.matmul4, (lv43_1, lv40_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv44_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv177, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv181 = R.call_tir(cls.softmax1, (lv44_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv45_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv181,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv184 = R.call_tir(cls.matmul5, (lv45_1, lv42_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv46_2 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv184,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv58: R.Tensor((1280, 1280), dtype="float32") = model_params[345]
            lv59: R.Tensor((1280,), dtype="float32") = model_params[258]
            lv47_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv46_2, lv58, lv59, lv37_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv60: R.Tensor((1280,), dtype="float32") = model_params[254]
            lv61: R.Tensor((1280,), dtype="float32") = model_params[253]
            lv192 = R.call_tir(cls.layer_norm, (lv47_1, lv60, lv61), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv62: R.Tensor((1280, 5120), dtype="float32") = model_params[346]
            lv63: R.Tensor((5120,), dtype="float32") = model_params[255]
            lv48_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv192, lv62, lv63), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv64: R.Tensor((5120, 1280), dtype="float32") = model_params[347]
            lv65: R.Tensor((1280,), dtype="float32") = model_params[256]
            lv49_2 = R.call_tir(cls.fused_matmul7_add16_add14, (lv48_1, lv64, lv65, lv47_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv66_1: R.Tensor((1280,), dtype="float32") = model_params[262]
            lv67: R.Tensor((1280,), dtype="float32") = model_params[261]
            lv201 = R.call_tir(cls.layer_norm, (lv49_2, lv66_1, lv67), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv68: R.Tensor((1280, 1280), dtype="float32") = model_params[348]
            lv69: R.Tensor((1280,), dtype="float32") = model_params[269]
            lv50_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv201, lv68, lv69), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv70: R.Tensor((1280, 1280), dtype="float32") = model_params[349]
            lv71: R.Tensor((1280,), dtype="float32") = model_params[267]
            lv51_1 = R.call_tir(cls.fused_matmul3_add16, (lv201, lv70, lv71), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv52_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv51_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv72: R.Tensor((1280, 1280), dtype="float32") = model_params[350]
            lv73: R.Tensor((1280,), dtype="float32") = model_params[270]
            lv53_1 = R.call_tir(cls.fused_matmul3_add16, (lv201, lv72, lv73), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv54_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv53_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv55_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv50_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv222 = R.call_tir(cls.matmul4, (lv55_1, lv52_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv56_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv222, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv226 = R.call_tir(cls.softmax1, (lv56_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv57_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv226,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv229 = R.call_tir(cls.matmul5, (lv57_2, lv54_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv58_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv229,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv74: R.Tensor((1280, 1280), dtype="float32") = model_params[351]
            lv75: R.Tensor((1280,), dtype="float32") = model_params[268]
            lv59_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv58_1, lv74, lv75, lv49_2), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv76: R.Tensor((1280,), dtype="float32") = model_params[264]
            lv77: R.Tensor((1280,), dtype="float32") = model_params[263]
            lv237 = R.call_tir(cls.layer_norm, (lv59_1, lv76, lv77), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv78: R.Tensor((1280, 5120), dtype="float32") = model_params[352]
            lv79: R.Tensor((5120,), dtype="float32") = model_params[265]
            lv60_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv237, lv78, lv79), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv80: R.Tensor((5120, 1280), dtype="float32") = model_params[353]
            lv81: R.Tensor((1280,), dtype="float32") = model_params[266]
            lv61_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv60_1, lv80, lv81, lv59_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv82: R.Tensor((1280,), dtype="float32") = model_params[272]
            lv83: R.Tensor((1280,), dtype="float32") = model_params[271]
            lv246 = R.call_tir(cls.layer_norm, (lv61_1, lv82, lv83), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv84: R.Tensor((1280, 1280), dtype="float32") = model_params[354]
            lv85: R.Tensor((1280,), dtype="float32") = model_params[279]
            lv62_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv246, lv84, lv85), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv86: R.Tensor((1280, 1280), dtype="float32") = model_params[355]
            lv87_1: R.Tensor((1280,), dtype="float32") = model_params[277]
            lv63_1 = R.call_tir(cls.fused_matmul3_add16, (lv246, lv86, lv87_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv64_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv63_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv88: R.Tensor((1280, 1280), dtype="float32") = model_params[356]
            lv89: R.Tensor((1280,), dtype="float32") = model_params[280]
            lv65_1 = R.call_tir(cls.fused_matmul3_add16, (lv246, lv88, lv89), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv66_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv65_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv67_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv62_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv267 = R.call_tir(cls.matmul4, (lv67_1, lv64_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv68_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv267, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv271 = R.call_tir(cls.softmax1, (lv68_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv69_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv271,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv274 = R.call_tir(cls.matmul5, (lv69_1, lv66_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv70_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv274,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv90: R.Tensor((1280, 1280), dtype="float32") = model_params[357]
            lv91_1: R.Tensor((1280,), dtype="float32") = model_params[278]
            lv71_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv70_1, lv90, lv91_1, lv61_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv92: R.Tensor((1280,), dtype="float32") = model_params[274]
            lv93: R.Tensor((1280,), dtype="float32") = model_params[273]
            lv282 = R.call_tir(cls.layer_norm, (lv71_1, lv92, lv93), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv94_1: R.Tensor((1280, 5120), dtype="float32") = model_params[358]
            lv95: R.Tensor((5120,), dtype="float32") = model_params[275]
            lv72_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv282, lv94_1, lv95), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv96: R.Tensor((5120, 1280), dtype="float32") = model_params[359]
            lv97: R.Tensor((1280,), dtype="float32") = model_params[276]
            lv73_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv72_1, lv96, lv97, lv71_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv98: R.Tensor((1280,), dtype="float32") = model_params[282]
            lv99: R.Tensor((1280,), dtype="float32") = model_params[281]
            lv291 = R.call_tir(cls.layer_norm, (lv73_1, lv98, lv99), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv100: R.Tensor((1280, 1280), dtype="float32") = model_params[360]
            lv101: R.Tensor((1280,), dtype="float32") = model_params[289]
            lv74_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv291, lv100, lv101), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv102_1: R.Tensor((1280, 1280), dtype="float32") = model_params[361]
            lv103: R.Tensor((1280,), dtype="float32") = model_params[287]
            lv75_1 = R.call_tir(cls.fused_matmul3_add16, (lv291, lv102_1, lv103), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv76_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv75_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv104: R.Tensor((1280, 1280), dtype="float32") = model_params[362]
            lv105: R.Tensor((1280,), dtype="float32") = model_params[290]
            lv77_1 = R.call_tir(cls.fused_matmul3_add16, (lv291, lv104, lv105), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv78_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv77_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv79_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv74_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv312 = R.call_tir(cls.matmul4, (lv79_1, lv76_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv80_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv312, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv316 = R.call_tir(cls.softmax1, (lv80_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv81_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv316,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv319 = R.call_tir(cls.matmul5, (lv81_1, lv78_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv82_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv319,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv106: R.Tensor((1280, 1280), dtype="float32") = model_params[363]
            lv107: R.Tensor((1280,), dtype="float32") = model_params[288]
            lv83_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv82_1, lv106, lv107, lv73_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv108: R.Tensor((1280,), dtype="float32") = model_params[284]
            lv109: R.Tensor((1280,), dtype="float32") = model_params[283]
            lv327 = R.call_tir(cls.layer_norm, (lv83_1, lv108, lv109), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv110: R.Tensor((1280, 5120), dtype="float32") = model_params[364]
            lv111_1: R.Tensor((5120,), dtype="float32") = model_params[285]
            lv84_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv327, lv110, lv111_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv112: R.Tensor((5120, 1280), dtype="float32") = model_params[365]
            lv113: R.Tensor((1280,), dtype="float32") = model_params[286]
            lv85_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv84_1, lv112, lv113, lv83_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv114: R.Tensor((1280,), dtype="float32") = model_params[292]
            lv115: R.Tensor((1280,), dtype="float32") = model_params[291]
            lv336 = R.call_tir(cls.layer_norm, (lv85_1, lv114, lv115), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv116: R.Tensor((1280, 1280), dtype="float32") = model_params[366]
            lv117: R.Tensor((1280,), dtype="float32") = model_params[299]
            lv86_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv336, lv116, lv117), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv118: R.Tensor((1280, 1280), dtype="float32") = model_params[367]
            lv119: R.Tensor((1280,), dtype="float32") = model_params[297]
            lv87_2 = R.call_tir(cls.fused_matmul3_add16, (lv336, lv118, lv119), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv88_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv87_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv120: R.Tensor((1280, 1280), dtype="float32") = model_params[368]
            lv121: R.Tensor((1280,), dtype="float32") = model_params[300]
            lv89_1 = R.call_tir(cls.fused_matmul3_add16, (lv336, lv120, lv121), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv90_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv89_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv91_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv86_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv357 = R.call_tir(cls.matmul4, (lv91_2, lv88_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv92_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv357, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv361 = R.call_tir(cls.softmax1, (lv92_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv93_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv361,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv364 = R.call_tir(cls.matmul5, (lv93_1, lv90_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv94_2 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv364,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv122: R.Tensor((1280, 1280), dtype="float32") = model_params[369]
            lv123: R.Tensor((1280,), dtype="float32") = model_params[298]
            lv95_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv94_2, lv122, lv123, lv85_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv124: R.Tensor((1280,), dtype="float32") = model_params[294]
            lv125: R.Tensor((1280,), dtype="float32") = model_params[293]
            lv372 = R.call_tir(cls.layer_norm, (lv95_1, lv124, lv125), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv126: R.Tensor((1280, 5120), dtype="float32") = model_params[370]
            lv127: R.Tensor((5120,), dtype="float32") = model_params[295]
            lv96_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv372, lv126, lv127), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv128: R.Tensor((5120, 1280), dtype="float32") = model_params[371]
            lv129: R.Tensor((1280,), dtype="float32") = model_params[296]
            lv97_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv96_1, lv128, lv129, lv95_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv130: R.Tensor((1280,), dtype="float32") = model_params[302]
            lv131: R.Tensor((1280,), dtype="float32") = model_params[301]
            lv381 = R.call_tir(cls.layer_norm, (lv97_1, lv130, lv131), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv132_1: R.Tensor((1280, 1280), dtype="float32") = model_params[372]
            lv133: R.Tensor((1280,), dtype="float32") = model_params[309]
            lv98_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv381, lv132_1, lv133), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv134: R.Tensor((1280, 1280), dtype="float32") = model_params[373]
            lv135: R.Tensor((1280,), dtype="float32") = model_params[307]
            lv99_1 = R.call_tir(cls.fused_matmul3_add16, (lv381, lv134, lv135), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv100_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv99_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv136_1: R.Tensor((1280, 1280), dtype="float32") = model_params[374]
            lv137: R.Tensor((1280,), dtype="float32") = model_params[310]
            lv101_1 = R.call_tir(cls.fused_matmul3_add16, (lv381, lv136_1, lv137), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv102_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv101_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv103_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv98_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv402 = R.call_tir(cls.matmul4, (lv103_1, lv100_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv104_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv402, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv406 = R.call_tir(cls.softmax1, (lv104_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv105_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv406,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv409 = R.call_tir(cls.matmul5, (lv105_1, lv102_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv106_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv409,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv138: R.Tensor((1280, 1280), dtype="float32") = model_params[375]
            lv139_1: R.Tensor((1280,), dtype="float32") = model_params[308]
            lv107_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv106_1, lv138, lv139_1, lv97_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv140: R.Tensor((1280,), dtype="float32") = model_params[304]
            lv141: R.Tensor((1280,), dtype="float32") = model_params[303]
            lv417 = R.call_tir(cls.layer_norm, (lv107_1, lv140, lv141), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv142: R.Tensor((1280, 5120), dtype="float32") = model_params[376]
            lv143: R.Tensor((5120,), dtype="float32") = model_params[305]
            lv108_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv417, lv142, lv143), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv144: R.Tensor((5120, 1280), dtype="float32") = model_params[377]
            lv145: R.Tensor((1280,), dtype="float32") = model_params[306]
            lv109_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv108_1, lv144, lv145, lv107_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv146: R.Tensor((1280,), dtype="float32") = model_params[312]
            lv147_1: R.Tensor((1280,), dtype="float32") = model_params[311]
            lv426 = R.call_tir(cls.layer_norm, (lv109_1, lv146, lv147_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv148: R.Tensor((1280, 1280), dtype="float32") = model_params[378]
            lv149: R.Tensor((1280,), dtype="float32") = model_params[319]
            lv110_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv426, lv148, lv149), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv150: R.Tensor((1280, 1280), dtype="float32") = model_params[379]
            lv151: R.Tensor((1280,), dtype="float32") = model_params[317]
            lv111_2 = R.call_tir(cls.fused_matmul3_add16, (lv426, lv150, lv151), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv112_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv111_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv152: R.Tensor((1280, 1280), dtype="float32") = model_params[380]
            lv153: R.Tensor((1280,), dtype="float32") = model_params[320]
            lv113_1 = R.call_tir(cls.fused_matmul3_add16, (lv426, lv152, lv153), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv114_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv113_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv115_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv110_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv447 = R.call_tir(cls.matmul4, (lv115_1, lv112_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv116_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv447, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv451 = R.call_tir(cls.softmax1, (lv116_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv117_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv451,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv454 = R.call_tir(cls.matmul5, (lv117_1, lv114_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv118_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv454,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv154: R.Tensor((1280, 1280), dtype="float32") = model_params[381]
            lv155: R.Tensor((1280,), dtype="float32") = model_params[318]
            lv119_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv118_1, lv154, lv155, lv109_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv156_1: R.Tensor((1280,), dtype="float32") = model_params[314]
            lv157: R.Tensor((1280,), dtype="float32") = model_params[313]
            lv462 = R.call_tir(cls.layer_norm, (lv119_1, lv156_1, lv157), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv158: R.Tensor((1280, 5120), dtype="float32") = model_params[382]
            lv159: R.Tensor((5120,), dtype="float32") = model_params[315]
            lv120_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv462, lv158, lv159), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv160: R.Tensor((5120, 1280), dtype="float32") = model_params[383]
            lv161: R.Tensor((1280,), dtype="float32") = model_params[316]
            lv121_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv120_1, lv160, lv161, lv119_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv162: R.Tensor((1280,), dtype="float32") = model_params[12]
            lv163: R.Tensor((1280,), dtype="float32") = model_params[11]
            lv471 = R.call_tir(cls.layer_norm, (lv121_1, lv162, lv163), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv164: R.Tensor((1280, 1280), dtype="float32") = model_params[384]
            lv165: R.Tensor((1280,), dtype="float32") = model_params[19]
            lv122_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv471, lv164, lv165), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv166: R.Tensor((1280, 1280), dtype="float32") = model_params[385]
            lv167: R.Tensor((1280,), dtype="float32") = model_params[17]
            lv123_1 = R.call_tir(cls.fused_matmul3_add16, (lv471, lv166, lv167), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv124_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv123_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv168: R.Tensor((1280, 1280), dtype="float32") = model_params[386]
            lv169: R.Tensor((1280,), dtype="float32") = model_params[20]
            lv125_1 = R.call_tir(cls.fused_matmul3_add16, (lv471, lv168, lv169), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv126_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv125_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv127_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv122_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv492 = R.call_tir(cls.matmul4, (lv127_1, lv124_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv128_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv492, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv496 = R.call_tir(cls.softmax1, (lv128_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv129_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv496,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv499 = R.call_tir(cls.matmul5, (lv129_1, lv126_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv130_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv499,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv170: R.Tensor((1280, 1280), dtype="float32") = model_params[387]
            lv171: R.Tensor((1280,), dtype="float32") = model_params[18]
            lv131_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv130_1, lv170, lv171, lv121_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv172: R.Tensor((1280,), dtype="float32") = model_params[14]
            lv173: R.Tensor((1280,), dtype="float32") = model_params[13]
            lv507 = R.call_tir(cls.layer_norm, (lv131_1, lv172, lv173), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv174: R.Tensor((1280, 5120), dtype="float32") = model_params[388]
            lv175: R.Tensor((5120,), dtype="float32") = model_params[15]
            lv132_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv507, lv174, lv175), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv176: R.Tensor((5120, 1280), dtype="float32") = model_params[389]
            lv177_1: R.Tensor((1280,), dtype="float32") = model_params[16]
            lv133_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv132_2, lv176, lv177_1, lv131_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv178: R.Tensor((1280,), dtype="float32") = model_params[22]
            lv179: R.Tensor((1280,), dtype="float32") = model_params[21]
            lv516 = R.call_tir(cls.layer_norm, (lv133_1, lv178, lv179), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv180: R.Tensor((1280, 1280), dtype="float32") = model_params[390]
            lv181_1: R.Tensor((1280,), dtype="float32") = model_params[29]
            lv134_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv516, lv180, lv181_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv182: R.Tensor((1280, 1280), dtype="float32") = model_params[391]
            lv183: R.Tensor((1280,), dtype="float32") = model_params[27]
            lv135_1 = R.call_tir(cls.fused_matmul3_add16, (lv516, lv182, lv183), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv136_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv135_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv184_1: R.Tensor((1280, 1280), dtype="float32") = model_params[392]
            lv185: R.Tensor((1280,), dtype="float32") = model_params[30]
            lv137_1 = R.call_tir(cls.fused_matmul3_add16, (lv516, lv184_1, lv185), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv138_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv137_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv139_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv134_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv537 = R.call_tir(cls.matmul4, (lv139_2, lv136_2), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv140_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv537, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv541 = R.call_tir(cls.softmax1, (lv140_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv141_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv541,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv544 = R.call_tir(cls.matmul5, (lv141_1, lv138_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv142_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv544,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv186: R.Tensor((1280, 1280), dtype="float32") = model_params[393]
            lv187: R.Tensor((1280,), dtype="float32") = model_params[28]
            lv143_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv142_1, lv186, lv187, lv133_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv188: R.Tensor((1280,), dtype="float32") = model_params[24]
            lv189: R.Tensor((1280,), dtype="float32") = model_params[23]
            lv552 = R.call_tir(cls.layer_norm, (lv143_1, lv188, lv189), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv190: R.Tensor((1280, 5120), dtype="float32") = model_params[394]
            lv191: R.Tensor((5120,), dtype="float32") = model_params[25]
            lv144_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv552, lv190, lv191), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv192_1: R.Tensor((5120, 1280), dtype="float32") = model_params[395]
            lv193: R.Tensor((1280,), dtype="float32") = model_params[26]
            lv145_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv144_1, lv192_1, lv193, lv143_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv194: R.Tensor((1280,), dtype="float32") = model_params[32]
            lv195: R.Tensor((1280,), dtype="float32") = model_params[31]
            lv561 = R.call_tir(cls.layer_norm, (lv145_1, lv194, lv195), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv196: R.Tensor((1280, 1280), dtype="float32") = model_params[396]
            lv197: R.Tensor((1280,), dtype="float32") = model_params[39]
            lv146_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv561, lv196, lv197), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv198: R.Tensor((1280, 1280), dtype="float32") = model_params[397]
            lv199: R.Tensor((1280,), dtype="float32") = model_params[37]
            lv147_2 = R.call_tir(cls.fused_matmul3_add16, (lv561, lv198, lv199), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv148_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv147_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv200: R.Tensor((1280, 1280), dtype="float32") = model_params[398]
            lv201_1: R.Tensor((1280,), dtype="float32") = model_params[40]
            lv149_1 = R.call_tir(cls.fused_matmul3_add16, (lv561, lv200, lv201_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv150_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv149_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv151_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv146_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv582 = R.call_tir(cls.matmul4, (lv151_1, lv148_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv152_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv582, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv586 = R.call_tir(cls.softmax1, (lv152_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv153_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv586,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv589 = R.call_tir(cls.matmul5, (lv153_1, lv150_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv154_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv589,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv202: R.Tensor((1280, 1280), dtype="float32") = model_params[399]
            lv203: R.Tensor((1280,), dtype="float32") = model_params[38]
            lv155_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv154_1, lv202, lv203, lv145_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv204: R.Tensor((1280,), dtype="float32") = model_params[34]
            lv205: R.Tensor((1280,), dtype="float32") = model_params[33]
            lv597 = R.call_tir(cls.layer_norm, (lv155_1, lv204, lv205), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv206: R.Tensor((1280, 5120), dtype="float32") = model_params[400]
            lv207: R.Tensor((5120,), dtype="float32") = model_params[35]
            lv156_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv597, lv206, lv207), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv208: R.Tensor((5120, 1280), dtype="float32") = model_params[401]
            lv209: R.Tensor((1280,), dtype="float32") = model_params[36]
            lv157_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv156_2, lv208, lv209, lv155_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv210: R.Tensor((1280,), dtype="float32") = model_params[42]
            lv211: R.Tensor((1280,), dtype="float32") = model_params[41]
            lv606 = R.call_tir(cls.layer_norm, (lv157_1, lv210, lv211), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv212: R.Tensor((1280, 1280), dtype="float32") = model_params[402]
            lv213: R.Tensor((1280,), dtype="float32") = model_params[49]
            lv158_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv606, lv212, lv213), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv214: R.Tensor((1280, 1280), dtype="float32") = model_params[403]
            lv215: R.Tensor((1280,), dtype="float32") = model_params[47]
            lv159_1 = R.call_tir(cls.fused_matmul3_add16, (lv606, lv214, lv215), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv160_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv159_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv216: R.Tensor((1280, 1280), dtype="float32") = model_params[404]
            lv217: R.Tensor((1280,), dtype="float32") = model_params[50]
            lv161_1 = R.call_tir(cls.fused_matmul3_add16, (lv606, lv216, lv217), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv162_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv161_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv163_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv158_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv627 = R.call_tir(cls.matmul4, (lv163_1, lv160_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv164_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv627, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv631 = R.call_tir(cls.softmax1, (lv164_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv165_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv631,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv634 = R.call_tir(cls.matmul5, (lv165_1, lv162_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv166_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv634,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv218: R.Tensor((1280, 1280), dtype="float32") = model_params[405]
            lv219: R.Tensor((1280,), dtype="float32") = model_params[48]
            lv167_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv166_1, lv218, lv219, lv157_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv220: R.Tensor((1280,), dtype="float32") = model_params[44]
            lv221: R.Tensor((1280,), dtype="float32") = model_params[43]
            lv642 = R.call_tir(cls.layer_norm, (lv167_1, lv220, lv221), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv222_1: R.Tensor((1280, 5120), dtype="float32") = model_params[406]
            lv223: R.Tensor((5120,), dtype="float32") = model_params[45]
            lv168_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv642, lv222_1, lv223), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv224: R.Tensor((5120, 1280), dtype="float32") = model_params[407]
            lv225: R.Tensor((1280,), dtype="float32") = model_params[46]
            lv169_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv168_1, lv224, lv225, lv167_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv226_1: R.Tensor((1280,), dtype="float32") = model_params[52]
            lv227: R.Tensor((1280,), dtype="float32") = model_params[51]
            lv651 = R.call_tir(cls.layer_norm, (lv169_1, lv226_1, lv227), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv228: R.Tensor((1280, 1280), dtype="float32") = model_params[408]
            lv229_1: R.Tensor((1280,), dtype="float32") = model_params[59]
            lv170_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv651, lv228, lv229_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv230: R.Tensor((1280, 1280), dtype="float32") = model_params[409]
            lv231: R.Tensor((1280,), dtype="float32") = model_params[57]
            lv171_1 = R.call_tir(cls.fused_matmul3_add16, (lv651, lv230, lv231), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv172_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv171_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv232: R.Tensor((1280, 1280), dtype="float32") = model_params[410]
            lv233: R.Tensor((1280,), dtype="float32") = model_params[60]
            lv173_1 = R.call_tir(cls.fused_matmul3_add16, (lv651, lv232, lv233), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv174_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv173_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv175_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv170_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv672 = R.call_tir(cls.matmul4, (lv175_1, lv172_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv176_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv672, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv676 = R.call_tir(cls.softmax1, (lv176_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv177_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv676,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv679 = R.call_tir(cls.matmul5, (lv177_2, lv174_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv178_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv679,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv234: R.Tensor((1280, 1280), dtype="float32") = model_params[411]
            lv235: R.Tensor((1280,), dtype="float32") = model_params[58]
            lv179_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv178_1, lv234, lv235, lv169_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv236: R.Tensor((1280,), dtype="float32") = model_params[54]
            lv237_1: R.Tensor((1280,), dtype="float32") = model_params[53]
            lv687 = R.call_tir(cls.layer_norm, (lv179_1, lv236, lv237_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv238: R.Tensor((1280, 5120), dtype="float32") = model_params[412]
            lv239: R.Tensor((5120,), dtype="float32") = model_params[55]
            lv180_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv687, lv238, lv239), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv240: R.Tensor((5120, 1280), dtype="float32") = model_params[413]
            lv241: R.Tensor((1280,), dtype="float32") = model_params[56]
            lv181_2 = R.call_tir(cls.fused_matmul7_add16_add14, (lv180_1, lv240, lv241, lv179_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv242: R.Tensor((1280,), dtype="float32") = model_params[62]
            lv243: R.Tensor((1280,), dtype="float32") = model_params[61]
            lv696 = R.call_tir(cls.layer_norm, (lv181_2, lv242, lv243), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv244: R.Tensor((1280, 1280), dtype="float32") = model_params[414]
            lv245: R.Tensor((1280,), dtype="float32") = model_params[69]
            lv182_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv696, lv244, lv245), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv246_1: R.Tensor((1280, 1280), dtype="float32") = model_params[415]
            lv247: R.Tensor((1280,), dtype="float32") = model_params[67]
            lv183_1 = R.call_tir(cls.fused_matmul3_add16, (lv696, lv246_1, lv247), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv184_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv183_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv248: R.Tensor((1280, 1280), dtype="float32") = model_params[416]
            lv249: R.Tensor((1280,), dtype="float32") = model_params[70]
            lv185_1 = R.call_tir(cls.fused_matmul3_add16, (lv696, lv248, lv249), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv186_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv185_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv187_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv182_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv717 = R.call_tir(cls.matmul4, (lv187_1, lv184_2), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv188_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv717, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv721 = R.call_tir(cls.softmax1, (lv188_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv189_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv721,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv724 = R.call_tir(cls.matmul5, (lv189_1, lv186_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv190_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv724,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv250: R.Tensor((1280, 1280), dtype="float32") = model_params[417]
            lv251: R.Tensor((1280,), dtype="float32") = model_params[68]
            lv191_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv190_1, lv250, lv251, lv181_2), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv252: R.Tensor((1280,), dtype="float32") = model_params[64]
            lv253: R.Tensor((1280,), dtype="float32") = model_params[63]
            lv732 = R.call_tir(cls.layer_norm, (lv191_1, lv252, lv253), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv254: R.Tensor((1280, 5120), dtype="float32") = model_params[418]
            lv255: R.Tensor((5120,), dtype="float32") = model_params[65]
            lv192_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv732, lv254, lv255), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv256: R.Tensor((5120, 1280), dtype="float32") = model_params[419]
            lv257: R.Tensor((1280,), dtype="float32") = model_params[66]
            lv193_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv192_2, lv256, lv257, lv191_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv258: R.Tensor((1280,), dtype="float32") = model_params[72]
            lv259: R.Tensor((1280,), dtype="float32") = model_params[71]
            lv741 = R.call_tir(cls.layer_norm, (lv193_1, lv258, lv259), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv260: R.Tensor((1280, 1280), dtype="float32") = model_params[420]
            lv261: R.Tensor((1280,), dtype="float32") = model_params[79]
            lv194_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv741, lv260, lv261), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv262: R.Tensor((1280, 1280), dtype="float32") = model_params[421]
            lv263: R.Tensor((1280,), dtype="float32") = model_params[77]
            lv195_1 = R.call_tir(cls.fused_matmul3_add16, (lv741, lv262, lv263), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv196_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv195_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv264: R.Tensor((1280, 1280), dtype="float32") = model_params[422]
            lv265: R.Tensor((1280,), dtype="float32") = model_params[80]
            lv197_1 = R.call_tir(cls.fused_matmul3_add16, (lv741, lv264, lv265), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv198_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv197_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv199_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv194_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv762 = R.call_tir(cls.matmul4, (lv199_1, lv196_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv200_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv762, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv766 = R.call_tir(cls.softmax1, (lv200_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv201_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv766,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv769 = R.call_tir(cls.matmul5, (lv201_2, lv198_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv202_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv769,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv266: R.Tensor((1280, 1280), dtype="float32") = model_params[423]
            lv267_1: R.Tensor((1280,), dtype="float32") = model_params[78]
            lv203_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv202_1, lv266, lv267_1, lv193_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv268: R.Tensor((1280,), dtype="float32") = model_params[74]
            lv269: R.Tensor((1280,), dtype="float32") = model_params[73]
            lv777 = R.call_tir(cls.layer_norm, (lv203_1, lv268, lv269), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv270: R.Tensor((1280, 5120), dtype="float32") = model_params[424]
            lv271_1: R.Tensor((5120,), dtype="float32") = model_params[75]
            lv204_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv777, lv270, lv271_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv272: R.Tensor((5120, 1280), dtype="float32") = model_params[425]
            lv273: R.Tensor((1280,), dtype="float32") = model_params[76]
            lv205_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv204_1, lv272, lv273, lv203_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv274_1: R.Tensor((1280,), dtype="float32") = model_params[82]
            lv275: R.Tensor((1280,), dtype="float32") = model_params[81]
            lv786 = R.call_tir(cls.layer_norm, (lv205_1, lv274_1, lv275), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv276: R.Tensor((1280, 1280), dtype="float32") = model_params[426]
            lv277: R.Tensor((1280,), dtype="float32") = model_params[89]
            lv206_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv786, lv276, lv277), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv278: R.Tensor((1280, 1280), dtype="float32") = model_params[427]
            lv279: R.Tensor((1280,), dtype="float32") = model_params[87]
            lv207_1 = R.call_tir(cls.fused_matmul3_add16, (lv786, lv278, lv279), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv208_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv207_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv280: R.Tensor((1280, 1280), dtype="float32") = model_params[428]
            lv281: R.Tensor((1280,), dtype="float32") = model_params[90]
            lv209_1 = R.call_tir(cls.fused_matmul3_add16, (lv786, lv280, lv281), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv210_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv209_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv211_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv206_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv807 = R.call_tir(cls.matmul4, (lv211_1, lv208_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv212_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv807, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv811 = R.call_tir(cls.softmax1, (lv212_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv213_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv811,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv814 = R.call_tir(cls.matmul5, (lv213_1, lv210_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv214_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv814,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv282_1: R.Tensor((1280, 1280), dtype="float32") = model_params[429]
            lv283: R.Tensor((1280,), dtype="float32") = model_params[88]
            lv215_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv214_1, lv282_1, lv283, lv205_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv284: R.Tensor((1280,), dtype="float32") = model_params[84]
            lv285: R.Tensor((1280,), dtype="float32") = model_params[83]
            lv822 = R.call_tir(cls.layer_norm, (lv215_1, lv284, lv285), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv286: R.Tensor((1280, 5120), dtype="float32") = model_params[430]
            lv287: R.Tensor((5120,), dtype="float32") = model_params[85]
            lv216_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv822, lv286, lv287), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv288: R.Tensor((5120, 1280), dtype="float32") = model_params[431]
            lv289: R.Tensor((1280,), dtype="float32") = model_params[86]
            lv217_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv216_1, lv288, lv289, lv215_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv290: R.Tensor((1280,), dtype="float32") = model_params[92]
            lv291_1: R.Tensor((1280,), dtype="float32") = model_params[91]
            lv831 = R.call_tir(cls.layer_norm, (lv217_1, lv290, lv291_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv292: R.Tensor((1280, 1280), dtype="float32") = model_params[432]
            lv293: R.Tensor((1280,), dtype="float32") = model_params[99]
            lv218_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv831, lv292, lv293), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv294: R.Tensor((1280, 1280), dtype="float32") = model_params[433]
            lv295: R.Tensor((1280,), dtype="float32") = model_params[97]
            lv219_1 = R.call_tir(cls.fused_matmul3_add16, (lv831, lv294, lv295), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv220_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv219_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv296: R.Tensor((1280, 1280), dtype="float32") = model_params[434]
            lv297: R.Tensor((1280,), dtype="float32") = model_params[100]
            lv221_1 = R.call_tir(cls.fused_matmul3_add16, (lv831, lv296, lv297), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv222_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv221_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv223_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv218_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv852 = R.call_tir(cls.matmul4, (lv223_1, lv220_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv224_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv852, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv856 = R.call_tir(cls.softmax1, (lv224_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv225_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv856,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv859 = R.call_tir(cls.matmul5, (lv225_1, lv222_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv226_2 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv859,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv298: R.Tensor((1280, 1280), dtype="float32") = model_params[435]
            lv299: R.Tensor((1280,), dtype="float32") = model_params[98]
            lv227_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv226_2, lv298, lv299, lv217_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv300: R.Tensor((1280,), dtype="float32") = model_params[94]
            lv301: R.Tensor((1280,), dtype="float32") = model_params[93]
            lv867 = R.call_tir(cls.layer_norm, (lv227_1, lv300, lv301), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv302: R.Tensor((1280, 5120), dtype="float32") = model_params[436]
            lv303: R.Tensor((5120,), dtype="float32") = model_params[95]
            lv228_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv867, lv302, lv303), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv304: R.Tensor((5120, 1280), dtype="float32") = model_params[437]
            lv305: R.Tensor((1280,), dtype="float32") = model_params[96]
            lv229_2 = R.call_tir(cls.fused_matmul7_add16_add14, (lv228_1, lv304, lv305, lv227_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv306: R.Tensor((1280,), dtype="float32") = model_params[102]
            lv307: R.Tensor((1280,), dtype="float32") = model_params[101]
            lv876 = R.call_tir(cls.layer_norm, (lv229_2, lv306, lv307), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv308: R.Tensor((1280, 1280), dtype="float32") = model_params[438]
            lv309: R.Tensor((1280,), dtype="float32") = model_params[109]
            lv230_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv876, lv308, lv309), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv310: R.Tensor((1280, 1280), dtype="float32") = model_params[439]
            lv311: R.Tensor((1280,), dtype="float32") = model_params[107]
            lv231_1 = R.call_tir(cls.fused_matmul3_add16, (lv876, lv310, lv311), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv232_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv231_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv312_1: R.Tensor((1280, 1280), dtype="float32") = model_params[440]
            lv313: R.Tensor((1280,), dtype="float32") = model_params[110]
            lv233_1 = R.call_tir(cls.fused_matmul3_add16, (lv876, lv312_1, lv313), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv234_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv233_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv235_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv230_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv897 = R.call_tir(cls.matmul4, (lv235_1, lv232_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv236_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv897, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv901 = R.call_tir(cls.softmax1, (lv236_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv237_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv901,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv904 = R.call_tir(cls.matmul5, (lv237_2, lv234_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv238_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv904,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv314: R.Tensor((1280, 1280), dtype="float32") = model_params[441]
            lv315: R.Tensor((1280,), dtype="float32") = model_params[108]
            lv239_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv238_1, lv314, lv315, lv229_2), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv316_1: R.Tensor((1280,), dtype="float32") = model_params[104]
            lv317: R.Tensor((1280,), dtype="float32") = model_params[103]
            lv912 = R.call_tir(cls.layer_norm, (lv239_1, lv316_1, lv317), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv318: R.Tensor((1280, 5120), dtype="float32") = model_params[442]
            lv319_1: R.Tensor((5120,), dtype="float32") = model_params[105]
            lv240_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv912, lv318, lv319_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv320: R.Tensor((5120, 1280), dtype="float32") = model_params[443]
            lv321: R.Tensor((1280,), dtype="float32") = model_params[106]
            lv241_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv240_1, lv320, lv321, lv239_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv322: R.Tensor((1280,), dtype="float32") = model_params[122]
            lv323: R.Tensor((1280,), dtype="float32") = model_params[121]
            lv921 = R.call_tir(cls.layer_norm, (lv241_1, lv322, lv323), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv324: R.Tensor((1280, 1280), dtype="float32") = model_params[444]
            lv325: R.Tensor((1280,), dtype="float32") = model_params[129]
            lv242_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv921, lv324, lv325), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv326: R.Tensor((1280, 1280), dtype="float32") = model_params[445]
            lv327_1: R.Tensor((1280,), dtype="float32") = model_params[127]
            lv243_1 = R.call_tir(cls.fused_matmul3_add16, (lv921, lv326, lv327_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv244_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv243_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv328: R.Tensor((1280, 1280), dtype="float32") = model_params[446]
            lv329: R.Tensor((1280,), dtype="float32") = model_params[130]
            lv245_1 = R.call_tir(cls.fused_matmul3_add16, (lv921, lv328, lv329), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv246_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv245_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv247_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv242_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv942 = R.call_tir(cls.matmul4, (lv247_1, lv244_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv248_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv942, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv946 = R.call_tir(cls.softmax1, (lv248_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv249_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv946,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv949 = R.call_tir(cls.matmul5, (lv249_1, lv246_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv250_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv949,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv330: R.Tensor((1280, 1280), dtype="float32") = model_params[447]
            lv331: R.Tensor((1280,), dtype="float32") = model_params[128]
            lv251_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv250_1, lv330, lv331, lv241_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv332: R.Tensor((1280,), dtype="float32") = model_params[124]
            lv333: R.Tensor((1280,), dtype="float32") = model_params[123]
            lv957 = R.call_tir(cls.layer_norm, (lv251_1, lv332, lv333), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv334: R.Tensor((1280, 5120), dtype="float32") = model_params[448]
            lv335: R.Tensor((5120,), dtype="float32") = model_params[125]
            lv252_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv957, lv334, lv335), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv336_1: R.Tensor((5120, 1280), dtype="float32") = model_params[449]
            lv337: R.Tensor((1280,), dtype="float32") = model_params[126]
            lv253_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv252_1, lv336_1, lv337, lv251_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv338: R.Tensor((1280,), dtype="float32") = model_params[132]
            lv339: R.Tensor((1280,), dtype="float32") = model_params[131]
            lv966 = R.call_tir(cls.layer_norm, (lv253_1, lv338, lv339), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv340: R.Tensor((1280, 1280), dtype="float32") = model_params[450]
            lv341: R.Tensor((1280,), dtype="float32") = model_params[139]
            lv254_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv966, lv340, lv341), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv342: R.Tensor((1280, 1280), dtype="float32") = model_params[451]
            lv343: R.Tensor((1280,), dtype="float32") = model_params[137]
            lv255_1 = R.call_tir(cls.fused_matmul3_add16, (lv966, lv342, lv343), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv256_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv255_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv344: R.Tensor((1280, 1280), dtype="float32") = model_params[452]
            lv345: R.Tensor((1280,), dtype="float32") = model_params[140]
            lv257_1 = R.call_tir(cls.fused_matmul3_add16, (lv966, lv344, lv345), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv258_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv257_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv259_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv254_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv987 = R.call_tir(cls.matmul4, (lv259_1, lv256_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv260_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv987, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv991 = R.call_tir(cls.softmax1, (lv260_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv261_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv991,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv994 = R.call_tir(cls.matmul5, (lv261_1, lv258_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv262_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv994,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv346: R.Tensor((1280, 1280), dtype="float32") = model_params[453]
            lv347: R.Tensor((1280,), dtype="float32") = model_params[138]
            lv263_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv262_1, lv346, lv347, lv253_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv348: R.Tensor((1280,), dtype="float32") = model_params[134]
            lv349: R.Tensor((1280,), dtype="float32") = model_params[133]
            lv1002 = R.call_tir(cls.layer_norm, (lv263_1, lv348, lv349), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv350: R.Tensor((1280, 5120), dtype="float32") = model_params[454]
            lv351: R.Tensor((5120,), dtype="float32") = model_params[135]
            lv264_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1002, lv350, lv351), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv352: R.Tensor((5120, 1280), dtype="float32") = model_params[455]
            lv353: R.Tensor((1280,), dtype="float32") = model_params[136]
            lv265_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv264_1, lv352, lv353, lv263_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv354: R.Tensor((1280,), dtype="float32") = model_params[142]
            lv355: R.Tensor((1280,), dtype="float32") = model_params[141]
            lv1011 = R.call_tir(cls.layer_norm, (lv265_1, lv354, lv355), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv356: R.Tensor((1280, 1280), dtype="float32") = model_params[456]
            lv357_1: R.Tensor((1280,), dtype="float32") = model_params[149]
            lv266_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1011, lv356, lv357_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv358: R.Tensor((1280, 1280), dtype="float32") = model_params[457]
            lv359: R.Tensor((1280,), dtype="float32") = model_params[147]
            lv267_2 = R.call_tir(cls.fused_matmul3_add16, (lv1011, lv358, lv359), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv268_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv267_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv360: R.Tensor((1280, 1280), dtype="float32") = model_params[458]
            lv361_1: R.Tensor((1280,), dtype="float32") = model_params[150]
            lv269_1 = R.call_tir(cls.fused_matmul3_add16, (lv1011, lv360, lv361_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv270_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv269_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv271_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv266_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1032 = R.call_tir(cls.matmul4, (lv271_2, lv268_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv272_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1032, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1036 = R.call_tir(cls.softmax1, (lv272_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv273_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1036,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1039 = R.call_tir(cls.matmul5, (lv273_1, lv270_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv274_2 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1039,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv362: R.Tensor((1280, 1280), dtype="float32") = model_params[459]
            lv363: R.Tensor((1280,), dtype="float32") = model_params[148]
            lv275_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv274_2, lv362, lv363, lv265_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv364_1: R.Tensor((1280,), dtype="float32") = model_params[144]
            lv365: R.Tensor((1280,), dtype="float32") = model_params[143]
            lv1047 = R.call_tir(cls.layer_norm, (lv275_1, lv364_1, lv365), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv366: R.Tensor((1280, 5120), dtype="float32") = model_params[460]
            lv367: R.Tensor((5120,), dtype="float32") = model_params[145]
            lv276_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1047, lv366, lv367), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv368: R.Tensor((5120, 1280), dtype="float32") = model_params[461]
            lv369: R.Tensor((1280,), dtype="float32") = model_params[146]
            lv277_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv276_1, lv368, lv369, lv275_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv370: R.Tensor((1280,), dtype="float32") = model_params[152]
            lv371: R.Tensor((1280,), dtype="float32") = model_params[151]
            lv1056 = R.call_tir(cls.layer_norm, (lv277_1, lv370, lv371), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv372_1: R.Tensor((1280, 1280), dtype="float32") = model_params[462]
            lv373: R.Tensor((1280,), dtype="float32") = model_params[159]
            lv278_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1056, lv372_1, lv373), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv374: R.Tensor((1280, 1280), dtype="float32") = model_params[463]
            lv375: R.Tensor((1280,), dtype="float32") = model_params[157]
            lv279_1 = R.call_tir(cls.fused_matmul3_add16, (lv1056, lv374, lv375), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv280_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv279_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv376: R.Tensor((1280, 1280), dtype="float32") = model_params[464]
            lv377: R.Tensor((1280,), dtype="float32") = model_params[160]
            lv281_1 = R.call_tir(cls.fused_matmul3_add16, (lv1056, lv376, lv377), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv282_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv281_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv283_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv278_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1077 = R.call_tir(cls.matmul4, (lv283_1, lv280_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv284_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1077, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1081 = R.call_tir(cls.softmax1, (lv284_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv285_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1081,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1084 = R.call_tir(cls.matmul5, (lv285_1, lv282_2), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv286_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1084,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv378: R.Tensor((1280, 1280), dtype="float32") = model_params[465]
            lv379: R.Tensor((1280,), dtype="float32") = model_params[158]
            lv287_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv286_1, lv378, lv379, lv277_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv380: R.Tensor((1280,), dtype="float32") = model_params[154]
            lv381_1: R.Tensor((1280,), dtype="float32") = model_params[153]
            lv1092 = R.call_tir(cls.layer_norm, (lv287_1, lv380, lv381_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv382: R.Tensor((1280, 5120), dtype="float32") = model_params[466]
            lv383: R.Tensor((5120,), dtype="float32") = model_params[155]
            lv288_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1092, lv382, lv383), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv384: R.Tensor((5120, 1280), dtype="float32") = model_params[467]
            lv385: R.Tensor((1280,), dtype="float32") = model_params[156]
            lv289_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv288_1, lv384, lv385, lv287_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv386: R.Tensor((1280,), dtype="float32") = model_params[162]
            lv387: R.Tensor((1280,), dtype="float32") = model_params[161]
            lv1101 = R.call_tir(cls.layer_norm, (lv289_1, lv386, lv387), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv388: R.Tensor((1280, 1280), dtype="float32") = model_params[468]
            lv389: R.Tensor((1280,), dtype="float32") = model_params[169]
            lv290_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1101, lv388, lv389), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv390: R.Tensor((1280, 1280), dtype="float32") = model_params[469]
            lv391: R.Tensor((1280,), dtype="float32") = model_params[167]
            lv291_2 = R.call_tir(cls.fused_matmul3_add16, (lv1101, lv390, lv391), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv292_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv291_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv392: R.Tensor((1280, 1280), dtype="float32") = model_params[470]
            lv393: R.Tensor((1280,), dtype="float32") = model_params[170]
            lv293_1 = R.call_tir(cls.fused_matmul3_add16, (lv1101, lv392, lv393), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv294_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv293_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv295_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv290_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1122 = R.call_tir(cls.matmul4, (lv295_1, lv292_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv296_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1122, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1126 = R.call_tir(cls.softmax1, (lv296_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv297_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1126,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1129 = R.call_tir(cls.matmul5, (lv297_1, lv294_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv298_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1129,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv394: R.Tensor((1280, 1280), dtype="float32") = model_params[471]
            lv395: R.Tensor((1280,), dtype="float32") = model_params[168]
            lv299_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv298_1, lv394, lv395, lv289_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv396: R.Tensor((1280,), dtype="float32") = model_params[164]
            lv397: R.Tensor((1280,), dtype="float32") = model_params[163]
            lv1137 = R.call_tir(cls.layer_norm, (lv299_1, lv396, lv397), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv398: R.Tensor((1280, 5120), dtype="float32") = model_params[472]
            lv399: R.Tensor((5120,), dtype="float32") = model_params[165]
            lv300_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1137, lv398, lv399), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv400: R.Tensor((5120, 1280), dtype="float32") = model_params[473]
            lv401: R.Tensor((1280,), dtype="float32") = model_params[166]
            lv301_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv300_1, lv400, lv401, lv299_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv402_1: R.Tensor((1280,), dtype="float32") = model_params[172]
            lv403: R.Tensor((1280,), dtype="float32") = model_params[171]
            lv1146 = R.call_tir(cls.layer_norm, (lv301_1, lv402_1, lv403), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv404: R.Tensor((1280, 1280), dtype="float32") = model_params[474]
            lv405: R.Tensor((1280,), dtype="float32") = model_params[179]
            lv302_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1146, lv404, lv405), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv406_1: R.Tensor((1280, 1280), dtype="float32") = model_params[475]
            lv407: R.Tensor((1280,), dtype="float32") = model_params[177]
            lv303_1 = R.call_tir(cls.fused_matmul3_add16, (lv1146, lv406_1, lv407), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv304_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv303_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv408: R.Tensor((1280, 1280), dtype="float32") = model_params[476]
            lv409_1: R.Tensor((1280,), dtype="float32") = model_params[180]
            lv305_1 = R.call_tir(cls.fused_matmul3_add16, (lv1146, lv408, lv409_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv306_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv305_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv307_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv302_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1167 = R.call_tir(cls.matmul4, (lv307_1, lv304_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv308_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1167, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1171 = R.call_tir(cls.softmax1, (lv308_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv309_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1171,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul5, (lv309_1, lv306_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv310_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1174,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv410: R.Tensor((1280, 1280), dtype="float32") = model_params[477]
            lv411: R.Tensor((1280,), dtype="float32") = model_params[178]
            lv311_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv310_1, lv410, lv411, lv301_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv412: R.Tensor((1280,), dtype="float32") = model_params[174]
            lv413: R.Tensor((1280,), dtype="float32") = model_params[173]
            lv1182 = R.call_tir(cls.layer_norm, (lv311_1, lv412, lv413), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv414: R.Tensor((1280, 5120), dtype="float32") = model_params[478]
            lv415: R.Tensor((5120,), dtype="float32") = model_params[175]
            lv312_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1182, lv414, lv415), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv416: R.Tensor((5120, 1280), dtype="float32") = model_params[479]
            lv417_1: R.Tensor((1280,), dtype="float32") = model_params[176]
            lv313_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv312_2, lv416, lv417_1, lv311_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv418: R.Tensor((1280,), dtype="float32") = model_params[182]
            lv419: R.Tensor((1280,), dtype="float32") = model_params[181]
            lv1191 = R.call_tir(cls.layer_norm, (lv313_1, lv418, lv419), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv420: R.Tensor((1280, 1280), dtype="float32") = model_params[480]
            lv421: R.Tensor((1280,), dtype="float32") = model_params[189]
            lv314_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1191, lv420, lv421), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv422: R.Tensor((1280, 1280), dtype="float32") = model_params[481]
            lv423: R.Tensor((1280,), dtype="float32") = model_params[187]
            lv315_1 = R.call_tir(cls.fused_matmul3_add16, (lv1191, lv422, lv423), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv316_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv315_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv424: R.Tensor((1280, 1280), dtype="float32") = model_params[482]
            lv425: R.Tensor((1280,), dtype="float32") = model_params[190]
            lv317_1 = R.call_tir(cls.fused_matmul3_add16, (lv1191, lv424, lv425), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv318_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv317_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv319_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv314_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1212 = R.call_tir(cls.matmul4, (lv319_2, lv316_2), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv320_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1212, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1216 = R.call_tir(cls.softmax1, (lv320_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv321_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1216,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1219 = R.call_tir(cls.matmul5, (lv321_1, lv318_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv322_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1219,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv426_1: R.Tensor((1280, 1280), dtype="float32") = model_params[483]
            lv427: R.Tensor((1280,), dtype="float32") = model_params[188]
            lv323_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv322_1, lv426_1, lv427, lv313_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv428: R.Tensor((1280,), dtype="float32") = model_params[184]
            lv429: R.Tensor((1280,), dtype="float32") = model_params[183]
            lv1227 = R.call_tir(cls.layer_norm, (lv323_1, lv428, lv429), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv430: R.Tensor((1280, 5120), dtype="float32") = model_params[484]
            lv431: R.Tensor((5120,), dtype="float32") = model_params[185]
            lv324_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1227, lv430, lv431), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv432: R.Tensor((5120, 1280), dtype="float32") = model_params[485]
            lv433: R.Tensor((1280,), dtype="float32") = model_params[186]
            lv325_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv324_1, lv432, lv433, lv323_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv434: R.Tensor((1280,), dtype="float32") = model_params[192]
            lv435: R.Tensor((1280,), dtype="float32") = model_params[191]
            lv1236 = R.call_tir(cls.layer_norm, (lv325_1, lv434, lv435), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv436: R.Tensor((1280, 1280), dtype="float32") = model_params[486]
            lv437: R.Tensor((1280,), dtype="float32") = model_params[199]
            lv326_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1236, lv436, lv437), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv438: R.Tensor((1280, 1280), dtype="float32") = model_params[487]
            lv439: R.Tensor((1280,), dtype="float32") = model_params[197]
            lv327_2 = R.call_tir(cls.fused_matmul3_add16, (lv1236, lv438, lv439), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv328_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv327_2,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv440: R.Tensor((1280, 1280), dtype="float32") = model_params[488]
            lv441: R.Tensor((1280,), dtype="float32") = model_params[200]
            lv329_1 = R.call_tir(cls.fused_matmul3_add16, (lv1236, lv440, lv441), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv330_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv329_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv331_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv326_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1257 = R.call_tir(cls.matmul4, (lv331_1, lv328_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv332_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1257, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1261 = R.call_tir(cls.softmax1, (lv332_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv333_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1261,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1264 = R.call_tir(cls.matmul5, (lv333_1, lv330_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv334_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1264,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv442: R.Tensor((1280, 1280), dtype="float32") = model_params[489]
            lv443: R.Tensor((1280,), dtype="float32") = model_params[198]
            lv335_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv334_1, lv442, lv443, lv325_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv444: R.Tensor((1280,), dtype="float32") = model_params[194]
            lv445: R.Tensor((1280,), dtype="float32") = model_params[193]
            lv1272 = R.call_tir(cls.layer_norm, (lv335_1, lv444, lv445), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv446: R.Tensor((1280, 5120), dtype="float32") = model_params[490]
            lv447_1: R.Tensor((5120,), dtype="float32") = model_params[195]
            lv336_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1272, lv446, lv447_1), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv448: R.Tensor((5120, 1280), dtype="float32") = model_params[491]
            lv449: R.Tensor((1280,), dtype="float32") = model_params[196]
            lv337_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv336_2, lv448, lv449, lv335_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv450: R.Tensor((1280,), dtype="float32") = model_params[202]
            lv451_1: R.Tensor((1280,), dtype="float32") = model_params[201]
            lv1281 = R.call_tir(cls.layer_norm, (lv337_1, lv450, lv451_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv452: R.Tensor((1280, 1280), dtype="float32") = model_params[492]
            lv453: R.Tensor((1280,), dtype="float32") = model_params[209]
            lv338_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1281, lv452, lv453), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv454_1: R.Tensor((1280, 1280), dtype="float32") = model_params[493]
            lv455: R.Tensor((1280,), dtype="float32") = model_params[207]
            lv339_1 = R.call_tir(cls.fused_matmul3_add16, (lv1281, lv454_1, lv455), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv340_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv339_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv456: R.Tensor((1280, 1280), dtype="float32") = model_params[494]
            lv457: R.Tensor((1280,), dtype="float32") = model_params[210]
            lv341_1 = R.call_tir(cls.fused_matmul3_add16, (lv1281, lv456, lv457), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv342_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv341_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv343_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv338_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1302 = R.call_tir(cls.matmul4, (lv343_1, lv340_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv344_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1302, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1306 = R.call_tir(cls.softmax1, (lv344_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv345_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1306,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1309 = R.call_tir(cls.matmul5, (lv345_1, lv342_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv346_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1309,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv458: R.Tensor((1280, 1280), dtype="float32") = model_params[495]
            lv459: R.Tensor((1280,), dtype="float32") = model_params[208]
            lv347_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv346_1, lv458, lv459, lv337_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv460: R.Tensor((1280,), dtype="float32") = model_params[204]
            lv461: R.Tensor((1280,), dtype="float32") = model_params[203]
            lv1317 = R.call_tir(cls.layer_norm, (lv347_1, lv460, lv461), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv462_1: R.Tensor((1280, 5120), dtype="float32") = model_params[496]
            lv463: R.Tensor((5120,), dtype="float32") = model_params[205]
            lv348_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1317, lv462_1, lv463), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv464: R.Tensor((5120, 1280), dtype="float32") = model_params[497]
            lv465: R.Tensor((1280,), dtype="float32") = model_params[206]
            lv349_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv348_1, lv464, lv465, lv347_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv466: R.Tensor((1280,), dtype="float32") = model_params[212]
            lv467: R.Tensor((1280,), dtype="float32") = model_params[211]
            lv1326 = R.call_tir(cls.layer_norm, (lv349_1, lv466, lv467), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv468: R.Tensor((1280, 1280), dtype="float32") = model_params[498]
            lv469: R.Tensor((1280,), dtype="float32") = model_params[219]
            lv350_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1326, lv468, lv469), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv470: R.Tensor((1280, 1280), dtype="float32") = model_params[499]
            lv471_1: R.Tensor((1280,), dtype="float32") = model_params[217]
            lv351_1 = R.call_tir(cls.fused_matmul3_add16, (lv1326, lv470, lv471_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv352_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv351_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv472: R.Tensor((1280, 1280), dtype="float32") = model_params[500]
            lv473: R.Tensor((1280,), dtype="float32") = model_params[220]
            lv353_1 = R.call_tir(cls.fused_matmul3_add16, (lv1326, lv472, lv473), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv354_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv353_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv355_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv350_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1347 = R.call_tir(cls.matmul4, (lv355_1, lv352_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv356_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1347, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1351 = R.call_tir(cls.softmax1, (lv356_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv357_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv1351,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1354 = R.call_tir(cls.matmul5, (lv357_2, lv354_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv358_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1354,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv474: R.Tensor((1280, 1280), dtype="float32") = model_params[501]
            lv475: R.Tensor((1280,), dtype="float32") = model_params[218]
            lv359_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv358_1, lv474, lv475, lv349_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv476: R.Tensor((1280,), dtype="float32") = model_params[214]
            lv477: R.Tensor((1280,), dtype="float32") = model_params[213]
            lv1362 = R.call_tir(cls.layer_norm, (lv359_1, lv476, lv477), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv478: R.Tensor((1280, 5120), dtype="float32") = model_params[502]
            lv479: R.Tensor((5120,), dtype="float32") = model_params[215]
            lv360_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1362, lv478, lv479), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv480: R.Tensor((5120, 1280), dtype="float32") = model_params[503]
            lv481: R.Tensor((1280,), dtype="float32") = model_params[216]
            lv361_2 = R.call_tir(cls.fused_matmul7_add16_add14, (lv360_1, lv480, lv481, lv359_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv482: R.Tensor((1280,), dtype="float32") = model_params[232]
            lv483: R.Tensor((1280,), dtype="float32") = model_params[231]
            lv1371 = R.call_tir(cls.layer_norm, (lv361_2, lv482, lv483), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv484: R.Tensor((1280, 1280), dtype="float32") = model_params[504]
            lv485: R.Tensor((1280,), dtype="float32") = model_params[239]
            lv362_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1371, lv484, lv485), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv486: R.Tensor((1280, 1280), dtype="float32") = model_params[505]
            lv487: R.Tensor((1280,), dtype="float32") = model_params[237]
            lv363_1 = R.call_tir(cls.fused_matmul3_add16, (lv1371, lv486, lv487), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv364_2 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv363_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv488: R.Tensor((1280, 1280), dtype="float32") = model_params[506]
            lv489: R.Tensor((1280,), dtype="float32") = model_params[240]
            lv365_1 = R.call_tir(cls.fused_matmul3_add16, (lv1371, lv488, lv489), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv366_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv365_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv367_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv362_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1392 = R.call_tir(cls.matmul4, (lv367_1, lv364_2), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv368_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1392, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1396 = R.call_tir(cls.softmax1, (lv368_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv369_1 = R.call_tir(cls.fused_reshape16_reshape17, (lv1396,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1399 = R.call_tir(cls.matmul5, (lv369_1, lv366_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv370_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1399,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv490: R.Tensor((1280, 1280), dtype="float32") = model_params[507]
            lv491: R.Tensor((1280,), dtype="float32") = model_params[238]
            lv371_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv370_1, lv490, lv491, lv361_2), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv492_1: R.Tensor((1280,), dtype="float32") = model_params[234]
            lv493: R.Tensor((1280,), dtype="float32") = model_params[233]
            lv1407 = R.call_tir(cls.layer_norm, (lv371_1, lv492_1, lv493), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv494: R.Tensor((1280, 5120), dtype="float32") = model_params[508]
            lv495: R.Tensor((5120,), dtype="float32") = model_params[235]
            lv372_2 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1407, lv494, lv495), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv496_1: R.Tensor((5120, 1280), dtype="float32") = model_params[509]
            lv497: R.Tensor((1280,), dtype="float32") = model_params[236]
            lv373_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv372_2, lv496_1, lv497, lv371_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv498: R.Tensor((1280,), dtype="float32") = model_params[242]
            lv499_1: R.Tensor((1280,), dtype="float32") = model_params[241]
            lv1416 = R.call_tir(cls.layer_norm, (lv373_1, lv498, lv499_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv500: R.Tensor((1280, 1280), dtype="float32") = model_params[510]
            lv501: R.Tensor((1280,), dtype="float32") = model_params[249]
            lv374_1 = R.call_tir(cls.fused_matmul3_add16_multiply3, (lv1416, lv500, lv501), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv502: R.Tensor((1280, 1280), dtype="float32") = model_params[511]
            lv503: R.Tensor((1280,), dtype="float32") = model_params[247]
            lv375_1 = R.call_tir(cls.fused_matmul3_add16, (lv1416, lv502, lv503), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv376_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15_transpose9, (lv375_1,), out_sinfo=R.Tensor((20, 64, 77), dtype="float32"))
            lv504: R.Tensor((1280, 1280), dtype="float32") = model_params[512]
            lv505: R.Tensor((1280,), dtype="float32") = model_params[250]
            lv377_1 = R.call_tir(cls.fused_matmul3_add16, (lv1416, lv504, lv505), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv378_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv377_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv379_1 = R.call_tir(cls.fused_reshape14_transpose8_reshape15, (lv374_1,), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv1437 = R.call_tir(cls.matmul4, (lv379_1, lv376_1), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv380_1 = R.call_tir(cls.fused_reshape16_add17_reshape17, (lv1437, metadata["relax.expr.Constant"][1]), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1441 = R.call_tir(cls.softmax1, (lv380_1,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv381_2 = R.call_tir(cls.fused_reshape16_reshape17, (lv1441,), out_sinfo=R.Tensor((20, 77, 77), dtype="float32"))
            lv1444 = R.call_tir(cls.matmul5, (lv381_2, lv378_1), out_sinfo=R.Tensor((20, 77, 64), dtype="float32"))
            lv382_1 = R.call_tir(cls.fused_reshape18_transpose10_reshape19, (lv1444,), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv506: R.Tensor((1280, 1280), dtype="float32") = model_params[513]
            lv507_1: R.Tensor((1280,), dtype="float32") = model_params[248]
            lv383_1 = R.call_tir(cls.fused_matmul3_add16_add14, (lv382_1, lv506, lv507_1, lv373_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv508: R.Tensor((1280,), dtype="float32") = model_params[244]
            lv509: R.Tensor((1280,), dtype="float32") = model_params[243]
            lv1452 = R.call_tir(cls.layer_norm, (lv383_1, lv508, lv509), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv510: R.Tensor((1280, 5120), dtype="float32") = model_params[514]
            lv511: R.Tensor((5120,), dtype="float32") = model_params[245]
            lv384_1 = R.call_tir(cls.fused_matmul6_add18_gelu, (lv1452, lv510, lv511), out_sinfo=R.Tensor((1, 77, 5120), dtype="float32"))
            lv512: R.Tensor((5120, 1280), dtype="float32") = model_params[515]
            lv513: R.Tensor((1280,), dtype="float32") = model_params[246]
            lv385_1 = R.call_tir(cls.fused_matmul7_add16_add14, (lv384_1, lv512, lv513, lv383_1), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv514: R.Tensor((1280,), dtype="float32") = model_params[322]
            lv515: R.Tensor((1280,), dtype="float32") = model_params[321]
            lv1461 = R.call_tir(cls.layer_norm, (lv385_1, lv514, lv515), out_sinfo=R.Tensor((1, 77, 1280), dtype="float32"))
            lv1462 = R.call_tir(cls.squeeze, (lv1461,), out_sinfo=R.Tensor((77, 1280), dtype="float32"))
            lv1463 = R.call_tir(cls.cast, (lv,), out_sinfo=R.Tensor((1, 77), dtype="int32"))
            lv1464 = R.call_tir(cls.argmax, (lv1463,), out_sinfo=R.Tensor((1,), dtype="int32"))
            lv1465 = R.call_tir(cls.take2, (lv1462, lv1464), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv386_1 = R.call_tir(cls.fused_strided_slice_reshape20, (lv1465,), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            lv516_1: R.Tensor((1280, 1280), dtype="float32") = model_params[516]
            lv1469 = R.call_tir(cls.matmul8, (lv386_1, lv516_1), out_sinfo=R.Tensor((1, 1280), dtype="float32"))
            gv: R.Tuple(R.Tensor((1, 77, 1280), dtype="float32"), R.Tensor((1, 1280), dtype="float32")) = lv373_1, lv1469
            R.output(gv)
        return gv

    @R.function
    def concat_embeddings(cond_embeddings: R.Tensor((1, 77, 2048), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 2048), dtype="float32")) -> R.Tensor((2, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate1, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_enocder_outputs(cond_embeddings: R.Tensor((1, 77, 768), dtype="float32"), uncond_embeddings: R.Tensor((1, 77, 1280), dtype="float32")) -> R.Tensor((1, 77, 2048), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate3, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((1, 77, 2048), dtype="float32"))
        return gv

    @R.function
    def concat_pool_embeddings(cond_embeddings: R.Tensor((1, 1280), dtype="float32"), uncond_embeddings: R.Tensor((1, 1280), dtype="float32")) -> R.Tensor((2, 1280), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.concatenate, (cond_embeddings, uncond_embeddings), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
        return gv

    @R.function
    def euler_discrete_scheduler_scale(sample: R.Tensor((2, 4, 128, 128), dtype="float32"), sigma: R.Tensor((), dtype="float32")) -> R.Tensor((2, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.power, (sigma,), out_sinfo=R.Tensor((), dtype="float32"))
        gv1 = R.call_tir(cls.add19, (gv,), out_sinfo=R.Tensor((), dtype="float32"))
        gv2 = R.call_tir(cls.power1, (gv1,), out_sinfo=R.Tensor((), dtype="float32"))
        scaled_latent_model_input = R.call_tir(cls.divide6, (sample, gv2), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
        return scaled_latent_model_input

    @R.function
    def euler_discrete_scheduler_step(sample: R.Tensor((1, 4, 128, 128), dtype="float32"), model_output: R.Tensor((1, 4, 128, 128), dtype="float32"), sigma: R.Tensor((), dtype="float32"), sigma_1: R.Tensor((), dtype="float32")) -> R.Tensor((1, 4, 128, 128), dtype="float32"):
        cls = Module
        gv = R.call_tir(cls.subtract, (sigma_1, sigma), out_sinfo=R.Tensor((), dtype="float32"))
        gv1 = R.call_tir(cls.multiply4, (model_output, gv), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
        prev_sample = R.call_tir(cls.add20, (sample, gv1), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
        return prev_sample

    @R.function
    def image_to_rgba(x: R.Tensor((1, 1024, 1024, 3), dtype="float32")) -> R.Tensor((1024, 1024), dtype="uint32"):
        cls = Module
        gv = R.call_tir(cls.tir_image_to_rgba, (x,), out_sinfo=R.Tensor((1024, 1024), dtype="uint32"))
        return gv

    @R.function
    def unet(inp_0: R.Tensor((2, 4, 128, 128), dtype="float32"), inp_1: R.Tensor((), dtype="int32"), inp_2: R.Tensor((2, 77, 2048), dtype="float32"), inp_3: R.Tensor((2, 1280), dtype="float32"), inp_4: R.Tensor((2, 6), dtype="float32"), model_params: R.Tuple(R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((320, 4, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((4, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 320, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 320, 1, 1), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 640, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((10240,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 2560, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 2560, 1, 1), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 2560, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 2560, 1, 1), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((2560,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1920, 3, 3), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((1280, 1920, 1, 1), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280, 1280, 3, 3), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((5120,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 1920, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 1920, 1, 1), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((1920,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 1280, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 1280, 1, 1), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((1280,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 960, 3, 3), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((640, 960, 1, 1), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640, 640, 3, 3), dtype="float32"), R.Tensor((320, 960, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 960, 1, 1), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((960,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 640, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 640, 3, 3), dtype="float32"), R.Tensor((320, 320, 3, 3), dtype="float32"), R.Tensor((320, 640, 1, 1), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((640,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320,), dtype="float32"), R.Tensor((320, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2816, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((2048, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1280, 10240), dtype="float32"), R.Tensor((5120, 1280), dtype="float32"), R.Tensor((1280, 1280), dtype="float32"), R.Tensor((1, 1280, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1280, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((2048, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((640, 5120), dtype="float32"), R.Tensor((2560, 640), dtype="float32"), R.Tensor((640, 640), dtype="float32"), R.Tensor((1, 640, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1280, 320), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 320, 1, 1), dtype="float32"), R.Tensor((1, 4, 1, 1), dtype="float32"))) -> R.Tensor((1, 4, 128, 128), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 5})
        cls = Module
        with R.dataflow():
            lv598 = R.call_tir(cls.fused_broadcast_to1_strided_slice1_reshape28_cast3_multiply8_multiply9_tir_sin_tir_cos_concatenate4_strided_slice2_reshape29_strided_slice3_reshape29_concatenate4_cast4, (inp_1, metadata["relax.expr.Constant"][2]), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv713: R.Tensor((320, 1280), dtype="float32") = model_params[886]
            lv714: R.Tensor((1280,), dtype="float32") = model_params[426]
            lv599 = R.call_tir(cls.fused_matmul14_add25_silu6, (lv598, lv713, lv714), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv600 = R.call_tir(cls.fused_reshape30_strided_slice4_reshape31_cast5_multiply10_multiply11_tir_sin1_tir_cos1_concatenate5_strided_slice5_reshape32_strided_slice6_reshape32_concatenate5_reshape33_concatenate6, (inp_4, metadata["relax.expr.Constant"][3], inp_3), out_sinfo=R.Tensor((2, 2816), dtype="float32"))
            lv715: R.Tensor((2816, 1280), dtype="float32") = model_params[888]
            lv716: R.Tensor((1280,), dtype="float32") = model_params[0]
            lv601 = R.call_tir(cls.fused_matmul16_add25_silu6, (lv600, lv715, lv716), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv717: R.Tensor((1280, 1280), dtype="float32") = model_params[889]
            lv718: R.Tensor((1280,), dtype="float32") = model_params[1]
            lv602 = R.call_tir(cls.fused_matmul15_add25, (lv601, lv717, lv718), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv719: R.Tensor((1280, 1280), dtype="float32") = model_params[887]
            lv720: R.Tensor((1280,), dtype="float32") = model_params[427]
            lv603 = R.call_tir(cls.fused_matmul15_add25_add26, (lv599, lv719, lv720, lv602), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv721: R.Tensor((320, 4, 3, 3), dtype="float32") = model_params[2]
            lv722: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[890]
            lv604 = R.call_tir(cls.fused_conv2d13_add27, (inp_0, lv721, lv722), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv723: R.Tensor((320,), dtype="float32") = model_params[10]
            lv724: R.Tensor((320,), dtype="float32") = model_params[9]
            lv605 = R.call_tir(cls.fused_group_norm7_silu7, (lv604, lv723, lv724), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv54 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv725: R.Tensor((1280, 320), dtype="float32") = model_params[892]
            lv726: R.Tensor((320,), dtype="float32") = model_params[13]
            lv606 = R.call_tir(cls.fused_matmul17_add28_cast4, (lv54, lv725, lv726), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv59 = R.call_tir(cls.reshape35, (lv606,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv727: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[7]
            lv728: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[891]
            lv607 = R.call_tir(cls.fused_conv2d14_add27_add29, (lv605, lv727, lv728, lv59), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv729: R.Tensor((320,), dtype="float32") = model_params[12]
            lv730: R.Tensor((320,), dtype="float32") = model_params[11]
            lv608 = R.call_tir(cls.fused_group_norm7_silu7, (lv607, lv729, lv730), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv731: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[8]
            lv732: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[893]
            lv609 = R.call_tir(cls.fused_conv2d14_add27_add30_divide7, (lv608, lv731, lv732, lv604), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv733: R.Tensor((320,), dtype="float32") = model_params[17]
            lv734: R.Tensor((320,), dtype="float32") = model_params[16]
            lv610 = R.call_tir(cls.fused_group_norm7_silu7, (lv609, lv733, lv734), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv73 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv735: R.Tensor((1280, 320), dtype="float32") = model_params[895]
            lv736: R.Tensor((320,), dtype="float32") = model_params[20]
            lv611 = R.call_tir(cls.fused_matmul17_add28_cast4, (lv73, lv735, lv736), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv78 = R.call_tir(cls.reshape35, (lv611,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv737: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[14]
            lv738: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[894]
            lv612 = R.call_tir(cls.fused_conv2d14_add27_add29, (lv610, lv737, lv738, lv78), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv739: R.Tensor((320,), dtype="float32") = model_params[19]
            lv740: R.Tensor((320,), dtype="float32") = model_params[18]
            lv613 = R.call_tir(cls.fused_group_norm7_silu7, (lv612, lv739, lv740), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv741: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[15]
            lv742: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[896]
            lv614 = R.call_tir(cls.fused_conv2d14_add27_add30_divide7, (lv613, lv741, lv742, lv609), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv743: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[6]
            lv744: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[897]
            lv615 = R.call_tir(cls.fused_conv2d15_add31, (lv614, lv743, lv744), out_sinfo=R.Tensor((2, 320, 64, 64), dtype="float32"))
            lv745: R.Tensor((320,), dtype="float32") = model_params[74]
            lv746: R.Tensor((320,), dtype="float32") = model_params[73]
            lv616 = R.call_tir(cls.fused_group_norm8_silu8, (lv615, lv745, lv746), out_sinfo=R.Tensor((2, 320, 64, 64), dtype="float32"))
            lv95 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv747: R.Tensor((1280, 640), dtype="float32") = model_params[899]
            lv748: R.Tensor((640,), dtype="float32") = model_params[77]
            lv617 = R.call_tir(cls.fused_matmul18_add33_strided_slice7, (lv95, lv747, lv748), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv100 = R.call_tir(cls.reshape37, (lv617,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv749: R.Tensor((640, 320, 3, 3), dtype="float32") = model_params[70]
            lv750: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[898]
            lv618 = R.call_tir(cls.fused_conv2d16_add32_add34, (lv616, lv749, lv750, lv100), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv751: R.Tensor((640,), dtype="float32") = model_params[76]
            lv752: R.Tensor((640,), dtype="float32") = model_params[75]
            lv619 = R.call_tir(cls.fused_group_norm9_silu9, (lv618, lv751, lv752), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv753: R.Tensor((640, 320, 1, 1), dtype="float32") = model_params[72]
            lv754: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[901]
            lv620 = R.call_tir(cls.fused_conv2d18_add32, (lv615, lv753, lv754), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv755: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[71]
            lv756: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[900]
            lv621 = R.call_tir(cls.fused_conv2d17_add32_add35_divide8, (lv619, lv755, lv756, lv620), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv757: R.Tensor((640,), dtype="float32") = model_params[22]
            lv758: R.Tensor((640,), dtype="float32") = model_params[21]
            lv112 = R.call_tir(cls.group_norm10, (lv621, lv757, lv758), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv622 = R.call_tir(cls.fused_transpose23_reshape38, (lv112,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv759: R.Tensor((640, 640), dtype="float32") = model_params[902]
            lv760: R.Tensor((640,), dtype="float32") = model_params[23]
            lv623 = R.call_tir(cls.fused_matmul19_add36, (lv622, lv759, lv760), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv761: R.Tensor((640,), dtype="float32") = model_params[30]
            lv762: R.Tensor((640,), dtype="float32") = model_params[29]
            lv118 = R.call_tir(cls.layer_norm2, (lv623, lv761, lv762), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv763: R.Tensor((640, 640), dtype="float32") = model_params[903]
            lv120 = R.call_tir(cls.matmul19, (lv118, lv763), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv764: R.Tensor((640, 640), dtype="float32") = model_params[904]
            lv122 = R.call_tir(cls.matmul19, (lv118, lv764), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv765: R.Tensor((640, 640), dtype="float32") = model_params[905]
            lv124 = R.call_tir(cls.matmul19, (lv118, lv765), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv624 = R.call_tir(cls.fused_reshape39_transpose25, (lv120,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv625 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv122,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv626 = R.call_tir(cls.fused_reshape39_transpose25, (lv124,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv627 = R.call_tir(cls.fused_matmul20_multiply12, (lv624, lv625, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv136 = R.call_tir(cls.softmax3, (lv627,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv137 = R.call_tir(cls.matmul21, (lv136, lv626), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv628 = R.call_tir(cls.fused_transpose27_reshape40, (lv137,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv766: R.Tensor((640, 640), dtype="float32") = model_params[906]
            lv767: R.Tensor((640,), dtype="float32") = model_params[25]
            lv629 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv628, lv766, lv767, lv623), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv768: R.Tensor((640,), dtype="float32") = model_params[32]
            lv769: R.Tensor((640,), dtype="float32") = model_params[31]
            lv145 = R.call_tir(cls.layer_norm2, (lv629, lv768, lv769), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv770: R.Tensor((640, 640), dtype="float32") = model_params[907]
            lv147 = R.call_tir(cls.matmul19, (lv145, lv770), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv771: R.Tensor((2048, 640), dtype="float32") = model_params[908]
            lv149 = R.call_tir(cls.matmul22, (inp_2, lv771), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv772: R.Tensor((2048, 640), dtype="float32") = model_params[909]
            lv151 = R.call_tir(cls.matmul22, (inp_2, lv772), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv630 = R.call_tir(cls.fused_reshape39_transpose25, (lv147,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv631 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv149,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv632 = R.call_tir(cls.fused_reshape41_transpose29, (lv151,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv633 = R.call_tir(cls.fused_matmul23_multiply13, (lv630, lv631, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv163 = R.call_tir(cls.softmax4, (lv633,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv164 = R.call_tir(cls.matmul24, (lv163, lv632), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv634 = R.call_tir(cls.fused_transpose27_reshape40, (lv164,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv773: R.Tensor((640, 640), dtype="float32") = model_params[910]
            lv774: R.Tensor((640,), dtype="float32") = model_params[26]
            lv635 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv634, lv773, lv774, lv629), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv775: R.Tensor((640,), dtype="float32") = model_params[34]
            lv776: R.Tensor((640,), dtype="float32") = model_params[33]
            lv172 = R.call_tir(cls.layer_norm2, (lv635, lv775, lv776), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv777: R.Tensor((640, 5120), dtype="float32") = model_params[911]
            lv778: R.Tensor((5120,), dtype="float32") = model_params[27]
            lv636 = R.call_tir(cls.fused_matmul25_add38, (lv172, lv777, lv778), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv637 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv636,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv779: R.Tensor((2560, 640), dtype="float32") = model_params[912]
            lv780: R.Tensor((640,), dtype="float32") = model_params[28]
            lv638 = R.call_tir(cls.fused_matmul26_add36_add37, (lv637, lv779, lv780, lv635), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv781: R.Tensor((640,), dtype="float32") = model_params[40]
            lv782: R.Tensor((640,), dtype="float32") = model_params[39]
            lv185 = R.call_tir(cls.layer_norm2, (lv638, lv781, lv782), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv783: R.Tensor((640, 640), dtype="float32") = model_params[913]
            lv187 = R.call_tir(cls.matmul19, (lv185, lv783), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv784: R.Tensor((640, 640), dtype="float32") = model_params[914]
            lv189 = R.call_tir(cls.matmul19, (lv185, lv784), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv785: R.Tensor((640, 640), dtype="float32") = model_params[915]
            lv191 = R.call_tir(cls.matmul19, (lv185, lv785), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv639 = R.call_tir(cls.fused_reshape39_transpose25, (lv187,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv640 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv189,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv641 = R.call_tir(cls.fused_reshape39_transpose25, (lv191,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv642 = R.call_tir(cls.fused_matmul20_multiply12, (lv639, lv640, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv203 = R.call_tir(cls.softmax3, (lv642,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv204 = R.call_tir(cls.matmul21, (lv203, lv641), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv643 = R.call_tir(cls.fused_transpose27_reshape40, (lv204,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv786: R.Tensor((640, 640), dtype="float32") = model_params[916]
            lv787: R.Tensor((640,), dtype="float32") = model_params[35]
            lv644 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv643, lv786, lv787, lv638), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv788: R.Tensor((640,), dtype="float32") = model_params[42]
            lv789: R.Tensor((640,), dtype="float32") = model_params[41]
            lv212 = R.call_tir(cls.layer_norm2, (lv644, lv788, lv789), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv790: R.Tensor((640, 640), dtype="float32") = model_params[917]
            lv214 = R.call_tir(cls.matmul19, (lv212, lv790), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv791: R.Tensor((2048, 640), dtype="float32") = model_params[918]
            lv216 = R.call_tir(cls.matmul22, (inp_2, lv791), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv792: R.Tensor((2048, 640), dtype="float32") = model_params[919]
            lv218 = R.call_tir(cls.matmul22, (inp_2, lv792), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv645 = R.call_tir(cls.fused_reshape39_transpose25, (lv214,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv646 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv216,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv647 = R.call_tir(cls.fused_reshape41_transpose29, (lv218,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv648 = R.call_tir(cls.fused_matmul23_multiply13, (lv645, lv646, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv230 = R.call_tir(cls.softmax4, (lv648,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv231 = R.call_tir(cls.matmul24, (lv230, lv647), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv649 = R.call_tir(cls.fused_transpose27_reshape40, (lv231,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv793: R.Tensor((640, 640), dtype="float32") = model_params[920]
            lv794: R.Tensor((640,), dtype="float32") = model_params[36]
            lv650 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv649, lv793, lv794, lv644), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv795: R.Tensor((640,), dtype="float32") = model_params[44]
            lv796: R.Tensor((640,), dtype="float32") = model_params[43]
            lv239 = R.call_tir(cls.layer_norm2, (lv650, lv795, lv796), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv797: R.Tensor((640, 5120), dtype="float32") = model_params[921]
            lv798: R.Tensor((5120,), dtype="float32") = model_params[37]
            lv651 = R.call_tir(cls.fused_matmul25_add38, (lv239, lv797, lv798), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv652 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv651,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv799: R.Tensor((2560, 640), dtype="float32") = model_params[922]
            lv800: R.Tensor((640,), dtype="float32") = model_params[38]
            lv653 = R.call_tir(cls.fused_matmul26_add36_add37, (lv652, lv799, lv800, lv650), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv801: R.Tensor((640, 640), dtype="float32") = model_params[923]
            lv802: R.Tensor((640,), dtype="float32") = model_params[24]
            lv654 = R.call_tir(cls.fused_matmul19_add36, (lv653, lv801, lv802), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv655 = R.call_tir(cls.fused_reshape42_transpose33_add35, (lv654, lv621), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv803: R.Tensor((640,), dtype="float32") = model_params[81]
            lv804: R.Tensor((640,), dtype="float32") = model_params[80]
            lv656 = R.call_tir(cls.fused_group_norm9_silu9, (lv655, lv803, lv804), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv263 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv805: R.Tensor((1280, 640), dtype="float32") = model_params[925]
            lv806: R.Tensor((640,), dtype="float32") = model_params[84]
            lv657 = R.call_tir(cls.fused_matmul18_add33_strided_slice7, (lv263, lv805, lv806), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv268 = R.call_tir(cls.reshape37, (lv657,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv807: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[78]
            lv808: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[924]
            lv658 = R.call_tir(cls.fused_conv2d17_add32_add34, (lv656, lv807, lv808, lv268), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv809: R.Tensor((640,), dtype="float32") = model_params[83]
            lv810: R.Tensor((640,), dtype="float32") = model_params[82]
            lv659 = R.call_tir(cls.fused_group_norm9_silu9, (lv658, lv809, lv810), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv811: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[79]
            lv812: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[926]
            lv660 = R.call_tir(cls.fused_conv2d17_add32_add35_divide8, (lv659, lv811, lv812, lv655), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv813: R.Tensor((640,), dtype="float32") = model_params[46]
            lv814: R.Tensor((640,), dtype="float32") = model_params[45]
            lv277 = R.call_tir(cls.group_norm10, (lv660, lv813, lv814), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv661 = R.call_tir(cls.fused_transpose23_reshape38, (lv277,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv815: R.Tensor((640, 640), dtype="float32") = model_params[927]
            lv816: R.Tensor((640,), dtype="float32") = model_params[47]
            lv662 = R.call_tir(cls.fused_matmul19_add36, (lv661, lv815, lv816), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv817: R.Tensor((640,), dtype="float32") = model_params[54]
            lv818: R.Tensor((640,), dtype="float32") = model_params[53]
            lv283 = R.call_tir(cls.layer_norm2, (lv662, lv817, lv818), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv819: R.Tensor((640, 640), dtype="float32") = model_params[928]
            lv285 = R.call_tir(cls.matmul19, (lv283, lv819), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv820: R.Tensor((640, 640), dtype="float32") = model_params[929]
            lv287 = R.call_tir(cls.matmul19, (lv283, lv820), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv821: R.Tensor((640, 640), dtype="float32") = model_params[930]
            lv289 = R.call_tir(cls.matmul19, (lv283, lv821), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv663 = R.call_tir(cls.fused_reshape39_transpose25, (lv285,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv664 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv287,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv665 = R.call_tir(cls.fused_reshape39_transpose25, (lv289,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv666 = R.call_tir(cls.fused_matmul20_multiply12, (lv663, lv664, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv301 = R.call_tir(cls.softmax3, (lv666,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv302 = R.call_tir(cls.matmul21, (lv301, lv665), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv667 = R.call_tir(cls.fused_transpose27_reshape40, (lv302,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv822: R.Tensor((640, 640), dtype="float32") = model_params[931]
            lv823: R.Tensor((640,), dtype="float32") = model_params[49]
            lv668 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv667, lv822, lv823, lv662), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv824: R.Tensor((640,), dtype="float32") = model_params[56]
            lv825: R.Tensor((640,), dtype="float32") = model_params[55]
            lv310 = R.call_tir(cls.layer_norm2, (lv668, lv824, lv825), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv826: R.Tensor((640, 640), dtype="float32") = model_params[932]
            lv312 = R.call_tir(cls.matmul19, (lv310, lv826), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv827: R.Tensor((2048, 640), dtype="float32") = model_params[933]
            lv314 = R.call_tir(cls.matmul22, (inp_2, lv827), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv828: R.Tensor((2048, 640), dtype="float32") = model_params[934]
            lv316 = R.call_tir(cls.matmul22, (inp_2, lv828), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv669 = R.call_tir(cls.fused_reshape39_transpose25, (lv312,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv670 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv314,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv671 = R.call_tir(cls.fused_reshape41_transpose29, (lv316,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv672 = R.call_tir(cls.fused_matmul23_multiply13, (lv669, lv670, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv328 = R.call_tir(cls.softmax4, (lv672,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv329 = R.call_tir(cls.matmul24, (lv328, lv671), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv673 = R.call_tir(cls.fused_transpose27_reshape40, (lv329,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv829: R.Tensor((640, 640), dtype="float32") = model_params[935]
            lv830: R.Tensor((640,), dtype="float32") = model_params[50]
            lv674 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv673, lv829, lv830, lv668), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv831: R.Tensor((640,), dtype="float32") = model_params[58]
            lv832: R.Tensor((640,), dtype="float32") = model_params[57]
            lv337 = R.call_tir(cls.layer_norm2, (lv674, lv831, lv832), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv833: R.Tensor((640, 5120), dtype="float32") = model_params[936]
            lv834: R.Tensor((5120,), dtype="float32") = model_params[51]
            lv675 = R.call_tir(cls.fused_matmul25_add38, (lv337, lv833, lv834), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv676 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv675,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv835: R.Tensor((2560, 640), dtype="float32") = model_params[937]
            lv836: R.Tensor((640,), dtype="float32") = model_params[52]
            lv677 = R.call_tir(cls.fused_matmul26_add36_add37, (lv676, lv835, lv836, lv674), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv837: R.Tensor((640,), dtype="float32") = model_params[64]
            lv838: R.Tensor((640,), dtype="float32") = model_params[63]
            lv350 = R.call_tir(cls.layer_norm2, (lv677, lv837, lv838), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv839: R.Tensor((640, 640), dtype="float32") = model_params[938]
            lv352 = R.call_tir(cls.matmul19, (lv350, lv839), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv840: R.Tensor((640, 640), dtype="float32") = model_params[939]
            lv354 = R.call_tir(cls.matmul19, (lv350, lv840), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv841: R.Tensor((640, 640), dtype="float32") = model_params[940]
            lv356 = R.call_tir(cls.matmul19, (lv350, lv841), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv678 = R.call_tir(cls.fused_reshape39_transpose25, (lv352,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv679 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv354,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv680 = R.call_tir(cls.fused_reshape39_transpose25, (lv356,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv681 = R.call_tir(cls.fused_matmul20_multiply12, (lv678, lv679, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv368 = R.call_tir(cls.softmax3, (lv681,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv369 = R.call_tir(cls.matmul21, (lv368, lv680), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv682 = R.call_tir(cls.fused_transpose27_reshape40, (lv369,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv842: R.Tensor((640, 640), dtype="float32") = model_params[941]
            lv843: R.Tensor((640,), dtype="float32") = model_params[59]
            lv683 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv682, lv842, lv843, lv677), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv844: R.Tensor((640,), dtype="float32") = model_params[66]
            lv845: R.Tensor((640,), dtype="float32") = model_params[65]
            lv377 = R.call_tir(cls.layer_norm2, (lv683, lv844, lv845), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv846: R.Tensor((640, 640), dtype="float32") = model_params[942]
            lv379 = R.call_tir(cls.matmul19, (lv377, lv846), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv847: R.Tensor((2048, 640), dtype="float32") = model_params[943]
            lv381 = R.call_tir(cls.matmul22, (inp_2, lv847), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv848: R.Tensor((2048, 640), dtype="float32") = model_params[944]
            lv383 = R.call_tir(cls.matmul22, (inp_2, lv848), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv684 = R.call_tir(cls.fused_reshape39_transpose25, (lv379,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv685 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv381,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv686 = R.call_tir(cls.fused_reshape41_transpose29, (lv383,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv687 = R.call_tir(cls.fused_matmul23_multiply13, (lv684, lv685, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv395 = R.call_tir(cls.softmax4, (lv687,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv396 = R.call_tir(cls.matmul24, (lv395, lv686), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv688 = R.call_tir(cls.fused_transpose27_reshape40, (lv396,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv849: R.Tensor((640, 640), dtype="float32") = model_params[945]
            lv850: R.Tensor((640,), dtype="float32") = model_params[60]
            lv689 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv688, lv849, lv850, lv683), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv851: R.Tensor((640,), dtype="float32") = model_params[68]
            lv852: R.Tensor((640,), dtype="float32") = model_params[67]
            lv404 = R.call_tir(cls.layer_norm2, (lv689, lv851, lv852), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv853: R.Tensor((640, 5120), dtype="float32") = model_params[946]
            lv854: R.Tensor((5120,), dtype="float32") = model_params[61]
            lv690 = R.call_tir(cls.fused_matmul25_add38, (lv404, lv853, lv854), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv691 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv690,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv855: R.Tensor((2560, 640), dtype="float32") = model_params[947]
            lv856: R.Tensor((640,), dtype="float32") = model_params[62]
            lv692 = R.call_tir(cls.fused_matmul26_add36_add37, (lv691, lv855, lv856, lv689), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv857: R.Tensor((640, 640), dtype="float32") = model_params[948]
            lv858: R.Tensor((640,), dtype="float32") = model_params[48]
            lv693 = R.call_tir(cls.fused_matmul19_add36, (lv692, lv857, lv858), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv694 = R.call_tir(cls.fused_reshape42_transpose33_add35, (lv693, lv660), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv859: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[69]
            lv860: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[949]
            lv695 = R.call_tir(cls.fused_conv2d19_add39, (lv694, lv859, lv860), out_sinfo=R.Tensor((2, 640, 32, 32), dtype="float32"))
            lv861: R.Tensor((640,), dtype="float32") = model_params[297]
            lv862: R.Tensor((640,), dtype="float32") = model_params[296]
            lv696 = R.call_tir(cls.fused_group_norm11_silu10, (lv695, lv861, lv862), out_sinfo=R.Tensor((2, 640, 32, 32), dtype="float32"))
            lv431 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv863: R.Tensor((1280, 1280), dtype="float32") = model_params[951]
            lv864: R.Tensor((1280,), dtype="float32") = model_params[300]
            lv697 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv431, lv863, lv864), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv436 = R.call_tir(cls.reshape44, (lv697,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv865: R.Tensor((1280, 640, 3, 3), dtype="float32") = model_params[293]
            lv866: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[950]
            lv698 = R.call_tir(cls.fused_conv2d20_add40_add41, (lv696, lv865, lv866, lv436), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv867: R.Tensor((1280,), dtype="float32") = model_params[299]
            lv868: R.Tensor((1280,), dtype="float32") = model_params[298]
            lv699 = R.call_tir(cls.fused_group_norm12_silu11, (lv698, lv867, lv868), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv869: R.Tensor((1280, 640, 1, 1), dtype="float32") = model_params[295]
            lv870: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[953]
            lv700 = R.call_tir(cls.fused_conv2d22_add40, (lv695, lv869, lv870), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv871: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[294]
            lv872: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[952]
            lv701 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv699, lv871, lv872, lv700), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv873: R.Tensor((1280,), dtype="float32") = model_params[86]
            lv874: R.Tensor((1280,), dtype="float32") = model_params[85]
            lv448 = R.call_tir(cls.group_norm13, (lv701, lv873, lv874), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv702 = R.call_tir(cls.fused_transpose34_reshape45, (lv448,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv875: R.Tensor((1280, 1280), dtype="float32") = model_params[954]
            lv876: R.Tensor((1280,), dtype="float32") = model_params[87]
            lv703 = R.call_tir(cls.fused_matmul27_add43, (lv702, lv875, lv876), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv877: R.Tensor((1280,), dtype="float32") = model_params[94]
            lv878: R.Tensor((1280,), dtype="float32") = model_params[93]
            lv454 = R.call_tir(cls.layer_norm3, (lv703, lv877, lv878), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv879: R.Tensor((1280, 1280), dtype="float32") = model_params[955]
            lv456 = R.call_tir(cls.matmul27, (lv454, lv879), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv880: R.Tensor((1280, 1280), dtype="float32") = model_params[956]
            lv458 = R.call_tir(cls.matmul27, (lv454, lv880), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv881: R.Tensor((1280, 1280), dtype="float32") = model_params[957]
            lv460 = R.call_tir(cls.matmul27, (lv454, lv881), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv704 = R.call_tir(cls.fused_reshape46_transpose35, (lv456,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv705 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv458,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv706 = R.call_tir(cls.fused_reshape46_transpose35, (lv460,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv707 = R.call_tir(cls.fused_matmul28_multiply15, (lv704, lv705, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv472 = R.call_tir(cls.softmax5, (lv707,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv473 = R.call_tir(cls.matmul29, (lv472, lv706), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv708 = R.call_tir(cls.fused_transpose37_reshape47, (lv473,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv882: R.Tensor((1280, 1280), dtype="float32") = model_params[958]
            lv883: R.Tensor((1280,), dtype="float32") = model_params[89]
            lv709 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv708, lv882, lv883, lv703), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv884: R.Tensor((1280,), dtype="float32") = model_params[96]
            lv885: R.Tensor((1280,), dtype="float32") = model_params[95]
            lv481 = R.call_tir(cls.layer_norm3, (lv709, lv884, lv885), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv886: R.Tensor((1280, 1280), dtype="float32") = model_params[959]
            lv483 = R.call_tir(cls.matmul27, (lv481, lv886), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv887: R.Tensor((2048, 1280), dtype="float32") = model_params[960]
            lv485 = R.call_tir(cls.matmul30, (inp_2, lv887), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv888: R.Tensor((2048, 1280), dtype="float32") = model_params[961]
            lv487 = R.call_tir(cls.matmul30, (inp_2, lv888), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv710 = R.call_tir(cls.fused_reshape46_transpose35, (lv483,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv711 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv485,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv712 = R.call_tir(cls.fused_reshape48_transpose39, (lv487,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv713_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv710, lv711, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv499 = R.call_tir(cls.softmax6, (lv713_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv500 = R.call_tir(cls.matmul32, (lv499, lv712), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv714_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv500,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv889: R.Tensor((1280, 1280), dtype="float32") = model_params[962]
            lv890: R.Tensor((1280,), dtype="float32") = model_params[90]
            lv715_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv714_1, lv889, lv890, lv709), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv891: R.Tensor((1280,), dtype="float32") = model_params[98]
            lv892: R.Tensor((1280,), dtype="float32") = model_params[97]
            lv508 = R.call_tir(cls.layer_norm3, (lv715_1, lv891, lv892), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv893: R.Tensor((1280, 10240), dtype="float32") = model_params[963]
            lv894: R.Tensor((10240,), dtype="float32") = model_params[91]
            lv716_1 = R.call_tir(cls.fused_matmul33_add45, (lv508, lv893, lv894), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv717_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv716_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv895: R.Tensor((5120, 1280), dtype="float32") = model_params[964]
            lv896: R.Tensor((1280,), dtype="float32") = model_params[92]
            lv718_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv717_1, lv895, lv896, lv715_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv897: R.Tensor((1280,), dtype="float32") = model_params[104]
            lv898: R.Tensor((1280,), dtype="float32") = model_params[103]
            lv521 = R.call_tir(cls.layer_norm3, (lv718_1, lv897, lv898), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv899: R.Tensor((1280, 1280), dtype="float32") = model_params[965]
            lv523 = R.call_tir(cls.matmul27, (lv521, lv899), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv900: R.Tensor((1280, 1280), dtype="float32") = model_params[966]
            lv525 = R.call_tir(cls.matmul27, (lv521, lv900), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv901: R.Tensor((1280, 1280), dtype="float32") = model_params[967]
            lv527 = R.call_tir(cls.matmul27, (lv521, lv901), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv719_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv523,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv720_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv525,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv721_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv527,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv722_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv719_1, lv720_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv539 = R.call_tir(cls.softmax5, (lv722_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv540 = R.call_tir(cls.matmul29, (lv539, lv721_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv723_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv540,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv902: R.Tensor((1280, 1280), dtype="float32") = model_params[968]
            lv903: R.Tensor((1280,), dtype="float32") = model_params[99]
            lv724_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv723_1, lv902, lv903, lv718_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv904: R.Tensor((1280,), dtype="float32") = model_params[106]
            lv905: R.Tensor((1280,), dtype="float32") = model_params[105]
            lv548 = R.call_tir(cls.layer_norm3, (lv724_1, lv904, lv905), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv906: R.Tensor((1280, 1280), dtype="float32") = model_params[969]
            lv550 = R.call_tir(cls.matmul27, (lv548, lv906), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv907: R.Tensor((2048, 1280), dtype="float32") = model_params[970]
            lv552 = R.call_tir(cls.matmul30, (inp_2, lv907), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv908: R.Tensor((2048, 1280), dtype="float32") = model_params[971]
            lv554 = R.call_tir(cls.matmul30, (inp_2, lv908), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv725_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv550,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv726_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv552,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv727_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv554,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv728_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv725_1, lv726_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv566 = R.call_tir(cls.softmax6, (lv728_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv567 = R.call_tir(cls.matmul32, (lv566, lv727_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv729_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv567,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv909: R.Tensor((1280, 1280), dtype="float32") = model_params[972]
            lv910: R.Tensor((1280,), dtype="float32") = model_params[100]
            lv730_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv729_1, lv909, lv910, lv724_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv911: R.Tensor((1280,), dtype="float32") = model_params[108]
            lv912: R.Tensor((1280,), dtype="float32") = model_params[107]
            lv575 = R.call_tir(cls.layer_norm3, (lv730_1, lv911, lv912), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv913: R.Tensor((1280, 10240), dtype="float32") = model_params[973]
            lv914: R.Tensor((10240,), dtype="float32") = model_params[101]
            lv731_1 = R.call_tir(cls.fused_matmul33_add45, (lv575, lv913, lv914), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv732_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv731_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv915: R.Tensor((5120, 1280), dtype="float32") = model_params[974]
            lv916: R.Tensor((1280,), dtype="float32") = model_params[102]
            lv733_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv732_1, lv915, lv916, lv730_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv917: R.Tensor((1280,), dtype="float32") = model_params[114]
            lv918: R.Tensor((1280,), dtype="float32") = model_params[113]
            lv588 = R.call_tir(cls.layer_norm3, (lv733_1, lv917, lv918), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv919: R.Tensor((1280, 1280), dtype="float32") = model_params[975]
            lv590 = R.call_tir(cls.matmul27, (lv588, lv919), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv920: R.Tensor((1280, 1280), dtype="float32") = model_params[976]
            lv592 = R.call_tir(cls.matmul27, (lv588, lv920), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv921: R.Tensor((1280, 1280), dtype="float32") = model_params[977]
            lv594 = R.call_tir(cls.matmul27, (lv588, lv921), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv734_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv590,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv735_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv592,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv736_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv594,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv737_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv734_1, lv735_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv606_1 = R.call_tir(cls.softmax5, (lv737_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv607_1 = R.call_tir(cls.matmul29, (lv606_1, lv736_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv738_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv607_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv922: R.Tensor((1280, 1280), dtype="float32") = model_params[978]
            lv923: R.Tensor((1280,), dtype="float32") = model_params[109]
            lv739_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv738_1, lv922, lv923, lv733_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv924: R.Tensor((1280,), dtype="float32") = model_params[116]
            lv925: R.Tensor((1280,), dtype="float32") = model_params[115]
            lv615_1 = R.call_tir(cls.layer_norm3, (lv739_1, lv924, lv925), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv926: R.Tensor((1280, 1280), dtype="float32") = model_params[979]
            lv617_1 = R.call_tir(cls.matmul27, (lv615_1, lv926), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv927: R.Tensor((2048, 1280), dtype="float32") = model_params[980]
            lv619_1 = R.call_tir(cls.matmul30, (inp_2, lv927), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv928: R.Tensor((2048, 1280), dtype="float32") = model_params[981]
            lv621_1 = R.call_tir(cls.matmul30, (inp_2, lv928), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv740_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv617_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv741_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv619_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv742_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv621_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv743_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv740_1, lv741_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv633_1 = R.call_tir(cls.softmax6, (lv743_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv634_1 = R.call_tir(cls.matmul32, (lv633_1, lv742_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv744_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv634_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv929: R.Tensor((1280, 1280), dtype="float32") = model_params[982]
            lv930: R.Tensor((1280,), dtype="float32") = model_params[110]
            lv745_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv744_1, lv929, lv930, lv739_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv931: R.Tensor((1280,), dtype="float32") = model_params[118]
            lv932: R.Tensor((1280,), dtype="float32") = model_params[117]
            lv642_1 = R.call_tir(cls.layer_norm3, (lv745_1, lv931, lv932), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv933: R.Tensor((1280, 10240), dtype="float32") = model_params[983]
            lv934: R.Tensor((10240,), dtype="float32") = model_params[111]
            lv746_1 = R.call_tir(cls.fused_matmul33_add45, (lv642_1, lv933, lv934), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv747_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv746_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv935: R.Tensor((5120, 1280), dtype="float32") = model_params[984]
            lv936: R.Tensor((1280,), dtype="float32") = model_params[112]
            lv748_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv747_1, lv935, lv936, lv745_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv937: R.Tensor((1280,), dtype="float32") = model_params[124]
            lv938: R.Tensor((1280,), dtype="float32") = model_params[123]
            lv655_1 = R.call_tir(cls.layer_norm3, (lv748_1, lv937, lv938), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv939: R.Tensor((1280, 1280), dtype="float32") = model_params[985]
            lv657_1 = R.call_tir(cls.matmul27, (lv655_1, lv939), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv940: R.Tensor((1280, 1280), dtype="float32") = model_params[986]
            lv659_1 = R.call_tir(cls.matmul27, (lv655_1, lv940), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv941: R.Tensor((1280, 1280), dtype="float32") = model_params[987]
            lv661_1 = R.call_tir(cls.matmul27, (lv655_1, lv941), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv749_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv657_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv750_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv659_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv751_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv661_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv752_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv749_1, lv750_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv673_1 = R.call_tir(cls.softmax5, (lv752_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv674_1 = R.call_tir(cls.matmul29, (lv673_1, lv751_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv753_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv674_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv942: R.Tensor((1280, 1280), dtype="float32") = model_params[988]
            lv943: R.Tensor((1280,), dtype="float32") = model_params[119]
            lv754_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv753_1, lv942, lv943, lv748_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv944: R.Tensor((1280,), dtype="float32") = model_params[126]
            lv945: R.Tensor((1280,), dtype="float32") = model_params[125]
            lv682_1 = R.call_tir(cls.layer_norm3, (lv754_1, lv944, lv945), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv946: R.Tensor((1280, 1280), dtype="float32") = model_params[989]
            lv684_1 = R.call_tir(cls.matmul27, (lv682_1, lv946), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv947: R.Tensor((2048, 1280), dtype="float32") = model_params[990]
            lv686_1 = R.call_tir(cls.matmul30, (inp_2, lv947), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv948: R.Tensor((2048, 1280), dtype="float32") = model_params[991]
            lv688_1 = R.call_tir(cls.matmul30, (inp_2, lv948), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv755_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv684_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv756_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv686_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv757_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv688_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv758_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv755_1, lv756_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv700_1 = R.call_tir(cls.softmax6, (lv758_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv701_1 = R.call_tir(cls.matmul32, (lv700_1, lv757_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv759_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv701_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv949: R.Tensor((1280, 1280), dtype="float32") = model_params[992]
            lv950: R.Tensor((1280,), dtype="float32") = model_params[120]
            lv760_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv759_1, lv949, lv950, lv754_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv951: R.Tensor((1280,), dtype="float32") = model_params[128]
            lv952: R.Tensor((1280,), dtype="float32") = model_params[127]
            lv709_1 = R.call_tir(cls.layer_norm3, (lv760_1, lv951, lv952), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv953: R.Tensor((1280, 10240), dtype="float32") = model_params[993]
            lv954: R.Tensor((10240,), dtype="float32") = model_params[121]
            lv761_1 = R.call_tir(cls.fused_matmul33_add45, (lv709_1, lv953, lv954), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv762_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv761_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv955: R.Tensor((5120, 1280), dtype="float32") = model_params[994]
            lv956: R.Tensor((1280,), dtype="float32") = model_params[122]
            lv763_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv762_1, lv955, lv956, lv760_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv957: R.Tensor((1280,), dtype="float32") = model_params[134]
            lv958: R.Tensor((1280,), dtype="float32") = model_params[133]
            lv722_2 = R.call_tir(cls.layer_norm3, (lv763_1, lv957, lv958), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv959: R.Tensor((1280, 1280), dtype="float32") = model_params[995]
            lv724_2 = R.call_tir(cls.matmul27, (lv722_2, lv959), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv960: R.Tensor((1280, 1280), dtype="float32") = model_params[996]
            lv726_2 = R.call_tir(cls.matmul27, (lv722_2, lv960), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv961: R.Tensor((1280, 1280), dtype="float32") = model_params[997]
            lv728_2 = R.call_tir(cls.matmul27, (lv722_2, lv961), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv764_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv724_2,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv765_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv726_2,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv766_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv728_2,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv767_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv764_1, lv765_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv740_2 = R.call_tir(cls.softmax5, (lv767_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv741_2 = R.call_tir(cls.matmul29, (lv740_2, lv766_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv768_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv741_2,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv962: R.Tensor((1280, 1280), dtype="float32") = model_params[998]
            lv963: R.Tensor((1280,), dtype="float32") = model_params[129]
            lv769_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv768_1, lv962, lv963, lv763_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv964: R.Tensor((1280,), dtype="float32") = model_params[136]
            lv965: R.Tensor((1280,), dtype="float32") = model_params[135]
            lv749_2 = R.call_tir(cls.layer_norm3, (lv769_1, lv964, lv965), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv966: R.Tensor((1280, 1280), dtype="float32") = model_params[999]
            lv751_2 = R.call_tir(cls.matmul27, (lv749_2, lv966), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv967: R.Tensor((2048, 1280), dtype="float32") = model_params[1000]
            lv753_2 = R.call_tir(cls.matmul30, (inp_2, lv967), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv968: R.Tensor((2048, 1280), dtype="float32") = model_params[1001]
            lv755_2 = R.call_tir(cls.matmul30, (inp_2, lv968), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv770_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv751_2,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv771_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv753_2,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv772_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv755_2,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv773_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv770_1, lv771_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv767_2 = R.call_tir(cls.softmax6, (lv773_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv768_2 = R.call_tir(cls.matmul32, (lv767_2, lv772_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv774_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv768_2,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv969: R.Tensor((1280, 1280), dtype="float32") = model_params[1002]
            lv970: R.Tensor((1280,), dtype="float32") = model_params[130]
            lv775_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv774_1, lv969, lv970, lv769_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv971: R.Tensor((1280,), dtype="float32") = model_params[138]
            lv972: R.Tensor((1280,), dtype="float32") = model_params[137]
            lv776_1 = R.call_tir(cls.layer_norm3, (lv775_1, lv971, lv972), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv973: R.Tensor((1280, 10240), dtype="float32") = model_params[1003]
            lv974: R.Tensor((10240,), dtype="float32") = model_params[131]
            lv776_2 = R.call_tir(cls.fused_matmul33_add45, (lv776_1, lv973, lv974), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv777_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv776_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv975: R.Tensor((5120, 1280), dtype="float32") = model_params[1004]
            lv976: R.Tensor((1280,), dtype="float32") = model_params[132]
            lv778_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv777_1, lv975, lv976, lv775_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv977: R.Tensor((1280,), dtype="float32") = model_params[144]
            lv978: R.Tensor((1280,), dtype="float32") = model_params[143]
            lv789_1 = R.call_tir(cls.layer_norm3, (lv778_1, lv977, lv978), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv979: R.Tensor((1280, 1280), dtype="float32") = model_params[1005]
            lv791_1 = R.call_tir(cls.matmul27, (lv789_1, lv979), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv980: R.Tensor((1280, 1280), dtype="float32") = model_params[1006]
            lv793_1 = R.call_tir(cls.matmul27, (lv789_1, lv980), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv981: R.Tensor((1280, 1280), dtype="float32") = model_params[1007]
            lv795_1 = R.call_tir(cls.matmul27, (lv789_1, lv981), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv779_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv791_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv780_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv793_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv781_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv795_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv782_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv779_1, lv780_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv807_1 = R.call_tir(cls.softmax5, (lv782_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv808_1 = R.call_tir(cls.matmul29, (lv807_1, lv781_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv783_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv808_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv982: R.Tensor((1280, 1280), dtype="float32") = model_params[1008]
            lv983: R.Tensor((1280,), dtype="float32") = model_params[139]
            lv784_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv783_1, lv982, lv983, lv778_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv984: R.Tensor((1280,), dtype="float32") = model_params[146]
            lv985: R.Tensor((1280,), dtype="float32") = model_params[145]
            lv816_1 = R.call_tir(cls.layer_norm3, (lv784_1, lv984, lv985), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv986: R.Tensor((1280, 1280), dtype="float32") = model_params[1009]
            lv818_1 = R.call_tir(cls.matmul27, (lv816_1, lv986), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv987: R.Tensor((2048, 1280), dtype="float32") = model_params[1010]
            lv820_1 = R.call_tir(cls.matmul30, (inp_2, lv987), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv988: R.Tensor((2048, 1280), dtype="float32") = model_params[1011]
            lv822_1 = R.call_tir(cls.matmul30, (inp_2, lv988), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv785_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv818_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv786_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv820_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv787_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv822_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv788_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv785_1, lv786_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv834_1 = R.call_tir(cls.softmax6, (lv788_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv835_1 = R.call_tir(cls.matmul32, (lv834_1, lv787_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv789_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv835_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv989: R.Tensor((1280, 1280), dtype="float32") = model_params[1012]
            lv990: R.Tensor((1280,), dtype="float32") = model_params[140]
            lv790_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv789_2, lv989, lv990, lv784_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv991: R.Tensor((1280,), dtype="float32") = model_params[148]
            lv992: R.Tensor((1280,), dtype="float32") = model_params[147]
            lv843_1 = R.call_tir(cls.layer_norm3, (lv790_1, lv991, lv992), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv993: R.Tensor((1280, 10240), dtype="float32") = model_params[1013]
            lv994: R.Tensor((10240,), dtype="float32") = model_params[141]
            lv791_2 = R.call_tir(cls.fused_matmul33_add45, (lv843_1, lv993, lv994), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv792_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv791_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv995: R.Tensor((5120, 1280), dtype="float32") = model_params[1014]
            lv996: R.Tensor((1280,), dtype="float32") = model_params[142]
            lv793_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv792_1, lv995, lv996, lv790_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv997: R.Tensor((1280,), dtype="float32") = model_params[154]
            lv998: R.Tensor((1280,), dtype="float32") = model_params[153]
            lv856_1 = R.call_tir(cls.layer_norm3, (lv793_2, lv997, lv998), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv999: R.Tensor((1280, 1280), dtype="float32") = model_params[1015]
            lv858_1 = R.call_tir(cls.matmul27, (lv856_1, lv999), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1000: R.Tensor((1280, 1280), dtype="float32") = model_params[1016]
            lv860_1 = R.call_tir(cls.matmul27, (lv856_1, lv1000), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1001: R.Tensor((1280, 1280), dtype="float32") = model_params[1017]
            lv862_1 = R.call_tir(cls.matmul27, (lv856_1, lv1001), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv794_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv858_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv795_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv860_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv796_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv862_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv797_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv794_1, lv795_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv874_1 = R.call_tir(cls.softmax5, (lv797_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv875_1 = R.call_tir(cls.matmul29, (lv874_1, lv796_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv798_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv875_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1002: R.Tensor((1280, 1280), dtype="float32") = model_params[1018]
            lv1003: R.Tensor((1280,), dtype="float32") = model_params[149]
            lv799_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv798_1, lv1002, lv1003, lv793_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1004: R.Tensor((1280,), dtype="float32") = model_params[156]
            lv1005: R.Tensor((1280,), dtype="float32") = model_params[155]
            lv883_1 = R.call_tir(cls.layer_norm3, (lv799_1, lv1004, lv1005), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1006: R.Tensor((1280, 1280), dtype="float32") = model_params[1019]
            lv885_1 = R.call_tir(cls.matmul27, (lv883_1, lv1006), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1007: R.Tensor((2048, 1280), dtype="float32") = model_params[1020]
            lv887_1 = R.call_tir(cls.matmul30, (inp_2, lv1007), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1008: R.Tensor((2048, 1280), dtype="float32") = model_params[1021]
            lv889_1 = R.call_tir(cls.matmul30, (inp_2, lv1008), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv800_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv885_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv801_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv887_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv802_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv889_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv803_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv800_1, lv801_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv901_1 = R.call_tir(cls.softmax6, (lv803_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv902_1 = R.call_tir(cls.matmul32, (lv901_1, lv802_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv804_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv902_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1009: R.Tensor((1280, 1280), dtype="float32") = model_params[1022]
            lv1010: R.Tensor((1280,), dtype="float32") = model_params[150]
            lv805_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv804_1, lv1009, lv1010, lv799_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1011: R.Tensor((1280,), dtype="float32") = model_params[158]
            lv1012: R.Tensor((1280,), dtype="float32") = model_params[157]
            lv910_1 = R.call_tir(cls.layer_norm3, (lv805_1, lv1011, lv1012), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1013: R.Tensor((1280, 10240), dtype="float32") = model_params[1023]
            lv1014: R.Tensor((10240,), dtype="float32") = model_params[151]
            lv806_1 = R.call_tir(cls.fused_matmul33_add45, (lv910_1, lv1013, lv1014), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv807_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv806_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1015: R.Tensor((5120, 1280), dtype="float32") = model_params[1024]
            lv1016: R.Tensor((1280,), dtype="float32") = model_params[152]
            lv808_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv807_2, lv1015, lv1016, lv805_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1017: R.Tensor((1280,), dtype="float32") = model_params[164]
            lv1018: R.Tensor((1280,), dtype="float32") = model_params[163]
            lv923_1 = R.call_tir(cls.layer_norm3, (lv808_2, lv1017, lv1018), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1019: R.Tensor((1280, 1280), dtype="float32") = model_params[1025]
            lv925_1 = R.call_tir(cls.matmul27, (lv923_1, lv1019), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1020: R.Tensor((1280, 1280), dtype="float32") = model_params[1026]
            lv927_1 = R.call_tir(cls.matmul27, (lv923_1, lv1020), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1021: R.Tensor((1280, 1280), dtype="float32") = model_params[1027]
            lv929_1 = R.call_tir(cls.matmul27, (lv923_1, lv1021), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv809_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv925_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv810_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv927_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv811_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv929_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv812_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv809_1, lv810_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv941_1 = R.call_tir(cls.softmax5, (lv812_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv942_1 = R.call_tir(cls.matmul29, (lv941_1, lv811_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv813_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv942_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1022: R.Tensor((1280, 1280), dtype="float32") = model_params[1028]
            lv1023: R.Tensor((1280,), dtype="float32") = model_params[159]
            lv814_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv813_1, lv1022, lv1023, lv808_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1024: R.Tensor((1280,), dtype="float32") = model_params[166]
            lv1025: R.Tensor((1280,), dtype="float32") = model_params[165]
            lv950_1 = R.call_tir(cls.layer_norm3, (lv814_1, lv1024, lv1025), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1026: R.Tensor((1280, 1280), dtype="float32") = model_params[1029]
            lv952_1 = R.call_tir(cls.matmul27, (lv950_1, lv1026), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1027: R.Tensor((2048, 1280), dtype="float32") = model_params[1030]
            lv954_1 = R.call_tir(cls.matmul30, (inp_2, lv1027), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1028: R.Tensor((2048, 1280), dtype="float32") = model_params[1031]
            lv956_1 = R.call_tir(cls.matmul30, (inp_2, lv1028), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv815_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv952_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv816_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv954_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv817_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv956_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv818_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv815_1, lv816_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv968_1 = R.call_tir(cls.softmax6, (lv818_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv969_1 = R.call_tir(cls.matmul32, (lv968_1, lv817_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv819_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv969_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1029: R.Tensor((1280, 1280), dtype="float32") = model_params[1032]
            lv1030: R.Tensor((1280,), dtype="float32") = model_params[160]
            lv820_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv819_1, lv1029, lv1030, lv814_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1031: R.Tensor((1280,), dtype="float32") = model_params[168]
            lv1032: R.Tensor((1280,), dtype="float32") = model_params[167]
            lv977_1 = R.call_tir(cls.layer_norm3, (lv820_2, lv1031, lv1032), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1033: R.Tensor((1280, 10240), dtype="float32") = model_params[1033]
            lv1034: R.Tensor((10240,), dtype="float32") = model_params[161]
            lv821_1 = R.call_tir(cls.fused_matmul33_add45, (lv977_1, lv1033, lv1034), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv822_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv821_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1035: R.Tensor((5120, 1280), dtype="float32") = model_params[1034]
            lv1036: R.Tensor((1280,), dtype="float32") = model_params[162]
            lv823_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv822_2, lv1035, lv1036, lv820_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1037: R.Tensor((1280,), dtype="float32") = model_params[174]
            lv1038: R.Tensor((1280,), dtype="float32") = model_params[173]
            lv990_1 = R.call_tir(cls.layer_norm3, (lv823_1, lv1037, lv1038), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1039: R.Tensor((1280, 1280), dtype="float32") = model_params[1035]
            lv992_1 = R.call_tir(cls.matmul27, (lv990_1, lv1039), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1040: R.Tensor((1280, 1280), dtype="float32") = model_params[1036]
            lv994_1 = R.call_tir(cls.matmul27, (lv990_1, lv1040), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1041: R.Tensor((1280, 1280), dtype="float32") = model_params[1037]
            lv996_1 = R.call_tir(cls.matmul27, (lv990_1, lv1041), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv824_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv992_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv825_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv994_1,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv826_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv996_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv827_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv824_1, lv825_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1008_1 = R.call_tir(cls.softmax5, (lv827_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1009_1 = R.call_tir(cls.matmul29, (lv1008_1, lv826_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv828_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1009_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1042: R.Tensor((1280, 1280), dtype="float32") = model_params[1038]
            lv1043: R.Tensor((1280,), dtype="float32") = model_params[169]
            lv829_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv828_1, lv1042, lv1043, lv823_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1044: R.Tensor((1280,), dtype="float32") = model_params[176]
            lv1045: R.Tensor((1280,), dtype="float32") = model_params[175]
            lv1017_1 = R.call_tir(cls.layer_norm3, (lv829_1, lv1044, lv1045), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1046: R.Tensor((1280, 1280), dtype="float32") = model_params[1039]
            lv1019_1 = R.call_tir(cls.matmul27, (lv1017_1, lv1046), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1047: R.Tensor((2048, 1280), dtype="float32") = model_params[1040]
            lv1021_1 = R.call_tir(cls.matmul30, (inp_2, lv1047), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1048: R.Tensor((2048, 1280), dtype="float32") = model_params[1041]
            lv1023_1 = R.call_tir(cls.matmul30, (inp_2, lv1048), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv830_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1019_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv831_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1021_1,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv832_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1023_1,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv833_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv830_1, lv831_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1035_1 = R.call_tir(cls.softmax6, (lv833_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1036_1 = R.call_tir(cls.matmul32, (lv1035_1, lv832_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv834_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv1036_1,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1049: R.Tensor((1280, 1280), dtype="float32") = model_params[1042]
            lv1050: R.Tensor((1280,), dtype="float32") = model_params[170]
            lv835_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv834_2, lv1049, lv1050, lv829_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1051: R.Tensor((1280,), dtype="float32") = model_params[178]
            lv1052: R.Tensor((1280,), dtype="float32") = model_params[177]
            lv1044_1 = R.call_tir(cls.layer_norm3, (lv835_2, lv1051, lv1052), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1053: R.Tensor((1280, 10240), dtype="float32") = model_params[1043]
            lv1054: R.Tensor((10240,), dtype="float32") = model_params[171]
            lv836_1 = R.call_tir(cls.fused_matmul33_add45, (lv1044_1, lv1053, lv1054), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv837_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv836_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1055: R.Tensor((5120, 1280), dtype="float32") = model_params[1044]
            lv1056: R.Tensor((1280,), dtype="float32") = model_params[172]
            lv838_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv837_1, lv1055, lv1056, lv835_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1057: R.Tensor((1280,), dtype="float32") = model_params[184]
            lv1058: R.Tensor((1280,), dtype="float32") = model_params[183]
            lv1057_1 = R.call_tir(cls.layer_norm3, (lv838_1, lv1057, lv1058), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1059: R.Tensor((1280, 1280), dtype="float32") = model_params[1045]
            lv1059_1 = R.call_tir(cls.matmul27, (lv1057_1, lv1059), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1060: R.Tensor((1280, 1280), dtype="float32") = model_params[1046]
            lv1061 = R.call_tir(cls.matmul27, (lv1057_1, lv1060), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1061_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1047]
            lv1063 = R.call_tir(cls.matmul27, (lv1057_1, lv1061_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv839_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1059_1,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv840_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv841_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv842_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv839_1, lv840_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1075 = R.call_tir(cls.softmax5, (lv842_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1076 = R.call_tir(cls.matmul29, (lv1075, lv841_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv843_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv1076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1062: R.Tensor((1280, 1280), dtype="float32") = model_params[1048]
            lv1063_1: R.Tensor((1280,), dtype="float32") = model_params[179]
            lv844_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv843_2, lv1062, lv1063_1, lv838_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1064: R.Tensor((1280,), dtype="float32") = model_params[186]
            lv1065: R.Tensor((1280,), dtype="float32") = model_params[185]
            lv1084 = R.call_tir(cls.layer_norm3, (lv844_1, lv1064, lv1065), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1066: R.Tensor((1280, 1280), dtype="float32") = model_params[1049]
            lv1086 = R.call_tir(cls.matmul27, (lv1084, lv1066), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1067: R.Tensor((2048, 1280), dtype="float32") = model_params[1050]
            lv1088 = R.call_tir(cls.matmul30, (inp_2, lv1067), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1068: R.Tensor((2048, 1280), dtype="float32") = model_params[1051]
            lv1090 = R.call_tir(cls.matmul30, (inp_2, lv1068), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv845_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv846_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv847_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv848_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv845_1, lv846_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1102 = R.call_tir(cls.softmax6, (lv848_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1103 = R.call_tir(cls.matmul32, (lv1102, lv847_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv849_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1069: R.Tensor((1280, 1280), dtype="float32") = model_params[1052]
            lv1070: R.Tensor((1280,), dtype="float32") = model_params[180]
            lv850_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv849_1, lv1069, lv1070, lv844_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1071: R.Tensor((1280,), dtype="float32") = model_params[188]
            lv1072: R.Tensor((1280,), dtype="float32") = model_params[187]
            lv1111 = R.call_tir(cls.layer_norm3, (lv850_1, lv1071, lv1072), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1073: R.Tensor((1280, 10240), dtype="float32") = model_params[1053]
            lv1074: R.Tensor((10240,), dtype="float32") = model_params[181]
            lv851_1 = R.call_tir(cls.fused_matmul33_add45, (lv1111, lv1073, lv1074), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv852_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv851_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1075_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1054]
            lv1076_1: R.Tensor((1280,), dtype="float32") = model_params[182]
            lv853_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv852_1, lv1075_1, lv1076_1, lv850_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1077: R.Tensor((1280, 1280), dtype="float32") = model_params[1055]
            lv1078: R.Tensor((1280,), dtype="float32") = model_params[88]
            lv854_1 = R.call_tir(cls.fused_matmul27_add43, (lv853_1, lv1077, lv1078), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv855_1 = R.call_tir(cls.fused_reshape49_transpose42_add42, (lv854_1, lv701), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1079: R.Tensor((1280,), dtype="float32") = model_params[304]
            lv1080: R.Tensor((1280,), dtype="float32") = model_params[303]
            lv856_2 = R.call_tir(cls.fused_group_norm12_silu11, (lv855_1, lv1079, lv1080), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1135 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1081: R.Tensor((1280, 1280), dtype="float32") = model_params[1057]
            lv1082: R.Tensor((1280,), dtype="float32") = model_params[307]
            lv857_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv1135, lv1081, lv1082), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1140 = R.call_tir(cls.reshape44, (lv857_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1083: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[301]
            lv1084_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1056]
            lv858_2 = R.call_tir(cls.fused_conv2d21_add40_add41, (lv856_2, lv1083, lv1084_1, lv1140), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1085: R.Tensor((1280,), dtype="float32") = model_params[306]
            lv1086_1: R.Tensor((1280,), dtype="float32") = model_params[305]
            lv859_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv858_2, lv1085, lv1086_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1087: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[302]
            lv1088_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1058]
            lv860_2 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv859_1, lv1087, lv1088_1, lv855_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1089: R.Tensor((1280,), dtype="float32") = model_params[190]
            lv1090_1: R.Tensor((1280,), dtype="float32") = model_params[189]
            lv1149 = R.call_tir(cls.group_norm13, (lv860_2, lv1089, lv1090_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv861_1 = R.call_tir(cls.fused_transpose34_reshape45, (lv1149,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1091: R.Tensor((1280, 1280), dtype="float32") = model_params[1059]
            lv1092: R.Tensor((1280,), dtype="float32") = model_params[191]
            lv862_2 = R.call_tir(cls.fused_matmul27_add43, (lv861_1, lv1091, lv1092), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1093: R.Tensor((1280,), dtype="float32") = model_params[198]
            lv1094: R.Tensor((1280,), dtype="float32") = model_params[197]
            lv1155 = R.call_tir(cls.layer_norm3, (lv862_2, lv1093, lv1094), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1095: R.Tensor((1280, 1280), dtype="float32") = model_params[1060]
            lv1157 = R.call_tir(cls.matmul27, (lv1155, lv1095), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1096: R.Tensor((1280, 1280), dtype="float32") = model_params[1061]
            lv1159 = R.call_tir(cls.matmul27, (lv1155, lv1096), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1097: R.Tensor((1280, 1280), dtype="float32") = model_params[1062]
            lv1161 = R.call_tir(cls.matmul27, (lv1155, lv1097), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv863_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1157,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv864_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1159,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv865_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1161,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv866_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv863_1, lv864_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1173 = R.call_tir(cls.softmax5, (lv866_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1174 = R.call_tir(cls.matmul29, (lv1173, lv865_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv867_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1174,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1098: R.Tensor((1280, 1280), dtype="float32") = model_params[1063]
            lv1099: R.Tensor((1280,), dtype="float32") = model_params[193]
            lv868_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv867_1, lv1098, lv1099, lv862_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1100: R.Tensor((1280,), dtype="float32") = model_params[200]
            lv1101: R.Tensor((1280,), dtype="float32") = model_params[199]
            lv1182 = R.call_tir(cls.layer_norm3, (lv868_1, lv1100, lv1101), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1102_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1064]
            lv1184 = R.call_tir(cls.matmul27, (lv1182, lv1102_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1103_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1065]
            lv1186 = R.call_tir(cls.matmul30, (inp_2, lv1103_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1104: R.Tensor((2048, 1280), dtype="float32") = model_params[1066]
            lv1188 = R.call_tir(cls.matmul30, (inp_2, lv1104), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv869_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1184,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv870_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1186,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv871_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1188,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv872_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv869_1, lv870_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1200 = R.call_tir(cls.softmax6, (lv872_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1201 = R.call_tir(cls.matmul32, (lv1200, lv871_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv873_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1201,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1105: R.Tensor((1280, 1280), dtype="float32") = model_params[1067]
            lv1106: R.Tensor((1280,), dtype="float32") = model_params[194]
            lv874_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv873_1, lv1105, lv1106, lv868_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1107: R.Tensor((1280,), dtype="float32") = model_params[202]
            lv1108: R.Tensor((1280,), dtype="float32") = model_params[201]
            lv1209 = R.call_tir(cls.layer_norm3, (lv874_2, lv1107, lv1108), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1109: R.Tensor((1280, 10240), dtype="float32") = model_params[1068]
            lv1110: R.Tensor((10240,), dtype="float32") = model_params[195]
            lv875_2 = R.call_tir(cls.fused_matmul33_add45, (lv1209, lv1109, lv1110), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv876_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv875_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1111_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1069]
            lv1112: R.Tensor((1280,), dtype="float32") = model_params[196]
            lv877_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv876_1, lv1111_1, lv1112, lv874_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1113: R.Tensor((1280,), dtype="float32") = model_params[208]
            lv1114: R.Tensor((1280,), dtype="float32") = model_params[207]
            lv1222 = R.call_tir(cls.layer_norm3, (lv877_1, lv1113, lv1114), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1115: R.Tensor((1280, 1280), dtype="float32") = model_params[1070]
            lv1224 = R.call_tir(cls.matmul27, (lv1222, lv1115), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1116: R.Tensor((1280, 1280), dtype="float32") = model_params[1071]
            lv1226 = R.call_tir(cls.matmul27, (lv1222, lv1116), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1117: R.Tensor((1280, 1280), dtype="float32") = model_params[1072]
            lv1228 = R.call_tir(cls.matmul27, (lv1222, lv1117), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv878_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1224,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv879_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1226,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv880_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1228,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv881_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv878_1, lv879_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1240 = R.call_tir(cls.softmax5, (lv881_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1241 = R.call_tir(cls.matmul29, (lv1240, lv880_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv882_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1241,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1118: R.Tensor((1280, 1280), dtype="float32") = model_params[1073]
            lv1119: R.Tensor((1280,), dtype="float32") = model_params[203]
            lv883_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv882_1, lv1118, lv1119, lv877_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1120: R.Tensor((1280,), dtype="float32") = model_params[210]
            lv1121: R.Tensor((1280,), dtype="float32") = model_params[209]
            lv1249 = R.call_tir(cls.layer_norm3, (lv883_2, lv1120, lv1121), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1122: R.Tensor((1280, 1280), dtype="float32") = model_params[1074]
            lv1251 = R.call_tir(cls.matmul27, (lv1249, lv1122), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1123: R.Tensor((2048, 1280), dtype="float32") = model_params[1075]
            lv1253 = R.call_tir(cls.matmul30, (inp_2, lv1123), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1124: R.Tensor((2048, 1280), dtype="float32") = model_params[1076]
            lv1255 = R.call_tir(cls.matmul30, (inp_2, lv1124), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv884_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1251,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv885_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1253,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv886_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1255,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv887_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv884_1, lv885_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1267 = R.call_tir(cls.softmax6, (lv887_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1268 = R.call_tir(cls.matmul32, (lv1267, lv886_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv888_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1268,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1125: R.Tensor((1280, 1280), dtype="float32") = model_params[1077]
            lv1126: R.Tensor((1280,), dtype="float32") = model_params[204]
            lv889_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv888_1, lv1125, lv1126, lv883_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1127: R.Tensor((1280,), dtype="float32") = model_params[212]
            lv1128: R.Tensor((1280,), dtype="float32") = model_params[211]
            lv1276 = R.call_tir(cls.layer_norm3, (lv889_2, lv1127, lv1128), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1129: R.Tensor((1280, 10240), dtype="float32") = model_params[1078]
            lv1130: R.Tensor((10240,), dtype="float32") = model_params[205]
            lv890_1 = R.call_tir(cls.fused_matmul33_add45, (lv1276, lv1129, lv1130), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv891_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv890_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1131: R.Tensor((5120, 1280), dtype="float32") = model_params[1079]
            lv1132: R.Tensor((1280,), dtype="float32") = model_params[206]
            lv892_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv891_1, lv1131, lv1132, lv889_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1133: R.Tensor((1280,), dtype="float32") = model_params[218]
            lv1134: R.Tensor((1280,), dtype="float32") = model_params[217]
            lv1289 = R.call_tir(cls.layer_norm3, (lv892_1, lv1133, lv1134), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1135_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1080]
            lv1291 = R.call_tir(cls.matmul27, (lv1289, lv1135_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1136: R.Tensor((1280, 1280), dtype="float32") = model_params[1081]
            lv1293 = R.call_tir(cls.matmul27, (lv1289, lv1136), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1137: R.Tensor((1280, 1280), dtype="float32") = model_params[1082]
            lv1295 = R.call_tir(cls.matmul27, (lv1289, lv1137), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv893_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1291,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv894_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1293,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv895_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1295,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv896_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv893_1, lv894_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1307 = R.call_tir(cls.softmax5, (lv896_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1308 = R.call_tir(cls.matmul29, (lv1307, lv895_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv897_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1308,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1138: R.Tensor((1280, 1280), dtype="float32") = model_params[1083]
            lv1139: R.Tensor((1280,), dtype="float32") = model_params[213]
            lv898_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv897_1, lv1138, lv1139, lv892_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1140_1: R.Tensor((1280,), dtype="float32") = model_params[220]
            lv1141: R.Tensor((1280,), dtype="float32") = model_params[219]
            lv1316 = R.call_tir(cls.layer_norm3, (lv898_1, lv1140_1, lv1141), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1142: R.Tensor((1280, 1280), dtype="float32") = model_params[1084]
            lv1318 = R.call_tir(cls.matmul27, (lv1316, lv1142), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1143: R.Tensor((2048, 1280), dtype="float32") = model_params[1085]
            lv1320 = R.call_tir(cls.matmul30, (inp_2, lv1143), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1144: R.Tensor((2048, 1280), dtype="float32") = model_params[1086]
            lv1322 = R.call_tir(cls.matmul30, (inp_2, lv1144), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv899_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1318,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv900_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1320,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv901_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv1322,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv902_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv899_1, lv900_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1334 = R.call_tir(cls.softmax6, (lv902_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1335 = R.call_tir(cls.matmul32, (lv1334, lv901_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv903_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1335,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1145: R.Tensor((1280, 1280), dtype="float32") = model_params[1087]
            lv1146: R.Tensor((1280,), dtype="float32") = model_params[214]
            lv904_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv903_1, lv1145, lv1146, lv898_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1147: R.Tensor((1280,), dtype="float32") = model_params[222]
            lv1148: R.Tensor((1280,), dtype="float32") = model_params[221]
            lv1343 = R.call_tir(cls.layer_norm3, (lv904_1, lv1147, lv1148), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1149_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1088]
            lv1150: R.Tensor((10240,), dtype="float32") = model_params[215]
            lv905_1 = R.call_tir(cls.fused_matmul33_add45, (lv1343, lv1149_1, lv1150), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv906_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv905_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1151: R.Tensor((5120, 1280), dtype="float32") = model_params[1089]
            lv1152: R.Tensor((1280,), dtype="float32") = model_params[216]
            lv907_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv906_1, lv1151, lv1152, lv904_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1153: R.Tensor((1280,), dtype="float32") = model_params[228]
            lv1154: R.Tensor((1280,), dtype="float32") = model_params[227]
            lv1356 = R.call_tir(cls.layer_norm3, (lv907_1, lv1153, lv1154), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1155_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1090]
            lv1358 = R.call_tir(cls.matmul27, (lv1356, lv1155_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1156: R.Tensor((1280, 1280), dtype="float32") = model_params[1091]
            lv1360 = R.call_tir(cls.matmul27, (lv1356, lv1156), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1157_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1092]
            lv1362 = R.call_tir(cls.matmul27, (lv1356, lv1157_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv908_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1358,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv909_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1360,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv910_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv1362,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv911_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv908_1, lv909_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1374 = R.call_tir(cls.softmax5, (lv911_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1375 = R.call_tir(cls.matmul29, (lv1374, lv910_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv912_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1375,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1158: R.Tensor((1280, 1280), dtype="float32") = model_params[1093]
            lv1159_1: R.Tensor((1280,), dtype="float32") = model_params[223]
            lv913_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv912_1, lv1158, lv1159_1, lv907_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1160: R.Tensor((1280,), dtype="float32") = model_params[230]
            lv1161_1: R.Tensor((1280,), dtype="float32") = model_params[229]
            lv1383 = R.call_tir(cls.layer_norm3, (lv913_1, lv1160, lv1161_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1162: R.Tensor((1280, 1280), dtype="float32") = model_params[1094]
            lv1385 = R.call_tir(cls.matmul27, (lv1383, lv1162), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1163: R.Tensor((2048, 1280), dtype="float32") = model_params[1095]
            lv1387 = R.call_tir(cls.matmul30, (inp_2, lv1163), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1164: R.Tensor((2048, 1280), dtype="float32") = model_params[1096]
            lv1389 = R.call_tir(cls.matmul30, (inp_2, lv1164), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv914_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1385,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv915_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1387,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv916_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1389,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv917_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv914_1, lv915_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1401 = R.call_tir(cls.softmax6, (lv917_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1402 = R.call_tir(cls.matmul32, (lv1401, lv916_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv918_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1402,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1165: R.Tensor((1280, 1280), dtype="float32") = model_params[1097]
            lv1166: R.Tensor((1280,), dtype="float32") = model_params[224]
            lv919_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv918_1, lv1165, lv1166, lv913_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1167: R.Tensor((1280,), dtype="float32") = model_params[232]
            lv1168: R.Tensor((1280,), dtype="float32") = model_params[231]
            lv1410 = R.call_tir(cls.layer_norm3, (lv919_1, lv1167, lv1168), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1169: R.Tensor((1280, 10240), dtype="float32") = model_params[1098]
            lv1170: R.Tensor((10240,), dtype="float32") = model_params[225]
            lv920_1 = R.call_tir(cls.fused_matmul33_add45, (lv1410, lv1169, lv1170), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv921_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv920_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1171: R.Tensor((5120, 1280), dtype="float32") = model_params[1099]
            lv1172: R.Tensor((1280,), dtype="float32") = model_params[226]
            lv922_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv921_1, lv1171, lv1172, lv919_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1173_1: R.Tensor((1280,), dtype="float32") = model_params[238]
            lv1174_1: R.Tensor((1280,), dtype="float32") = model_params[237]
            lv1423 = R.call_tir(cls.layer_norm3, (lv922_1, lv1173_1, lv1174_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1175: R.Tensor((1280, 1280), dtype="float32") = model_params[1100]
            lv1425 = R.call_tir(cls.matmul27, (lv1423, lv1175), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1176: R.Tensor((1280, 1280), dtype="float32") = model_params[1101]
            lv1427 = R.call_tir(cls.matmul27, (lv1423, lv1176), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1177: R.Tensor((1280, 1280), dtype="float32") = model_params[1102]
            lv1429 = R.call_tir(cls.matmul27, (lv1423, lv1177), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv923_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv1425,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv924_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1427,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv925_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv1429,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv926_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv923_2, lv924_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1441 = R.call_tir(cls.softmax5, (lv926_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1442 = R.call_tir(cls.matmul29, (lv1441, lv925_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv927_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv1442,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1178: R.Tensor((1280, 1280), dtype="float32") = model_params[1103]
            lv1179: R.Tensor((1280,), dtype="float32") = model_params[233]
            lv928_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv927_2, lv1178, lv1179, lv922_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1180: R.Tensor((1280,), dtype="float32") = model_params[240]
            lv1181: R.Tensor((1280,), dtype="float32") = model_params[239]
            lv1450 = R.call_tir(cls.layer_norm3, (lv928_1, lv1180, lv1181), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1182_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1104]
            lv1452 = R.call_tir(cls.matmul27, (lv1450, lv1182_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1183: R.Tensor((2048, 1280), dtype="float32") = model_params[1105]
            lv1454 = R.call_tir(cls.matmul30, (inp_2, lv1183), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1184_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1106]
            lv1456 = R.call_tir(cls.matmul30, (inp_2, lv1184_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv929_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv1452,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv930_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1454,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv931_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1456,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv932_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv929_2, lv930_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1468 = R.call_tir(cls.softmax6, (lv932_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1469 = R.call_tir(cls.matmul32, (lv1468, lv931_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv933_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1469,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1185: R.Tensor((1280, 1280), dtype="float32") = model_params[1107]
            lv1186_1: R.Tensor((1280,), dtype="float32") = model_params[234]
            lv934_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv933_1, lv1185, lv1186_1, lv928_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1187: R.Tensor((1280,), dtype="float32") = model_params[242]
            lv1188_1: R.Tensor((1280,), dtype="float32") = model_params[241]
            lv1477 = R.call_tir(cls.layer_norm3, (lv934_1, lv1187, lv1188_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1189: R.Tensor((1280, 10240), dtype="float32") = model_params[1108]
            lv1190: R.Tensor((10240,), dtype="float32") = model_params[235]
            lv935_1 = R.call_tir(cls.fused_matmul33_add45, (lv1477, lv1189, lv1190), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv936_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv935_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1191: R.Tensor((5120, 1280), dtype="float32") = model_params[1109]
            lv1192: R.Tensor((1280,), dtype="float32") = model_params[236]
            lv937_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv936_1, lv1191, lv1192, lv934_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1193: R.Tensor((1280,), dtype="float32") = model_params[248]
            lv1194: R.Tensor((1280,), dtype="float32") = model_params[247]
            lv1490 = R.call_tir(cls.layer_norm3, (lv937_1, lv1193, lv1194), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1195: R.Tensor((1280, 1280), dtype="float32") = model_params[1110]
            lv1492 = R.call_tir(cls.matmul27, (lv1490, lv1195), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1196: R.Tensor((1280, 1280), dtype="float32") = model_params[1111]
            lv1494 = R.call_tir(cls.matmul27, (lv1490, lv1196), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1197: R.Tensor((1280, 1280), dtype="float32") = model_params[1112]
            lv1496 = R.call_tir(cls.matmul27, (lv1490, lv1197), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv938_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1492,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv939_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1494,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv940_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1496,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv941_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv938_1, lv939_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1508 = R.call_tir(cls.softmax5, (lv941_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1509 = R.call_tir(cls.matmul29, (lv1508, lv940_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv942_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv1509,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1198: R.Tensor((1280, 1280), dtype="float32") = model_params[1113]
            lv1199: R.Tensor((1280,), dtype="float32") = model_params[243]
            lv943_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv942_2, lv1198, lv1199, lv937_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1200_1: R.Tensor((1280,), dtype="float32") = model_params[250]
            lv1201_1: R.Tensor((1280,), dtype="float32") = model_params[249]
            lv1517 = R.call_tir(cls.layer_norm3, (lv943_1, lv1200_1, lv1201_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1202: R.Tensor((1280, 1280), dtype="float32") = model_params[1114]
            lv1519 = R.call_tir(cls.matmul27, (lv1517, lv1202), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1203: R.Tensor((2048, 1280), dtype="float32") = model_params[1115]
            lv1521 = R.call_tir(cls.matmul30, (inp_2, lv1203), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1204: R.Tensor((2048, 1280), dtype="float32") = model_params[1116]
            lv1523 = R.call_tir(cls.matmul30, (inp_2, lv1204), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv944_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1519,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv945_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1521,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv946_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1523,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv947_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv944_1, lv945_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1535 = R.call_tir(cls.softmax6, (lv947_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1536 = R.call_tir(cls.matmul32, (lv1535, lv946_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv948_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1536,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1205: R.Tensor((1280, 1280), dtype="float32") = model_params[1117]
            lv1206: R.Tensor((1280,), dtype="float32") = model_params[244]
            lv949_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv948_1, lv1205, lv1206, lv943_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1207: R.Tensor((1280,), dtype="float32") = model_params[252]
            lv1208: R.Tensor((1280,), dtype="float32") = model_params[251]
            lv1544 = R.call_tir(cls.layer_norm3, (lv949_1, lv1207, lv1208), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1209_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1118]
            lv1210: R.Tensor((10240,), dtype="float32") = model_params[245]
            lv950_2 = R.call_tir(cls.fused_matmul33_add45, (lv1544, lv1209_1, lv1210), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv951_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv950_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1211: R.Tensor((5120, 1280), dtype="float32") = model_params[1119]
            lv1212: R.Tensor((1280,), dtype="float32") = model_params[246]
            lv952_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv951_1, lv1211, lv1212, lv949_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1213: R.Tensor((1280,), dtype="float32") = model_params[258]
            lv1214: R.Tensor((1280,), dtype="float32") = model_params[257]
            lv1557 = R.call_tir(cls.layer_norm3, (lv952_2, lv1213, lv1214), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1215: R.Tensor((1280, 1280), dtype="float32") = model_params[1120]
            lv1559 = R.call_tir(cls.matmul27, (lv1557, lv1215), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1216: R.Tensor((1280, 1280), dtype="float32") = model_params[1121]
            lv1561 = R.call_tir(cls.matmul27, (lv1557, lv1216), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1217: R.Tensor((1280, 1280), dtype="float32") = model_params[1122]
            lv1563 = R.call_tir(cls.matmul27, (lv1557, lv1217), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv953_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1559,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv954_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1561,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv955_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1563,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv956_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv953_1, lv954_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1575 = R.call_tir(cls.softmax5, (lv956_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1576 = R.call_tir(cls.matmul29, (lv1575, lv955_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv957_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1576,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1218: R.Tensor((1280, 1280), dtype="float32") = model_params[1123]
            lv1219: R.Tensor((1280,), dtype="float32") = model_params[253]
            lv958_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv957_1, lv1218, lv1219, lv952_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1220: R.Tensor((1280,), dtype="float32") = model_params[260]
            lv1221: R.Tensor((1280,), dtype="float32") = model_params[259]
            lv1584 = R.call_tir(cls.layer_norm3, (lv958_1, lv1220, lv1221), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1222_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1124]
            lv1586 = R.call_tir(cls.matmul27, (lv1584, lv1222_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1223: R.Tensor((2048, 1280), dtype="float32") = model_params[1125]
            lv1588 = R.call_tir(cls.matmul30, (inp_2, lv1223), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1224_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1126]
            lv1590 = R.call_tir(cls.matmul30, (inp_2, lv1224_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv959_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1586,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv960_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1588,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv961_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1590,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv962_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv959_1, lv960_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1602 = R.call_tir(cls.softmax6, (lv962_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1603 = R.call_tir(cls.matmul32, (lv1602, lv961_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv963_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1603,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1225: R.Tensor((1280, 1280), dtype="float32") = model_params[1127]
            lv1226_1: R.Tensor((1280,), dtype="float32") = model_params[254]
            lv964_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv963_1, lv1225, lv1226_1, lv958_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1227: R.Tensor((1280,), dtype="float32") = model_params[262]
            lv1228_1: R.Tensor((1280,), dtype="float32") = model_params[261]
            lv1611 = R.call_tir(cls.layer_norm3, (lv964_1, lv1227, lv1228_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1229: R.Tensor((1280, 10240), dtype="float32") = model_params[1128]
            lv1230: R.Tensor((10240,), dtype="float32") = model_params[255]
            lv965_1 = R.call_tir(cls.fused_matmul33_add45, (lv1611, lv1229, lv1230), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv966_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv965_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1231: R.Tensor((5120, 1280), dtype="float32") = model_params[1129]
            lv1232: R.Tensor((1280,), dtype="float32") = model_params[256]
            lv967_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv966_1, lv1231, lv1232, lv964_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1233: R.Tensor((1280,), dtype="float32") = model_params[268]
            lv1234: R.Tensor((1280,), dtype="float32") = model_params[267]
            lv1624 = R.call_tir(cls.layer_norm3, (lv967_1, lv1233, lv1234), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1235: R.Tensor((1280, 1280), dtype="float32") = model_params[1130]
            lv1626 = R.call_tir(cls.matmul27, (lv1624, lv1235), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1236: R.Tensor((1280, 1280), dtype="float32") = model_params[1131]
            lv1628 = R.call_tir(cls.matmul27, (lv1624, lv1236), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1237: R.Tensor((1280, 1280), dtype="float32") = model_params[1132]
            lv1630 = R.call_tir(cls.matmul27, (lv1624, lv1237), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv968_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv1626,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv969_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1628,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv970_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1630,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv971_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv968_2, lv969_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1642 = R.call_tir(cls.softmax5, (lv971_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1643 = R.call_tir(cls.matmul29, (lv1642, lv970_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv972_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1643,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1238: R.Tensor((1280, 1280), dtype="float32") = model_params[1133]
            lv1239: R.Tensor((1280,), dtype="float32") = model_params[263]
            lv973_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv972_1, lv1238, lv1239, lv967_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1240_1: R.Tensor((1280,), dtype="float32") = model_params[270]
            lv1241_1: R.Tensor((1280,), dtype="float32") = model_params[269]
            lv1651 = R.call_tir(cls.layer_norm3, (lv973_1, lv1240_1, lv1241_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1242: R.Tensor((1280, 1280), dtype="float32") = model_params[1134]
            lv1653 = R.call_tir(cls.matmul27, (lv1651, lv1242), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1243: R.Tensor((2048, 1280), dtype="float32") = model_params[1135]
            lv1655 = R.call_tir(cls.matmul30, (inp_2, lv1243), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1244: R.Tensor((2048, 1280), dtype="float32") = model_params[1136]
            lv1657 = R.call_tir(cls.matmul30, (inp_2, lv1244), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv974_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1653,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv975_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1655,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv976_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1657,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv977_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv974_1, lv975_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1669 = R.call_tir(cls.softmax6, (lv977_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1670 = R.call_tir(cls.matmul32, (lv1669, lv976_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv978_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1670,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1245: R.Tensor((1280, 1280), dtype="float32") = model_params[1137]
            lv1246: R.Tensor((1280,), dtype="float32") = model_params[264]
            lv979_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv978_1, lv1245, lv1246, lv973_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1247: R.Tensor((1280,), dtype="float32") = model_params[272]
            lv1248: R.Tensor((1280,), dtype="float32") = model_params[271]
            lv1678 = R.call_tir(cls.layer_norm3, (lv979_1, lv1247, lv1248), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1249_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1138]
            lv1250: R.Tensor((10240,), dtype="float32") = model_params[265]
            lv980_1 = R.call_tir(cls.fused_matmul33_add45, (lv1678, lv1249_1, lv1250), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv981_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv980_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1251_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1139]
            lv1252: R.Tensor((1280,), dtype="float32") = model_params[266]
            lv982_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv981_1, lv1251_1, lv1252, lv979_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1253_1: R.Tensor((1280,), dtype="float32") = model_params[278]
            lv1254: R.Tensor((1280,), dtype="float32") = model_params[277]
            lv1691 = R.call_tir(cls.layer_norm3, (lv982_1, lv1253_1, lv1254), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1255_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1140]
            lv1693 = R.call_tir(cls.matmul27, (lv1691, lv1255_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1256: R.Tensor((1280, 1280), dtype="float32") = model_params[1141]
            lv1695 = R.call_tir(cls.matmul27, (lv1691, lv1256), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1257: R.Tensor((1280, 1280), dtype="float32") = model_params[1142]
            lv1697 = R.call_tir(cls.matmul27, (lv1691, lv1257), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv983_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1693,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv984_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1695,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv985_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1697,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv986_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv983_1, lv984_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1709 = R.call_tir(cls.softmax5, (lv986_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1710 = R.call_tir(cls.matmul29, (lv1709, lv985_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv987_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1710,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1258: R.Tensor((1280, 1280), dtype="float32") = model_params[1143]
            lv1259: R.Tensor((1280,), dtype="float32") = model_params[273]
            lv988_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv987_1, lv1258, lv1259, lv982_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1260: R.Tensor((1280,), dtype="float32") = model_params[280]
            lv1261: R.Tensor((1280,), dtype="float32") = model_params[279]
            lv1718 = R.call_tir(cls.layer_norm3, (lv988_1, lv1260, lv1261), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1262: R.Tensor((1280, 1280), dtype="float32") = model_params[1144]
            lv1720 = R.call_tir(cls.matmul27, (lv1718, lv1262), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1263: R.Tensor((2048, 1280), dtype="float32") = model_params[1145]
            lv1722 = R.call_tir(cls.matmul30, (inp_2, lv1263), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1264: R.Tensor((2048, 1280), dtype="float32") = model_params[1146]
            lv1724 = R.call_tir(cls.matmul30, (inp_2, lv1264), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv989_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1720,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv990_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1722,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv991_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1724,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv992_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv989_1, lv990_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1736 = R.call_tir(cls.softmax6, (lv992_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1737 = R.call_tir(cls.matmul32, (lv1736, lv991_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv993_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1737,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1265: R.Tensor((1280, 1280), dtype="float32") = model_params[1147]
            lv1266: R.Tensor((1280,), dtype="float32") = model_params[274]
            lv994_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv993_1, lv1265, lv1266, lv988_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1267_1: R.Tensor((1280,), dtype="float32") = model_params[282]
            lv1268_1: R.Tensor((1280,), dtype="float32") = model_params[281]
            lv1745 = R.call_tir(cls.layer_norm3, (lv994_2, lv1267_1, lv1268_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1269: R.Tensor((1280, 10240), dtype="float32") = model_params[1148]
            lv1270: R.Tensor((10240,), dtype="float32") = model_params[275]
            lv995_1 = R.call_tir(cls.fused_matmul33_add45, (lv1745, lv1269, lv1270), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv996_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv995_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1271: R.Tensor((5120, 1280), dtype="float32") = model_params[1149]
            lv1272: R.Tensor((1280,), dtype="float32") = model_params[276]
            lv997_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv996_2, lv1271, lv1272, lv994_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1273: R.Tensor((1280,), dtype="float32") = model_params[288]
            lv1274: R.Tensor((1280,), dtype="float32") = model_params[287]
            lv1758 = R.call_tir(cls.layer_norm3, (lv997_1, lv1273, lv1274), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1275: R.Tensor((1280, 1280), dtype="float32") = model_params[1150]
            lv1760 = R.call_tir(cls.matmul27, (lv1758, lv1275), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1276_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1151]
            lv1762 = R.call_tir(cls.matmul27, (lv1758, lv1276_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1277: R.Tensor((1280, 1280), dtype="float32") = model_params[1152]
            lv1764 = R.call_tir(cls.matmul27, (lv1758, lv1277), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv998_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1760,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv999_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1762,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1000_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1764,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1001_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv998_1, lv999_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1776 = R.call_tir(cls.softmax5, (lv1001_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1777 = R.call_tir(cls.matmul29, (lv1776, lv1000_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1002_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1777,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1278: R.Tensor((1280, 1280), dtype="float32") = model_params[1153]
            lv1279: R.Tensor((1280,), dtype="float32") = model_params[283]
            lv1003_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1002_1, lv1278, lv1279, lv997_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1280: R.Tensor((1280,), dtype="float32") = model_params[290]
            lv1281: R.Tensor((1280,), dtype="float32") = model_params[289]
            lv1785 = R.call_tir(cls.layer_norm3, (lv1003_1, lv1280, lv1281), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1282: R.Tensor((1280, 1280), dtype="float32") = model_params[1154]
            lv1787 = R.call_tir(cls.matmul27, (lv1785, lv1282), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1283: R.Tensor((2048, 1280), dtype="float32") = model_params[1155]
            lv1789 = R.call_tir(cls.matmul30, (inp_2, lv1283), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1284: R.Tensor((2048, 1280), dtype="float32") = model_params[1156]
            lv1791 = R.call_tir(cls.matmul30, (inp_2, lv1284), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1004_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1787,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1005_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1789,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1006_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1791,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1007_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1004_1, lv1005_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1803 = R.call_tir(cls.softmax6, (lv1007_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1804 = R.call_tir(cls.matmul32, (lv1803, lv1006_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1008_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv1804,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1285: R.Tensor((1280, 1280), dtype="float32") = model_params[1157]
            lv1286: R.Tensor((1280,), dtype="float32") = model_params[284]
            lv1009_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1008_2, lv1285, lv1286, lv1003_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1287: R.Tensor((1280,), dtype="float32") = model_params[292]
            lv1288: R.Tensor((1280,), dtype="float32") = model_params[291]
            lv1812 = R.call_tir(cls.layer_norm3, (lv1009_2, lv1287, lv1288), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1289_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1158]
            lv1290: R.Tensor((10240,), dtype="float32") = model_params[285]
            lv1010_1 = R.call_tir(cls.fused_matmul33_add45, (lv1812, lv1289_1, lv1290), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1011_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1010_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1291_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1159]
            lv1292: R.Tensor((1280,), dtype="float32") = model_params[286]
            lv1012_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1011_1, lv1291_1, lv1292, lv1009_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1293_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1160]
            lv1294: R.Tensor((1280,), dtype="float32") = model_params[192]
            lv1013_1 = R.call_tir(cls.fused_matmul27_add43, (lv1012_1, lv1293_1, lv1294), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1014_1 = R.call_tir(cls.fused_reshape49_transpose42_add42, (lv1013_1, lv860_2), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1295_1: R.Tensor((1280,), dtype="float32") = model_params[415]
            lv1296: R.Tensor((1280,), dtype="float32") = model_params[414]
            lv1015_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv1014_1, lv1295_1, lv1296), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1836 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1297: R.Tensor((1280, 1280), dtype="float32") = model_params[1162]
            lv1298: R.Tensor((1280,), dtype="float32") = model_params[418]
            lv1016_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv1836, lv1297, lv1298), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1841 = R.call_tir(cls.reshape44, (lv1016_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1299: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[412]
            lv1300: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1161]
            lv1017_2 = R.call_tir(cls.fused_conv2d21_add40_add41, (lv1015_1, lv1299, lv1300, lv1841), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1301: R.Tensor((1280,), dtype="float32") = model_params[417]
            lv1302: R.Tensor((1280,), dtype="float32") = model_params[416]
            lv1018_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv1017_2, lv1301, lv1302), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1303: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[413]
            lv1304: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1163]
            lv1019_2 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv1018_1, lv1303, lv1304, lv1014_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1305: R.Tensor((1280,), dtype="float32") = model_params[309]
            lv1306: R.Tensor((1280,), dtype="float32") = model_params[308]
            lv1850 = R.call_tir(cls.group_norm13, (lv1019_2, lv1305, lv1306), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1020_1 = R.call_tir(cls.fused_transpose34_reshape45, (lv1850,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1307_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1164]
            lv1308_1: R.Tensor((1280,), dtype="float32") = model_params[310]
            lv1021_2 = R.call_tir(cls.fused_matmul27_add43, (lv1020_1, lv1307_1, lv1308_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1309: R.Tensor((1280,), dtype="float32") = model_params[317]
            lv1310: R.Tensor((1280,), dtype="float32") = model_params[316]
            lv1856 = R.call_tir(cls.layer_norm3, (lv1021_2, lv1309, lv1310), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1311: R.Tensor((1280, 1280), dtype="float32") = model_params[1165]
            lv1858 = R.call_tir(cls.matmul27, (lv1856, lv1311), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1312: R.Tensor((1280, 1280), dtype="float32") = model_params[1166]
            lv1860 = R.call_tir(cls.matmul27, (lv1856, lv1312), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1313: R.Tensor((1280, 1280), dtype="float32") = model_params[1167]
            lv1862 = R.call_tir(cls.matmul27, (lv1856, lv1313), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1022_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1858,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1023_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1860,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1024_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1862,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1025_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1022_1, lv1023_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1874 = R.call_tir(cls.softmax5, (lv1025_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1875 = R.call_tir(cls.matmul29, (lv1874, lv1024_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1026_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1875,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1314: R.Tensor((1280, 1280), dtype="float32") = model_params[1168]
            lv1315: R.Tensor((1280,), dtype="float32") = model_params[312]
            lv1027_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1026_1, lv1314, lv1315, lv1021_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1316_1: R.Tensor((1280,), dtype="float32") = model_params[319]
            lv1317: R.Tensor((1280,), dtype="float32") = model_params[318]
            lv1883 = R.call_tir(cls.layer_norm3, (lv1027_1, lv1316_1, lv1317), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1318_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1169]
            lv1885 = R.call_tir(cls.matmul27, (lv1883, lv1318_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1319: R.Tensor((2048, 1280), dtype="float32") = model_params[1170]
            lv1887 = R.call_tir(cls.matmul30, (inp_2, lv1319), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1320_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1171]
            lv1889 = R.call_tir(cls.matmul30, (inp_2, lv1320_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1028_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1885,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1029_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1887,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1030_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1889,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1031_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1028_1, lv1029_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1901 = R.call_tir(cls.softmax6, (lv1031_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1902 = R.call_tir(cls.matmul32, (lv1901, lv1030_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1032_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1902,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1321: R.Tensor((1280, 1280), dtype="float32") = model_params[1172]
            lv1322_1: R.Tensor((1280,), dtype="float32") = model_params[313]
            lv1033_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1032_1, lv1321, lv1322_1, lv1027_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1323: R.Tensor((1280,), dtype="float32") = model_params[321]
            lv1324: R.Tensor((1280,), dtype="float32") = model_params[320]
            lv1910 = R.call_tir(cls.layer_norm3, (lv1033_1, lv1323, lv1324), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1325: R.Tensor((1280, 10240), dtype="float32") = model_params[1173]
            lv1326: R.Tensor((10240,), dtype="float32") = model_params[314]
            lv1034_1 = R.call_tir(cls.fused_matmul33_add45, (lv1910, lv1325, lv1326), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1035_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1034_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1327: R.Tensor((5120, 1280), dtype="float32") = model_params[1174]
            lv1328: R.Tensor((1280,), dtype="float32") = model_params[315]
            lv1036_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1035_2, lv1327, lv1328, lv1033_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1329: R.Tensor((1280,), dtype="float32") = model_params[327]
            lv1330: R.Tensor((1280,), dtype="float32") = model_params[326]
            lv1923 = R.call_tir(cls.layer_norm3, (lv1036_2, lv1329, lv1330), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1331: R.Tensor((1280, 1280), dtype="float32") = model_params[1175]
            lv1925 = R.call_tir(cls.matmul27, (lv1923, lv1331), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1332: R.Tensor((1280, 1280), dtype="float32") = model_params[1176]
            lv1927 = R.call_tir(cls.matmul27, (lv1923, lv1332), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1333: R.Tensor((1280, 1280), dtype="float32") = model_params[1177]
            lv1929 = R.call_tir(cls.matmul27, (lv1923, lv1333), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1037_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1925,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1038_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1927,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1039_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1929,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1040_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1037_1, lv1038_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1941 = R.call_tir(cls.softmax5, (lv1040_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv1942 = R.call_tir(cls.matmul29, (lv1941, lv1039_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1041_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1942,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1334_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1178]
            lv1335_1: R.Tensor((1280,), dtype="float32") = model_params[322]
            lv1042_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1041_1, lv1334_1, lv1335_1, lv1036_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1336: R.Tensor((1280,), dtype="float32") = model_params[329]
            lv1337: R.Tensor((1280,), dtype="float32") = model_params[328]
            lv1950 = R.call_tir(cls.layer_norm3, (lv1042_1, lv1336, lv1337), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1338: R.Tensor((1280, 1280), dtype="float32") = model_params[1179]
            lv1952 = R.call_tir(cls.matmul27, (lv1950, lv1338), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1339: R.Tensor((2048, 1280), dtype="float32") = model_params[1180]
            lv1954 = R.call_tir(cls.matmul30, (inp_2, lv1339), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1340: R.Tensor((2048, 1280), dtype="float32") = model_params[1181]
            lv1956 = R.call_tir(cls.matmul30, (inp_2, lv1340), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1043_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1952,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1044_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv1954,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1045_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv1956,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1046_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1043_1, lv1044_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1968 = R.call_tir(cls.softmax6, (lv1046_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv1969 = R.call_tir(cls.matmul32, (lv1968, lv1045_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1047_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv1969,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1341: R.Tensor((1280, 1280), dtype="float32") = model_params[1182]
            lv1342: R.Tensor((1280,), dtype="float32") = model_params[323]
            lv1048_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1047_1, lv1341, lv1342, lv1042_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1343_1: R.Tensor((1280,), dtype="float32") = model_params[331]
            lv1344: R.Tensor((1280,), dtype="float32") = model_params[330]
            lv1977 = R.call_tir(cls.layer_norm3, (lv1048_1, lv1343_1, lv1344), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1345: R.Tensor((1280, 10240), dtype="float32") = model_params[1183]
            lv1346: R.Tensor((10240,), dtype="float32") = model_params[324]
            lv1049_1 = R.call_tir(cls.fused_matmul33_add45, (lv1977, lv1345, lv1346), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1050_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1049_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1347: R.Tensor((5120, 1280), dtype="float32") = model_params[1184]
            lv1348: R.Tensor((1280,), dtype="float32") = model_params[325]
            lv1051_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1050_1, lv1347, lv1348, lv1048_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1349: R.Tensor((1280,), dtype="float32") = model_params[337]
            lv1350: R.Tensor((1280,), dtype="float32") = model_params[336]
            lv1990 = R.call_tir(cls.layer_norm3, (lv1051_1, lv1349, lv1350), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1351: R.Tensor((1280, 1280), dtype="float32") = model_params[1185]
            lv1992 = R.call_tir(cls.matmul27, (lv1990, lv1351), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1352: R.Tensor((1280, 1280), dtype="float32") = model_params[1186]
            lv1994 = R.call_tir(cls.matmul27, (lv1990, lv1352), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1353: R.Tensor((1280, 1280), dtype="float32") = model_params[1187]
            lv1996 = R.call_tir(cls.matmul27, (lv1990, lv1353), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1052_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1992,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1053_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv1994,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1054_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv1996,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1055_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1052_1, lv1053_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2008 = R.call_tir(cls.softmax5, (lv1055_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2009 = R.call_tir(cls.matmul29, (lv2008, lv1054_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1056_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2009,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1354: R.Tensor((1280, 1280), dtype="float32") = model_params[1188]
            lv1355: R.Tensor((1280,), dtype="float32") = model_params[332]
            lv1057_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1056_1, lv1354, lv1355, lv1051_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1356_1: R.Tensor((1280,), dtype="float32") = model_params[339]
            lv1357: R.Tensor((1280,), dtype="float32") = model_params[338]
            lv2017 = R.call_tir(cls.layer_norm3, (lv1057_2, lv1356_1, lv1357), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1358_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1189]
            lv2019 = R.call_tir(cls.matmul27, (lv2017, lv1358_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1359: R.Tensor((2048, 1280), dtype="float32") = model_params[1190]
            lv2021 = R.call_tir(cls.matmul30, (inp_2, lv1359), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1360_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1191]
            lv2023 = R.call_tir(cls.matmul30, (inp_2, lv1360_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1058_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2019,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1059_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2021,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1060_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2023,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1061_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1058_1, lv1059_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2035 = R.call_tir(cls.softmax6, (lv1061_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2036 = R.call_tir(cls.matmul32, (lv2035, lv1060_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1062_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2036,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1361: R.Tensor((1280, 1280), dtype="float32") = model_params[1192]
            lv1362_1: R.Tensor((1280,), dtype="float32") = model_params[333]
            lv1063_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1062_1, lv1361, lv1362_1, lv1057_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1363: R.Tensor((1280,), dtype="float32") = model_params[341]
            lv1364: R.Tensor((1280,), dtype="float32") = model_params[340]
            lv2044 = R.call_tir(cls.layer_norm3, (lv1063_2, lv1363, lv1364), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1365: R.Tensor((1280, 10240), dtype="float32") = model_params[1193]
            lv1366: R.Tensor((10240,), dtype="float32") = model_params[334]
            lv1064_1 = R.call_tir(cls.fused_matmul33_add45, (lv2044, lv1365, lv1366), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1065_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1064_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1367: R.Tensor((5120, 1280), dtype="float32") = model_params[1194]
            lv1368: R.Tensor((1280,), dtype="float32") = model_params[335]
            lv1066_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1065_1, lv1367, lv1368, lv1063_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1369: R.Tensor((1280,), dtype="float32") = model_params[347]
            lv1370: R.Tensor((1280,), dtype="float32") = model_params[346]
            lv2057 = R.call_tir(cls.layer_norm3, (lv1066_1, lv1369, lv1370), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1371: R.Tensor((1280, 1280), dtype="float32") = model_params[1195]
            lv2059 = R.call_tir(cls.matmul27, (lv2057, lv1371), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1372: R.Tensor((1280, 1280), dtype="float32") = model_params[1196]
            lv2061 = R.call_tir(cls.matmul27, (lv2057, lv1372), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1373: R.Tensor((1280, 1280), dtype="float32") = model_params[1197]
            lv2063 = R.call_tir(cls.matmul27, (lv2057, lv1373), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1067_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2059,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1068_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1069_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1070_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1067_1, lv1068_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2075 = R.call_tir(cls.softmax5, (lv1070_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2076 = R.call_tir(cls.matmul29, (lv2075, lv1069_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1071_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1374_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1198]
            lv1375_1: R.Tensor((1280,), dtype="float32") = model_params[342]
            lv1072_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1071_1, lv1374_1, lv1375_1, lv1066_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1376: R.Tensor((1280,), dtype="float32") = model_params[349]
            lv1377: R.Tensor((1280,), dtype="float32") = model_params[348]
            lv2084 = R.call_tir(cls.layer_norm3, (lv1072_1, lv1376, lv1377), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1378: R.Tensor((1280, 1280), dtype="float32") = model_params[1199]
            lv2086 = R.call_tir(cls.matmul27, (lv2084, lv1378), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1379: R.Tensor((2048, 1280), dtype="float32") = model_params[1200]
            lv2088 = R.call_tir(cls.matmul30, (inp_2, lv1379), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1380: R.Tensor((2048, 1280), dtype="float32") = model_params[1201]
            lv2090 = R.call_tir(cls.matmul30, (inp_2, lv1380), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1073_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1074_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1075_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv2090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1076_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1073_1, lv1074_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2102 = R.call_tir(cls.softmax6, (lv1076_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2103 = R.call_tir(cls.matmul32, (lv2102, lv1075_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1077_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1381: R.Tensor((1280, 1280), dtype="float32") = model_params[1202]
            lv1382: R.Tensor((1280,), dtype="float32") = model_params[343]
            lv1078_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1077_1, lv1381, lv1382, lv1072_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1383_1: R.Tensor((1280,), dtype="float32") = model_params[351]
            lv1384: R.Tensor((1280,), dtype="float32") = model_params[350]
            lv2111 = R.call_tir(cls.layer_norm3, (lv1078_1, lv1383_1, lv1384), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1385_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1203]
            lv1386: R.Tensor((10240,), dtype="float32") = model_params[344]
            lv1079_1 = R.call_tir(cls.fused_matmul33_add45, (lv2111, lv1385_1, lv1386), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1080_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1079_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1387_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1204]
            lv1388: R.Tensor((1280,), dtype="float32") = model_params[345]
            lv1081_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1080_1, lv1387_1, lv1388, lv1078_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1389_1: R.Tensor((1280,), dtype="float32") = model_params[357]
            lv1390: R.Tensor((1280,), dtype="float32") = model_params[356]
            lv2124 = R.call_tir(cls.layer_norm3, (lv1081_1, lv1389_1, lv1390), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1391: R.Tensor((1280, 1280), dtype="float32") = model_params[1205]
            lv2126 = R.call_tir(cls.matmul27, (lv2124, lv1391), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1392: R.Tensor((1280, 1280), dtype="float32") = model_params[1206]
            lv2128 = R.call_tir(cls.matmul27, (lv2124, lv1392), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1393: R.Tensor((1280, 1280), dtype="float32") = model_params[1207]
            lv2130 = R.call_tir(cls.matmul27, (lv2124, lv1393), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1082_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2126,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1083_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2128,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1084_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2130,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1085_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1082_1, lv1083_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2142 = R.call_tir(cls.softmax5, (lv1085_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2143 = R.call_tir(cls.matmul29, (lv2142, lv1084_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1086_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv2143,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1394: R.Tensor((1280, 1280), dtype="float32") = model_params[1208]
            lv1395: R.Tensor((1280,), dtype="float32") = model_params[352]
            lv1087_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1086_2, lv1394, lv1395, lv1081_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1396: R.Tensor((1280,), dtype="float32") = model_params[359]
            lv1397: R.Tensor((1280,), dtype="float32") = model_params[358]
            lv2151 = R.call_tir(cls.layer_norm3, (lv1087_1, lv1396, lv1397), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1398: R.Tensor((1280, 1280), dtype="float32") = model_params[1209]
            lv2153 = R.call_tir(cls.matmul27, (lv2151, lv1398), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1399: R.Tensor((2048, 1280), dtype="float32") = model_params[1210]
            lv2155 = R.call_tir(cls.matmul30, (inp_2, lv1399), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1400: R.Tensor((2048, 1280), dtype="float32") = model_params[1211]
            lv2157 = R.call_tir(cls.matmul30, (inp_2, lv1400), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1088_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2153,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1089_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2155,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1090_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv2157,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1091_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1088_2, lv1089_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2169 = R.call_tir(cls.softmax6, (lv1091_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2170 = R.call_tir(cls.matmul32, (lv2169, lv1090_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1092_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2170,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1401_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1212]
            lv1402_1: R.Tensor((1280,), dtype="float32") = model_params[353]
            lv1093_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1092_1, lv1401_1, lv1402_1, lv1087_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1403: R.Tensor((1280,), dtype="float32") = model_params[361]
            lv1404: R.Tensor((1280,), dtype="float32") = model_params[360]
            lv2178 = R.call_tir(cls.layer_norm3, (lv1093_1, lv1403, lv1404), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1405: R.Tensor((1280, 10240), dtype="float32") = model_params[1213]
            lv1406: R.Tensor((10240,), dtype="float32") = model_params[354]
            lv1094_1 = R.call_tir(cls.fused_matmul33_add45, (lv2178, lv1405, lv1406), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1095_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1094_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1407: R.Tensor((5120, 1280), dtype="float32") = model_params[1214]
            lv1408: R.Tensor((1280,), dtype="float32") = model_params[355]
            lv1096_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1095_1, lv1407, lv1408, lv1093_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1409: R.Tensor((1280,), dtype="float32") = model_params[367]
            lv1410_1: R.Tensor((1280,), dtype="float32") = model_params[366]
            lv2191 = R.call_tir(cls.layer_norm3, (lv1096_1, lv1409, lv1410_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1411: R.Tensor((1280, 1280), dtype="float32") = model_params[1215]
            lv2193 = R.call_tir(cls.matmul27, (lv2191, lv1411), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1412: R.Tensor((1280, 1280), dtype="float32") = model_params[1216]
            lv2195 = R.call_tir(cls.matmul27, (lv2191, lv1412), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1413: R.Tensor((1280, 1280), dtype="float32") = model_params[1217]
            lv2197 = R.call_tir(cls.matmul27, (lv2191, lv1413), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1097_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2193,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1098_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2195,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1099_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2197,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1100_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1097_1, lv1098_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2209 = R.call_tir(cls.softmax5, (lv1100_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2210 = R.call_tir(cls.matmul29, (lv2209, lv1099_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1101_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2210,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1414: R.Tensor((1280, 1280), dtype="float32") = model_params[1218]
            lv1415: R.Tensor((1280,), dtype="float32") = model_params[362]
            lv1102_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1101_1, lv1414, lv1415, lv1096_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1416: R.Tensor((1280,), dtype="float32") = model_params[369]
            lv1417: R.Tensor((1280,), dtype="float32") = model_params[368]
            lv2218 = R.call_tir(cls.layer_norm3, (lv1102_2, lv1416, lv1417), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1418: R.Tensor((1280, 1280), dtype="float32") = model_params[1219]
            lv2220 = R.call_tir(cls.matmul27, (lv2218, lv1418), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1419: R.Tensor((2048, 1280), dtype="float32") = model_params[1220]
            lv2222 = R.call_tir(cls.matmul30, (inp_2, lv1419), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1420: R.Tensor((2048, 1280), dtype="float32") = model_params[1221]
            lv2224 = R.call_tir(cls.matmul30, (inp_2, lv1420), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1103_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2220,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1104_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2222,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1105_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2224,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1106_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1103_2, lv1104_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2236 = R.call_tir(cls.softmax6, (lv1106_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2237 = R.call_tir(cls.matmul32, (lv2236, lv1105_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1107_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2237,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1421: R.Tensor((1280, 1280), dtype="float32") = model_params[1222]
            lv1422: R.Tensor((1280,), dtype="float32") = model_params[363]
            lv1108_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1107_1, lv1421, lv1422, lv1102_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1423_1: R.Tensor((1280,), dtype="float32") = model_params[371]
            lv1424: R.Tensor((1280,), dtype="float32") = model_params[370]
            lv2245 = R.call_tir(cls.layer_norm3, (lv1108_1, lv1423_1, lv1424), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1425_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1223]
            lv1426: R.Tensor((10240,), dtype="float32") = model_params[364]
            lv1109_1 = R.call_tir(cls.fused_matmul33_add45, (lv2245, lv1425_1, lv1426), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1110_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1109_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1427_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1224]
            lv1428: R.Tensor((1280,), dtype="float32") = model_params[365]
            lv1111_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1110_1, lv1427_1, lv1428, lv1108_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1429_1: R.Tensor((1280,), dtype="float32") = model_params[377]
            lv1430: R.Tensor((1280,), dtype="float32") = model_params[376]
            lv2258 = R.call_tir(cls.layer_norm3, (lv1111_2, lv1429_1, lv1430), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1431: R.Tensor((1280, 1280), dtype="float32") = model_params[1225]
            lv2260 = R.call_tir(cls.matmul27, (lv2258, lv1431), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1432: R.Tensor((1280, 1280), dtype="float32") = model_params[1226]
            lv2262 = R.call_tir(cls.matmul27, (lv2258, lv1432), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1433: R.Tensor((1280, 1280), dtype="float32") = model_params[1227]
            lv2264 = R.call_tir(cls.matmul27, (lv2258, lv1433), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1112_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2260,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1113_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2262,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1114_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2264,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1115_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1112_1, lv1113_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2276 = R.call_tir(cls.softmax5, (lv1115_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2277 = R.call_tir(cls.matmul29, (lv2276, lv1114_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1116_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2277,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1434: R.Tensor((1280, 1280), dtype="float32") = model_params[1228]
            lv1435: R.Tensor((1280,), dtype="float32") = model_params[372]
            lv1117_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1116_1, lv1434, lv1435, lv1111_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1436: R.Tensor((1280,), dtype="float32") = model_params[379]
            lv1437: R.Tensor((1280,), dtype="float32") = model_params[378]
            lv2285 = R.call_tir(cls.layer_norm3, (lv1117_1, lv1436, lv1437), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1438: R.Tensor((1280, 1280), dtype="float32") = model_params[1229]
            lv2287 = R.call_tir(cls.matmul27, (lv2285, lv1438), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1439: R.Tensor((2048, 1280), dtype="float32") = model_params[1230]
            lv2289 = R.call_tir(cls.matmul30, (inp_2, lv1439), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1440: R.Tensor((2048, 1280), dtype="float32") = model_params[1231]
            lv2291 = R.call_tir(cls.matmul30, (inp_2, lv1440), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1118_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1119_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2289,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1120_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2291,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1121_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1118_1, lv1119_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2303 = R.call_tir(cls.softmax6, (lv1121_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2304 = R.call_tir(cls.matmul32, (lv2303, lv1120_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1122_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1441_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1232]
            lv1442_1: R.Tensor((1280,), dtype="float32") = model_params[373]
            lv1123_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1122_1, lv1441_1, lv1442_1, lv1117_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1443: R.Tensor((1280,), dtype="float32") = model_params[381]
            lv1444: R.Tensor((1280,), dtype="float32") = model_params[380]
            lv2312 = R.call_tir(cls.layer_norm3, (lv1123_1, lv1443, lv1444), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1445: R.Tensor((1280, 10240), dtype="float32") = model_params[1233]
            lv1446: R.Tensor((10240,), dtype="float32") = model_params[374]
            lv1124_1 = R.call_tir(cls.fused_matmul33_add45, (lv2312, lv1445, lv1446), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1125_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1124_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1447: R.Tensor((5120, 1280), dtype="float32") = model_params[1234]
            lv1448: R.Tensor((1280,), dtype="float32") = model_params[375]
            lv1126_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1125_1, lv1447, lv1448, lv1123_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1449: R.Tensor((1280,), dtype="float32") = model_params[387]
            lv1450_1: R.Tensor((1280,), dtype="float32") = model_params[386]
            lv2325 = R.call_tir(cls.layer_norm3, (lv1126_1, lv1449, lv1450_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1451: R.Tensor((1280, 1280), dtype="float32") = model_params[1235]
            lv2327 = R.call_tir(cls.matmul27, (lv2325, lv1451), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1452_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1236]
            lv2329 = R.call_tir(cls.matmul27, (lv2325, lv1452_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1453: R.Tensor((1280, 1280), dtype="float32") = model_params[1237]
            lv2331 = R.call_tir(cls.matmul27, (lv2325, lv1453), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1127_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2327,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1128_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2329,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1129_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2331,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1130_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1127_1, lv1128_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2343 = R.call_tir(cls.softmax5, (lv1130_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2344 = R.call_tir(cls.matmul29, (lv2343, lv1129_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1131_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2344,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1454_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1238]
            lv1455: R.Tensor((1280,), dtype="float32") = model_params[382]
            lv1132_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1131_1, lv1454_1, lv1455, lv1126_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1456_1: R.Tensor((1280,), dtype="float32") = model_params[389]
            lv1457: R.Tensor((1280,), dtype="float32") = model_params[388]
            lv2352 = R.call_tir(cls.layer_norm3, (lv1132_1, lv1456_1, lv1457), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1458: R.Tensor((1280, 1280), dtype="float32") = model_params[1239]
            lv2354 = R.call_tir(cls.matmul27, (lv2352, lv1458), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1459: R.Tensor((2048, 1280), dtype="float32") = model_params[1240]
            lv2356 = R.call_tir(cls.matmul30, (inp_2, lv1459), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1460: R.Tensor((2048, 1280), dtype="float32") = model_params[1241]
            lv2358 = R.call_tir(cls.matmul30, (inp_2, lv1460), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1133_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1134_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2356,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1135_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv2358,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1136_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1133_1, lv1134_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2370 = R.call_tir(cls.softmax6, (lv1136_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2371 = R.call_tir(cls.matmul32, (lv2370, lv1135_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1137_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1461: R.Tensor((1280, 1280), dtype="float32") = model_params[1242]
            lv1462: R.Tensor((1280,), dtype="float32") = model_params[383]
            lv1138_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1137_1, lv1461, lv1462, lv1132_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1463: R.Tensor((1280,), dtype="float32") = model_params[391]
            lv1464: R.Tensor((1280,), dtype="float32") = model_params[390]
            lv2379 = R.call_tir(cls.layer_norm3, (lv1138_1, lv1463, lv1464), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1465: R.Tensor((1280, 10240), dtype="float32") = model_params[1243]
            lv1466: R.Tensor((10240,), dtype="float32") = model_params[384]
            lv1139_1 = R.call_tir(cls.fused_matmul33_add45, (lv2379, lv1465, lv1466), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1140_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1139_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1467: R.Tensor((5120, 1280), dtype="float32") = model_params[1244]
            lv1468_1: R.Tensor((1280,), dtype="float32") = model_params[385]
            lv1141_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1140_2, lv1467, lv1468_1, lv1138_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1469_1: R.Tensor((1280,), dtype="float32") = model_params[397]
            lv1470: R.Tensor((1280,), dtype="float32") = model_params[396]
            lv2392 = R.call_tir(cls.layer_norm3, (lv1141_1, lv1469_1, lv1470), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1471: R.Tensor((1280, 1280), dtype="float32") = model_params[1245]
            lv2394 = R.call_tir(cls.matmul27, (lv2392, lv1471), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1472: R.Tensor((1280, 1280), dtype="float32") = model_params[1246]
            lv2396 = R.call_tir(cls.matmul27, (lv2392, lv1472), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1473: R.Tensor((1280, 1280), dtype="float32") = model_params[1247]
            lv2398 = R.call_tir(cls.matmul27, (lv2392, lv1473), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1142_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2394,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1143_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2396,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1144_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2398,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1145_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1142_1, lv1143_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2410 = R.call_tir(cls.softmax5, (lv1145_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2411 = R.call_tir(cls.matmul29, (lv2410, lv1144_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1146_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2411,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1474: R.Tensor((1280, 1280), dtype="float32") = model_params[1248]
            lv1475: R.Tensor((1280,), dtype="float32") = model_params[392]
            lv1147_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1146_1, lv1474, lv1475, lv1141_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1476: R.Tensor((1280,), dtype="float32") = model_params[399]
            lv1477_1: R.Tensor((1280,), dtype="float32") = model_params[398]
            lv2419 = R.call_tir(cls.layer_norm3, (lv1147_1, lv1476, lv1477_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1478: R.Tensor((1280, 1280), dtype="float32") = model_params[1249]
            lv2421 = R.call_tir(cls.matmul27, (lv2419, lv1478), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1479: R.Tensor((2048, 1280), dtype="float32") = model_params[1250]
            lv2423 = R.call_tir(cls.matmul30, (inp_2, lv1479), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1480: R.Tensor((2048, 1280), dtype="float32") = model_params[1251]
            lv2425 = R.call_tir(cls.matmul30, (inp_2, lv1480), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1148_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1149_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2423,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1150_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2425,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1151_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1148_1, lv1149_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2437 = R.call_tir(cls.softmax6, (lv1151_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2438 = R.call_tir(cls.matmul32, (lv2437, lv1150_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1152_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1481: R.Tensor((1280, 1280), dtype="float32") = model_params[1252]
            lv1482: R.Tensor((1280,), dtype="float32") = model_params[393]
            lv1153_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1152_1, lv1481, lv1482, lv1147_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1483: R.Tensor((1280,), dtype="float32") = model_params[401]
            lv1484: R.Tensor((1280,), dtype="float32") = model_params[400]
            lv2446 = R.call_tir(cls.layer_norm3, (lv1153_1, lv1483, lv1484), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1485: R.Tensor((1280, 10240), dtype="float32") = model_params[1253]
            lv1486: R.Tensor((10240,), dtype="float32") = model_params[394]
            lv1154_1 = R.call_tir(cls.fused_matmul33_add45, (lv2446, lv1485, lv1486), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1155_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1154_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1487: R.Tensor((5120, 1280), dtype="float32") = model_params[1254]
            lv1488: R.Tensor((1280,), dtype="float32") = model_params[395]
            lv1156_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1155_2, lv1487, lv1488, lv1153_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1489: R.Tensor((1280,), dtype="float32") = model_params[407]
            lv1490_1: R.Tensor((1280,), dtype="float32") = model_params[406]
            lv2459 = R.call_tir(cls.layer_norm3, (lv1156_1, lv1489, lv1490_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1491: R.Tensor((1280, 1280), dtype="float32") = model_params[1255]
            lv2461 = R.call_tir(cls.matmul27, (lv2459, lv1491), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1492_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1256]
            lv2463 = R.call_tir(cls.matmul27, (lv2459, lv1492_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1493: R.Tensor((1280, 1280), dtype="float32") = model_params[1257]
            lv2465 = R.call_tir(cls.matmul27, (lv2459, lv1493), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1157_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2461,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1158_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2463,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1159_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2465,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1160_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1157_2, lv1158_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2477 = R.call_tir(cls.softmax5, (lv1160_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2478 = R.call_tir(cls.matmul29, (lv2477, lv1159_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1161_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv2478,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1494_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1258]
            lv1495: R.Tensor((1280,), dtype="float32") = model_params[402]
            lv1162_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1161_2, lv1494_1, lv1495, lv1156_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1496_1: R.Tensor((1280,), dtype="float32") = model_params[409]
            lv1497: R.Tensor((1280,), dtype="float32") = model_params[408]
            lv2486 = R.call_tir(cls.layer_norm3, (lv1162_1, lv1496_1, lv1497), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1498: R.Tensor((1280, 1280), dtype="float32") = model_params[1259]
            lv2488 = R.call_tir(cls.matmul27, (lv2486, lv1498), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1499: R.Tensor((2048, 1280), dtype="float32") = model_params[1260]
            lv2490 = R.call_tir(cls.matmul30, (inp_2, lv1499), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1500: R.Tensor((2048, 1280), dtype="float32") = model_params[1261]
            lv2492 = R.call_tir(cls.matmul30, (inp_2, lv1500), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1163_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1164_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2490,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1165_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2492,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1166_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1163_1, lv1164_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2504 = R.call_tir(cls.softmax6, (lv1166_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2505 = R.call_tir(cls.matmul32, (lv2504, lv1165_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1167_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1501: R.Tensor((1280, 1280), dtype="float32") = model_params[1262]
            lv1502: R.Tensor((1280,), dtype="float32") = model_params[403]
            lv1168_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1167_1, lv1501, lv1502, lv1162_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1503: R.Tensor((1280,), dtype="float32") = model_params[411]
            lv1504: R.Tensor((1280,), dtype="float32") = model_params[410]
            lv2513 = R.call_tir(cls.layer_norm3, (lv1168_1, lv1503, lv1504), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1505: R.Tensor((1280, 10240), dtype="float32") = model_params[1263]
            lv1506: R.Tensor((10240,), dtype="float32") = model_params[404]
            lv1169_1 = R.call_tir(cls.fused_matmul33_add45, (lv2513, lv1505, lv1506), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1170_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1169_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1507: R.Tensor((5120, 1280), dtype="float32") = model_params[1264]
            lv1508_1: R.Tensor((1280,), dtype="float32") = model_params[405]
            lv1171_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1170_1, lv1507, lv1508_1, lv1168_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1509_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1265]
            lv1510: R.Tensor((1280,), dtype="float32") = model_params[311]
            lv1172_1 = R.call_tir(cls.fused_matmul27_add43, (lv1171_1, lv1509_1, lv1510), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1173_2 = R.call_tir(cls.fused_reshape49_transpose42_add42, (lv1172_1, lv1019_2), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1511: R.Tensor((1280,), dtype="float32") = model_params[422]
            lv1512: R.Tensor((1280,), dtype="float32") = model_params[421]
            lv1174_2 = R.call_tir(cls.fused_group_norm12_silu11, (lv1173_2, lv1511, lv1512), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv2537 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1513: R.Tensor((1280, 1280), dtype="float32") = model_params[1267]
            lv1514: R.Tensor((1280,), dtype="float32") = model_params[425]
            lv1175_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv2537, lv1513, lv1514), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2542 = R.call_tir(cls.reshape44, (lv1175_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1515: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[419]
            lv1516: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1266]
            lv1176_1 = R.call_tir(cls.fused_conv2d21_add40_add41, (lv1174_2, lv1515, lv1516, lv2542), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1517_1: R.Tensor((1280,), dtype="float32") = model_params[424]
            lv1518: R.Tensor((1280,), dtype="float32") = model_params[423]
            lv1177_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv1176_1, lv1517_1, lv1518), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1519_1: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[420]
            lv1520: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1268]
            lv1178_1 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv1177_1, lv1519_1, lv1520, lv1173_2), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv2551 = R.call_tir(cls.concatenate7, (lv1178_1, lv1014_1), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv1521_1: R.Tensor((2560,), dtype="float32") = model_params[744]
            lv1522: R.Tensor((2560,), dtype="float32") = model_params[743]
            lv1179_1 = R.call_tir(cls.fused_group_norm14_silu12, (lv2551, lv1521_1, lv1522), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv2557 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1523_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1270]
            lv1524: R.Tensor((1280,), dtype="float32") = model_params[747]
            lv1180_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv2557, lv1523_1, lv1524), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2562 = R.call_tir(cls.reshape44, (lv1180_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1525: R.Tensor((1280, 2560, 3, 3), dtype="float32") = model_params[740]
            lv1526: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1269]
            lv1181_1 = R.call_tir(cls.fused_conv2d23_add40_add41, (lv1179_1, lv1525, lv1526, lv2562), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1527: R.Tensor((1280,), dtype="float32") = model_params[746]
            lv1528: R.Tensor((1280,), dtype="float32") = model_params[745]
            lv1182_2 = R.call_tir(cls.fused_group_norm12_silu11, (lv1181_1, lv1527, lv1528), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1529: R.Tensor((1280, 2560, 1, 1), dtype="float32") = model_params[742]
            lv1530: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1272]
            lv1183_1 = R.call_tir(cls.fused_conv2d24_add40, (lv2551, lv1529, lv1530), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1531: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[741]
            lv1532: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1271]
            lv1184_2 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv1182_2, lv1531, lv1532, lv1183_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1533: R.Tensor((1280,), dtype="float32") = model_params[429]
            lv1534: R.Tensor((1280,), dtype="float32") = model_params[428]
            lv2574 = R.call_tir(cls.group_norm13, (lv1184_2, lv1533, lv1534), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1185_1 = R.call_tir(cls.fused_transpose34_reshape45, (lv2574,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1535_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1273]
            lv1536_1: R.Tensor((1280,), dtype="float32") = model_params[430]
            lv1186_2 = R.call_tir(cls.fused_matmul27_add43, (lv1185_1, lv1535_1, lv1536_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1537: R.Tensor((1280,), dtype="float32") = model_params[437]
            lv1538: R.Tensor((1280,), dtype="float32") = model_params[436]
            lv2580 = R.call_tir(cls.layer_norm3, (lv1186_2, lv1537, lv1538), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1539: R.Tensor((1280, 1280), dtype="float32") = model_params[1274]
            lv2582 = R.call_tir(cls.matmul27, (lv2580, lv1539), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1540: R.Tensor((1280, 1280), dtype="float32") = model_params[1275]
            lv2584 = R.call_tir(cls.matmul27, (lv2580, lv1540), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1541: R.Tensor((1280, 1280), dtype="float32") = model_params[1276]
            lv2586 = R.call_tir(cls.matmul27, (lv2580, lv1541), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1187_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2582,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1188_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2584,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1189_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2586,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1190_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1187_1, lv1188_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2598 = R.call_tir(cls.softmax5, (lv1190_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2599 = R.call_tir(cls.matmul29, (lv2598, lv1189_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1191_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2599,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1542: R.Tensor((1280, 1280), dtype="float32") = model_params[1277]
            lv1543: R.Tensor((1280,), dtype="float32") = model_params[432]
            lv1192_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1191_1, lv1542, lv1543, lv1186_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1544_1: R.Tensor((1280,), dtype="float32") = model_params[439]
            lv1545: R.Tensor((1280,), dtype="float32") = model_params[438]
            lv2607 = R.call_tir(cls.layer_norm3, (lv1192_1, lv1544_1, lv1545), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1546: R.Tensor((1280, 1280), dtype="float32") = model_params[1278]
            lv2609 = R.call_tir(cls.matmul27, (lv2607, lv1546), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1547: R.Tensor((2048, 1280), dtype="float32") = model_params[1279]
            lv2611 = R.call_tir(cls.matmul30, (inp_2, lv1547), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1548: R.Tensor((2048, 1280), dtype="float32") = model_params[1280]
            lv2613 = R.call_tir(cls.matmul30, (inp_2, lv1548), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1193_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2609,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1194_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2611,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1195_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2613,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1196_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1193_1, lv1194_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2625 = R.call_tir(cls.softmax6, (lv1196_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2626 = R.call_tir(cls.matmul32, (lv2625, lv1195_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1197_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2626,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1549: R.Tensor((1280, 1280), dtype="float32") = model_params[1281]
            lv1550: R.Tensor((1280,), dtype="float32") = model_params[433]
            lv1198_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1197_1, lv1549, lv1550, lv1192_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1551: R.Tensor((1280,), dtype="float32") = model_params[441]
            lv1552: R.Tensor((1280,), dtype="float32") = model_params[440]
            lv2634 = R.call_tir(cls.layer_norm3, (lv1198_1, lv1551, lv1552), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1553: R.Tensor((1280, 10240), dtype="float32") = model_params[1282]
            lv1554: R.Tensor((10240,), dtype="float32") = model_params[434]
            lv1199_1 = R.call_tir(cls.fused_matmul33_add45, (lv2634, lv1553, lv1554), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1200_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1199_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1555: R.Tensor((5120, 1280), dtype="float32") = model_params[1283]
            lv1556: R.Tensor((1280,), dtype="float32") = model_params[435]
            lv1201_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1200_2, lv1555, lv1556, lv1198_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1557_1: R.Tensor((1280,), dtype="float32") = model_params[447]
            lv1558: R.Tensor((1280,), dtype="float32") = model_params[446]
            lv2647 = R.call_tir(cls.layer_norm3, (lv1201_2, lv1557_1, lv1558), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1559_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1284]
            lv2649 = R.call_tir(cls.matmul27, (lv2647, lv1559_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1560: R.Tensor((1280, 1280), dtype="float32") = model_params[1285]
            lv2651 = R.call_tir(cls.matmul27, (lv2647, lv1560), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1561_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1286]
            lv2653 = R.call_tir(cls.matmul27, (lv2647, lv1561_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1202_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2649,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1203_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2651,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1204_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2653,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1205_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1202_1, lv1203_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2665 = R.call_tir(cls.softmax5, (lv1205_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2666 = R.call_tir(cls.matmul29, (lv2665, lv1204_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1206_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2666,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1562: R.Tensor((1280, 1280), dtype="float32") = model_params[1287]
            lv1563_1: R.Tensor((1280,), dtype="float32") = model_params[442]
            lv1207_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1206_1, lv1562, lv1563_1, lv1201_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1564: R.Tensor((1280,), dtype="float32") = model_params[449]
            lv1565: R.Tensor((1280,), dtype="float32") = model_params[448]
            lv2674 = R.call_tir(cls.layer_norm3, (lv1207_1, lv1564, lv1565), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1566: R.Tensor((1280, 1280), dtype="float32") = model_params[1288]
            lv2676 = R.call_tir(cls.matmul27, (lv2674, lv1566), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1567: R.Tensor((2048, 1280), dtype="float32") = model_params[1289]
            lv2678 = R.call_tir(cls.matmul30, (inp_2, lv1567), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1568: R.Tensor((2048, 1280), dtype="float32") = model_params[1290]
            lv2680 = R.call_tir(cls.matmul30, (inp_2, lv1568), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1208_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2676,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1209_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2678,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1210_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2680,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1211_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1208_1, lv1209_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2692 = R.call_tir(cls.softmax6, (lv1211_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2693 = R.call_tir(cls.matmul32, (lv2692, lv1210_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1212_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2693,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1569: R.Tensor((1280, 1280), dtype="float32") = model_params[1291]
            lv1570: R.Tensor((1280,), dtype="float32") = model_params[443]
            lv1213_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1212_1, lv1569, lv1570, lv1207_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1571: R.Tensor((1280,), dtype="float32") = model_params[451]
            lv1572: R.Tensor((1280,), dtype="float32") = model_params[450]
            lv2701 = R.call_tir(cls.layer_norm3, (lv1213_1, lv1571, lv1572), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1573: R.Tensor((1280, 10240), dtype="float32") = model_params[1292]
            lv1574: R.Tensor((10240,), dtype="float32") = model_params[444]
            lv1214_1 = R.call_tir(cls.fused_matmul33_add45, (lv2701, lv1573, lv1574), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1215_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1214_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1575_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1293]
            lv1576_1: R.Tensor((1280,), dtype="float32") = model_params[445]
            lv1216_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1215_1, lv1575_1, lv1576_1, lv1213_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1577: R.Tensor((1280,), dtype="float32") = model_params[457]
            lv1578: R.Tensor((1280,), dtype="float32") = model_params[456]
            lv2714 = R.call_tir(cls.layer_norm3, (lv1216_1, lv1577, lv1578), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1579: R.Tensor((1280, 1280), dtype="float32") = model_params[1294]
            lv2716 = R.call_tir(cls.matmul27, (lv2714, lv1579), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1580: R.Tensor((1280, 1280), dtype="float32") = model_params[1295]
            lv2718 = R.call_tir(cls.matmul27, (lv2714, lv1580), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1581: R.Tensor((1280, 1280), dtype="float32") = model_params[1296]
            lv2720 = R.call_tir(cls.matmul27, (lv2714, lv1581), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1217_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2716,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1218_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2718,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1219_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2720,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1220_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1217_1, lv1218_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2732 = R.call_tir(cls.softmax5, (lv1220_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2733 = R.call_tir(cls.matmul29, (lv2732, lv1219_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1221_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2733,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1582: R.Tensor((1280, 1280), dtype="float32") = model_params[1297]
            lv1583: R.Tensor((1280,), dtype="float32") = model_params[452]
            lv1222_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1221_1, lv1582, lv1583, lv1216_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1584_1: R.Tensor((1280,), dtype="float32") = model_params[459]
            lv1585: R.Tensor((1280,), dtype="float32") = model_params[458]
            lv2741 = R.call_tir(cls.layer_norm3, (lv1222_2, lv1584_1, lv1585), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1586_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1298]
            lv2743 = R.call_tir(cls.matmul27, (lv2741, lv1586_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1587: R.Tensor((2048, 1280), dtype="float32") = model_params[1299]
            lv2745 = R.call_tir(cls.matmul30, (inp_2, lv1587), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1588_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1300]
            lv2747 = R.call_tir(cls.matmul30, (inp_2, lv1588_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1223_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2743,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1224_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2745,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1225_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2747,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1226_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1223_1, lv1224_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2759 = R.call_tir(cls.softmax6, (lv1226_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2760 = R.call_tir(cls.matmul32, (lv2759, lv1225_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1227_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2760,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1589: R.Tensor((1280, 1280), dtype="float32") = model_params[1301]
            lv1590_1: R.Tensor((1280,), dtype="float32") = model_params[453]
            lv1228_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1227_1, lv1589, lv1590_1, lv1222_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1591: R.Tensor((1280,), dtype="float32") = model_params[461]
            lv1592: R.Tensor((1280,), dtype="float32") = model_params[460]
            lv2768 = R.call_tir(cls.layer_norm3, (lv1228_2, lv1591, lv1592), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1593: R.Tensor((1280, 10240), dtype="float32") = model_params[1302]
            lv1594: R.Tensor((10240,), dtype="float32") = model_params[454]
            lv1229_1 = R.call_tir(cls.fused_matmul33_add45, (lv2768, lv1593, lv1594), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1230_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1229_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1595: R.Tensor((5120, 1280), dtype="float32") = model_params[1303]
            lv1596: R.Tensor((1280,), dtype="float32") = model_params[455]
            lv1231_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1230_1, lv1595, lv1596, lv1228_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1597: R.Tensor((1280,), dtype="float32") = model_params[467]
            lv1598: R.Tensor((1280,), dtype="float32") = model_params[466]
            lv2781 = R.call_tir(cls.layer_norm3, (lv1231_1, lv1597, lv1598), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1599: R.Tensor((1280, 1280), dtype="float32") = model_params[1304]
            lv2783 = R.call_tir(cls.matmul27, (lv2781, lv1599), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1600: R.Tensor((1280, 1280), dtype="float32") = model_params[1305]
            lv2785 = R.call_tir(cls.matmul27, (lv2781, lv1600), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1601: R.Tensor((1280, 1280), dtype="float32") = model_params[1306]
            lv2787 = R.call_tir(cls.matmul27, (lv2781, lv1601), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1232_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2783,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1233_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2785,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1234_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2787,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1235_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1232_1, lv1233_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2799 = R.call_tir(cls.softmax5, (lv1235_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2800 = R.call_tir(cls.matmul29, (lv2799, lv1234_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1236_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2800,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1602_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1307]
            lv1603_1: R.Tensor((1280,), dtype="float32") = model_params[462]
            lv1237_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1236_1, lv1602_1, lv1603_1, lv1231_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1604: R.Tensor((1280,), dtype="float32") = model_params[469]
            lv1605: R.Tensor((1280,), dtype="float32") = model_params[468]
            lv2808 = R.call_tir(cls.layer_norm3, (lv1237_1, lv1604, lv1605), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1606: R.Tensor((1280, 1280), dtype="float32") = model_params[1308]
            lv2810 = R.call_tir(cls.matmul27, (lv2808, lv1606), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1607: R.Tensor((2048, 1280), dtype="float32") = model_params[1309]
            lv2812 = R.call_tir(cls.matmul30, (inp_2, lv1607), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1608: R.Tensor((2048, 1280), dtype="float32") = model_params[1310]
            lv2814 = R.call_tir(cls.matmul30, (inp_2, lv1608), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1238_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2810,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1239_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2812,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1240_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv2814,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1241_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1238_1, lv1239_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2826 = R.call_tir(cls.softmax6, (lv1241_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2827 = R.call_tir(cls.matmul32, (lv2826, lv1240_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1242_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2827,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1609: R.Tensor((1280, 1280), dtype="float32") = model_params[1311]
            lv1610: R.Tensor((1280,), dtype="float32") = model_params[463]
            lv1243_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1242_1, lv1609, lv1610, lv1237_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1611_1: R.Tensor((1280,), dtype="float32") = model_params[471]
            lv1612: R.Tensor((1280,), dtype="float32") = model_params[470]
            lv2835 = R.call_tir(cls.layer_norm3, (lv1243_1, lv1611_1, lv1612), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1613: R.Tensor((1280, 10240), dtype="float32") = model_params[1312]
            lv1614: R.Tensor((10240,), dtype="float32") = model_params[464]
            lv1244_1 = R.call_tir(cls.fused_matmul33_add45, (lv2835, lv1613, lv1614), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1245_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1244_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1615: R.Tensor((5120, 1280), dtype="float32") = model_params[1313]
            lv1616: R.Tensor((1280,), dtype="float32") = model_params[465]
            lv1246_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1245_1, lv1615, lv1616, lv1243_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1617: R.Tensor((1280,), dtype="float32") = model_params[477]
            lv1618: R.Tensor((1280,), dtype="float32") = model_params[476]
            lv2848 = R.call_tir(cls.layer_norm3, (lv1246_1, lv1617, lv1618), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1619: R.Tensor((1280, 1280), dtype="float32") = model_params[1314]
            lv2850 = R.call_tir(cls.matmul27, (lv2848, lv1619), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1620: R.Tensor((1280, 1280), dtype="float32") = model_params[1315]
            lv2852 = R.call_tir(cls.matmul27, (lv2848, lv1620), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1621: R.Tensor((1280, 1280), dtype="float32") = model_params[1316]
            lv2854 = R.call_tir(cls.matmul27, (lv2848, lv1621), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1247_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2850,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1248_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2852,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1249_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2854,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1250_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1247_1, lv1248_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2866 = R.call_tir(cls.softmax5, (lv1250_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2867 = R.call_tir(cls.matmul29, (lv2866, lv1249_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1251_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv2867,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1622: R.Tensor((1280, 1280), dtype="float32") = model_params[1317]
            lv1623: R.Tensor((1280,), dtype="float32") = model_params[472]
            lv1252_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1251_2, lv1622, lv1623, lv1246_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1624_1: R.Tensor((1280,), dtype="float32") = model_params[479]
            lv1625: R.Tensor((1280,), dtype="float32") = model_params[478]
            lv2875 = R.call_tir(cls.layer_norm3, (lv1252_1, lv1624_1, lv1625), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1626_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1318]
            lv2877 = R.call_tir(cls.matmul27, (lv2875, lv1626_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1627: R.Tensor((2048, 1280), dtype="float32") = model_params[1319]
            lv2879 = R.call_tir(cls.matmul30, (inp_2, lv1627), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1628_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1320]
            lv2881 = R.call_tir(cls.matmul30, (inp_2, lv1628_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1253_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2877,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1254_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2879,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1255_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv2881,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1256_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1253_2, lv1254_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2893 = R.call_tir(cls.softmax6, (lv1256_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2894 = R.call_tir(cls.matmul32, (lv2893, lv1255_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1257_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2894,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1629: R.Tensor((1280, 1280), dtype="float32") = model_params[1321]
            lv1630_1: R.Tensor((1280,), dtype="float32") = model_params[473]
            lv1258_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1257_1, lv1629, lv1630_1, lv1252_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1631: R.Tensor((1280,), dtype="float32") = model_params[481]
            lv1632: R.Tensor((1280,), dtype="float32") = model_params[480]
            lv2902 = R.call_tir(cls.layer_norm3, (lv1258_1, lv1631, lv1632), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1633: R.Tensor((1280, 10240), dtype="float32") = model_params[1322]
            lv1634: R.Tensor((10240,), dtype="float32") = model_params[474]
            lv1259_1 = R.call_tir(cls.fused_matmul33_add45, (lv2902, lv1633, lv1634), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1260_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1259_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1635: R.Tensor((5120, 1280), dtype="float32") = model_params[1323]
            lv1636: R.Tensor((1280,), dtype="float32") = model_params[475]
            lv1261_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1260_1, lv1635, lv1636, lv1258_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1637: R.Tensor((1280,), dtype="float32") = model_params[487]
            lv1638: R.Tensor((1280,), dtype="float32") = model_params[486]
            lv2915 = R.call_tir(cls.layer_norm3, (lv1261_1, lv1637, lv1638), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1639: R.Tensor((1280, 1280), dtype="float32") = model_params[1324]
            lv2917 = R.call_tir(cls.matmul27, (lv2915, lv1639), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1640: R.Tensor((1280, 1280), dtype="float32") = model_params[1325]
            lv2919 = R.call_tir(cls.matmul27, (lv2915, lv1640), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1641: R.Tensor((1280, 1280), dtype="float32") = model_params[1326]
            lv2921 = R.call_tir(cls.matmul27, (lv2915, lv1641), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1262_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2917,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1263_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2919,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1264_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2921,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1265_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1262_1, lv1263_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2933 = R.call_tir(cls.softmax5, (lv1265_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv2934 = R.call_tir(cls.matmul29, (lv2933, lv1264_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1266_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2934,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1642_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1327]
            lv1643_1: R.Tensor((1280,), dtype="float32") = model_params[482]
            lv1267_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1266_1, lv1642_1, lv1643_1, lv1261_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1644: R.Tensor((1280,), dtype="float32") = model_params[489]
            lv1645: R.Tensor((1280,), dtype="float32") = model_params[488]
            lv2942 = R.call_tir(cls.layer_norm3, (lv1267_2, lv1644, lv1645), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1646: R.Tensor((1280, 1280), dtype="float32") = model_params[1328]
            lv2944 = R.call_tir(cls.matmul27, (lv2942, lv1646), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1647: R.Tensor((2048, 1280), dtype="float32") = model_params[1329]
            lv2946 = R.call_tir(cls.matmul30, (inp_2, lv1647), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1648: R.Tensor((2048, 1280), dtype="float32") = model_params[1330]
            lv2948 = R.call_tir(cls.matmul30, (inp_2, lv1648), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1268_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv2944,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1269_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv2946,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1270_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv2948,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1271_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1268_2, lv1269_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2960 = R.call_tir(cls.softmax6, (lv1271_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv2961 = R.call_tir(cls.matmul32, (lv2960, lv1270_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1272_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv2961,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1649: R.Tensor((1280, 1280), dtype="float32") = model_params[1331]
            lv1650: R.Tensor((1280,), dtype="float32") = model_params[483]
            lv1273_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1272_1, lv1649, lv1650, lv1267_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1651_1: R.Tensor((1280,), dtype="float32") = model_params[491]
            lv1652: R.Tensor((1280,), dtype="float32") = model_params[490]
            lv2969 = R.call_tir(cls.layer_norm3, (lv1273_1, lv1651_1, lv1652), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1653_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1332]
            lv1654: R.Tensor((10240,), dtype="float32") = model_params[484]
            lv1274_1 = R.call_tir(cls.fused_matmul33_add45, (lv2969, lv1653_1, lv1654), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1275_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1274_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1655_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1333]
            lv1656: R.Tensor((1280,), dtype="float32") = model_params[485]
            lv1276_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1275_1, lv1655_1, lv1656, lv1273_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1657_1: R.Tensor((1280,), dtype="float32") = model_params[497]
            lv1658: R.Tensor((1280,), dtype="float32") = model_params[496]
            lv2982 = R.call_tir(cls.layer_norm3, (lv1276_2, lv1657_1, lv1658), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1659: R.Tensor((1280, 1280), dtype="float32") = model_params[1334]
            lv2984 = R.call_tir(cls.matmul27, (lv2982, lv1659), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1660: R.Tensor((1280, 1280), dtype="float32") = model_params[1335]
            lv2986 = R.call_tir(cls.matmul27, (lv2982, lv1660), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1661: R.Tensor((1280, 1280), dtype="float32") = model_params[1336]
            lv2988 = R.call_tir(cls.matmul27, (lv2982, lv1661), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1277_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2984,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1278_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv2986,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1279_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv2988,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1280_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1277_1, lv1278_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3000 = R.call_tir(cls.softmax5, (lv1280_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3001 = R.call_tir(cls.matmul29, (lv3000, lv1279_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1281_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3001,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1662: R.Tensor((1280, 1280), dtype="float32") = model_params[1337]
            lv1663: R.Tensor((1280,), dtype="float32") = model_params[492]
            lv1282_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1281_1, lv1662, lv1663, lv1276_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1664: R.Tensor((1280,), dtype="float32") = model_params[499]
            lv1665: R.Tensor((1280,), dtype="float32") = model_params[498]
            lv3009 = R.call_tir(cls.layer_norm3, (lv1282_1, lv1664, lv1665), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1666: R.Tensor((1280, 1280), dtype="float32") = model_params[1338]
            lv3011 = R.call_tir(cls.matmul27, (lv3009, lv1666), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1667: R.Tensor((2048, 1280), dtype="float32") = model_params[1339]
            lv3013 = R.call_tir(cls.matmul30, (inp_2, lv1667), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1668: R.Tensor((2048, 1280), dtype="float32") = model_params[1340]
            lv3015 = R.call_tir(cls.matmul30, (inp_2, lv1668), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1283_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3011,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1284_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3013,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1285_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3015,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1286_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1283_1, lv1284_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3027 = R.call_tir(cls.softmax6, (lv1286_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3028 = R.call_tir(cls.matmul32, (lv3027, lv1285_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1287_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3028,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1669_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1341]
            lv1670_1: R.Tensor((1280,), dtype="float32") = model_params[493]
            lv1288_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1287_1, lv1669_1, lv1670_1, lv1282_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1671: R.Tensor((1280,), dtype="float32") = model_params[501]
            lv1672: R.Tensor((1280,), dtype="float32") = model_params[500]
            lv3036 = R.call_tir(cls.layer_norm3, (lv1288_1, lv1671, lv1672), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1673: R.Tensor((1280, 10240), dtype="float32") = model_params[1342]
            lv1674: R.Tensor((10240,), dtype="float32") = model_params[494]
            lv1289_2 = R.call_tir(cls.fused_matmul33_add45, (lv3036, lv1673, lv1674), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1290_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1289_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1675: R.Tensor((5120, 1280), dtype="float32") = model_params[1343]
            lv1676: R.Tensor((1280,), dtype="float32") = model_params[495]
            lv1291_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1290_1, lv1675, lv1676, lv1288_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1677: R.Tensor((1280,), dtype="float32") = model_params[507]
            lv1678_1: R.Tensor((1280,), dtype="float32") = model_params[506]
            lv3049 = R.call_tir(cls.layer_norm3, (lv1291_2, lv1677, lv1678_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1679: R.Tensor((1280, 1280), dtype="float32") = model_params[1344]
            lv3051 = R.call_tir(cls.matmul27, (lv3049, lv1679), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1680: R.Tensor((1280, 1280), dtype="float32") = model_params[1345]
            lv3053 = R.call_tir(cls.matmul27, (lv3049, lv1680), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1681: R.Tensor((1280, 1280), dtype="float32") = model_params[1346]
            lv3055 = R.call_tir(cls.matmul27, (lv3049, lv1681), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1292_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3051,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1293_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3053,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1294_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3055,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1295_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv1292_1, lv1293_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3067 = R.call_tir(cls.softmax5, (lv1295_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3068 = R.call_tir(cls.matmul29, (lv3067, lv1294_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1296_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3068,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1682: R.Tensor((1280, 1280), dtype="float32") = model_params[1347]
            lv1683: R.Tensor((1280,), dtype="float32") = model_params[502]
            lv1297_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1296_1, lv1682, lv1683, lv1291_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1684: R.Tensor((1280,), dtype="float32") = model_params[509]
            lv1685: R.Tensor((1280,), dtype="float32") = model_params[508]
            lv3076 = R.call_tir(cls.layer_norm3, (lv1297_1, lv1684, lv1685), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1686: R.Tensor((1280, 1280), dtype="float32") = model_params[1348]
            lv3078 = R.call_tir(cls.matmul27, (lv3076, lv1686), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1687: R.Tensor((2048, 1280), dtype="float32") = model_params[1349]
            lv3080 = R.call_tir(cls.matmul30, (inp_2, lv1687), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1688: R.Tensor((2048, 1280), dtype="float32") = model_params[1350]
            lv3082 = R.call_tir(cls.matmul30, (inp_2, lv1688), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1298_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3078,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1299_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3080,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1300_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3082,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1301_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1298_1, lv1299_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3094 = R.call_tir(cls.softmax6, (lv1301_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3095 = R.call_tir(cls.matmul32, (lv3094, lv1300_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1302_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3095,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1689: R.Tensor((1280, 1280), dtype="float32") = model_params[1351]
            lv1690: R.Tensor((1280,), dtype="float32") = model_params[503]
            lv1303_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1302_1, lv1689, lv1690, lv1297_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1691_1: R.Tensor((1280,), dtype="float32") = model_params[511]
            lv1692: R.Tensor((1280,), dtype="float32") = model_params[510]
            lv3103 = R.call_tir(cls.layer_norm3, (lv1303_1, lv1691_1, lv1692), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1693_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1352]
            lv1694: R.Tensor((10240,), dtype="float32") = model_params[504]
            lv1304_1 = R.call_tir(cls.fused_matmul33_add45, (lv3103, lv1693_1, lv1694), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1305_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1304_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1695_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1353]
            lv1696: R.Tensor((1280,), dtype="float32") = model_params[505]
            lv1306_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1305_1, lv1695_1, lv1696, lv1303_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1697_1: R.Tensor((1280,), dtype="float32") = model_params[517]
            lv1698: R.Tensor((1280,), dtype="float32") = model_params[516]
            lv3116 = R.call_tir(cls.layer_norm3, (lv1306_1, lv1697_1, lv1698), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1699: R.Tensor((1280, 1280), dtype="float32") = model_params[1354]
            lv3118 = R.call_tir(cls.matmul27, (lv3116, lv1699), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1700: R.Tensor((1280, 1280), dtype="float32") = model_params[1355]
            lv3120 = R.call_tir(cls.matmul27, (lv3116, lv1700), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1701: R.Tensor((1280, 1280), dtype="float32") = model_params[1356]
            lv3122 = R.call_tir(cls.matmul27, (lv3116, lv1701), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1307_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3118,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1308_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3120,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1309_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3122,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1310_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1307_2, lv1308_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3134 = R.call_tir(cls.softmax5, (lv1310_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3135 = R.call_tir(cls.matmul29, (lv3134, lv1309_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1311_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3135,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1702: R.Tensor((1280, 1280), dtype="float32") = model_params[1357]
            lv1703: R.Tensor((1280,), dtype="float32") = model_params[512]
            lv1312_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1311_1, lv1702, lv1703, lv1306_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1704: R.Tensor((1280,), dtype="float32") = model_params[519]
            lv1705: R.Tensor((1280,), dtype="float32") = model_params[518]
            lv3143 = R.call_tir(cls.layer_norm3, (lv1312_1, lv1704, lv1705), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1706: R.Tensor((1280, 1280), dtype="float32") = model_params[1358]
            lv3145 = R.call_tir(cls.matmul27, (lv3143, lv1706), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1707: R.Tensor((2048, 1280), dtype="float32") = model_params[1359]
            lv3147 = R.call_tir(cls.matmul30, (inp_2, lv1707), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1708: R.Tensor((2048, 1280), dtype="float32") = model_params[1360]
            lv3149 = R.call_tir(cls.matmul30, (inp_2, lv1708), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1313_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3145,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1314_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3147,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1315_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3149,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1316_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1313_1, lv1314_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3161 = R.call_tir(cls.softmax6, (lv1316_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3162 = R.call_tir(cls.matmul32, (lv3161, lv1315_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1317_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3162,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1709_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1361]
            lv1710_1: R.Tensor((1280,), dtype="float32") = model_params[513]
            lv1318_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1317_1, lv1709_1, lv1710_1, lv1312_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1711: R.Tensor((1280,), dtype="float32") = model_params[521]
            lv1712: R.Tensor((1280,), dtype="float32") = model_params[520]
            lv3170 = R.call_tir(cls.layer_norm3, (lv1318_2, lv1711, lv1712), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1713: R.Tensor((1280, 10240), dtype="float32") = model_params[1362]
            lv1714: R.Tensor((10240,), dtype="float32") = model_params[514]
            lv1319_1 = R.call_tir(cls.fused_matmul33_add45, (lv3170, lv1713, lv1714), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1320_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1319_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1715: R.Tensor((5120, 1280), dtype="float32") = model_params[1363]
            lv1716: R.Tensor((1280,), dtype="float32") = model_params[515]
            lv1321_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1320_2, lv1715, lv1716, lv1318_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1717: R.Tensor((1280,), dtype="float32") = model_params[527]
            lv1718_1: R.Tensor((1280,), dtype="float32") = model_params[526]
            lv3183 = R.call_tir(cls.layer_norm3, (lv1321_1, lv1717, lv1718_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1719: R.Tensor((1280, 1280), dtype="float32") = model_params[1364]
            lv3185 = R.call_tir(cls.matmul27, (lv3183, lv1719), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1720_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1365]
            lv3187 = R.call_tir(cls.matmul27, (lv3183, lv1720_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1721: R.Tensor((1280, 1280), dtype="float32") = model_params[1366]
            lv3189 = R.call_tir(cls.matmul27, (lv3183, lv1721), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1322_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3185,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1323_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3187,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1324_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3189,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1325_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1322_2, lv1323_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3201 = R.call_tir(cls.softmax5, (lv1325_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3202 = R.call_tir(cls.matmul29, (lv3201, lv1324_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1326_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3202,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1722_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1367]
            lv1723: R.Tensor((1280,), dtype="float32") = model_params[522]
            lv1327_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1326_1, lv1722_1, lv1723, lv1321_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1724_1: R.Tensor((1280,), dtype="float32") = model_params[529]
            lv1725: R.Tensor((1280,), dtype="float32") = model_params[528]
            lv3210 = R.call_tir(cls.layer_norm3, (lv1327_1, lv1724_1, lv1725), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1726: R.Tensor((1280, 1280), dtype="float32") = model_params[1368]
            lv3212 = R.call_tir(cls.matmul27, (lv3210, lv1726), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1727: R.Tensor((2048, 1280), dtype="float32") = model_params[1369]
            lv3214 = R.call_tir(cls.matmul30, (inp_2, lv1727), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1728: R.Tensor((2048, 1280), dtype="float32") = model_params[1370]
            lv3216 = R.call_tir(cls.matmul30, (inp_2, lv1728), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1328_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3212,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1329_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3214,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1330_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3216,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1331_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1328_1, lv1329_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3228 = R.call_tir(cls.softmax6, (lv1331_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3229 = R.call_tir(cls.matmul32, (lv3228, lv1330_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1332_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3229,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1729: R.Tensor((1280, 1280), dtype="float32") = model_params[1371]
            lv1730: R.Tensor((1280,), dtype="float32") = model_params[523]
            lv1333_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1332_1, lv1729, lv1730, lv1327_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1731: R.Tensor((1280,), dtype="float32") = model_params[531]
            lv1732: R.Tensor((1280,), dtype="float32") = model_params[530]
            lv3237 = R.call_tir(cls.layer_norm3, (lv1333_1, lv1731, lv1732), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1733: R.Tensor((1280, 10240), dtype="float32") = model_params[1372]
            lv1734: R.Tensor((10240,), dtype="float32") = model_params[524]
            lv1334_2 = R.call_tir(cls.fused_matmul33_add45, (lv3237, lv1733, lv1734), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1335_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1334_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1735: R.Tensor((5120, 1280), dtype="float32") = model_params[1373]
            lv1736_1: R.Tensor((1280,), dtype="float32") = model_params[525]
            lv1336_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1335_2, lv1735, lv1736_1, lv1333_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1737_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1374]
            lv1738: R.Tensor((1280,), dtype="float32") = model_params[431]
            lv1337_1 = R.call_tir(cls.fused_matmul27_add43, (lv1336_1, lv1737_1, lv1738), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1338_1 = R.call_tir(cls.fused_reshape49_transpose42_add42_concatenate7, (lv1337_1, lv1184_2, lv855_1), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv1739: R.Tensor((2560,), dtype="float32") = model_params[752]
            lv1740: R.Tensor((2560,), dtype="float32") = model_params[751]
            lv1339_1 = R.call_tir(cls.fused_group_norm14_silu12, (lv1338_1, lv1739, lv1740), out_sinfo=R.Tensor((2, 2560, 32, 32), dtype="float32"))
            lv3262 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1741: R.Tensor((1280, 1280), dtype="float32") = model_params[1376]
            lv1742: R.Tensor((1280,), dtype="float32") = model_params[755]
            lv1340_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv3262, lv1741, lv1742), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv3267 = R.call_tir(cls.reshape44, (lv1340_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1743: R.Tensor((1280, 2560, 3, 3), dtype="float32") = model_params[748]
            lv1744: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1375]
            lv1341_1 = R.call_tir(cls.fused_conv2d23_add40_add41, (lv1339_1, lv1743, lv1744, lv3267), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1745_1: R.Tensor((1280,), dtype="float32") = model_params[754]
            lv1746: R.Tensor((1280,), dtype="float32") = model_params[753]
            lv1342_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv1341_1, lv1745_1, lv1746), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1747: R.Tensor((1280, 2560, 1, 1), dtype="float32") = model_params[750]
            lv1748: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1378]
            lv1343_2 = R.call_tir(cls.fused_conv2d24_add40, (lv1338_1, lv1747, lv1748), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1749: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[749]
            lv1750: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1377]
            lv1344_1 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv1342_1, lv1749, lv1750, lv1343_2), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1751: R.Tensor((1280,), dtype="float32") = model_params[533]
            lv1752: R.Tensor((1280,), dtype="float32") = model_params[532]
            lv3279 = R.call_tir(cls.group_norm13, (lv1344_1, lv1751, lv1752), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1345_1 = R.call_tir(cls.fused_transpose34_reshape45, (lv3279,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1753: R.Tensor((1280, 1280), dtype="float32") = model_params[1379]
            lv1754: R.Tensor((1280,), dtype="float32") = model_params[534]
            lv1346_1 = R.call_tir(cls.fused_matmul27_add43, (lv1345_1, lv1753, lv1754), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1755: R.Tensor((1280,), dtype="float32") = model_params[541]
            lv1756: R.Tensor((1280,), dtype="float32") = model_params[540]
            lv3285 = R.call_tir(cls.layer_norm3, (lv1346_1, lv1755, lv1756), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1757: R.Tensor((1280, 1280), dtype="float32") = model_params[1380]
            lv3287 = R.call_tir(cls.matmul27, (lv3285, lv1757), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1758_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1381]
            lv3289 = R.call_tir(cls.matmul27, (lv3285, lv1758_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1759: R.Tensor((1280, 1280), dtype="float32") = model_params[1382]
            lv3291 = R.call_tir(cls.matmul27, (lv3285, lv1759), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1347_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1348_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3289,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1349_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3291,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1350_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1347_1, lv1348_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3303 = R.call_tir(cls.softmax5, (lv1350_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3304 = R.call_tir(cls.matmul29, (lv3303, lv1349_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1351_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1760_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1383]
            lv1761: R.Tensor((1280,), dtype="float32") = model_params[536]
            lv1352_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1351_1, lv1760_1, lv1761, lv1346_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1762_1: R.Tensor((1280,), dtype="float32") = model_params[543]
            lv1763: R.Tensor((1280,), dtype="float32") = model_params[542]
            lv3312 = R.call_tir(cls.layer_norm3, (lv1352_1, lv1762_1, lv1763), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1764_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1384]
            lv3314 = R.call_tir(cls.matmul27, (lv3312, lv1764_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1765: R.Tensor((2048, 1280), dtype="float32") = model_params[1385]
            lv3316 = R.call_tir(cls.matmul30, (inp_2, lv1765), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1766: R.Tensor((2048, 1280), dtype="float32") = model_params[1386]
            lv3318 = R.call_tir(cls.matmul30, (inp_2, lv1766), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1353_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3314,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1354_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3316,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1355_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3318,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1356_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1353_1, lv1354_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3330 = R.call_tir(cls.softmax6, (lv1356_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3331 = R.call_tir(cls.matmul32, (lv3330, lv1355_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1357_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3331,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1767: R.Tensor((1280, 1280), dtype="float32") = model_params[1387]
            lv1768: R.Tensor((1280,), dtype="float32") = model_params[537]
            lv1358_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1357_1, lv1767, lv1768, lv1352_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1769: R.Tensor((1280,), dtype="float32") = model_params[545]
            lv1770: R.Tensor((1280,), dtype="float32") = model_params[544]
            lv3339 = R.call_tir(cls.layer_norm3, (lv1358_2, lv1769, lv1770), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1771: R.Tensor((1280, 10240), dtype="float32") = model_params[1388]
            lv1772: R.Tensor((10240,), dtype="float32") = model_params[538]
            lv1359_1 = R.call_tir(cls.fused_matmul33_add45, (lv3339, lv1771, lv1772), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1360_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1359_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1773: R.Tensor((5120, 1280), dtype="float32") = model_params[1389]
            lv1774: R.Tensor((1280,), dtype="float32") = model_params[539]
            lv1361_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1360_2, lv1773, lv1774, lv1358_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1775: R.Tensor((1280,), dtype="float32") = model_params[551]
            lv1776_1: R.Tensor((1280,), dtype="float32") = model_params[550]
            lv3352 = R.call_tir(cls.layer_norm3, (lv1361_1, lv1775, lv1776_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1777_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1390]
            lv3354 = R.call_tir(cls.matmul27, (lv3352, lv1777_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1778: R.Tensor((1280, 1280), dtype="float32") = model_params[1391]
            lv3356 = R.call_tir(cls.matmul27, (lv3352, lv1778), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1779: R.Tensor((1280, 1280), dtype="float32") = model_params[1392]
            lv3358 = R.call_tir(cls.matmul27, (lv3352, lv1779), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1362_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1363_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3356,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1364_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3358,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1365_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1362_2, lv1363_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3370 = R.call_tir(cls.softmax5, (lv1365_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3371 = R.call_tir(cls.matmul29, (lv3370, lv1364_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1366_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1780: R.Tensor((1280, 1280), dtype="float32") = model_params[1393]
            lv1781: R.Tensor((1280,), dtype="float32") = model_params[546]
            lv1367_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1366_1, lv1780, lv1781, lv1361_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1782: R.Tensor((1280,), dtype="float32") = model_params[553]
            lv1783: R.Tensor((1280,), dtype="float32") = model_params[552]
            lv3379 = R.call_tir(cls.layer_norm3, (lv1367_1, lv1782, lv1783), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1784: R.Tensor((1280, 1280), dtype="float32") = model_params[1394]
            lv3381 = R.call_tir(cls.matmul27, (lv3379, lv1784), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1785_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1395]
            lv3383 = R.call_tir(cls.matmul30, (inp_2, lv1785_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1786: R.Tensor((2048, 1280), dtype="float32") = model_params[1396]
            lv3385 = R.call_tir(cls.matmul30, (inp_2, lv1786), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1368_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3381,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1369_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3383,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1370_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3385,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1371_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1368_1, lv1369_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3397 = R.call_tir(cls.softmax6, (lv1371_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3398 = R.call_tir(cls.matmul32, (lv3397, lv1370_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1372_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3398,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1787_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1397]
            lv1788: R.Tensor((1280,), dtype="float32") = model_params[547]
            lv1373_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1372_1, lv1787_1, lv1788, lv1367_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1789_1: R.Tensor((1280,), dtype="float32") = model_params[555]
            lv1790: R.Tensor((1280,), dtype="float32") = model_params[554]
            lv3406 = R.call_tir(cls.layer_norm3, (lv1373_1, lv1789_1, lv1790), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1791_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1398]
            lv1792: R.Tensor((10240,), dtype="float32") = model_params[548]
            lv1374_2 = R.call_tir(cls.fused_matmul33_add45, (lv3406, lv1791_1, lv1792), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1375_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1374_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1793: R.Tensor((5120, 1280), dtype="float32") = model_params[1399]
            lv1794: R.Tensor((1280,), dtype="float32") = model_params[549]
            lv1376_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1375_2, lv1793, lv1794, lv1373_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1795: R.Tensor((1280,), dtype="float32") = model_params[561]
            lv1796: R.Tensor((1280,), dtype="float32") = model_params[560]
            lv3419 = R.call_tir(cls.layer_norm3, (lv1376_1, lv1795, lv1796), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1797: R.Tensor((1280, 1280), dtype="float32") = model_params[1400]
            lv3421 = R.call_tir(cls.matmul27, (lv3419, lv1797), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1798: R.Tensor((1280, 1280), dtype="float32") = model_params[1401]
            lv3423 = R.call_tir(cls.matmul27, (lv3419, lv1798), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1799: R.Tensor((1280, 1280), dtype="float32") = model_params[1402]
            lv3425 = R.call_tir(cls.matmul27, (lv3419, lv1799), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1377_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1378_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3423,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1379_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3425,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1380_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1377_1, lv1378_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3437 = R.call_tir(cls.softmax5, (lv1380_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3438 = R.call_tir(cls.matmul29, (lv3437, lv1379_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1381_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1800: R.Tensor((1280, 1280), dtype="float32") = model_params[1403]
            lv1801: R.Tensor((1280,), dtype="float32") = model_params[556]
            lv1382_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1381_1, lv1800, lv1801, lv1376_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1802: R.Tensor((1280,), dtype="float32") = model_params[563]
            lv1803_1: R.Tensor((1280,), dtype="float32") = model_params[562]
            lv3446 = R.call_tir(cls.layer_norm3, (lv1382_1, lv1802, lv1803_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1804_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1404]
            lv3448 = R.call_tir(cls.matmul27, (lv3446, lv1804_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1805: R.Tensor((2048, 1280), dtype="float32") = model_params[1405]
            lv3450 = R.call_tir(cls.matmul30, (inp_2, lv1805), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1806: R.Tensor((2048, 1280), dtype="float32") = model_params[1406]
            lv3452 = R.call_tir(cls.matmul30, (inp_2, lv1806), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1383_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3448,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1384_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3450,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1385_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv3452,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1386_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1383_2, lv1384_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3464 = R.call_tir(cls.softmax6, (lv1386_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3465 = R.call_tir(cls.matmul32, (lv3464, lv1385_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1387_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3465,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1807: R.Tensor((1280, 1280), dtype="float32") = model_params[1407]
            lv1808: R.Tensor((1280,), dtype="float32") = model_params[557]
            lv1388_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1387_2, lv1807, lv1808, lv1382_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1809: R.Tensor((1280,), dtype="float32") = model_params[565]
            lv1810: R.Tensor((1280,), dtype="float32") = model_params[564]
            lv3473 = R.call_tir(cls.layer_norm3, (lv1388_1, lv1809, lv1810), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1811: R.Tensor((1280, 10240), dtype="float32") = model_params[1408]
            lv1812_1: R.Tensor((10240,), dtype="float32") = model_params[558]
            lv1389_2 = R.call_tir(cls.fused_matmul33_add45, (lv3473, lv1811, lv1812_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1390_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1389_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1813: R.Tensor((5120, 1280), dtype="float32") = model_params[1409]
            lv1814: R.Tensor((1280,), dtype="float32") = model_params[559]
            lv1391_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1390_1, lv1813, lv1814, lv1388_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1815: R.Tensor((1280,), dtype="float32") = model_params[571]
            lv1816: R.Tensor((1280,), dtype="float32") = model_params[570]
            lv3486 = R.call_tir(cls.layer_norm3, (lv1391_1, lv1815, lv1816), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1817: R.Tensor((1280, 1280), dtype="float32") = model_params[1410]
            lv3488 = R.call_tir(cls.matmul27, (lv3486, lv1817), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1818: R.Tensor((1280, 1280), dtype="float32") = model_params[1411]
            lv3490 = R.call_tir(cls.matmul27, (lv3486, lv1818), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1819: R.Tensor((1280, 1280), dtype="float32") = model_params[1412]
            lv3492 = R.call_tir(cls.matmul27, (lv3486, lv1819), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1392_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1393_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3490,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1394_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3492,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1395_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1392_1, lv1393_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3504 = R.call_tir(cls.softmax5, (lv1395_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3505 = R.call_tir(cls.matmul29, (lv3504, lv1394_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1396_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1820: R.Tensor((1280, 1280), dtype="float32") = model_params[1413]
            lv1821: R.Tensor((1280,), dtype="float32") = model_params[566]
            lv1397_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1396_1, lv1820, lv1821, lv1391_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1822: R.Tensor((1280,), dtype="float32") = model_params[573]
            lv1823: R.Tensor((1280,), dtype="float32") = model_params[572]
            lv3513 = R.call_tir(cls.layer_norm3, (lv1397_1, lv1822, lv1823), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1824: R.Tensor((1280, 1280), dtype="float32") = model_params[1414]
            lv3515 = R.call_tir(cls.matmul27, (lv3513, lv1824), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1825: R.Tensor((2048, 1280), dtype="float32") = model_params[1415]
            lv3517 = R.call_tir(cls.matmul30, (inp_2, lv1825), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1826: R.Tensor((2048, 1280), dtype="float32") = model_params[1416]
            lv3519 = R.call_tir(cls.matmul30, (inp_2, lv1826), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1398_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3515,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1399_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3517,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1400_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3519,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1401_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1398_1, lv1399_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3531 = R.call_tir(cls.softmax6, (lv1401_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3532 = R.call_tir(cls.matmul32, (lv3531, lv1400_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1402_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3532,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1827: R.Tensor((1280, 1280), dtype="float32") = model_params[1417]
            lv1828: R.Tensor((1280,), dtype="float32") = model_params[567]
            lv1403_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1402_2, lv1827, lv1828, lv1397_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1829: R.Tensor((1280,), dtype="float32") = model_params[575]
            lv1830: R.Tensor((1280,), dtype="float32") = model_params[574]
            lv3540 = R.call_tir(cls.layer_norm3, (lv1403_1, lv1829, lv1830), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1831: R.Tensor((1280, 10240), dtype="float32") = model_params[1418]
            lv1832: R.Tensor((10240,), dtype="float32") = model_params[568]
            lv1404_1 = R.call_tir(cls.fused_matmul33_add45, (lv3540, lv1831, lv1832), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1405_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1404_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1833: R.Tensor((5120, 1280), dtype="float32") = model_params[1419]
            lv1834: R.Tensor((1280,), dtype="float32") = model_params[569]
            lv1406_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1405_1, lv1833, lv1834, lv1403_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1835: R.Tensor((1280,), dtype="float32") = model_params[581]
            lv1836_1: R.Tensor((1280,), dtype="float32") = model_params[580]
            lv3553 = R.call_tir(cls.layer_norm3, (lv1406_1, lv1835, lv1836_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1837: R.Tensor((1280, 1280), dtype="float32") = model_params[1420]
            lv3555 = R.call_tir(cls.matmul27, (lv3553, lv1837), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1838: R.Tensor((1280, 1280), dtype="float32") = model_params[1421]
            lv3557 = R.call_tir(cls.matmul27, (lv3553, lv1838), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1839: R.Tensor((1280, 1280), dtype="float32") = model_params[1422]
            lv3559 = R.call_tir(cls.matmul27, (lv3553, lv1839), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1407_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3555,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1408_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3557,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1409_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3559,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1410_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv1407_1, lv1408_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3571 = R.call_tir(cls.softmax5, (lv1410_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3572 = R.call_tir(cls.matmul29, (lv3571, lv1409_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1411_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3572,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1840: R.Tensor((1280, 1280), dtype="float32") = model_params[1423]
            lv1841_1: R.Tensor((1280,), dtype="float32") = model_params[576]
            lv1412_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1411_1, lv1840, lv1841_1, lv1406_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1842: R.Tensor((1280,), dtype="float32") = model_params[583]
            lv1843: R.Tensor((1280,), dtype="float32") = model_params[582]
            lv3580 = R.call_tir(cls.layer_norm3, (lv1412_1, lv1842, lv1843), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1844: R.Tensor((1280, 1280), dtype="float32") = model_params[1424]
            lv3582 = R.call_tir(cls.matmul27, (lv3580, lv1844), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1845: R.Tensor((2048, 1280), dtype="float32") = model_params[1425]
            lv3584 = R.call_tir(cls.matmul30, (inp_2, lv1845), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1846: R.Tensor((2048, 1280), dtype="float32") = model_params[1426]
            lv3586 = R.call_tir(cls.matmul30, (inp_2, lv1846), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1413_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3582,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1414_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3584,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1415_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3586,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1416_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1413_1, lv1414_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3598 = R.call_tir(cls.softmax6, (lv1416_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3599 = R.call_tir(cls.matmul32, (lv3598, lv1415_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1417_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3599,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1847: R.Tensor((1280, 1280), dtype="float32") = model_params[1427]
            lv1848: R.Tensor((1280,), dtype="float32") = model_params[577]
            lv1418_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1417_1, lv1847, lv1848, lv1412_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1849: R.Tensor((1280,), dtype="float32") = model_params[585]
            lv1850_1: R.Tensor((1280,), dtype="float32") = model_params[584]
            lv3607 = R.call_tir(cls.layer_norm3, (lv1418_1, lv1849, lv1850_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1851: R.Tensor((1280, 10240), dtype="float32") = model_params[1428]
            lv1852: R.Tensor((10240,), dtype="float32") = model_params[578]
            lv1419_1 = R.call_tir(cls.fused_matmul33_add45, (lv3607, lv1851, lv1852), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1420_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1419_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1853: R.Tensor((5120, 1280), dtype="float32") = model_params[1429]
            lv1854: R.Tensor((1280,), dtype="float32") = model_params[579]
            lv1421_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1420_1, lv1853, lv1854, lv1418_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1855: R.Tensor((1280,), dtype="float32") = model_params[591]
            lv1856_1: R.Tensor((1280,), dtype="float32") = model_params[590]
            lv3620 = R.call_tir(cls.layer_norm3, (lv1421_1, lv1855, lv1856_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1857: R.Tensor((1280, 1280), dtype="float32") = model_params[1430]
            lv3622 = R.call_tir(cls.matmul27, (lv3620, lv1857), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1858_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1431]
            lv3624 = R.call_tir(cls.matmul27, (lv3620, lv1858_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1859: R.Tensor((1280, 1280), dtype="float32") = model_params[1432]
            lv3626 = R.call_tir(cls.matmul27, (lv3620, lv1859), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1422_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3622,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1423_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3624,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1424_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3626,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1425_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv1422_1, lv1423_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3638 = R.call_tir(cls.softmax5, (lv1425_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3639 = R.call_tir(cls.matmul29, (lv3638, lv1424_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1426_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3639,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1860_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1433]
            lv1861: R.Tensor((1280,), dtype="float32") = model_params[586]
            lv1427_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1426_1, lv1860_1, lv1861, lv1421_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1862_1: R.Tensor((1280,), dtype="float32") = model_params[593]
            lv1863: R.Tensor((1280,), dtype="float32") = model_params[592]
            lv3647 = R.call_tir(cls.layer_norm3, (lv1427_2, lv1862_1, lv1863), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1864: R.Tensor((1280, 1280), dtype="float32") = model_params[1434]
            lv3649 = R.call_tir(cls.matmul27, (lv3647, lv1864), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1865: R.Tensor((2048, 1280), dtype="float32") = model_params[1435]
            lv3651 = R.call_tir(cls.matmul30, (inp_2, lv1865), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1866: R.Tensor((2048, 1280), dtype="float32") = model_params[1436]
            lv3653 = R.call_tir(cls.matmul30, (inp_2, lv1866), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1428_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3649,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1429_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3651,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1430_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3653,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1431_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1428_1, lv1429_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3665 = R.call_tir(cls.softmax6, (lv1431_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3666 = R.call_tir(cls.matmul32, (lv3665, lv1430_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1432_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3666,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1867: R.Tensor((1280, 1280), dtype="float32") = model_params[1437]
            lv1868: R.Tensor((1280,), dtype="float32") = model_params[587]
            lv1433_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1432_1, lv1867, lv1868, lv1427_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1869: R.Tensor((1280,), dtype="float32") = model_params[595]
            lv1870: R.Tensor((1280,), dtype="float32") = model_params[594]
            lv3674 = R.call_tir(cls.layer_norm3, (lv1433_1, lv1869, lv1870), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1871: R.Tensor((1280, 10240), dtype="float32") = model_params[1438]
            lv1872: R.Tensor((10240,), dtype="float32") = model_params[588]
            lv1434_1 = R.call_tir(cls.fused_matmul33_add45, (lv3674, lv1871, lv1872), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1435_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1434_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1873: R.Tensor((5120, 1280), dtype="float32") = model_params[1439]
            lv1874_1: R.Tensor((1280,), dtype="float32") = model_params[589]
            lv1436_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1435_1, lv1873, lv1874_1, lv1433_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1875_1: R.Tensor((1280,), dtype="float32") = model_params[601]
            lv1876: R.Tensor((1280,), dtype="float32") = model_params[600]
            lv3687 = R.call_tir(cls.layer_norm3, (lv1436_1, lv1875_1, lv1876), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1877: R.Tensor((1280, 1280), dtype="float32") = model_params[1440]
            lv3689 = R.call_tir(cls.matmul27, (lv3687, lv1877), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1878: R.Tensor((1280, 1280), dtype="float32") = model_params[1441]
            lv3691 = R.call_tir(cls.matmul27, (lv3687, lv1878), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1879: R.Tensor((1280, 1280), dtype="float32") = model_params[1442]
            lv3693 = R.call_tir(cls.matmul27, (lv3687, lv1879), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1437_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3689,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1438_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3691,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1439_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3693,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1440_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1437_1, lv1438_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3705 = R.call_tir(cls.softmax5, (lv1440_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3706 = R.call_tir(cls.matmul29, (lv3705, lv1439_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1441_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3706,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1880: R.Tensor((1280, 1280), dtype="float32") = model_params[1443]
            lv1881: R.Tensor((1280,), dtype="float32") = model_params[596]
            lv1442_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1441_2, lv1880, lv1881, lv1436_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1882: R.Tensor((1280,), dtype="float32") = model_params[603]
            lv1883_1: R.Tensor((1280,), dtype="float32") = model_params[602]
            lv3714 = R.call_tir(cls.layer_norm3, (lv1442_2, lv1882, lv1883_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1884: R.Tensor((1280, 1280), dtype="float32") = model_params[1444]
            lv3716 = R.call_tir(cls.matmul27, (lv3714, lv1884), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1885_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1445]
            lv3718 = R.call_tir(cls.matmul30, (inp_2, lv1885_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1886: R.Tensor((2048, 1280), dtype="float32") = model_params[1446]
            lv3720 = R.call_tir(cls.matmul30, (inp_2, lv1886), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1443_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3716,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1444_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3718,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1445_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3720,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1446_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1443_1, lv1444_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3732 = R.call_tir(cls.softmax6, (lv1446_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3733 = R.call_tir(cls.matmul32, (lv3732, lv1445_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1447_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3733,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1887_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1447]
            lv1888: R.Tensor((1280,), dtype="float32") = model_params[597]
            lv1448_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1447_1, lv1887_1, lv1888, lv1442_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1889_1: R.Tensor((1280,), dtype="float32") = model_params[605]
            lv1890: R.Tensor((1280,), dtype="float32") = model_params[604]
            lv3741 = R.call_tir(cls.layer_norm3, (lv1448_1, lv1889_1, lv1890), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1891: R.Tensor((1280, 10240), dtype="float32") = model_params[1448]
            lv1892: R.Tensor((10240,), dtype="float32") = model_params[598]
            lv1449_1 = R.call_tir(cls.fused_matmul33_add45, (lv3741, lv1891, lv1892), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1450_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1449_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1893: R.Tensor((5120, 1280), dtype="float32") = model_params[1449]
            lv1894: R.Tensor((1280,), dtype="float32") = model_params[599]
            lv1451_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1450_2, lv1893, lv1894, lv1448_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1895: R.Tensor((1280,), dtype="float32") = model_params[611]
            lv1896: R.Tensor((1280,), dtype="float32") = model_params[610]
            lv3754 = R.call_tir(cls.layer_norm3, (lv1451_1, lv1895, lv1896), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1897: R.Tensor((1280, 1280), dtype="float32") = model_params[1450]
            lv3756 = R.call_tir(cls.matmul27, (lv3754, lv1897), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1898: R.Tensor((1280, 1280), dtype="float32") = model_params[1451]
            lv3758 = R.call_tir(cls.matmul27, (lv3754, lv1898), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1899: R.Tensor((1280, 1280), dtype="float32") = model_params[1452]
            lv3760 = R.call_tir(cls.matmul27, (lv3754, lv1899), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1452_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3756,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1453_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3758,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1454_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3760,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1455_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1452_2, lv1453_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3772 = R.call_tir(cls.softmax5, (lv1455_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3773 = R.call_tir(cls.matmul29, (lv3772, lv1454_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1456_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3773,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1900: R.Tensor((1280, 1280), dtype="float32") = model_params[1453]
            lv1901_1: R.Tensor((1280,), dtype="float32") = model_params[606]
            lv1457_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1456_2, lv1900, lv1901_1, lv1451_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1902_1: R.Tensor((1280,), dtype="float32") = model_params[613]
            lv1903: R.Tensor((1280,), dtype="float32") = model_params[612]
            lv3781 = R.call_tir(cls.layer_norm3, (lv1457_1, lv1902_1, lv1903), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1904: R.Tensor((1280, 1280), dtype="float32") = model_params[1454]
            lv3783 = R.call_tir(cls.matmul27, (lv3781, lv1904), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1905: R.Tensor((2048, 1280), dtype="float32") = model_params[1455]
            lv3785 = R.call_tir(cls.matmul30, (inp_2, lv1905), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1906: R.Tensor((2048, 1280), dtype="float32") = model_params[1456]
            lv3787 = R.call_tir(cls.matmul30, (inp_2, lv1906), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1458_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3783,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1459_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3785,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1460_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3787,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1461_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1458_1, lv1459_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3799 = R.call_tir(cls.softmax6, (lv1461_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3800 = R.call_tir(cls.matmul32, (lv3799, lv1460_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1462_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3800,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1907: R.Tensor((1280, 1280), dtype="float32") = model_params[1457]
            lv1908: R.Tensor((1280,), dtype="float32") = model_params[607]
            lv1463_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1462_1, lv1907, lv1908, lv1457_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1909: R.Tensor((1280,), dtype="float32") = model_params[615]
            lv1910_1: R.Tensor((1280,), dtype="float32") = model_params[614]
            lv3808 = R.call_tir(cls.layer_norm3, (lv1463_1, lv1909, lv1910_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1911: R.Tensor((1280, 10240), dtype="float32") = model_params[1458]
            lv1912: R.Tensor((10240,), dtype="float32") = model_params[608]
            lv1464_1 = R.call_tir(cls.fused_matmul33_add45, (lv3808, lv1911, lv1912), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1465_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1464_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1913: R.Tensor((5120, 1280), dtype="float32") = model_params[1459]
            lv1914: R.Tensor((1280,), dtype="float32") = model_params[609]
            lv1466_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1465_1, lv1913, lv1914, lv1463_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1915: R.Tensor((1280,), dtype="float32") = model_params[621]
            lv1916: R.Tensor((1280,), dtype="float32") = model_params[620]
            lv3821 = R.call_tir(cls.layer_norm3, (lv1466_1, lv1915, lv1916), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1917: R.Tensor((1280, 1280), dtype="float32") = model_params[1460]
            lv3823 = R.call_tir(cls.matmul27, (lv3821, lv1917), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1918: R.Tensor((1280, 1280), dtype="float32") = model_params[1461]
            lv3825 = R.call_tir(cls.matmul27, (lv3821, lv1918), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1919: R.Tensor((1280, 1280), dtype="float32") = model_params[1462]
            lv3827 = R.call_tir(cls.matmul27, (lv3821, lv1919), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1467_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3823,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1468_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3825,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1469_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3827,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1470_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1467_1, lv1468_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3839 = R.call_tir(cls.softmax5, (lv1470_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3840 = R.call_tir(cls.matmul29, (lv3839, lv1469_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1471_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3840,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1920: R.Tensor((1280, 1280), dtype="float32") = model_params[1463]
            lv1921: R.Tensor((1280,), dtype="float32") = model_params[616]
            lv1472_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1471_1, lv1920, lv1921, lv1466_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1922: R.Tensor((1280,), dtype="float32") = model_params[623]
            lv1923_1: R.Tensor((1280,), dtype="float32") = model_params[622]
            lv3848 = R.call_tir(cls.layer_norm3, (lv1472_1, lv1922, lv1923_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1924: R.Tensor((1280, 1280), dtype="float32") = model_params[1464]
            lv3850 = R.call_tir(cls.matmul27, (lv3848, lv1924), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1925_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1465]
            lv3852 = R.call_tir(cls.matmul30, (inp_2, lv1925_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1926: R.Tensor((2048, 1280), dtype="float32") = model_params[1466]
            lv3854 = R.call_tir(cls.matmul30, (inp_2, lv1926), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1473_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3850,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1474_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3852,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1475_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv3854,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1476_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1473_1, lv1474_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3866 = R.call_tir(cls.softmax6, (lv1476_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3867 = R.call_tir(cls.matmul32, (lv3866, lv1475_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1477_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3867,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1927_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1467]
            lv1928: R.Tensor((1280,), dtype="float32") = model_params[617]
            lv1478_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1477_2, lv1927_1, lv1928, lv1472_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1929_1: R.Tensor((1280,), dtype="float32") = model_params[625]
            lv1930: R.Tensor((1280,), dtype="float32") = model_params[624]
            lv3875 = R.call_tir(cls.layer_norm3, (lv1478_1, lv1929_1, lv1930), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1931: R.Tensor((1280, 10240), dtype="float32") = model_params[1468]
            lv1932: R.Tensor((10240,), dtype="float32") = model_params[618]
            lv1479_1 = R.call_tir(cls.fused_matmul33_add45, (lv3875, lv1931, lv1932), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1480_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1479_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1933: R.Tensor((5120, 1280), dtype="float32") = model_params[1469]
            lv1934: R.Tensor((1280,), dtype="float32") = model_params[619]
            lv1481_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1480_1, lv1933, lv1934, lv1478_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1935: R.Tensor((1280,), dtype="float32") = model_params[631]
            lv1936: R.Tensor((1280,), dtype="float32") = model_params[630]
            lv3888 = R.call_tir(cls.layer_norm3, (lv1481_1, lv1935, lv1936), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1937: R.Tensor((1280, 1280), dtype="float32") = model_params[1470]
            lv3890 = R.call_tir(cls.matmul27, (lv3888, lv1937), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1938: R.Tensor((1280, 1280), dtype="float32") = model_params[1471]
            lv3892 = R.call_tir(cls.matmul27, (lv3888, lv1938), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1939: R.Tensor((1280, 1280), dtype="float32") = model_params[1472]
            lv3894 = R.call_tir(cls.matmul27, (lv3888, lv1939), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1482_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3890,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1483_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3892,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1484_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3894,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1485_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1482_1, lv1483_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3906 = R.call_tir(cls.softmax5, (lv1485_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv3907 = R.call_tir(cls.matmul29, (lv3906, lv1484_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1486_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv3907,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1940: R.Tensor((1280, 1280), dtype="float32") = model_params[1473]
            lv1941_1: R.Tensor((1280,), dtype="float32") = model_params[626]
            lv1487_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1486_1, lv1940, lv1941_1, lv1481_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1942_1: R.Tensor((1280,), dtype="float32") = model_params[633]
            lv1943: R.Tensor((1280,), dtype="float32") = model_params[632]
            lv3915 = R.call_tir(cls.layer_norm3, (lv1487_1, lv1942_1, lv1943), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1944: R.Tensor((1280, 1280), dtype="float32") = model_params[1474]
            lv3917 = R.call_tir(cls.matmul27, (lv3915, lv1944), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1945: R.Tensor((2048, 1280), dtype="float32") = model_params[1475]
            lv3919 = R.call_tir(cls.matmul30, (inp_2, lv1945), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1946: R.Tensor((2048, 1280), dtype="float32") = model_params[1476]
            lv3921 = R.call_tir(cls.matmul30, (inp_2, lv1946), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1488_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3917,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1489_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv3919,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1490_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv3921,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1491_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1488_1, lv1489_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3933 = R.call_tir(cls.softmax6, (lv1491_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv3934 = R.call_tir(cls.matmul32, (lv3933, lv1490_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1492_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv3934,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1947: R.Tensor((1280, 1280), dtype="float32") = model_params[1477]
            lv1948: R.Tensor((1280,), dtype="float32") = model_params[627]
            lv1493_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1492_2, lv1947, lv1948, lv1487_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1949: R.Tensor((1280,), dtype="float32") = model_params[635]
            lv1950_1: R.Tensor((1280,), dtype="float32") = model_params[634]
            lv3942 = R.call_tir(cls.layer_norm3, (lv1493_1, lv1949, lv1950_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1951: R.Tensor((1280, 10240), dtype="float32") = model_params[1478]
            lv1952_1: R.Tensor((10240,), dtype="float32") = model_params[628]
            lv1494_2 = R.call_tir(cls.fused_matmul33_add45, (lv3942, lv1951, lv1952_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1495_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1494_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1953: R.Tensor((5120, 1280), dtype="float32") = model_params[1479]
            lv1954_1: R.Tensor((1280,), dtype="float32") = model_params[629]
            lv1496_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1495_1, lv1953, lv1954_1, lv1493_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1955: R.Tensor((1280, 1280), dtype="float32") = model_params[1480]
            lv1956_1: R.Tensor((1280,), dtype="float32") = model_params[535]
            lv1497_1 = R.call_tir(cls.fused_matmul27_add43, (lv1496_2, lv1955, lv1956_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1498_1 = R.call_tir(cls.fused_reshape49_transpose42_add42_concatenate8, (lv1497_1, lv1344_1, lv695), out_sinfo=R.Tensor((2, 1920, 32, 32), dtype="float32"))
            lv1957: R.Tensor((1920,), dtype="float32") = model_params[760]
            lv1958: R.Tensor((1920,), dtype="float32") = model_params[759]
            lv1499_1 = R.call_tir(cls.fused_group_norm15_silu13, (lv1498_1, lv1957, lv1958), out_sinfo=R.Tensor((2, 1920, 32, 32), dtype="float32"))
            lv3967 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv1959: R.Tensor((1280, 1280), dtype="float32") = model_params[1482]
            lv1960: R.Tensor((1280,), dtype="float32") = model_params[763]
            lv1500_1 = R.call_tir(cls.fused_matmul15_add25_strided_slice8, (lv3967, lv1959, lv1960), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv3972 = R.call_tir(cls.reshape44, (lv1500_1,), out_sinfo=R.Tensor((2, 1280, 1, 1), dtype="float32"))
            lv1961: R.Tensor((1280, 1920, 3, 3), dtype="float32") = model_params[756]
            lv1962: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1481]
            lv1501_1 = R.call_tir(cls.fused_conv2d25_add40_add41, (lv1499_1, lv1961, lv1962, lv3972), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1963: R.Tensor((1280,), dtype="float32") = model_params[762]
            lv1964: R.Tensor((1280,), dtype="float32") = model_params[761]
            lv1502_1 = R.call_tir(cls.fused_group_norm12_silu11, (lv1501_1, lv1963, lv1964), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1965: R.Tensor((1280, 1920, 1, 1), dtype="float32") = model_params[758]
            lv1966: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1484]
            lv1503_1 = R.call_tir(cls.fused_conv2d26_add40, (lv1498_1, lv1965, lv1966), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1967: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[757]
            lv1968_1: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1483]
            lv1504_1 = R.call_tir(cls.fused_conv2d21_add40_add42_divide10, (lv1502_1, lv1967, lv1968_1, lv1503_1), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1969_1: R.Tensor((1280,), dtype="float32") = model_params[637]
            lv1970: R.Tensor((1280,), dtype="float32") = model_params[636]
            lv3984 = R.call_tir(cls.group_norm13, (lv1504_1, lv1969_1, lv1970), out_sinfo=R.Tensor((2, 1280, 32, 32), dtype="float32"))
            lv1505_1 = R.call_tir(cls.fused_transpose34_reshape45, (lv3984,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1971: R.Tensor((1280, 1280), dtype="float32") = model_params[1485]
            lv1972: R.Tensor((1280,), dtype="float32") = model_params[638]
            lv1506_1 = R.call_tir(cls.fused_matmul27_add43, (lv1505_1, lv1971, lv1972), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1973: R.Tensor((1280,), dtype="float32") = model_params[645]
            lv1974: R.Tensor((1280,), dtype="float32") = model_params[644]
            lv3990 = R.call_tir(cls.layer_norm3, (lv1506_1, lv1973, lv1974), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1975: R.Tensor((1280, 1280), dtype="float32") = model_params[1486]
            lv3992 = R.call_tir(cls.matmul27, (lv3990, lv1975), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1976: R.Tensor((1280, 1280), dtype="float32") = model_params[1487]
            lv3994 = R.call_tir(cls.matmul27, (lv3990, lv1976), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1977_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1488]
            lv3996 = R.call_tir(cls.matmul27, (lv3990, lv1977_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1507_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv3992,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1508_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv3994,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1509_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv3996,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1510_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1507_1, lv1508_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4008 = R.call_tir(cls.softmax5, (lv1510_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4009 = R.call_tir(cls.matmul29, (lv4008, lv1509_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1511_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4009,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1978: R.Tensor((1280, 1280), dtype="float32") = model_params[1489]
            lv1979: R.Tensor((1280,), dtype="float32") = model_params[640]
            lv1512_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1511_1, lv1978, lv1979, lv1506_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1980: R.Tensor((1280,), dtype="float32") = model_params[647]
            lv1981: R.Tensor((1280,), dtype="float32") = model_params[646]
            lv4017 = R.call_tir(cls.layer_norm3, (lv1512_1, lv1980, lv1981), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1982: R.Tensor((1280, 1280), dtype="float32") = model_params[1490]
            lv4019 = R.call_tir(cls.matmul27, (lv4017, lv1982), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1983: R.Tensor((2048, 1280), dtype="float32") = model_params[1491]
            lv4021 = R.call_tir(cls.matmul30, (inp_2, lv1983), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1984: R.Tensor((2048, 1280), dtype="float32") = model_params[1492]
            lv4023 = R.call_tir(cls.matmul30, (inp_2, lv1984), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1513_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4019,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1514_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4021,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1515_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4023,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1516_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1513_1, lv1514_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4035 = R.call_tir(cls.softmax6, (lv1516_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4036 = R.call_tir(cls.matmul32, (lv4035, lv1515_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1517_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv4036,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1985: R.Tensor((1280, 1280), dtype="float32") = model_params[1493]
            lv1986: R.Tensor((1280,), dtype="float32") = model_params[641]
            lv1518_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1517_2, lv1985, lv1986, lv1512_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1987: R.Tensor((1280,), dtype="float32") = model_params[649]
            lv1988: R.Tensor((1280,), dtype="float32") = model_params[648]
            lv4044 = R.call_tir(cls.layer_norm3, (lv1518_1, lv1987, lv1988), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1989: R.Tensor((1280, 10240), dtype="float32") = model_params[1494]
            lv1990_1: R.Tensor((10240,), dtype="float32") = model_params[642]
            lv1519_2 = R.call_tir(cls.fused_matmul33_add45, (lv4044, lv1989, lv1990_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1520_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1519_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv1991: R.Tensor((5120, 1280), dtype="float32") = model_params[1495]
            lv1992_1: R.Tensor((1280,), dtype="float32") = model_params[643]
            lv1521_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1520_1, lv1991, lv1992_1, lv1518_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1993: R.Tensor((1280,), dtype="float32") = model_params[655]
            lv1994_1: R.Tensor((1280,), dtype="float32") = model_params[654]
            lv4057 = R.call_tir(cls.layer_norm3, (lv1521_2, lv1993, lv1994_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1995: R.Tensor((1280, 1280), dtype="float32") = model_params[1496]
            lv4059 = R.call_tir(cls.matmul27, (lv4057, lv1995), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1996_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1497]
            lv4061 = R.call_tir(cls.matmul27, (lv4057, lv1996_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1997: R.Tensor((1280, 1280), dtype="float32") = model_params[1498]
            lv4063 = R.call_tir(cls.matmul27, (lv4057, lv1997), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1522_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4059,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1523_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4061,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1524_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4063,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1525_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1522_1, lv1523_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4075 = R.call_tir(cls.softmax5, (lv1525_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4076 = R.call_tir(cls.matmul29, (lv4075, lv1524_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1526_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4076,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1998: R.Tensor((1280, 1280), dtype="float32") = model_params[1499]
            lv1999: R.Tensor((1280,), dtype="float32") = model_params[650]
            lv1527_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1526_1, lv1998, lv1999, lv1521_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2000: R.Tensor((1280,), dtype="float32") = model_params[657]
            lv2001: R.Tensor((1280,), dtype="float32") = model_params[656]
            lv4084 = R.call_tir(cls.layer_norm3, (lv1527_1, lv2000, lv2001), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2002: R.Tensor((1280, 1280), dtype="float32") = model_params[1500]
            lv4086 = R.call_tir(cls.matmul27, (lv4084, lv2002), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2003: R.Tensor((2048, 1280), dtype="float32") = model_params[1501]
            lv4088 = R.call_tir(cls.matmul30, (inp_2, lv2003), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2004: R.Tensor((2048, 1280), dtype="float32") = model_params[1502]
            lv4090 = R.call_tir(cls.matmul30, (inp_2, lv2004), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1528_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4086,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1529_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4088,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1530_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4090,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1531_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1528_1, lv1529_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4102 = R.call_tir(cls.softmax6, (lv1531_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4103 = R.call_tir(cls.matmul32, (lv4102, lv1530_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1532_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4103,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2005: R.Tensor((1280, 1280), dtype="float32") = model_params[1503]
            lv2006: R.Tensor((1280,), dtype="float32") = model_params[651]
            lv1533_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1532_1, lv2005, lv2006, lv1527_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2007: R.Tensor((1280,), dtype="float32") = model_params[659]
            lv2008_1: R.Tensor((1280,), dtype="float32") = model_params[658]
            lv4111 = R.call_tir(cls.layer_norm3, (lv1533_1, lv2007, lv2008_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2009_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1504]
            lv2010: R.Tensor((10240,), dtype="float32") = model_params[652]
            lv1534_1 = R.call_tir(cls.fused_matmul33_add45, (lv4111, lv2009_1, lv2010), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1535_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1534_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2011: R.Tensor((5120, 1280), dtype="float32") = model_params[1505]
            lv2012: R.Tensor((1280,), dtype="float32") = model_params[653]
            lv1536_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1535_2, lv2011, lv2012, lv1533_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2013: R.Tensor((1280,), dtype="float32") = model_params[665]
            lv2014: R.Tensor((1280,), dtype="float32") = model_params[664]
            lv4124 = R.call_tir(cls.layer_norm3, (lv1536_2, lv2013, lv2014), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2015: R.Tensor((1280, 1280), dtype="float32") = model_params[1506]
            lv4126 = R.call_tir(cls.matmul27, (lv4124, lv2015), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2016: R.Tensor((1280, 1280), dtype="float32") = model_params[1507]
            lv4128 = R.call_tir(cls.matmul27, (lv4124, lv2016), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2017_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1508]
            lv4130 = R.call_tir(cls.matmul27, (lv4124, lv2017_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1537_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4126,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1538_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4128,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1539_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4130,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1540_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1537_1, lv1538_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4142 = R.call_tir(cls.softmax5, (lv1540_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4143 = R.call_tir(cls.matmul29, (lv4142, lv1539_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1541_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4143,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2018: R.Tensor((1280, 1280), dtype="float32") = model_params[1509]
            lv2019_1: R.Tensor((1280,), dtype="float32") = model_params[660]
            lv1542_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1541_1, lv2018, lv2019_1, lv1536_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2020: R.Tensor((1280,), dtype="float32") = model_params[667]
            lv2021_1: R.Tensor((1280,), dtype="float32") = model_params[666]
            lv4151 = R.call_tir(cls.layer_norm3, (lv1542_1, lv2020, lv2021_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2022: R.Tensor((1280, 1280), dtype="float32") = model_params[1510]
            lv4153 = R.call_tir(cls.matmul27, (lv4151, lv2022), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2023_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1511]
            lv4155 = R.call_tir(cls.matmul30, (inp_2, lv2023_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2024: R.Tensor((2048, 1280), dtype="float32") = model_params[1512]
            lv4157 = R.call_tir(cls.matmul30, (inp_2, lv2024), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1543_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4153,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1544_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4155,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1545_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4157,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1546_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1543_1, lv1544_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4169 = R.call_tir(cls.softmax6, (lv1546_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4170 = R.call_tir(cls.matmul32, (lv4169, lv1545_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1547_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4170,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2025: R.Tensor((1280, 1280), dtype="float32") = model_params[1513]
            lv2026: R.Tensor((1280,), dtype="float32") = model_params[661]
            lv1548_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1547_1, lv2025, lv2026, lv1542_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2027: R.Tensor((1280,), dtype="float32") = model_params[669]
            lv2028: R.Tensor((1280,), dtype="float32") = model_params[668]
            lv4178 = R.call_tir(cls.layer_norm3, (lv1548_1, lv2027, lv2028), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2029: R.Tensor((1280, 10240), dtype="float32") = model_params[1514]
            lv2030: R.Tensor((10240,), dtype="float32") = model_params[662]
            lv1549_1 = R.call_tir(cls.fused_matmul33_add45, (lv4178, lv2029, lv2030), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1550_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1549_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2031: R.Tensor((5120, 1280), dtype="float32") = model_params[1515]
            lv2032: R.Tensor((1280,), dtype="float32") = model_params[663]
            lv1551_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1550_1, lv2031, lv2032, lv1548_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2033: R.Tensor((1280,), dtype="float32") = model_params[675]
            lv2034: R.Tensor((1280,), dtype="float32") = model_params[674]
            lv4191 = R.call_tir(cls.layer_norm3, (lv1551_1, lv2033, lv2034), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2035_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1516]
            lv4193 = R.call_tir(cls.matmul27, (lv4191, lv2035_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2036_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1517]
            lv4195 = R.call_tir(cls.matmul27, (lv4191, lv2036_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2037: R.Tensor((1280, 1280), dtype="float32") = model_params[1518]
            lv4197 = R.call_tir(cls.matmul27, (lv4191, lv2037), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1552_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4193,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1553_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4195,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1554_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4197,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1555_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1552_1, lv1553_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4209 = R.call_tir(cls.softmax5, (lv1555_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4210 = R.call_tir(cls.matmul29, (lv4209, lv1554_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1556_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4210,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2038: R.Tensor((1280, 1280), dtype="float32") = model_params[1519]
            lv2039: R.Tensor((1280,), dtype="float32") = model_params[670]
            lv1557_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1556_1, lv2038, lv2039, lv1551_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2040: R.Tensor((1280,), dtype="float32") = model_params[677]
            lv2041: R.Tensor((1280,), dtype="float32") = model_params[676]
            lv4218 = R.call_tir(cls.layer_norm3, (lv1557_2, lv2040, lv2041), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2042: R.Tensor((1280, 1280), dtype="float32") = model_params[1520]
            lv4220 = R.call_tir(cls.matmul27, (lv4218, lv2042), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2043: R.Tensor((2048, 1280), dtype="float32") = model_params[1521]
            lv4222 = R.call_tir(cls.matmul30, (inp_2, lv2043), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2044_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1522]
            lv4224 = R.call_tir(cls.matmul30, (inp_2, lv2044_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1558_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4220,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1559_2 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4222,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1560_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4224,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1561_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1558_1, lv1559_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4236 = R.call_tir(cls.softmax6, (lv1561_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4237 = R.call_tir(cls.matmul32, (lv4236, lv1560_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1562_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4237,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2045: R.Tensor((1280, 1280), dtype="float32") = model_params[1523]
            lv2046: R.Tensor((1280,), dtype="float32") = model_params[671]
            lv1563_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1562_1, lv2045, lv2046, lv1557_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2047: R.Tensor((1280,), dtype="float32") = model_params[679]
            lv2048: R.Tensor((1280,), dtype="float32") = model_params[678]
            lv4245 = R.call_tir(cls.layer_norm3, (lv1563_2, lv2047, lv2048), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2049: R.Tensor((1280, 10240), dtype="float32") = model_params[1524]
            lv2050: R.Tensor((10240,), dtype="float32") = model_params[672]
            lv1564_1 = R.call_tir(cls.fused_matmul33_add45, (lv4245, lv2049, lv2050), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1565_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1564_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2051: R.Tensor((5120, 1280), dtype="float32") = model_params[1525]
            lv2052: R.Tensor((1280,), dtype="float32") = model_params[673]
            lv1566_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1565_1, lv2051, lv2052, lv1563_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2053: R.Tensor((1280,), dtype="float32") = model_params[685]
            lv2054: R.Tensor((1280,), dtype="float32") = model_params[684]
            lv4258 = R.call_tir(cls.layer_norm3, (lv1566_1, lv2053, lv2054), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2055: R.Tensor((1280, 1280), dtype="float32") = model_params[1526]
            lv4260 = R.call_tir(cls.matmul27, (lv4258, lv2055), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2056: R.Tensor((1280, 1280), dtype="float32") = model_params[1527]
            lv4262 = R.call_tir(cls.matmul27, (lv4258, lv2056), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2057_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1528]
            lv4264 = R.call_tir(cls.matmul27, (lv4258, lv2057_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1567_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4260,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1568_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4262,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1569_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4264,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1570_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1567_1, lv1568_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4276 = R.call_tir(cls.softmax5, (lv1570_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4277 = R.call_tir(cls.matmul29, (lv4276, lv1569_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1571_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4277,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2058: R.Tensor((1280, 1280), dtype="float32") = model_params[1529]
            lv2059_1: R.Tensor((1280,), dtype="float32") = model_params[680]
            lv1572_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1571_1, lv2058, lv2059_1, lv1566_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2060: R.Tensor((1280,), dtype="float32") = model_params[687]
            lv2061_1: R.Tensor((1280,), dtype="float32") = model_params[686]
            lv4285 = R.call_tir(cls.layer_norm3, (lv1572_1, lv2060, lv2061_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2062: R.Tensor((1280, 1280), dtype="float32") = model_params[1530]
            lv4287 = R.call_tir(cls.matmul27, (lv4285, lv2062), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2063_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1531]
            lv4289 = R.call_tir(cls.matmul30, (inp_2, lv2063_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2064: R.Tensor((2048, 1280), dtype="float32") = model_params[1532]
            lv4291 = R.call_tir(cls.matmul30, (inp_2, lv2064), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1573_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4287,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1574_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4289,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1575_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv4291,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1576_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1573_1, lv1574_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4303 = R.call_tir(cls.softmax6, (lv1576_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4304 = R.call_tir(cls.matmul32, (lv4303, lv1575_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1577_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4304,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2065: R.Tensor((1280, 1280), dtype="float32") = model_params[1533]
            lv2066: R.Tensor((1280,), dtype="float32") = model_params[681]
            lv1578_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1577_1, lv2065, lv2066, lv1572_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2067: R.Tensor((1280,), dtype="float32") = model_params[689]
            lv2068: R.Tensor((1280,), dtype="float32") = model_params[688]
            lv4312 = R.call_tir(cls.layer_norm3, (lv1578_1, lv2067, lv2068), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2069: R.Tensor((1280, 10240), dtype="float32") = model_params[1534]
            lv2070: R.Tensor((10240,), dtype="float32") = model_params[682]
            lv1579_1 = R.call_tir(cls.fused_matmul33_add45, (lv4312, lv2069, lv2070), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1580_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1579_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2071: R.Tensor((5120, 1280), dtype="float32") = model_params[1535]
            lv2072: R.Tensor((1280,), dtype="float32") = model_params[683]
            lv1581_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1580_1, lv2071, lv2072, lv1578_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2073: R.Tensor((1280,), dtype="float32") = model_params[695]
            lv2074: R.Tensor((1280,), dtype="float32") = model_params[694]
            lv4325 = R.call_tir(cls.layer_norm3, (lv1581_1, lv2073, lv2074), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2075_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1536]
            lv4327 = R.call_tir(cls.matmul27, (lv4325, lv2075_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2076_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1537]
            lv4329 = R.call_tir(cls.matmul27, (lv4325, lv2076_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2077: R.Tensor((1280, 1280), dtype="float32") = model_params[1538]
            lv4331 = R.call_tir(cls.matmul27, (lv4325, lv2077), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1582_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4327,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1583_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4329,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1584_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv4331,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1585_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1582_1, lv1583_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4343 = R.call_tir(cls.softmax5, (lv1585_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4344 = R.call_tir(cls.matmul29, (lv4343, lv1584_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1586_2 = R.call_tir(cls.fused_transpose37_reshape47, (lv4344,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2078: R.Tensor((1280, 1280), dtype="float32") = model_params[1539]
            lv2079: R.Tensor((1280,), dtype="float32") = model_params[690]
            lv1587_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1586_2, lv2078, lv2079, lv1581_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2080: R.Tensor((1280,), dtype="float32") = model_params[697]
            lv2081: R.Tensor((1280,), dtype="float32") = model_params[696]
            lv4352 = R.call_tir(cls.layer_norm3, (lv1587_1, lv2080, lv2081), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2082: R.Tensor((1280, 1280), dtype="float32") = model_params[1540]
            lv4354 = R.call_tir(cls.matmul27, (lv4352, lv2082), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2083: R.Tensor((2048, 1280), dtype="float32") = model_params[1541]
            lv4356 = R.call_tir(cls.matmul30, (inp_2, lv2083), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2084_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1542]
            lv4358 = R.call_tir(cls.matmul30, (inp_2, lv2084_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1588_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv4354,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1589_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4356,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1590_2 = R.call_tir(cls.fused_reshape48_transpose39, (lv4358,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1591_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1588_2, lv1589_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4370 = R.call_tir(cls.softmax6, (lv1591_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4371 = R.call_tir(cls.matmul32, (lv4370, lv1590_2), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1592_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4371,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2085: R.Tensor((1280, 1280), dtype="float32") = model_params[1543]
            lv2086_1: R.Tensor((1280,), dtype="float32") = model_params[691]
            lv1593_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1592_1, lv2085, lv2086_1, lv1587_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2087: R.Tensor((1280,), dtype="float32") = model_params[699]
            lv2088_1: R.Tensor((1280,), dtype="float32") = model_params[698]
            lv4379 = R.call_tir(cls.layer_norm3, (lv1593_1, lv2087, lv2088_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2089: R.Tensor((1280, 10240), dtype="float32") = model_params[1544]
            lv2090_1: R.Tensor((10240,), dtype="float32") = model_params[692]
            lv1594_1 = R.call_tir(cls.fused_matmul33_add45, (lv4379, lv2089, lv2090_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1595_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1594_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2091: R.Tensor((5120, 1280), dtype="float32") = model_params[1545]
            lv2092: R.Tensor((1280,), dtype="float32") = model_params[693]
            lv1596_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1595_1, lv2091, lv2092, lv1593_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2093: R.Tensor((1280,), dtype="float32") = model_params[705]
            lv2094: R.Tensor((1280,), dtype="float32") = model_params[704]
            lv4392 = R.call_tir(cls.layer_norm3, (lv1596_1, lv2093, lv2094), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2095: R.Tensor((1280, 1280), dtype="float32") = model_params[1546]
            lv4394 = R.call_tir(cls.matmul27, (lv4392, lv2095), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2096: R.Tensor((1280, 1280), dtype="float32") = model_params[1547]
            lv4396 = R.call_tir(cls.matmul27, (lv4392, lv2096), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2097: R.Tensor((1280, 1280), dtype="float32") = model_params[1548]
            lv4398 = R.call_tir(cls.matmul27, (lv4392, lv2097), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1597_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4394,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1598_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4396,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1599_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4398,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1600_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1597_1, lv1598_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4410 = R.call_tir(cls.softmax5, (lv1600_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4411 = R.call_tir(cls.matmul29, (lv4410, lv1599_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1601_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4411,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2098: R.Tensor((1280, 1280), dtype="float32") = model_params[1549]
            lv2099: R.Tensor((1280,), dtype="float32") = model_params[700]
            lv1602_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1601_1, lv2098, lv2099, lv1596_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2100: R.Tensor((1280,), dtype="float32") = model_params[707]
            lv2101: R.Tensor((1280,), dtype="float32") = model_params[706]
            lv4419 = R.call_tir(cls.layer_norm3, (lv1602_2, lv2100, lv2101), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2102_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1550]
            lv4421 = R.call_tir(cls.matmul27, (lv4419, lv2102_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2103_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1551]
            lv4423 = R.call_tir(cls.matmul30, (inp_2, lv2103_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2104: R.Tensor((2048, 1280), dtype="float32") = model_params[1552]
            lv4425 = R.call_tir(cls.matmul30, (inp_2, lv2104), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1603_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv4421,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1604_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4423,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1605_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4425,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1606_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1603_2, lv1604_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4437 = R.call_tir(cls.softmax6, (lv1606_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4438 = R.call_tir(cls.matmul32, (lv4437, lv1605_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1607_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4438,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2105: R.Tensor((1280, 1280), dtype="float32") = model_params[1553]
            lv2106: R.Tensor((1280,), dtype="float32") = model_params[701]
            lv1608_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1607_1, lv2105, lv2106, lv1602_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2107: R.Tensor((1280,), dtype="float32") = model_params[709]
            lv2108: R.Tensor((1280,), dtype="float32") = model_params[708]
            lv4446 = R.call_tir(cls.layer_norm3, (lv1608_1, lv2107, lv2108), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2109: R.Tensor((1280, 10240), dtype="float32") = model_params[1554]
            lv2110: R.Tensor((10240,), dtype="float32") = model_params[702]
            lv1609_1 = R.call_tir(cls.fused_matmul33_add45, (lv4446, lv2109, lv2110), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1610_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1609_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2111_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1555]
            lv2112: R.Tensor((1280,), dtype="float32") = model_params[703]
            lv1611_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1610_1, lv2111_1, lv2112, lv1608_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2113: R.Tensor((1280,), dtype="float32") = model_params[715]
            lv2114: R.Tensor((1280,), dtype="float32") = model_params[714]
            lv4459 = R.call_tir(cls.layer_norm3, (lv1611_2, lv2113, lv2114), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2115: R.Tensor((1280, 1280), dtype="float32") = model_params[1556]
            lv4461 = R.call_tir(cls.matmul27, (lv4459, lv2115), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2116: R.Tensor((1280, 1280), dtype="float32") = model_params[1557]
            lv4463 = R.call_tir(cls.matmul27, (lv4459, lv2116), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2117: R.Tensor((1280, 1280), dtype="float32") = model_params[1558]
            lv4465 = R.call_tir(cls.matmul27, (lv4459, lv2117), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1612_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4461,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1613_1 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4463,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1614_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4465,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1615_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1612_1, lv1613_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4477 = R.call_tir(cls.softmax5, (lv1615_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4478 = R.call_tir(cls.matmul29, (lv4477, lv1614_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1616_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4478,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2118: R.Tensor((1280, 1280), dtype="float32") = model_params[1559]
            lv2119: R.Tensor((1280,), dtype="float32") = model_params[710]
            lv1617_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1616_1, lv2118, lv2119, lv1611_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2120: R.Tensor((1280,), dtype="float32") = model_params[717]
            lv2121: R.Tensor((1280,), dtype="float32") = model_params[716]
            lv4486 = R.call_tir(cls.layer_norm3, (lv1617_1, lv2120, lv2121), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2122: R.Tensor((1280, 1280), dtype="float32") = model_params[1560]
            lv4488 = R.call_tir(cls.matmul27, (lv4486, lv2122), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2123: R.Tensor((2048, 1280), dtype="float32") = model_params[1561]
            lv4490 = R.call_tir(cls.matmul30, (inp_2, lv2123), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2124_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1562]
            lv4492 = R.call_tir(cls.matmul30, (inp_2, lv2124_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1618_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4488,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1619_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4490,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1620_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4492,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1621_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1618_1, lv1619_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4504 = R.call_tir(cls.softmax6, (lv1621_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4505 = R.call_tir(cls.matmul32, (lv4504, lv1620_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1622_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4505,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2125: R.Tensor((1280, 1280), dtype="float32") = model_params[1563]
            lv2126_1: R.Tensor((1280,), dtype="float32") = model_params[711]
            lv1623_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1622_1, lv2125, lv2126_1, lv1617_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2127: R.Tensor((1280,), dtype="float32") = model_params[719]
            lv2128_1: R.Tensor((1280,), dtype="float32") = model_params[718]
            lv4513 = R.call_tir(cls.layer_norm3, (lv1623_1, lv2127, lv2128_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2129: R.Tensor((1280, 10240), dtype="float32") = model_params[1564]
            lv2130_1: R.Tensor((10240,), dtype="float32") = model_params[712]
            lv1624_2 = R.call_tir(cls.fused_matmul33_add45, (lv4513, lv2129, lv2130_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1625_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1624_2,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2131: R.Tensor((5120, 1280), dtype="float32") = model_params[1565]
            lv2132: R.Tensor((1280,), dtype="float32") = model_params[713]
            lv1626_2 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1625_1, lv2131, lv2132, lv1623_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2133: R.Tensor((1280,), dtype="float32") = model_params[725]
            lv2134: R.Tensor((1280,), dtype="float32") = model_params[724]
            lv4526 = R.call_tir(cls.layer_norm3, (lv1626_2, lv2133, lv2134), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2135: R.Tensor((1280, 1280), dtype="float32") = model_params[1566]
            lv4528 = R.call_tir(cls.matmul27, (lv4526, lv2135), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2136: R.Tensor((1280, 1280), dtype="float32") = model_params[1567]
            lv4530 = R.call_tir(cls.matmul27, (lv4526, lv2136), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2137: R.Tensor((1280, 1280), dtype="float32") = model_params[1568]
            lv4532 = R.call_tir(cls.matmul27, (lv4526, lv2137), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1627_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4528,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1628_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4530,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1629_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4532,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1630_2 = R.call_tir(cls.fused_matmul28_multiply15, (lv1627_1, lv1628_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4544 = R.call_tir(cls.softmax5, (lv1630_2,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4545 = R.call_tir(cls.matmul29, (lv4544, lv1629_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1631_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4545,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2138: R.Tensor((1280, 1280), dtype="float32") = model_params[1569]
            lv2139: R.Tensor((1280,), dtype="float32") = model_params[720]
            lv1632_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1631_1, lv2138, lv2139, lv1626_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2140: R.Tensor((1280,), dtype="float32") = model_params[727]
            lv2141: R.Tensor((1280,), dtype="float32") = model_params[726]
            lv4553 = R.call_tir(cls.layer_norm3, (lv1632_1, lv2140, lv2141), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2142_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1570]
            lv4555 = R.call_tir(cls.matmul27, (lv4553, lv2142_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2143_1: R.Tensor((2048, 1280), dtype="float32") = model_params[1571]
            lv4557 = R.call_tir(cls.matmul30, (inp_2, lv2143_1), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2144: R.Tensor((2048, 1280), dtype="float32") = model_params[1572]
            lv4559 = R.call_tir(cls.matmul30, (inp_2, lv2144), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1633_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4555,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1634_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4557,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1635_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4559,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1636_1 = R.call_tir(cls.fused_matmul31_multiply16, (lv1633_1, lv1634_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4571 = R.call_tir(cls.softmax6, (lv1636_1,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4572 = R.call_tir(cls.matmul32, (lv4571, lv1635_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1637_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4572,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2145: R.Tensor((1280, 1280), dtype="float32") = model_params[1573]
            lv2146: R.Tensor((1280,), dtype="float32") = model_params[721]
            lv1638_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1637_1, lv2145, lv2146, lv1632_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2147: R.Tensor((1280,), dtype="float32") = model_params[729]
            lv2148: R.Tensor((1280,), dtype="float32") = model_params[728]
            lv4580 = R.call_tir(cls.layer_norm3, (lv1638_1, lv2147, lv2148), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2149: R.Tensor((1280, 10240), dtype="float32") = model_params[1574]
            lv2150: R.Tensor((10240,), dtype="float32") = model_params[722]
            lv1639_1 = R.call_tir(cls.fused_matmul33_add45, (lv4580, lv2149, lv2150), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1640_1 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1639_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2151_1: R.Tensor((5120, 1280), dtype="float32") = model_params[1575]
            lv2152: R.Tensor((1280,), dtype="float32") = model_params[723]
            lv1641_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1640_1, lv2151_1, lv2152, lv1638_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2153_1: R.Tensor((1280,), dtype="float32") = model_params[735]
            lv2154: R.Tensor((1280,), dtype="float32") = model_params[734]
            lv4593 = R.call_tir(cls.layer_norm3, (lv1641_1, lv2153_1, lv2154), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2155_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1576]
            lv4595 = R.call_tir(cls.matmul27, (lv4593, lv2155_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2156: R.Tensor((1280, 1280), dtype="float32") = model_params[1577]
            lv4597 = R.call_tir(cls.matmul27, (lv4593, lv2156), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2157_1: R.Tensor((1280, 1280), dtype="float32") = model_params[1578]
            lv4599 = R.call_tir(cls.matmul27, (lv4593, lv2157_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1642_2 = R.call_tir(cls.fused_reshape46_transpose35, (lv4595,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1643_2 = R.call_tir(cls.fused_reshape46_transpose35_transpose36, (lv4597,), out_sinfo=R.Tensor((2, 20, 64, 1024), dtype="float32"))
            lv1644_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4599,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1645_1 = R.call_tir(cls.fused_matmul28_multiply15, (lv1642_2, lv1643_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4611 = R.call_tir(cls.softmax5, (lv1645_1,), out_sinfo=R.Tensor((2, 20, 1024, 1024), dtype="float32"))
            lv4612 = R.call_tir(cls.matmul29, (lv4611, lv1644_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1646_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4612,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2158: R.Tensor((1280, 1280), dtype="float32") = model_params[1579]
            lv2159: R.Tensor((1280,), dtype="float32") = model_params[730]
            lv1647_1 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1646_1, lv2158, lv2159, lv1641_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2160: R.Tensor((1280,), dtype="float32") = model_params[737]
            lv2161: R.Tensor((1280,), dtype="float32") = model_params[736]
            lv4620 = R.call_tir(cls.layer_norm3, (lv1647_1, lv2160, lv2161), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2162: R.Tensor((1280, 1280), dtype="float32") = model_params[1580]
            lv4622 = R.call_tir(cls.matmul27, (lv4620, lv2162), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2163: R.Tensor((2048, 1280), dtype="float32") = model_params[1581]
            lv4624 = R.call_tir(cls.matmul30, (inp_2, lv2163), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv2164: R.Tensor((2048, 1280), dtype="float32") = model_params[1582]
            lv4626 = R.call_tir(cls.matmul30, (inp_2, lv2164), out_sinfo=R.Tensor((2, 77, 1280), dtype="float32"))
            lv1648_1 = R.call_tir(cls.fused_reshape46_transpose35, (lv4622,), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1649_1 = R.call_tir(cls.fused_reshape48_transpose39_transpose40, (lv4624,), out_sinfo=R.Tensor((2, 20, 64, 77), dtype="float32"))
            lv1650_1 = R.call_tir(cls.fused_reshape48_transpose39, (lv4626,), out_sinfo=R.Tensor((2, 20, 77, 64), dtype="float32"))
            lv1651_2 = R.call_tir(cls.fused_matmul31_multiply16, (lv1648_1, lv1649_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4638 = R.call_tir(cls.softmax6, (lv1651_2,), out_sinfo=R.Tensor((2, 20, 1024, 77), dtype="float32"))
            lv4639 = R.call_tir(cls.matmul32, (lv4638, lv1650_1), out_sinfo=R.Tensor((2, 20, 1024, 64), dtype="float32"))
            lv1652_1 = R.call_tir(cls.fused_transpose37_reshape47, (lv4639,), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2165: R.Tensor((1280, 1280), dtype="float32") = model_params[1583]
            lv2166: R.Tensor((1280,), dtype="float32") = model_params[731]
            lv1653_2 = R.call_tir(cls.fused_matmul27_add43_divide11_add44, (lv1652_1, lv2165, lv2166, lv1647_1), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2167: R.Tensor((1280,), dtype="float32") = model_params[739]
            lv2168: R.Tensor((1280,), dtype="float32") = model_params[738]
            lv4647 = R.call_tir(cls.layer_norm3, (lv1653_2, lv2167, lv2168), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2169_1: R.Tensor((1280, 10240), dtype="float32") = model_params[1584]
            lv2170_1: R.Tensor((10240,), dtype="float32") = model_params[732]
            lv1654_1 = R.call_tir(cls.fused_matmul33_add45, (lv4647, lv2169_1, lv2170_1), out_sinfo=R.Tensor((2, 1024, 10240), dtype="float32"))
            lv1655_2 = R.call_tir(cls.fused_split1_gelu2_multiply17, (lv1654_1,), out_sinfo=R.Tensor((2, 1024, 5120), dtype="float32"))
            lv2171: R.Tensor((5120, 1280), dtype="float32") = model_params[1585]
            lv2172: R.Tensor((1280,), dtype="float32") = model_params[733]
            lv1656_1 = R.call_tir(cls.fused_matmul34_add43_add44, (lv1655_2, lv2171, lv2172, lv1653_2), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv2173: R.Tensor((1280, 1280), dtype="float32") = model_params[1586]
            lv2174: R.Tensor((1280,), dtype="float32") = model_params[639]
            lv1657_2 = R.call_tir(cls.fused_matmul27_add43, (lv1656_1, lv2173, lv2174), out_sinfo=R.Tensor((2, 1024, 1280), dtype="float32"))
            lv1658_1 = R.call_tir(cls.fused_reshape49_transpose42_add42_resize2d3, (lv1657_2, lv1504_1), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv2175: R.Tensor((1280, 1280, 3, 3), dtype="float32") = model_params[764]
            lv2176: R.Tensor((1, 1280, 1, 1), dtype="float32") = model_params[1587]
            lv1659_1 = R.call_tir(cls.fused_conv2d27_add46, (lv1658_1, lv2175, lv2176), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv4670 = R.call_tir(cls.concatenate9, (lv1659_1, lv694), out_sinfo=R.Tensor((2, 1920, 64, 64), dtype="float32"))
            lv2177: R.Tensor((1920,), dtype="float32") = model_params[841]
            lv2178_1: R.Tensor((1920,), dtype="float32") = model_params[840]
            lv1660_1 = R.call_tir(cls.fused_group_norm16_silu14, (lv4670, lv2177, lv2178_1), out_sinfo=R.Tensor((2, 1920, 64, 64), dtype="float32"))
            lv4676 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2179: R.Tensor((1280, 640), dtype="float32") = model_params[1589]
            lv2180: R.Tensor((640,), dtype="float32") = model_params[844]
            lv1661_1 = R.call_tir(cls.fused_matmul18_add33_strided_slice7, (lv4676, lv2179, lv2180), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv4681 = R.call_tir(cls.reshape37, (lv1661_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2181: R.Tensor((640, 1920, 3, 3), dtype="float32") = model_params[837]
            lv2182: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1588]
            lv1662_1 = R.call_tir(cls.fused_conv2d28_add32_add34, (lv1660_1, lv2181, lv2182, lv4681), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2183: R.Tensor((640,), dtype="float32") = model_params[843]
            lv2184: R.Tensor((640,), dtype="float32") = model_params[842]
            lv1663_1 = R.call_tir(cls.fused_group_norm9_silu9, (lv1662_1, lv2183, lv2184), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2185: R.Tensor((640, 1920, 1, 1), dtype="float32") = model_params[839]
            lv2186: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1591]
            lv1664_1 = R.call_tir(cls.fused_conv2d29_add32, (lv4670, lv2185, lv2186), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2187: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[838]
            lv2188: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1590]
            lv1665_1 = R.call_tir(cls.fused_conv2d17_add32_add35_divide8, (lv1663_1, lv2187, lv2188, lv1664_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2189: R.Tensor((640,), dtype="float32") = model_params[766]
            lv2190: R.Tensor((640,), dtype="float32") = model_params[765]
            lv4693 = R.call_tir(cls.group_norm10, (lv1665_1, lv2189, lv2190), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1666_1 = R.call_tir(cls.fused_transpose23_reshape38, (lv4693,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2191_1: R.Tensor((640, 640), dtype="float32") = model_params[1592]
            lv2192: R.Tensor((640,), dtype="float32") = model_params[767]
            lv1667_1 = R.call_tir(cls.fused_matmul19_add36, (lv1666_1, lv2191_1, lv2192), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2193_1: R.Tensor((640,), dtype="float32") = model_params[774]
            lv2194: R.Tensor((640,), dtype="float32") = model_params[773]
            lv4699 = R.call_tir(cls.layer_norm2, (lv1667_1, lv2193_1, lv2194), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2195_1: R.Tensor((640, 640), dtype="float32") = model_params[1593]
            lv4701 = R.call_tir(cls.matmul19, (lv4699, lv2195_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2196: R.Tensor((640, 640), dtype="float32") = model_params[1594]
            lv4703 = R.call_tir(cls.matmul19, (lv4699, lv2196), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2197_1: R.Tensor((640, 640), dtype="float32") = model_params[1595]
            lv4705 = R.call_tir(cls.matmul19, (lv4699, lv2197_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1668_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4701,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1669_2 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv4703,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1670_2 = R.call_tir(cls.fused_reshape39_transpose25, (lv4705,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1671_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1668_1, lv1669_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4717 = R.call_tir(cls.softmax3, (lv1671_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4718 = R.call_tir(cls.matmul21, (lv4717, lv1670_2), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1672_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv4718,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2198: R.Tensor((640, 640), dtype="float32") = model_params[1596]
            lv2199: R.Tensor((640,), dtype="float32") = model_params[769]
            lv1673_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1672_1, lv2198, lv2199, lv1667_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2200: R.Tensor((640,), dtype="float32") = model_params[776]
            lv2201: R.Tensor((640,), dtype="float32") = model_params[775]
            lv4726 = R.call_tir(cls.layer_norm2, (lv1673_1, lv2200, lv2201), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2202: R.Tensor((640, 640), dtype="float32") = model_params[1597]
            lv4728 = R.call_tir(cls.matmul19, (lv4726, lv2202), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2203: R.Tensor((2048, 640), dtype="float32") = model_params[1598]
            lv4730 = R.call_tir(cls.matmul22, (inp_2, lv2203), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2204: R.Tensor((2048, 640), dtype="float32") = model_params[1599]
            lv4732 = R.call_tir(cls.matmul22, (inp_2, lv2204), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1674_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4728,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1675_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv4730,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1676_1 = R.call_tir(cls.fused_reshape41_transpose29, (lv4732,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1677_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1674_1, lv1675_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4744 = R.call_tir(cls.softmax4, (lv1677_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4745 = R.call_tir(cls.matmul24, (lv4744, lv1676_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1678_2 = R.call_tir(cls.fused_transpose27_reshape40, (lv4745,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2205: R.Tensor((640, 640), dtype="float32") = model_params[1600]
            lv2206: R.Tensor((640,), dtype="float32") = model_params[770]
            lv1679_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1678_2, lv2205, lv2206, lv1673_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2207: R.Tensor((640,), dtype="float32") = model_params[778]
            lv2208: R.Tensor((640,), dtype="float32") = model_params[777]
            lv4753 = R.call_tir(cls.layer_norm2, (lv1679_1, lv2207, lv2208), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2209_1: R.Tensor((640, 5120), dtype="float32") = model_params[1601]
            lv2210_1: R.Tensor((5120,), dtype="float32") = model_params[771]
            lv1680_1 = R.call_tir(cls.fused_matmul25_add38, (lv4753, lv2209_1, lv2210_1), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1681_1 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1680_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2211: R.Tensor((2560, 640), dtype="float32") = model_params[1602]
            lv2212: R.Tensor((640,), dtype="float32") = model_params[772]
            lv1682_1 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1681_1, lv2211, lv2212, lv1679_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2213: R.Tensor((640,), dtype="float32") = model_params[784]
            lv2214: R.Tensor((640,), dtype="float32") = model_params[783]
            lv4766 = R.call_tir(cls.layer_norm2, (lv1682_1, lv2213, lv2214), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2215: R.Tensor((640, 640), dtype="float32") = model_params[1603]
            lv4768 = R.call_tir(cls.matmul19, (lv4766, lv2215), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2216: R.Tensor((640, 640), dtype="float32") = model_params[1604]
            lv4770 = R.call_tir(cls.matmul19, (lv4766, lv2216), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2217: R.Tensor((640, 640), dtype="float32") = model_params[1605]
            lv4772 = R.call_tir(cls.matmul19, (lv4766, lv2217), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1683_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4768,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1684_1 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv4770,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1685_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4772,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1686_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1683_1, lv1684_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4784 = R.call_tir(cls.softmax3, (lv1686_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4785 = R.call_tir(cls.matmul21, (lv4784, lv1685_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1687_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv4785,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2218_1: R.Tensor((640, 640), dtype="float32") = model_params[1606]
            lv2219: R.Tensor((640,), dtype="float32") = model_params[779]
            lv1688_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1687_1, lv2218_1, lv2219, lv1682_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2220_1: R.Tensor((640,), dtype="float32") = model_params[786]
            lv2221: R.Tensor((640,), dtype="float32") = model_params[785]
            lv4793 = R.call_tir(cls.layer_norm2, (lv1688_1, lv2220_1, lv2221), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2222_1: R.Tensor((640, 640), dtype="float32") = model_params[1607]
            lv4795 = R.call_tir(cls.matmul19, (lv4793, lv2222_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2223: R.Tensor((2048, 640), dtype="float32") = model_params[1608]
            lv4797 = R.call_tir(cls.matmul22, (inp_2, lv2223), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2224_1: R.Tensor((2048, 640), dtype="float32") = model_params[1609]
            lv4799 = R.call_tir(cls.matmul22, (inp_2, lv2224_1), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1689_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4795,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1690_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv4797,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1691_2 = R.call_tir(cls.fused_reshape41_transpose29, (lv4799,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1692_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1689_1, lv1690_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4811 = R.call_tir(cls.softmax4, (lv1692_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4812 = R.call_tir(cls.matmul24, (lv4811, lv1691_2), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1693_2 = R.call_tir(cls.fused_transpose27_reshape40, (lv4812,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2225: R.Tensor((640, 640), dtype="float32") = model_params[1610]
            lv2226: R.Tensor((640,), dtype="float32") = model_params[780]
            lv1694_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1693_2, lv2225, lv2226, lv1688_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2227: R.Tensor((640,), dtype="float32") = model_params[788]
            lv2228: R.Tensor((640,), dtype="float32") = model_params[787]
            lv4820 = R.call_tir(cls.layer_norm2, (lv1694_1, lv2227, lv2228), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2229: R.Tensor((640, 5120), dtype="float32") = model_params[1611]
            lv2230: R.Tensor((5120,), dtype="float32") = model_params[781]
            lv1695_2 = R.call_tir(cls.fused_matmul25_add38, (lv4820, lv2229, lv2230), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1696_1 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1695_2,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2231: R.Tensor((2560, 640), dtype="float32") = model_params[1612]
            lv2232: R.Tensor((640,), dtype="float32") = model_params[782]
            lv1697_2 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1696_1, lv2231, lv2232, lv1694_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2233: R.Tensor((640, 640), dtype="float32") = model_params[1613]
            lv2234: R.Tensor((640,), dtype="float32") = model_params[768]
            lv1698_1 = R.call_tir(cls.fused_matmul19_add36, (lv1697_2, lv2233, lv2234), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1699_1 = R.call_tir(cls.fused_reshape42_transpose33_add35_concatenate10, (lv1698_1, lv1665_1, lv655), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv2235: R.Tensor((1280,), dtype="float32") = model_params[849]
            lv2236_1: R.Tensor((1280,), dtype="float32") = model_params[848]
            lv1700_1 = R.call_tir(cls.fused_group_norm17_silu15, (lv1699_1, lv2235, lv2236_1), out_sinfo=R.Tensor((2, 1280, 64, 64), dtype="float32"))
            lv4845 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2237_1: R.Tensor((1280, 640), dtype="float32") = model_params[1615]
            lv2238: R.Tensor((640,), dtype="float32") = model_params[852]
            lv1701_1 = R.call_tir(cls.fused_matmul18_add33_strided_slice7, (lv4845, lv2237_1, lv2238), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv4850 = R.call_tir(cls.reshape37, (lv1701_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2239: R.Tensor((640, 1280, 3, 3), dtype="float32") = model_params[845]
            lv2240: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1614]
            lv1702_1 = R.call_tir(cls.fused_conv2d30_add32_add34, (lv1700_1, lv2239, lv2240, lv4850), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2241: R.Tensor((640,), dtype="float32") = model_params[851]
            lv2242: R.Tensor((640,), dtype="float32") = model_params[850]
            lv1703_1 = R.call_tir(cls.fused_group_norm9_silu9, (lv1702_1, lv2241, lv2242), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2243: R.Tensor((640, 1280, 1, 1), dtype="float32") = model_params[847]
            lv2244: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1617]
            lv1704_1 = R.call_tir(cls.fused_conv2d31_add32, (lv1699_1, lv2243, lv2244), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2245_1: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[846]
            lv2246: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1616]
            lv1705_1 = R.call_tir(cls.fused_conv2d17_add32_add35_divide8, (lv1703_1, lv2245_1, lv2246, lv1704_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2247: R.Tensor((640,), dtype="float32") = model_params[790]
            lv2248: R.Tensor((640,), dtype="float32") = model_params[789]
            lv4862 = R.call_tir(cls.group_norm10, (lv1705_1, lv2247, lv2248), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1706_1 = R.call_tir(cls.fused_transpose23_reshape38, (lv4862,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2249: R.Tensor((640, 640), dtype="float32") = model_params[1618]
            lv2250: R.Tensor((640,), dtype="float32") = model_params[791]
            lv1707_1 = R.call_tir(cls.fused_matmul19_add36, (lv1706_1, lv2249, lv2250), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2251: R.Tensor((640,), dtype="float32") = model_params[798]
            lv2252: R.Tensor((640,), dtype="float32") = model_params[797]
            lv4868 = R.call_tir(cls.layer_norm2, (lv1707_1, lv2251, lv2252), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2253: R.Tensor((640, 640), dtype="float32") = model_params[1619]
            lv4870 = R.call_tir(cls.matmul19, (lv4868, lv2253), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2254: R.Tensor((640, 640), dtype="float32") = model_params[1620]
            lv4872 = R.call_tir(cls.matmul19, (lv4868, lv2254), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2255: R.Tensor((640, 640), dtype="float32") = model_params[1621]
            lv4874 = R.call_tir(cls.matmul19, (lv4868, lv2255), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1708_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4870,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1709_2 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv4872,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1710_2 = R.call_tir(cls.fused_reshape39_transpose25, (lv4874,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1711_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1708_1, lv1709_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4886 = R.call_tir(cls.softmax3, (lv1711_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4887 = R.call_tir(cls.matmul21, (lv4886, lv1710_2), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1712_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv4887,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2256: R.Tensor((640, 640), dtype="float32") = model_params[1622]
            lv2257: R.Tensor((640,), dtype="float32") = model_params[793]
            lv1713_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1712_1, lv2256, lv2257, lv1707_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2258_1: R.Tensor((640,), dtype="float32") = model_params[800]
            lv2259: R.Tensor((640,), dtype="float32") = model_params[799]
            lv4895 = R.call_tir(cls.layer_norm2, (lv1713_1, lv2258_1, lv2259), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2260_1: R.Tensor((640, 640), dtype="float32") = model_params[1623]
            lv4897 = R.call_tir(cls.matmul19, (lv4895, lv2260_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2261: R.Tensor((2048, 640), dtype="float32") = model_params[1624]
            lv4899 = R.call_tir(cls.matmul22, (inp_2, lv2261), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2262_1: R.Tensor((2048, 640), dtype="float32") = model_params[1625]
            lv4901 = R.call_tir(cls.matmul22, (inp_2, lv2262_1), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1714_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4897,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1715_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv4899,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1716_1 = R.call_tir(cls.fused_reshape41_transpose29, (lv4901,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1717_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1714_1, lv1715_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4913 = R.call_tir(cls.softmax4, (lv1717_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4914 = R.call_tir(cls.matmul24, (lv4913, lv1716_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1718_2 = R.call_tir(cls.fused_transpose27_reshape40, (lv4914,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2263: R.Tensor((640, 640), dtype="float32") = model_params[1626]
            lv2264_1: R.Tensor((640,), dtype="float32") = model_params[794]
            lv1719_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1718_2, lv2263, lv2264_1, lv1713_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2265: R.Tensor((640,), dtype="float32") = model_params[802]
            lv2266: R.Tensor((640,), dtype="float32") = model_params[801]
            lv4922 = R.call_tir(cls.layer_norm2, (lv1719_1, lv2265, lv2266), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2267: R.Tensor((640, 5120), dtype="float32") = model_params[1627]
            lv2268: R.Tensor((5120,), dtype="float32") = model_params[795]
            lv1720_2 = R.call_tir(cls.fused_matmul25_add38, (lv4922, lv2267, lv2268), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1721_1 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1720_2,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2269: R.Tensor((2560, 640), dtype="float32") = model_params[1628]
            lv2270: R.Tensor((640,), dtype="float32") = model_params[796]
            lv1722_2 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1721_1, lv2269, lv2270, lv1719_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2271: R.Tensor((640,), dtype="float32") = model_params[808]
            lv2272: R.Tensor((640,), dtype="float32") = model_params[807]
            lv4935 = R.call_tir(cls.layer_norm2, (lv1722_2, lv2271, lv2272), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2273: R.Tensor((640, 640), dtype="float32") = model_params[1629]
            lv4937 = R.call_tir(cls.matmul19, (lv4935, lv2273), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2274: R.Tensor((640, 640), dtype="float32") = model_params[1630]
            lv4939 = R.call_tir(cls.matmul19, (lv4935, lv2274), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2275: R.Tensor((640, 640), dtype="float32") = model_params[1631]
            lv4941 = R.call_tir(cls.matmul19, (lv4935, lv2275), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1723_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4937,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1724_2 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv4939,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1725_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4941,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1726_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1723_1, lv1724_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4953 = R.call_tir(cls.softmax3, (lv1726_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv4954 = R.call_tir(cls.matmul21, (lv4953, lv1725_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1727_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv4954,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2276_1: R.Tensor((640, 640), dtype="float32") = model_params[1632]
            lv2277_1: R.Tensor((640,), dtype="float32") = model_params[803]
            lv1728_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1727_1, lv2276_1, lv2277_1, lv1722_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2278: R.Tensor((640,), dtype="float32") = model_params[810]
            lv2279: R.Tensor((640,), dtype="float32") = model_params[809]
            lv4962 = R.call_tir(cls.layer_norm2, (lv1728_1, lv2278, lv2279), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2280: R.Tensor((640, 640), dtype="float32") = model_params[1633]
            lv4964 = R.call_tir(cls.matmul19, (lv4962, lv2280), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2281: R.Tensor((2048, 640), dtype="float32") = model_params[1634]
            lv4966 = R.call_tir(cls.matmul22, (inp_2, lv2281), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2282: R.Tensor((2048, 640), dtype="float32") = model_params[1635]
            lv4968 = R.call_tir(cls.matmul22, (inp_2, lv2282), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1729_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv4964,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1730_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv4966,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1731_1 = R.call_tir(cls.fused_reshape41_transpose29, (lv4968,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1732_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1729_1, lv1730_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4980 = R.call_tir(cls.softmax4, (lv1732_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv4981 = R.call_tir(cls.matmul24, (lv4980, lv1731_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1733_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv4981,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2283: R.Tensor((640, 640), dtype="float32") = model_params[1636]
            lv2284: R.Tensor((640,), dtype="float32") = model_params[804]
            lv1734_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1733_1, lv2283, lv2284, lv1728_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2285_1: R.Tensor((640,), dtype="float32") = model_params[812]
            lv2286: R.Tensor((640,), dtype="float32") = model_params[811]
            lv4989 = R.call_tir(cls.layer_norm2, (lv1734_1, lv2285_1, lv2286), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2287_1: R.Tensor((640, 5120), dtype="float32") = model_params[1637]
            lv2288: R.Tensor((5120,), dtype="float32") = model_params[805]
            lv1735_1 = R.call_tir(cls.fused_matmul25_add38, (lv4989, lv2287_1, lv2288), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1736_2 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1735_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2289_1: R.Tensor((2560, 640), dtype="float32") = model_params[1638]
            lv2290: R.Tensor((640,), dtype="float32") = model_params[806]
            lv1737_2 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1736_2, lv2289_1, lv2290, lv1734_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2291_1: R.Tensor((640, 640), dtype="float32") = model_params[1639]
            lv2292: R.Tensor((640,), dtype="float32") = model_params[792]
            lv1738_1 = R.call_tir(cls.fused_matmul19_add36, (lv1737_2, lv2291_1, lv2292), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1739_1 = R.call_tir(cls.fused_reshape42_transpose33_add35_concatenate11, (lv1738_1, lv1705_1, lv615), out_sinfo=R.Tensor((2, 960, 64, 64), dtype="float32"))
            lv2293: R.Tensor((960,), dtype="float32") = model_params[857]
            lv2294: R.Tensor((960,), dtype="float32") = model_params[856]
            lv1740_1 = R.call_tir(cls.fused_group_norm18_silu16, (lv1739_1, lv2293, lv2294), out_sinfo=R.Tensor((2, 960, 64, 64), dtype="float32"))
            lv5014 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2295: R.Tensor((1280, 640), dtype="float32") = model_params[1641]
            lv2296: R.Tensor((640,), dtype="float32") = model_params[860]
            lv1741_1 = R.call_tir(cls.fused_matmul18_add33_strided_slice7, (lv5014, lv2295, lv2296), out_sinfo=R.Tensor((2, 640), dtype="float32"))
            lv5019 = R.call_tir(cls.reshape37, (lv1741_1,), out_sinfo=R.Tensor((2, 640, 1, 1), dtype="float32"))
            lv2297: R.Tensor((640, 960, 3, 3), dtype="float32") = model_params[853]
            lv2298: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1640]
            lv1742_1 = R.call_tir(cls.fused_conv2d32_add32_add34, (lv1740_1, lv2297, lv2298, lv5019), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2299: R.Tensor((640,), dtype="float32") = model_params[859]
            lv2300: R.Tensor((640,), dtype="float32") = model_params[858]
            lv1743_1 = R.call_tir(cls.fused_group_norm9_silu9, (lv1742_1, lv2299, lv2300), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2301: R.Tensor((640, 960, 1, 1), dtype="float32") = model_params[855]
            lv2302: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1643]
            lv1744_1 = R.call_tir(cls.fused_conv2d33_add32, (lv1739_1, lv2301, lv2302), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2303_1: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[854]
            lv2304_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1642]
            lv1745_2 = R.call_tir(cls.fused_conv2d17_add32_add35_divide8, (lv1743_1, lv2303_1, lv2304_1, lv1744_1), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv2305: R.Tensor((640,), dtype="float32") = model_params[814]
            lv2306: R.Tensor((640,), dtype="float32") = model_params[813]
            lv5031 = R.call_tir(cls.group_norm10, (lv1745_2, lv2305, lv2306), out_sinfo=R.Tensor((2, 640, 64, 64), dtype="float32"))
            lv1746_1 = R.call_tir(cls.fused_transpose23_reshape38, (lv5031,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2307: R.Tensor((640, 640), dtype="float32") = model_params[1644]
            lv2308: R.Tensor((640,), dtype="float32") = model_params[815]
            lv1747_1 = R.call_tir(cls.fused_matmul19_add36, (lv1746_1, lv2307, lv2308), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2309: R.Tensor((640,), dtype="float32") = model_params[822]
            lv2310: R.Tensor((640,), dtype="float32") = model_params[821]
            lv5037 = R.call_tir(cls.layer_norm2, (lv1747_1, lv2309, lv2310), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2311: R.Tensor((640, 640), dtype="float32") = model_params[1645]
            lv5039 = R.call_tir(cls.matmul19, (lv5037, lv2311), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2312_1: R.Tensor((640, 640), dtype="float32") = model_params[1646]
            lv5041 = R.call_tir(cls.matmul19, (lv5037, lv2312_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2313: R.Tensor((640, 640), dtype="float32") = model_params[1647]
            lv5043 = R.call_tir(cls.matmul19, (lv5037, lv2313), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1748_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5039,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1749_1 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv5041,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1750_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5043,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1751_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1748_1, lv1749_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5055 = R.call_tir(cls.softmax3, (lv1751_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5056 = R.call_tir(cls.matmul21, (lv5055, lv1750_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1752_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv5056,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2314: R.Tensor((640, 640), dtype="float32") = model_params[1648]
            lv2315: R.Tensor((640,), dtype="float32") = model_params[817]
            lv1753_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1752_1, lv2314, lv2315, lv1747_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2316: R.Tensor((640,), dtype="float32") = model_params[824]
            lv2317: R.Tensor((640,), dtype="float32") = model_params[823]
            lv5064 = R.call_tir(cls.layer_norm2, (lv1753_1, lv2316, lv2317), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2318: R.Tensor((640, 640), dtype="float32") = model_params[1649]
            lv5066 = R.call_tir(cls.matmul19, (lv5064, lv2318), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2319: R.Tensor((2048, 640), dtype="float32") = model_params[1650]
            lv5068 = R.call_tir(cls.matmul22, (inp_2, lv2319), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2320: R.Tensor((2048, 640), dtype="float32") = model_params[1651]
            lv5070 = R.call_tir(cls.matmul22, (inp_2, lv2320), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1754_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5066,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1755_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv5068,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1756_1 = R.call_tir(cls.fused_reshape41_transpose29, (lv5070,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1757_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1754_1, lv1755_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5082 = R.call_tir(cls.softmax4, (lv1757_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5083 = R.call_tir(cls.matmul24, (lv5082, lv1756_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1758_2 = R.call_tir(cls.fused_transpose27_reshape40, (lv5083,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2321: R.Tensor((640, 640), dtype="float32") = model_params[1652]
            lv2322: R.Tensor((640,), dtype="float32") = model_params[818]
            lv1759_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1758_2, lv2321, lv2322, lv1753_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2323: R.Tensor((640,), dtype="float32") = model_params[826]
            lv2324: R.Tensor((640,), dtype="float32") = model_params[825]
            lv5091 = R.call_tir(cls.layer_norm2, (lv1759_1, lv2323, lv2324), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2325_1: R.Tensor((640, 5120), dtype="float32") = model_params[1653]
            lv2326: R.Tensor((5120,), dtype="float32") = model_params[819]
            lv1760_2 = R.call_tir(cls.fused_matmul25_add38, (lv5091, lv2325_1, lv2326), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1761_1 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1760_2,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2327_1: R.Tensor((2560, 640), dtype="float32") = model_params[1654]
            lv2328: R.Tensor((640,), dtype="float32") = model_params[820]
            lv1762_2 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1761_1, lv2327_1, lv2328, lv1759_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2329_1: R.Tensor((640,), dtype="float32") = model_params[832]
            lv2330: R.Tensor((640,), dtype="float32") = model_params[831]
            lv5104 = R.call_tir(cls.layer_norm2, (lv1762_2, lv2329_1, lv2330), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2331_1: R.Tensor((640, 640), dtype="float32") = model_params[1655]
            lv5106 = R.call_tir(cls.matmul19, (lv5104, lv2331_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2332: R.Tensor((640, 640), dtype="float32") = model_params[1656]
            lv5108 = R.call_tir(cls.matmul19, (lv5104, lv2332), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2333: R.Tensor((640, 640), dtype="float32") = model_params[1657]
            lv5110 = R.call_tir(cls.matmul19, (lv5104, lv2333), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1763_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5106,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1764_2 = R.call_tir(cls.fused_reshape39_transpose25_transpose26, (lv5108,), out_sinfo=R.Tensor((2, 10, 64, 4096), dtype="float32"))
            lv1765_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5110,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1766_1 = R.call_tir(cls.fused_matmul20_multiply12, (lv1763_1, lv1764_2, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5122 = R.call_tir(cls.softmax3, (lv1766_1,), out_sinfo=R.Tensor((2, 10, 4096, 4096), dtype="float32"))
            lv5123 = R.call_tir(cls.matmul21, (lv5122, lv1765_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1767_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv5123,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2334: R.Tensor((640, 640), dtype="float32") = model_params[1658]
            lv2335: R.Tensor((640,), dtype="float32") = model_params[827]
            lv1768_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1767_1, lv2334, lv2335, lv1762_2), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2336: R.Tensor((640,), dtype="float32") = model_params[834]
            lv2337: R.Tensor((640,), dtype="float32") = model_params[833]
            lv5131 = R.call_tir(cls.layer_norm2, (lv1768_1, lv2336, lv2337), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2338: R.Tensor((640, 640), dtype="float32") = model_params[1659]
            lv5133 = R.call_tir(cls.matmul19, (lv5131, lv2338), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2339: R.Tensor((2048, 640), dtype="float32") = model_params[1660]
            lv5135 = R.call_tir(cls.matmul22, (inp_2, lv2339), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv2340: R.Tensor((2048, 640), dtype="float32") = model_params[1661]
            lv5137 = R.call_tir(cls.matmul22, (inp_2, lv2340), out_sinfo=R.Tensor((2, 77, 640), dtype="float32"))
            lv1769_1 = R.call_tir(cls.fused_reshape39_transpose25, (lv5133,), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1770_1 = R.call_tir(cls.fused_reshape41_transpose29_transpose30, (lv5135,), out_sinfo=R.Tensor((2, 10, 64, 77), dtype="float32"))
            lv1771_1 = R.call_tir(cls.fused_reshape41_transpose29, (lv5137,), out_sinfo=R.Tensor((2, 10, 77, 64), dtype="float32"))
            lv1772_1 = R.call_tir(cls.fused_matmul23_multiply13, (lv1769_1, lv1770_1, R.const(0.125, "float32")), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5149 = R.call_tir(cls.softmax4, (lv1772_1,), out_sinfo=R.Tensor((2, 10, 4096, 77), dtype="float32"))
            lv5150 = R.call_tir(cls.matmul24, (lv5149, lv1771_1), out_sinfo=R.Tensor((2, 10, 4096, 64), dtype="float32"))
            lv1773_1 = R.call_tir(cls.fused_transpose27_reshape40, (lv5150,), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2341: R.Tensor((640, 640), dtype="float32") = model_params[1662]
            lv2342: R.Tensor((640,), dtype="float32") = model_params[828]
            lv1774_1 = R.call_tir(cls.fused_matmul19_add36_divide9_add37, (lv1773_1, lv2341, lv2342, lv1768_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2343_1: R.Tensor((640,), dtype="float32") = model_params[836]
            lv2344_1: R.Tensor((640,), dtype="float32") = model_params[835]
            lv5158 = R.call_tir(cls.layer_norm2, (lv1774_1, lv2343_1, lv2344_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2345: R.Tensor((640, 5120), dtype="float32") = model_params[1663]
            lv2346: R.Tensor((5120,), dtype="float32") = model_params[829]
            lv1775_1 = R.call_tir(cls.fused_matmul25_add38, (lv5158, lv2345, lv2346), out_sinfo=R.Tensor((2, 4096, 5120), dtype="float32"))
            lv1776_2 = R.call_tir(cls.fused_split_gelu1_multiply14, (lv1775_1,), out_sinfo=R.Tensor((2, 4096, 2560), dtype="float32"))
            lv2347: R.Tensor((2560, 640), dtype="float32") = model_params[1664]
            lv2348: R.Tensor((640,), dtype="float32") = model_params[830]
            lv1777_2 = R.call_tir(cls.fused_matmul26_add36_add37, (lv1776_2, lv2347, lv2348, lv1774_1), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv2349: R.Tensor((640, 640), dtype="float32") = model_params[1665]
            lv2350: R.Tensor((640,), dtype="float32") = model_params[816]
            lv1778_1 = R.call_tir(cls.fused_matmul19_add36, (lv1777_2, lv2349, lv2350), out_sinfo=R.Tensor((2, 4096, 640), dtype="float32"))
            lv1779_1 = R.call_tir(cls.fused_reshape42_transpose33_add35_resize2d4, (lv1778_1, lv1745_2), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2351: R.Tensor((640, 640, 3, 3), dtype="float32") = model_params[861]
            lv2352_1: R.Tensor((1, 640, 1, 1), dtype="float32") = model_params[1666]
            lv1780_1 = R.call_tir(cls.fused_conv2d34_add47, (lv1779_1, lv2351, lv2352_1), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5181 = R.call_tir(cls.concatenate12, (lv1780_1, lv614), out_sinfo=R.Tensor((2, 960, 128, 128), dtype="float32"))
            lv2353: R.Tensor((960,), dtype="float32") = model_params[866]
            lv2354_1: R.Tensor((960,), dtype="float32") = model_params[865]
            lv1781_1 = R.call_tir(cls.fused_group_norm19_silu17, (lv5181, lv2353, lv2354_1), out_sinfo=R.Tensor((2, 960, 128, 128), dtype="float32"))
            lv5187 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2355: R.Tensor((1280, 320), dtype="float32") = model_params[1668]
            lv2356_1: R.Tensor((320,), dtype="float32") = model_params[869]
            lv1782_1 = R.call_tir(cls.fused_matmul17_add28_cast4, (lv5187, lv2355, lv2356_1), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5192 = R.call_tir(cls.reshape35, (lv1782_1,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2357: R.Tensor((320, 960, 3, 3), dtype="float32") = model_params[862]
            lv2358_1: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1667]
            lv1783_1 = R.call_tir(cls.fused_conv2d35_add27_add29, (lv1781_1, lv2357, lv2358_1, lv5192), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2359: R.Tensor((320,), dtype="float32") = model_params[868]
            lv2360: R.Tensor((320,), dtype="float32") = model_params[867]
            lv1784_1 = R.call_tir(cls.fused_group_norm7_silu7, (lv1783_1, lv2359, lv2360), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2361: R.Tensor((320, 960, 1, 1), dtype="float32") = model_params[864]
            lv2362: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1670]
            lv1785_2 = R.call_tir(cls.fused_conv2d36_add27, (lv5181, lv2361, lv2362), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2363: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[863]
            lv2364: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1669]
            lv1786_1 = R.call_tir(cls.fused_conv2d14_add27_add30_divide7, (lv1784_1, lv2363, lv2364, lv1785_2), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv5204 = R.call_tir(cls.concatenate13, (lv1786_1, lv609), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2365: R.Tensor((640,), dtype="float32") = model_params[874]
            lv2366: R.Tensor((640,), dtype="float32") = model_params[873]
            lv1787_2 = R.call_tir(cls.fused_group_norm20_silu18, (lv5204, lv2365, lv2366), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5210 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2367: R.Tensor((1280, 320), dtype="float32") = model_params[1672]
            lv2368: R.Tensor((320,), dtype="float32") = model_params[877]
            lv1788_1 = R.call_tir(cls.fused_matmul17_add28_cast4, (lv5210, lv2367, lv2368), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5215 = R.call_tir(cls.reshape35, (lv1788_1,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2369: R.Tensor((320, 640, 3, 3), dtype="float32") = model_params[870]
            lv2370_1: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1671]
            lv1789_2 = R.call_tir(cls.fused_conv2d37_add27_add29, (lv1787_2, lv2369, lv2370_1, lv5215), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2371_1: R.Tensor((320,), dtype="float32") = model_params[876]
            lv2372: R.Tensor((320,), dtype="float32") = model_params[875]
            lv1790_1 = R.call_tir(cls.fused_group_norm7_silu7, (lv1789_2, lv2371_1, lv2372), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2373: R.Tensor((320, 640, 1, 1), dtype="float32") = model_params[872]
            lv2374: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1674]
            lv1791_2 = R.call_tir(cls.fused_conv2d38_add27, (lv5204, lv2373, lv2374), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2375: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[871]
            lv2376: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1673]
            lv1792_1 = R.call_tir(cls.fused_conv2d14_add27_add30_divide7, (lv1790_1, lv2375, lv2376, lv1791_2), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv5227 = R.call_tir(cls.concatenate13, (lv1792_1, lv604), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv2377: R.Tensor((640,), dtype="float32") = model_params[882]
            lv2378: R.Tensor((640,), dtype="float32") = model_params[881]
            lv1793_1 = R.call_tir(cls.fused_group_norm20_silu18, (lv5227, lv2377, lv2378), out_sinfo=R.Tensor((2, 640, 128, 128), dtype="float32"))
            lv5233 = R.call_tir(cls.silu6, (lv603,), out_sinfo=R.Tensor((2, 1280), dtype="float32"))
            lv2379_1: R.Tensor((1280, 320), dtype="float32") = model_params[1676]
            lv2380: R.Tensor((320,), dtype="float32") = model_params[885]
            lv1794_1 = R.call_tir(cls.fused_matmul17_add28_cast4, (lv5233, lv2379_1, lv2380), out_sinfo=R.Tensor((2, 320), dtype="float32"))
            lv5238 = R.call_tir(cls.reshape35, (lv1794_1,), out_sinfo=R.Tensor((2, 320, 1, 1), dtype="float32"))
            lv2381: R.Tensor((320, 640, 3, 3), dtype="float32") = model_params[878]
            lv2382: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1675]
            lv1795_1 = R.call_tir(cls.fused_conv2d37_add27_add29, (lv1793_1, lv2381, lv2382, lv5238), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2383: R.Tensor((320,), dtype="float32") = model_params[884]
            lv2384: R.Tensor((320,), dtype="float32") = model_params[883]
            lv1796_1 = R.call_tir(cls.fused_group_norm7_silu7, (lv1795_1, lv2383, lv2384), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2385: R.Tensor((320, 640, 1, 1), dtype="float32") = model_params[880]
            lv2386: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1678]
            lv1797_1 = R.call_tir(cls.fused_conv2d38_add27, (lv5227, lv2385, lv2386), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2387: R.Tensor((320, 320, 3, 3), dtype="float32") = model_params[879]
            lv2388: R.Tensor((1, 320, 1, 1), dtype="float32") = model_params[1677]
            lv1798_1 = R.call_tir(cls.fused_conv2d14_add27_add30_divide7, (lv1796_1, lv2387, lv2388, lv1797_1), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2389: R.Tensor((320,), dtype="float32") = model_params[4]
            lv2390: R.Tensor((320,), dtype="float32") = model_params[3]
            lv1799_1 = R.call_tir(cls.fused_group_norm7_silu7, (lv1798_1, lv2389, lv2390), out_sinfo=R.Tensor((2, 320, 128, 128), dtype="float32"))
            lv2391: R.Tensor((4, 320, 3, 3), dtype="float32") = model_params[5]
            lv2392_1: R.Tensor((1, 4, 1, 1), dtype="float32") = model_params[1679]
            lv1800_1 = R.call_tir(cls.fused_conv2d39_add48, (lv1799_1, lv2391, lv2392_1), out_sinfo=R.Tensor((2, 4, 128, 128), dtype="float32"))
            lv1801_1 = R.call_tir(cls.fused_split2_subtract1_multiply18_add20, (lv1800_1,), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            gv: R.Tensor((1, 4, 128, 128), dtype="float32") = lv1801_1
            R.output(gv)
        return gv

    @R.function
    def vae(inp_0: R.Tensor((1, 4, 128, 128), dtype="float32"), model_params: R.Tuple(R.Tensor((512, 4, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((3, 128, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512, 512, 3, 3), dtype="float32"), R.Tensor((256, 512, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 512, 1, 1), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((512,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256, 256, 3, 3), dtype="float32"), R.Tensor((128, 256, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 256, 1, 1), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((256,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128, 128, 3, 3), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((128,), dtype="float32"), R.Tensor((4, 4, 1, 1), dtype="float32"), R.Tensor((1, 4, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((512, 512), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 512, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 256, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 128, 1, 1), dtype="float32"), R.Tensor((1, 3, 1, 1), dtype="float32"))) -> R.Tensor((1, 1024, 1024, 3), dtype="float32"):
        R.func_attr({"global_symbol": "main", "num_input": 1})
        cls = Module
        with R.dataflow():
            lv = R.call_tir(cls.multiply, (inp_0,), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            lv2393: R.Tensor((4, 4, 1, 1), dtype="float32") = model_params[99]
            lv2394: R.Tensor((1, 4, 1, 1), dtype="float32") = model_params[100]
            lv387 = R.call_tir(cls.fused_conv2d_add, (lv, lv2393, lv2394), out_sinfo=R.Tensor((1, 4, 128, 128), dtype="float32"))
            lv2395: R.Tensor((512, 4, 3, 3), dtype="float32") = model_params[0]
            lv2396: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[101]
            lv388 = R.call_tir(cls.fused_conv2d1_add1, (lv387, lv2395, lv2396), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2397: R.Tensor((512,), dtype="float32") = model_params[13]
            lv2398: R.Tensor((512,), dtype="float32") = model_params[12]
            lv389 = R.call_tir(cls.fused_group_norm_silu, (lv388, lv2397, lv2398), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2399: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[10]
            lv2400: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[102]
            lv390 = R.call_tir(cls.fused_conv2d2_add1, (lv389, lv2399, lv2400), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2401: R.Tensor((512,), dtype="float32") = model_params[15]
            lv2402: R.Tensor((512,), dtype="float32") = model_params[14]
            lv391 = R.call_tir(cls.fused_group_norm_silu, (lv390, lv2401, lv2402), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2403: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[11]
            lv2404: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[103]
            lv392 = R.call_tir(cls.fused_conv2d2_add1_add2_divide, (lv391, lv2403, lv2404, lv388), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv393 = R.call_tir(cls.fused_reshape2_transpose_transpose1, (lv392,), out_sinfo=R.Tensor((1, 512, 16384), dtype="float32"))
            lv2405: R.Tensor((512,), dtype="float32") = model_params[5]
            lv2406: R.Tensor((512,), dtype="float32") = model_params[4]
            lv22 = R.call_tir(cls.group_norm1, (lv393, lv2405, lv2406), out_sinfo=R.Tensor((1, 512, 16384), dtype="float32"))
            lv23 = R.call_tir(cls.transpose, (lv22,), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2407: R.Tensor((512, 512), dtype="float32") = model_params[104]
            lv2408: R.Tensor((512,), dtype="float32") = model_params[8]
            lv394 = R.call_tir(cls.fused_matmul_add3, (lv23, lv2407, lv2408), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2409: R.Tensor((512, 512), dtype="float32") = model_params[105]
            lv2410: R.Tensor((512,), dtype="float32") = model_params[6]
            lv395 = R.call_tir(cls.fused_matmul_add3, (lv23, lv2409, lv2410), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2411: R.Tensor((512, 512), dtype="float32") = model_params[106]
            lv2412: R.Tensor((512,), dtype="float32") = model_params[9]
            lv396 = R.call_tir(cls.fused_matmul_add3, (lv23, lv2411, lv2412), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv397 = R.call_tir(cls.fused_reshape3_transpose3, (lv394,), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv398 = R.call_tir(cls.fused_reshape3_transpose3_transpose4, (lv395,), out_sinfo=R.Tensor((1, 1, 512, 16384), dtype="float32"))
            lv399 = R.call_tir(cls.fused_reshape3_transpose3, (lv396,), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv400 = R.call_tir(cls.fused_matmul1_multiply1, (lv397, lv398, R.const(0.044194173067808151, "float32")), out_sinfo=R.Tensor((1, 1, 16384, 16384), dtype="float32"))
            lv44 = R.call_tir(cls.softmax, (lv400,), out_sinfo=R.Tensor((1, 1, 16384, 16384), dtype="float32"))
            lv45 = R.call_tir(cls.matmul2, (lv44, lv399), out_sinfo=R.Tensor((1, 1, 16384, 512), dtype="float32"))
            lv401 = R.call_tir(cls.fused_transpose5_reshape4, (lv45,), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv2413: R.Tensor((512, 512), dtype="float32") = model_params[107]
            lv2414: R.Tensor((512,), dtype="float32") = model_params[7]
            lv402 = R.call_tir(cls.fused_matmul_add3, (lv401, lv2413, lv2414), out_sinfo=R.Tensor((1, 16384, 512), dtype="float32"))
            lv403 = R.call_tir(cls.fused_transpose1_reshape5_add2_divide, (lv402, lv392), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2415: R.Tensor((512,), dtype="float32") = model_params[19]
            lv2416: R.Tensor((512,), dtype="float32") = model_params[18]
            lv404 = R.call_tir(cls.fused_group_norm_silu, (lv403, lv2415, lv2416), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2417: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[16]
            lv2418: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[108]
            lv405 = R.call_tir(cls.fused_conv2d2_add1, (lv404, lv2417, lv2418), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2419: R.Tensor((512,), dtype="float32") = model_params[21]
            lv2420: R.Tensor((512,), dtype="float32") = model_params[20]
            lv406 = R.call_tir(cls.fused_group_norm_silu, (lv405, lv2419, lv2420), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2421: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[17]
            lv2422: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[109]
            lv407 = R.call_tir(cls.fused_conv2d2_add1_add2_divide_divide, (lv406, lv2421, lv2422, lv403), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2423: R.Tensor((512,), dtype="float32") = model_params[25]
            lv2424: R.Tensor((512,), dtype="float32") = model_params[24]
            lv408 = R.call_tir(cls.fused_group_norm_silu, (lv407, lv2423, lv2424), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2425: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[22]
            lv2426: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[110]
            lv409 = R.call_tir(cls.fused_conv2d2_add1, (lv408, lv2425, lv2426), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2427: R.Tensor((512,), dtype="float32") = model_params[27]
            lv2428: R.Tensor((512,), dtype="float32") = model_params[26]
            lv410 = R.call_tir(cls.fused_group_norm_silu, (lv409, lv2427, lv2428), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2429: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[23]
            lv2430: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[111]
            lv411 = R.call_tir(cls.fused_conv2d2_add1_add2_divide, (lv410, lv2429, lv2430, lv407), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2431: R.Tensor((512,), dtype="float32") = model_params[31]
            lv2432: R.Tensor((512,), dtype="float32") = model_params[30]
            lv412 = R.call_tir(cls.fused_group_norm_silu, (lv411, lv2431, lv2432), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2433: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[28]
            lv2434: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[112]
            lv413 = R.call_tir(cls.fused_conv2d2_add1, (lv412, lv2433, lv2434), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2435: R.Tensor((512,), dtype="float32") = model_params[33]
            lv2436: R.Tensor((512,), dtype="float32") = model_params[32]
            lv414 = R.call_tir(cls.fused_group_norm_silu, (lv413, lv2435, lv2436), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2437: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[29]
            lv2438: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[113]
            lv415 = R.call_tir(cls.fused_conv2d2_add1_add2_divide, (lv414, lv2437, lv2438, lv411), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2439: R.Tensor((512,), dtype="float32") = model_params[37]
            lv2440: R.Tensor((512,), dtype="float32") = model_params[36]
            lv416 = R.call_tir(cls.fused_group_norm_silu, (lv415, lv2439, lv2440), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2441: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[34]
            lv2442: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[114]
            lv417 = R.call_tir(cls.fused_conv2d2_add1, (lv416, lv2441, lv2442), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2443: R.Tensor((512,), dtype="float32") = model_params[39]
            lv2444: R.Tensor((512,), dtype="float32") = model_params[38]
            lv418 = R.call_tir(cls.fused_group_norm_silu, (lv417, lv2443, lv2444), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv2445: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[35]
            lv2446: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[115]
            lv419 = R.call_tir(cls.fused_conv2d2_add1_add2_divide, (lv418, lv2445, lv2446, lv415), out_sinfo=R.Tensor((1, 512, 128, 128), dtype="float32"))
            lv104 = R.call_tir(cls.resize2d, (lv419,), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2447: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[40]
            lv2448: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[116]
            lv420 = R.call_tir(cls.fused_conv2d3_add4, (lv104, lv2447, lv2448), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2449: R.Tensor((512,), dtype="float32") = model_params[44]
            lv2450: R.Tensor((512,), dtype="float32") = model_params[43]
            lv421 = R.call_tir(cls.fused_group_norm2_silu1, (lv420, lv2449, lv2450), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2451: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[41]
            lv2452: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[117]
            lv422 = R.call_tir(cls.fused_conv2d3_add4, (lv421, lv2451, lv2452), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2453: R.Tensor((512,), dtype="float32") = model_params[46]
            lv2454: R.Tensor((512,), dtype="float32") = model_params[45]
            lv423 = R.call_tir(cls.fused_group_norm2_silu1, (lv422, lv2453, lv2454), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2455: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[42]
            lv2456: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[118]
            lv424 = R.call_tir(cls.fused_conv2d3_add4_add5_divide2, (lv423, lv2455, lv2456, lv420), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2457: R.Tensor((512,), dtype="float32") = model_params[50]
            lv2458: R.Tensor((512,), dtype="float32") = model_params[49]
            lv425 = R.call_tir(cls.fused_group_norm2_silu1, (lv424, lv2457, lv2458), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2459: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[47]
            lv2460: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[119]
            lv426 = R.call_tir(cls.fused_conv2d3_add4, (lv425, lv2459, lv2460), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2461: R.Tensor((512,), dtype="float32") = model_params[52]
            lv2462: R.Tensor((512,), dtype="float32") = model_params[51]
            lv427 = R.call_tir(cls.fused_group_norm2_silu1, (lv426, lv2461, lv2462), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2463: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[48]
            lv2464: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[120]
            lv428 = R.call_tir(cls.fused_conv2d3_add4_add5_divide2, (lv427, lv2463, lv2464, lv424), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2465: R.Tensor((512,), dtype="float32") = model_params[56]
            lv2466: R.Tensor((512,), dtype="float32") = model_params[55]
            lv429 = R.call_tir(cls.fused_group_norm2_silu1, (lv428, lv2465, lv2466), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2467: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[53]
            lv2468: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[121]
            lv430 = R.call_tir(cls.fused_conv2d3_add4, (lv429, lv2467, lv2468), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2469: R.Tensor((512,), dtype="float32") = model_params[58]
            lv2470: R.Tensor((512,), dtype="float32") = model_params[57]
            lv431 = R.call_tir(cls.fused_group_norm2_silu1, (lv430, lv2469, lv2470), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv2471: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[54]
            lv2472: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[122]
            lv432 = R.call_tir(cls.fused_conv2d3_add4_add5_divide2, (lv431, lv2471, lv2472, lv428), out_sinfo=R.Tensor((1, 512, 256, 256), dtype="float32"))
            lv144 = R.call_tir(cls.resize2d1, (lv432,), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv2473: R.Tensor((512, 512, 3, 3), dtype="float32") = model_params[59]
            lv2474: R.Tensor((1, 512, 1, 1), dtype="float32") = model_params[123]
            lv433 = R.call_tir(cls.fused_conv2d4_add6, (lv144, lv2473, lv2474), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv2475: R.Tensor((512,), dtype="float32") = model_params[64]
            lv2476: R.Tensor((512,), dtype="float32") = model_params[63]
            lv434 = R.call_tir(cls.fused_group_norm3_silu2, (lv433, lv2475, lv2476), out_sinfo=R.Tensor((1, 512, 512, 512), dtype="float32"))
            lv2477: R.Tensor((256, 512, 3, 3), dtype="float32") = model_params[60]
            lv2478: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[124]
            lv435 = R.call_tir(cls.fused_conv2d5_add7, (lv434, lv2477, lv2478), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2479: R.Tensor((256,), dtype="float32") = model_params[66]
            lv2480: R.Tensor((256,), dtype="float32") = model_params[65]
            lv436 = R.call_tir(cls.fused_group_norm4_silu3, (lv435, lv2479, lv2480), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2481: R.Tensor((256, 512, 1, 1), dtype="float32") = model_params[62]
            lv2482: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[126]
            lv437 = R.call_tir(cls.fused_conv2d7_add7, (lv433, lv2481, lv2482), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2483: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[61]
            lv2484: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[125]
            lv438 = R.call_tir(cls.fused_conv2d6_add7_add8_divide3, (lv436, lv2483, lv2484, lv437), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2485: R.Tensor((256,), dtype="float32") = model_params[70]
            lv2486: R.Tensor((256,), dtype="float32") = model_params[69]
            lv439 = R.call_tir(cls.fused_group_norm4_silu3, (lv438, lv2485, lv2486), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2487: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[67]
            lv2488: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[127]
            lv440 = R.call_tir(cls.fused_conv2d6_add7, (lv439, lv2487, lv2488), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2489: R.Tensor((256,), dtype="float32") = model_params[72]
            lv2490: R.Tensor((256,), dtype="float32") = model_params[71]
            lv441 = R.call_tir(cls.fused_group_norm4_silu3, (lv440, lv2489, lv2490), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2491: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[68]
            lv2492: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[128]
            lv442 = R.call_tir(cls.fused_conv2d6_add7_add8_divide3, (lv441, lv2491, lv2492, lv438), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2493: R.Tensor((256,), dtype="float32") = model_params[76]
            lv2494: R.Tensor((256,), dtype="float32") = model_params[75]
            lv443 = R.call_tir(cls.fused_group_norm4_silu3, (lv442, lv2493, lv2494), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2495: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[73]
            lv2496: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[129]
            lv444 = R.call_tir(cls.fused_conv2d6_add7, (lv443, lv2495, lv2496), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2497: R.Tensor((256,), dtype="float32") = model_params[78]
            lv2498: R.Tensor((256,), dtype="float32") = model_params[77]
            lv445 = R.call_tir(cls.fused_group_norm4_silu3, (lv444, lv2497, lv2498), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv2499: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[74]
            lv2500: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[130]
            lv446 = R.call_tir(cls.fused_conv2d6_add7_add8_divide3, (lv445, lv2499, lv2500, lv442), out_sinfo=R.Tensor((1, 256, 512, 512), dtype="float32"))
            lv187 = R.call_tir(cls.resize2d2, (lv446,), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv2501: R.Tensor((256, 256, 3, 3), dtype="float32") = model_params[79]
            lv2502: R.Tensor((1, 256, 1, 1), dtype="float32") = model_params[131]
            lv447 = R.call_tir(cls.fused_conv2d8_add9, (lv187, lv2501, lv2502), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv2503: R.Tensor((256,), dtype="float32") = model_params[84]
            lv2504: R.Tensor((256,), dtype="float32") = model_params[83]
            lv448 = R.call_tir(cls.fused_group_norm5_silu4, (lv447, lv2503, lv2504), out_sinfo=R.Tensor((1, 256, 1024, 1024), dtype="float32"))
            lv2505: R.Tensor((128, 256, 3, 3), dtype="float32") = model_params[80]
            lv2506: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[132]
            lv449 = R.call_tir(cls.fused_conv2d9_add10, (lv448, lv2505, lv2506), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2507: R.Tensor((128,), dtype="float32") = model_params[86]
            lv2508: R.Tensor((128,), dtype="float32") = model_params[85]
            lv450 = R.call_tir(cls.fused_group_norm6_silu5, (lv449, lv2507, lv2508), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2509: R.Tensor((128, 256, 1, 1), dtype="float32") = model_params[82]
            lv2510: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[134]
            lv451 = R.call_tir(cls.fused_conv2d11_add10, (lv447, lv2509, lv2510), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2511: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[81]
            lv2512: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[133]
            lv452 = R.call_tir(cls.fused_conv2d10_add10_add11_divide4, (lv450, lv2511, lv2512, lv451), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2513: R.Tensor((128,), dtype="float32") = model_params[90]
            lv2514: R.Tensor((128,), dtype="float32") = model_params[89]
            lv453 = R.call_tir(cls.fused_group_norm6_silu5, (lv452, lv2513, lv2514), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2515: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[87]
            lv2516: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[135]
            lv454 = R.call_tir(cls.fused_conv2d10_add10, (lv453, lv2515, lv2516), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2517: R.Tensor((128,), dtype="float32") = model_params[92]
            lv2518: R.Tensor((128,), dtype="float32") = model_params[91]
            lv455 = R.call_tir(cls.fused_group_norm6_silu5, (lv454, lv2517, lv2518), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2519: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[88]
            lv2520: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[136]
            lv456 = R.call_tir(cls.fused_conv2d10_add10_add11_divide4, (lv455, lv2519, lv2520, lv452), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2521: R.Tensor((128,), dtype="float32") = model_params[96]
            lv2522: R.Tensor((128,), dtype="float32") = model_params[95]
            lv457 = R.call_tir(cls.fused_group_norm6_silu5, (lv456, lv2521, lv2522), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2523: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[93]
            lv2524: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[137]
            lv458 = R.call_tir(cls.fused_conv2d10_add10, (lv457, lv2523, lv2524), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2525: R.Tensor((128,), dtype="float32") = model_params[98]
            lv2526: R.Tensor((128,), dtype="float32") = model_params[97]
            lv459 = R.call_tir(cls.fused_group_norm6_silu5, (lv458, lv2525, lv2526), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2527: R.Tensor((128, 128, 3, 3), dtype="float32") = model_params[94]
            lv2528: R.Tensor((1, 128, 1, 1), dtype="float32") = model_params[138]
            lv460 = R.call_tir(cls.fused_conv2d10_add10_add11_divide4, (lv459, lv2527, lv2528, lv456), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2529: R.Tensor((128,), dtype="float32") = model_params[2]
            lv2530: R.Tensor((128,), dtype="float32") = model_params[1]
            lv461 = R.call_tir(cls.fused_group_norm6_silu5, (lv460, lv2529, lv2530), out_sinfo=R.Tensor((1, 128, 1024, 1024), dtype="float32"))
            lv2531: R.Tensor((3, 128, 3, 3), dtype="float32") = model_params[3]
            lv2532: R.Tensor((1, 3, 1, 1), dtype="float32") = model_params[139]
            lv462 = R.call_tir(cls.fused_conv2d12_add12_divide5_add13_tir_clip, (lv461, lv2531, lv2532), out_sinfo=R.Tensor((1, 3, 1024, 1024), dtype="float32"))
            lv463 = R.call_tir(cls.fused_transpose6_multiply2_tir_round, (lv462,), out_sinfo=R.Tensor((1, 1024, 1024, 3), dtype="float32"))
            gv: R.Tensor((1, 1024, 1024, 3), dtype="float32") = lv463
            R.output(gv)
        return gv
